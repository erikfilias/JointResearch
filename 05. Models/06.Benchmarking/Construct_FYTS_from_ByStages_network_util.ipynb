{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461a7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6f5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder_A = 'A.The_full_year_MILP'\n",
    "Folder_B = 'B.Operation_cost'\n",
    "Folder_D = 'D.Representative_days_based_on_RES_and_Demand'\n",
    "Folder_E = 'E.Representative_days_based_on_Line_Benefits_OptModel'\n",
    "Folder_K = 'K.Investments_per_hour'\n",
    "Folder_L = 'L.Cont_Investments_per_hour'\n",
    "\n",
    "category_dict = { \"FYMILP\": Folder_A,\n",
    "                 \"OPC\":Folder_B,\n",
    "                 \"R&D\": Folder_D ,\n",
    "                 \"OPT_LB\": Folder_E,\n",
    "                 \"HI\": Folder_K,\n",
    "                  \"CHI\": Folder_L,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab75105",
   "metadata": {},
   "source": [
    "## Utilization per node Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e905dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_utilization_fyts_frame(CaseName_Base,cm,nbc):\n",
    "    destination_folder = f\"Y.FYTS_from_ByStages/{CaseName_Base}/{cm}\"\n",
    "\n",
    "    filename = f\"NetworkUtilization_nc{nbc}.csv\"\n",
    "\n",
    "\n",
    "    # Read input data\n",
    "    df_duration = pd.read_csv(f\"{folder_name}/{CaseName_Base}_ByStages_nc{nbc}/2.Par/oT_Data_Duration_{CaseName_Base}_ByStages_nc{nbc}.csv\")\n",
    "    df_ts_bs = pd.read_csv(f\"{folder_name}/{CaseName_Base}_ByStages_nc{nbc}/4.OutWoInv/oT_Result_NetworkUtilizationPerNode_DC_{CaseName_Base}_ByStages_nc{nbc}.csv\")\n",
    "\n",
    "    # Ensure data types are consistent: convert load levels to strings\n",
    "    df_duration[\"LoadLevel\"] = df_duration[\"LoadLevel\"].astype(str)\n",
    "    df_ts_bs[\"LoadLevel\"] = df_ts_bs[\"LoadLevel\"].astype(str)\n",
    "    df_ts_bs[\"InitialNode\"] = df_ts_bs[\"InitialNode\"].astype(str)\n",
    "    df_ts_bs[\"FinalNode\"] = df_ts_bs[\"FinalNode\"].astype(str)\n",
    "\n",
    "    #Filter out line candidates\n",
    "    df_ts_bs =df_ts_bs[df_ts_bs[\"Circuit\"] == \"eac1\"]\n",
    "\n",
    "    # Create mapping of load level to stage name\n",
    "    load_level_stage_map = df_duration.set_index(\"LoadLevel\")[\"Stage\"].to_dict()\n",
    "    all_load_levels = df_duration.LoadLevel\n",
    "\n",
    "    #Create dataframe that that wil hold all timeseries\n",
    "    frame_values = pd.DataFrame({\"LoadLevel\":all_load_levels})\n",
    "    \n",
    "    #Get unique node pairs connected by an existing line \n",
    "    unique_node_pairs = [tuple(x) for x in df_ts_bs[['InitialNode', 'FinalNode']].drop_duplicates().values.tolist()]\n",
    "\n",
    "    # Create a MultiIndex from the unique node pairs\n",
    "    multi_index = pd.MultiIndex.from_tuples(unique_node_pairs, names=['InitialNode', 'FinalNode'])\n",
    "\n",
    "    # Initialize a DataFrame to hold all time series with MultiIndex\n",
    "    frame_values = pd.DataFrame(index=all_load_levels, columns=multi_index)\n",
    "\n",
    "    #Select one node pair\n",
    "    node_pair = unique_node_pairs[0]\n",
    "\n",
    "    for node_pair in unique_node_pairs:\n",
    "        print(node_pair)\n",
    "\n",
    "        initial_node, final_node = node_pair\n",
    "\n",
    "        # Initialize the full-year time series array\n",
    "        fy_ts = np.zeros(len(all_load_levels))\n",
    "        for i, load_level in enumerate(all_load_levels):\n",
    "            this_loadlevel_stage = load_level_stage_map[load_level]\n",
    "\n",
    "            # Filter to find the correct reduced load level\n",
    "            filtered_duration = df_duration[(df_duration[\"Stage\"] == this_loadlevel_stage) & (df_duration[\"Duration\"] == 1)]\n",
    "\n",
    "            if not filtered_duration.empty:\n",
    "                reduced_temp_load_level = filtered_duration.LoadLevel.iloc[0]\n",
    "\n",
    "                # Find the corresponding value in df_ts_bs\n",
    "                reduced_temp_value = df_ts_bs[(df_ts_bs[\"InitialNode\"] == node_pair[0]) &(df_ts_bs[\"FinalNode\"] == node_pair[1]) & (df_ts_bs[\"LoadLevel\"] == str(reduced_temp_load_level))]\n",
    "\n",
    "                if not reduced_temp_value.empty:\n",
    "                    # Assuming you want to assign a value from reduced_temp_value to fy_ts\n",
    "                    # You might need to aggregate if there are multiple values\n",
    "                    fy_ts[i] = reduced_temp_value['GWh'].iloc[0]\n",
    "        frame_values[(initial_node,final_node)] = fy_ts\n",
    "    return frame_values,destination_folder,filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757b5a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N_120', 'N_123')\n",
      "('N_113', 'N_123')\n",
      "('N_119', 'N_120')\n",
      "('N_108', 'N_110')\n",
      "('N_112', 'N_123')\n",
      "('N_104', 'N_109')\n",
      "('N_112', 'N_113')\n",
      "('N_121', 'N_122')\n",
      "('N_108', 'N_109')\n",
      "('N_114', 'N_116')\n",
      "('N_101', 'N_103')\n",
      "('N_117', 'N_118')\n",
      "('N_107', 'N_108')\n",
      "('N_111', 'N_114')\n",
      "('N_116', 'N_117')\n",
      "('N_105', 'N_110')\n",
      "('N_103', 'N_124')\n",
      "('N_109', 'N_111')\n",
      "('N_117', 'N_122')\n",
      "('N_102', 'N_106')\n",
      "('N_103', 'N_109')\n",
      "('N_118', 'N_121')\n",
      "('N_111', 'N_113')\n",
      "('N_109', 'N_112')\n",
      "('N_110', 'N_111')\n",
      "('N_110', 'N_112')\n",
      "('N_101', 'N_105')\n",
      "('N_115', 'N_116')\n",
      "('N_101', 'N_102')\n",
      "('N_102', 'N_104')\n",
      "('N_106', 'N_110')\n",
      "('N_115', 'N_124')\n",
      "('N_115', 'N_121')\n",
      "('N_116', 'N_119')\n",
      "('N_112', 'N_113')\n",
      "('N_115', 'N_124')\n",
      "('N_110', 'N_112')\n",
      "('N_103', 'N_109')\n",
      "('N_113', 'N_123')\n",
      "('N_106', 'N_110')\n",
      "('N_120', 'N_123')\n",
      "('N_104', 'N_109')\n",
      "('N_118', 'N_121')\n",
      "('N_111', 'N_113')\n",
      "('N_119', 'N_120')\n",
      "('N_105', 'N_110')\n",
      "('N_101', 'N_105')\n",
      "('N_107', 'N_108')\n",
      "('N_110', 'N_111')\n",
      "('N_116', 'N_119')\n",
      "('N_114', 'N_116')\n",
      "('N_117', 'N_122')\n",
      "('N_101', 'N_102')\n",
      "('N_109', 'N_111')\n",
      "('N_103', 'N_124')\n",
      "('N_101', 'N_103')\n",
      "('N_116', 'N_117')\n",
      "('N_115', 'N_121')\n",
      "('N_108', 'N_109')\n",
      "('N_117', 'N_118')\n",
      "('N_111', 'N_114')\n",
      "('N_115', 'N_116')\n",
      "('N_121', 'N_122')\n",
      "('N_108', 'N_110')\n",
      "('N_102', 'N_106')\n",
      "('N_102', 'N_104')\n",
      "('N_112', 'N_123')\n",
      "('N_109', 'N_112')\n",
      "('N_110', 'N_112')\n",
      "('N_103', 'N_109')\n",
      "('N_101', 'N_105')\n",
      "('N_106', 'N_110')\n",
      "('N_103', 'N_124')\n",
      "('N_110', 'N_111')\n",
      "('N_116', 'N_117')\n",
      "('N_112', 'N_113')\n",
      "('N_114', 'N_116')\n",
      "('N_119', 'N_120')\n",
      "('N_105', 'N_110')\n",
      "('N_101', 'N_102')\n",
      "('N_107', 'N_108')\n",
      "('N_111', 'N_113')\n",
      "('N_117', 'N_122')\n",
      "('N_117', 'N_118')\n",
      "('N_120', 'N_123')\n",
      "('N_115', 'N_124')\n",
      "('N_108', 'N_109')\n",
      "('N_109', 'N_112')\n",
      "('N_115', 'N_116')\n",
      "('N_113', 'N_123')\n",
      "('N_109', 'N_111')\n",
      "('N_118', 'N_121')\n",
      "('N_116', 'N_119')\n",
      "('N_115', 'N_121')\n",
      "('N_108', 'N_110')\n",
      "('N_102', 'N_104')\n",
      "('N_111', 'N_114')\n",
      "('N_121', 'N_122')\n",
      "('N_101', 'N_103')\n",
      "('N_102', 'N_106')\n",
      "('N_104', 'N_109')\n",
      "('N_112', 'N_123')\n",
      "('N_103', 'N_124')\n",
      "('N_117', 'N_118')\n",
      "('N_120', 'N_123')\n",
      "('N_107', 'N_108')\n",
      "('N_112', 'N_123')\n",
      "('N_112', 'N_113')\n",
      "('N_106', 'N_110')\n",
      "('N_109', 'N_112')\n",
      "('N_115', 'N_121')\n",
      "('N_110', 'N_112')\n",
      "('N_115', 'N_116')\n",
      "('N_105', 'N_110')\n",
      "('N_121', 'N_122')\n",
      "('N_103', 'N_109')\n",
      "('N_102', 'N_106')\n",
      "('N_101', 'N_102')\n",
      "('N_116', 'N_119')\n",
      "('N_101', 'N_105')\n",
      "('N_115', 'N_124')\n",
      "('N_109', 'N_111')\n",
      "('N_117', 'N_122')\n",
      "('N_108', 'N_110')\n",
      "('N_102', 'N_104')\n",
      "('N_110', 'N_111')\n",
      "('N_114', 'N_116')\n",
      "('N_119', 'N_120')\n",
      "('N_104', 'N_109')\n",
      "('N_113', 'N_123')\n",
      "('N_111', 'N_113')\n",
      "('N_111', 'N_114')\n",
      "('N_108', 'N_109')\n",
      "('N_118', 'N_121')\n",
      "('N_101', 'N_103')\n",
      "('N_116', 'N_117')\n",
      "('N_113', 'N_123')\n",
      "('N_110', 'N_111')\n",
      "('N_115', 'N_121')\n",
      "('N_104', 'N_109')\n",
      "('N_115', 'N_116')\n",
      "('N_117', 'N_122')\n",
      "('N_101', 'N_102')\n",
      "('N_112', 'N_123')\n",
      "('N_116', 'N_119')\n",
      "('N_105', 'N_110')\n",
      "('N_109', 'N_111')\n",
      "('N_117', 'N_118')\n",
      "('N_103', 'N_124')\n",
      "('N_106', 'N_110')\n",
      "('N_112', 'N_113')\n",
      "('N_110', 'N_112')\n",
      "('N_121', 'N_122')\n",
      "('N_103', 'N_109')\n",
      "('N_120', 'N_123')\n",
      "('N_107', 'N_108')\n",
      "('N_111', 'N_113')\n",
      "('N_108', 'N_110')\n",
      "('N_116', 'N_117')\n",
      "('N_102', 'N_106')\n",
      "('N_119', 'N_120')\n",
      "('N_115', 'N_124')\n",
      "('N_109', 'N_112')\n",
      "('N_108', 'N_109')\n",
      "('N_111', 'N_114')\n",
      "('N_101', 'N_105')\n",
      "('N_118', 'N_121')\n",
      "('N_114', 'N_116')\n",
      "('N_102', 'N_104')\n",
      "('N_101', 'N_103')\n"
     ]
    }
   ],
   "source": [
    "#Define case \n",
    "CaseName_Base = 'RTS24_mod1'\n",
    "\n",
    "\n",
    "cm = \"CHI\"\n",
    "folder_name = category_dict[cm]\n",
    "\n",
    "nbcs = [10,20,50,100,200]\n",
    "\n",
    "for nbc in nbcs:\n",
    "    frame_values,destination_folder,filename = create_utilization_fyts_frame(CaseName_Base,cm,nbc)\n",
    "    # Check if the destination folder exists, if not, create it\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    #And write dataframe to destination\n",
    "    frame_values.to_csv(os.path.join(destination_folder,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c00eb7",
   "metadata": {},
   "source": [
    "## Flow per node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flow_fyts_frame(CaseName_Base,cm,nbc):\n",
    "    destination_folder = f\"Y.FYTS_from_ByStages/{CaseName_Base}/{cm}\"\n",
    "\n",
    "    filename = f\"Flow_per_node_nc{nbc}.csv\"\n",
    "\n",
    "\n",
    "    # Read input data\n",
    "    df_duration = pd.read_csv(f\"{folder_name}/{CaseName_Base}_ByStages_nc{nbc}/2.Par/oT_Data_Duration_{CaseName_Base}_ByStages_nc{nbc}.csv\")\n",
    "    df_ts_bs = pd.read_csv(f\"{folder_name}/{CaseName_Base}_ByStages_nc{nbc}/4.OutWoInv/oT_Result_NetworkFlowPerNode_{CaseName_Base}_ByStages_nc{nbc}.csv\")\n",
    "\n",
    "    # Ensure data types are consistent: convert load levels to strings\n",
    "    df_duration[\"LoadLevel\"] = df_duration[\"LoadLevel\"].astype(str)\n",
    "    df_ts_bs[\"LoadLevel\"] = df_ts_bs[\"LoadLevel\"].astype(str)\n",
    "    df_ts_bs[\"InitialNode\"] = df_ts_bs[\"InitialNode\"].astype(str)\n",
    "    df_ts_bs[\"FinalNode\"] = df_ts_bs[\"FinalNode\"].astype(str)\n",
    "\n",
    "    #Filter out line candidates\n",
    "    df_ts_bs =df_ts_bs[df_ts_bs[\"Circuit\"] == \"eac1\"]\n",
    "\n",
    "    # Create mapping of load level to stage name\n",
    "    load_level_stage_map = df_duration.set_index(\"LoadLevel\")[\"Stage\"].to_dict()\n",
    "    all_load_levels = df_duration.LoadLevel\n",
    "\n",
    "    #Create dataframe that that wil hold all timeseries\n",
    "    frame_values = pd.DataFrame({\"LoadLevel\":all_load_levels})\n",
    "    \n",
    "    #Get unique node pairs connected by an existing line \n",
    "    unique_node_pairs = [tuple(x) for x in df_ts_bs[['InitialNode', 'FinalNode']].drop_duplicates().values.tolist()]\n",
    "\n",
    "    # Create a MultiIndex from the unique node pairs\n",
    "    multi_index = pd.MultiIndex.from_tuples(unique_node_pairs, names=['InitialNode', 'FinalNode'])\n",
    "\n",
    "    # Initialize a DataFrame to hold all time series with MultiIndex\n",
    "    frame_values = pd.DataFrame(index=all_load_levels, columns=multi_index)\n",
    "\n",
    "    #Select one node pair\n",
    "    node_pair = unique_node_pairs[0]\n",
    "\n",
    "    for node_pair in unique_node_pairs:\n",
    "        print(node_pair)\n",
    "\n",
    "        initial_node, final_node = node_pair\n",
    "\n",
    "        # Initialize the full-year time series array\n",
    "        fy_ts = np.zeros(len(all_load_levels))\n",
    "        for i, load_level in enumerate(all_load_levels[:20]):\n",
    "            this_loadlevel_stage = load_level_stage_map[load_level]\n",
    "\n",
    "            # Filter to find the correct reduced load level\n",
    "            filtered_duration = df_duration[(df_duration[\"Stage\"] == this_loadlevel_stage) & (df_duration[\"Duration\"] == 1)]\n",
    "\n",
    "            if not filtered_duration.empty:\n",
    "                reduced_temp_load_level = filtered_duration.LoadLevel.iloc[0]\n",
    "\n",
    "                # Find the corresponding value in df_ts_bs\n",
    "                reduced_temp_value = df_ts_bs[(df_ts_bs[\"InitialNode\"] == node_pair[0]) &(df_ts_bs[\"FinalNode\"] == node_pair[1]) & (df_ts_bs[\"LoadLevel\"] == str(reduced_temp_load_level))]\n",
    "\n",
    "                if not reduced_temp_value.empty:\n",
    "                    # Assuming you want to assign a value from reduced_temp_value to fy_ts\n",
    "                    # You might need to aggregate if there are multiple values\n",
    "                    fy_ts[i] = reduced_temp_value['GWh'].iloc[0]\n",
    "        frame_values[(initial_node,final_node)] = fy_ts\n",
    "    return frame_values,destination_folder,filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2efff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define case \n",
    "CaseName_Base = 'RTS24_mod1'\n",
    "\n",
    "\n",
    "cm = \"CHI\"\n",
    "folder_name = category_dict[cm]\n",
    "\n",
    "nbcs = [10,20,50,100,200]\n",
    "\n",
    "for nbc in nbcs:\n",
    "    frame_values,destination_folder,filename = create_flow_fyts_frame(CaseName_Base,cm,nbc)\n",
    "    # Check if the destination folder exists, if not, create it\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    #And write dataframe to destination\n",
    "    frame_values.to_csv(os.path.join(destination_folder,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33def4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f1f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a6417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78726e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CaseName_Base = 'RTS24_mod1'\n",
    "\n",
    "cm = \"R&D\"\n",
    "folder_name = category_dict[cm]\n",
    "\n",
    "nbc=20\n",
    "\n",
    "destination_folder = f\"Y.FYTS_from_ByStages/{CaseName_Base}/{cm}\"\n",
    "\n",
    "filename = f\"NetworkUtilization_nc{nbc}.csv\"\n",
    "\n",
    "\n",
    "# Read input data\n",
    "df_duration = pd.read_csv(f\"{folder_name}/{CaseName_Base}_ByStages_nc{nbc}/2.Par/oT_Data_Duration_{CaseName_Base}_ByStages_nc{nbc}.csv\")\n",
    "df_ts_bs = pd.read_csv(f\"{folder_name}/{CaseName_Base}_ByStages_nc{nbc}/4.OutWoInv/oT_Result_NetworkUtilizationPerNode_DC_{CaseName_Base}_ByStages_nc{nbc}.csv\")\n",
    "\n",
    "# Ensure data types are consistent: convert load levels to strings\n",
    "df_duration[\"LoadLevel\"] = df_duration[\"LoadLevel\"].astype(str)\n",
    "df_ts_bs[\"LoadLevel\"] = df_ts_bs[\"LoadLevel\"].astype(str)\n",
    "df_ts_bs[\"InitialNode\"] = df_ts_bs[\"InitialNode\"].astype(str)\n",
    "df_ts_bs[\"FinalNode\"] = df_ts_bs[\"FinalNode\"].astype(str)\n",
    "\n",
    "#Filter out line candidates\n",
    "#df_ts_bs =df_ts_bs[df_ts_bs[\"Circuit\"] == \"eac1\"]\n",
    "\n",
    "# Create mapping of load level to stage name\n",
    "load_level_stage_map = df_duration.set_index(\"LoadLevel\")[\"Stage\"].to_dict()\n",
    "all_load_levels = df_duration.LoadLevel\n",
    "\n",
    "#Create dataframe that that wil hold all timeseries\n",
    "frame_values = pd.DataFrame({\"LoadLevel\":all_load_levels})\n",
    "\n",
    "# Select a unit\n",
    "#units = np.unique(df_ts_bs.Unit)\n",
    "\n",
    "# for unit in units:\n",
    "\n",
    "#     # Initialize the full-year time series array\n",
    "#     fy_ts = np.zeros(len(all_load_levels))\n",
    "\n",
    "#     # Create full-year time series based on mapping and values of representative load levels\n",
    "#     for i, load_level in enumerate(all_load_levels):\n",
    "#         this_loadlevel_stage = load_level_stage_map[load_level]\n",
    "\n",
    "#         # Filter to find the correct reduced load level\n",
    "#         filtered_duration = df_duration[(df_duration[\"Stage\"] == this_loadlevel_stage) & (df_duration[\"Duration\"] == 1)]\n",
    "\n",
    "#         if not filtered_duration.empty:\n",
    "#             reduced_temp_load_level = filtered_duration.LoadLevel.iloc[0]\n",
    "\n",
    "#             # Find the corresponding value in df_ts_bs\n",
    "#             reduced_temp_value = df_ts_bs[(df_ts_bs[\"Unit\"] == unit) & (df_ts_bs[\"LoadLevel\"] == str(reduced_temp_load_level))]\n",
    "\n",
    "#             if not reduced_temp_value.empty:\n",
    "#                 # Assuming you want to assign a value from reduced_temp_value to fy_ts\n",
    "#                 # You might need to aggregate if there are multiple values\n",
    "#                 fy_ts[i] = reduced_temp_value['MW'].iloc[0]  # Replace 'YourValueColumn' with the actual column name\n",
    "#     frame_values[unit] = fy_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N_117', 'N_122')\n",
      "('N_102', 'N_104')\n",
      "('N_102', 'N_106')\n",
      "('N_105', 'N_110')\n",
      "('N_101', 'N_102')\n",
      "('N_104', 'N_109')\n",
      "('N_118', 'N_121')\n",
      "('N_115', 'N_116')\n",
      "('N_112', 'N_123')\n",
      "('N_107', 'N_108')\n",
      "('N_103', 'N_124')\n",
      "('N_120', 'N_123')\n",
      "('N_111', 'N_114')\n",
      "('N_106', 'N_108')\n",
      "('N_103', 'N_109')\n",
      "('N_112', 'N_113')\n",
      "('N_115', 'N_124')\n",
      "('N_114', 'N_116')\n",
      "('N_109', 'N_111')\n",
      "('N_113', 'N_123')\n",
      "('N_101', 'N_105')\n"
     ]
    }
   ],
   "source": [
    "#Get unique node pairs connected by an existing line \n",
    "unique_node_pairs = [tuple(x) for x in df_ts_bs[['InitialNode', 'FinalNode']].drop_duplicates().values.tolist()]\n",
    "\n",
    "# Create a MultiIndex from the unique node pairs\n",
    "multi_index = pd.MultiIndex.from_tuples(unique_node_pairs, names=['InitialNode', 'FinalNode'])\n",
    "\n",
    "# Initialize a DataFrame to hold all time series with MultiIndex\n",
    "frame_values = pd.DataFrame(index=all_load_levels, columns=multi_index)\n",
    "\n",
    "#Select one node pair\n",
    "node_pair = unique_node_pairs[0]\n",
    "\n",
    "for node_pair in unique_node_pairs:\n",
    "    print(node_pair)\n",
    "\n",
    "    initial_node, final_node = node_pair\n",
    "\n",
    "    # Initialize the full-year time series array\n",
    "    fy_ts = np.zeros(len(all_load_levels))\n",
    "    for i, load_level in enumerate(all_load_levels):\n",
    "        this_loadlevel_stage = load_level_stage_map[load_level]\n",
    "\n",
    "        # Filter to find the correct reduced load level\n",
    "        filtered_duration = df_duration[(df_duration[\"Stage\"] == this_loadlevel_stage) & (df_duration[\"Duration\"] == 1)]\n",
    "\n",
    "        if not filtered_duration.empty:\n",
    "            reduced_temp_load_level = filtered_duration.LoadLevel.iloc[0]\n",
    "\n",
    "            # Find the corresponding value in df_ts_bs\n",
    "            reduced_temp_value = df_ts_bs[(df_ts_bs[\"InitialNode\"] == node_pair[0]) &(df_ts_bs[\"FinalNode\"] == node_pair[1]) & (df_ts_bs[\"LoadLevel\"] == str(reduced_temp_load_level))]\n",
    "\n",
    "            if not reduced_temp_value.empty:\n",
    "                # Assuming you want to assign a value from reduced_temp_value to fy_ts\n",
    "                # You might need to aggregate if there are multiple values\n",
    "                fy_ts[i] = reduced_temp_value['GWh'].iloc[0]  # Replace 'YourValueColumn' with the actual column name\n",
    "    frame_values[(initial_node,final_node)] = fy_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de97f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>InitialNode</th>\n",
       "      <th>N_117</th>\n",
       "      <th colspan=\"2\" halign=\"left\">N_102</th>\n",
       "      <th>N_105</th>\n",
       "      <th>N_101</th>\n",
       "      <th>N_104</th>\n",
       "      <th>N_118</th>\n",
       "      <th>N_115</th>\n",
       "      <th>N_112</th>\n",
       "      <th>N_107</th>\n",
       "      <th>...</th>\n",
       "      <th>N_110</th>\n",
       "      <th>N_119</th>\n",
       "      <th>N_121</th>\n",
       "      <th>N_101</th>\n",
       "      <th>N_106</th>\n",
       "      <th colspan=\"2\" halign=\"left\">N_108</th>\n",
       "      <th>N_110</th>\n",
       "      <th>N_116</th>\n",
       "      <th>N_115</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalNode</th>\n",
       "      <th>N_122</th>\n",
       "      <th>N_104</th>\n",
       "      <th>N_106</th>\n",
       "      <th>N_110</th>\n",
       "      <th>N_102</th>\n",
       "      <th>N_109</th>\n",
       "      <th>N_121</th>\n",
       "      <th>N_116</th>\n",
       "      <th>N_123</th>\n",
       "      <th>N_108</th>\n",
       "      <th>...</th>\n",
       "      <th>N_112</th>\n",
       "      <th>N_120</th>\n",
       "      <th>N_122</th>\n",
       "      <th>N_103</th>\n",
       "      <th>N_110</th>\n",
       "      <th>N_109</th>\n",
       "      <th>N_110</th>\n",
       "      <th>N_111</th>\n",
       "      <th>N_119</th>\n",
       "      <th>N_121</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoadLevel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01 00:00:00+01:00</th>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.276988</td>\n",
       "      <td>0.235467</td>\n",
       "      <td>0.66507</td>\n",
       "      <td>0.487303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08008</td>\n",
       "      <td>0.178455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.19354</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.097851</td>\n",
       "      <td>0.581913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 01:00:00+01:00</th>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.276988</td>\n",
       "      <td>0.235467</td>\n",
       "      <td>0.66507</td>\n",
       "      <td>0.487303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08008</td>\n",
       "      <td>0.178455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.19354</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.097851</td>\n",
       "      <td>0.581913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 02:00:00+01:00</th>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.276988</td>\n",
       "      <td>0.235467</td>\n",
       "      <td>0.66507</td>\n",
       "      <td>0.487303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08008</td>\n",
       "      <td>0.178455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.19354</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.097851</td>\n",
       "      <td>0.581913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 03:00:00+01:00</th>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.276988</td>\n",
       "      <td>0.235467</td>\n",
       "      <td>0.66507</td>\n",
       "      <td>0.487303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08008</td>\n",
       "      <td>0.178455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.19354</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.097851</td>\n",
       "      <td>0.581913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 04:00:00+01:00</th>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.276988</td>\n",
       "      <td>0.235467</td>\n",
       "      <td>0.66507</td>\n",
       "      <td>0.487303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08008</td>\n",
       "      <td>0.178455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.19354</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.097851</td>\n",
       "      <td>0.581913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-30 19:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-30 20:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-30 21:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-30 22:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-30 23:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8736 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "InitialNode              N_117     N_102               N_105    N_101   \n",
       "FinalNode                N_122     N_104     N_106     N_110    N_102   \n",
       "LoadLevel                                                               \n",
       "01-01 00:00:00+01:00  0.002298  0.012218  0.276988  0.235467  0.66507  \\\n",
       "01-01 01:00:00+01:00  0.002298  0.012218  0.276988  0.235467  0.66507   \n",
       "01-01 02:00:00+01:00  0.002298  0.012218  0.276988  0.235467  0.66507   \n",
       "01-01 03:00:00+01:00  0.002298  0.012218  0.276988  0.235467  0.66507   \n",
       "01-01 04:00:00+01:00  0.002298  0.012218  0.276988  0.235467  0.66507   \n",
       "...                        ...       ...       ...       ...      ...   \n",
       "12-30 19:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "12-30 20:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "12-30 21:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "12-30 22:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "12-30 23:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "\n",
       "InitialNode              N_104 N_118 N_115    N_112     N_107  ...     N_110   \n",
       "FinalNode                N_109 N_121 N_116    N_123     N_108  ...     N_112   \n",
       "LoadLevel                                                      ...             \n",
       "01-01 00:00:00+01:00  0.487303   0.0   0.0  0.08008  0.178455  ...  0.109616  \\\n",
       "01-01 01:00:00+01:00  0.487303   0.0   0.0  0.08008  0.178455  ...  0.109616   \n",
       "01-01 02:00:00+01:00  0.487303   0.0   0.0  0.08008  0.178455  ...  0.109616   \n",
       "01-01 03:00:00+01:00  0.487303   0.0   0.0  0.08008  0.178455  ...  0.109616   \n",
       "01-01 04:00:00+01:00  0.487303   0.0   0.0  0.08008  0.178455  ...  0.109616   \n",
       "...                        ...   ...   ...      ...       ...  ...       ...   \n",
       "12-30 19:00:00+01:00  0.000000   0.0   0.0  0.00000  0.000000  ...  0.000000   \n",
       "12-30 20:00:00+01:00  0.000000   0.0   0.0  0.00000  0.000000  ...  0.000000   \n",
       "12-30 21:00:00+01:00  0.000000   0.0   0.0  0.00000  0.000000  ...  0.000000   \n",
       "12-30 22:00:00+01:00  0.000000   0.0   0.0  0.00000  0.000000  ...  0.000000   \n",
       "12-30 23:00:00+01:00  0.000000   0.0   0.0  0.00000  0.000000  ...  0.000000   \n",
       "\n",
       "InitialNode              N_119     N_121     N_101     N_106     N_108   \n",
       "FinalNode                N_120     N_122     N_103     N_110     N_109   \n",
       "LoadLevel                                                                \n",
       "01-01 00:00:00+01:00  0.051525  0.002298  0.146579  0.079294  0.248013  \\\n",
       "01-01 01:00:00+01:00  0.051525  0.002298  0.146579  0.079294  0.248013   \n",
       "01-01 02:00:00+01:00  0.051525  0.002298  0.146579  0.079294  0.248013   \n",
       "01-01 03:00:00+01:00  0.051525  0.002298  0.146579  0.079294  0.248013   \n",
       "01-01 04:00:00+01:00  0.051525  0.002298  0.146579  0.079294  0.248013   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "12-30 19:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12-30 20:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12-30 21:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12-30 22:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12-30 23:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "InitialNode                       N_110     N_116     N_115  \n",
       "FinalNode               N_110     N_111     N_119     N_121  \n",
       "LoadLevel                                                    \n",
       "01-01 00:00:00+01:00  0.19354  0.076084  0.097851  0.581913  \n",
       "01-01 01:00:00+01:00  0.19354  0.076084  0.097851  0.581913  \n",
       "01-01 02:00:00+01:00  0.19354  0.076084  0.097851  0.581913  \n",
       "01-01 03:00:00+01:00  0.19354  0.076084  0.097851  0.581913  \n",
       "01-01 04:00:00+01:00  0.19354  0.076084  0.097851  0.581913  \n",
       "...                       ...       ...       ...       ...  \n",
       "12-30 19:00:00+01:00  0.00000  0.000000  0.000000  0.000000  \n",
       "12-30 20:00:00+01:00  0.00000  0.000000  0.000000  0.000000  \n",
       "12-30 21:00:00+01:00  0.00000  0.000000  0.000000  0.000000  \n",
       "12-30 22:00:00+01:00  0.00000  0.000000  0.000000  0.000000  \n",
       "12-30 23:00:00+01:00  0.00000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[8736 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdcc67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoadLevel</th>\n",
       "      <th>N_101-N_102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01 00:00:00+01:00</td>\n",
       "      <td>0.66507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01 01:00:00+01:00</td>\n",
       "      <td>0.66507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01 02:00:00+01:00</td>\n",
       "      <td>0.66507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01 03:00:00+01:00</td>\n",
       "      <td>0.66507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01 04:00:00+01:00</td>\n",
       "      <td>0.66507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>12-30 19:00:00+01:00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>12-30 20:00:00+01:00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8733</th>\n",
       "      <td>12-30 21:00:00+01:00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>12-30 22:00:00+01:00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8735</th>\n",
       "      <td>12-30 23:00:00+01:00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8736 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LoadLevel  N_101-N_102\n",
       "0     01-01 00:00:00+01:00      0.66507\n",
       "1     01-01 01:00:00+01:00      0.66507\n",
       "2     01-01 02:00:00+01:00      0.66507\n",
       "3     01-01 03:00:00+01:00      0.66507\n",
       "4     01-01 04:00:00+01:00      0.66507\n",
       "...                    ...          ...\n",
       "8731  12-30 19:00:00+01:00      0.00000\n",
       "8732  12-30 20:00:00+01:00      0.00000\n",
       "8733  12-30 21:00:00+01:00      0.00000\n",
       "8734  12-30 22:00:00+01:00      0.00000\n",
       "8735  12-30 23:00:00+01:00      0.00000\n",
       "\n",
       "[8736 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique node pairs from df_ts_bs\n",
    "unique_node_pairs = df_ts_bs[['InitialNode', 'FinalNode']].drop_duplicates().values\n",
    "\n",
    "# Initialize a DataFrame to hold all time series\n",
    "frame_values = pd.DataFrame({\"LoadLevel\": all_load_levels})\n",
    "\n",
    "# Iterate over each unique node pair\n",
    "for node_pair in unique_node_pairs:\n",
    "    initial_node, final_node = node_pair\n",
    "\n",
    "    # Initialize the full-year time series array for the current node pair\n",
    "    fy_ts = np.zeros(len(all_load_levels))\n",
    "    \n",
    "    for i, load_level in enumerate(all_load_levels):\n",
    "        this_loadlevel_stage = load_level_stage_map[load_level]\n",
    "\n",
    "        # Filter to find the correct reduced load level\n",
    "        filtered_duration = df_duration[\n",
    "            (df_duration[\"Stage\"] == this_loadlevel_stage) & \n",
    "            (df_duration[\"Duration\"] == 1)\n",
    "        ]\n",
    "\n",
    "        if not filtered_duration.empty:\n",
    "            reduced_temp_load_level = filtered_duration.LoadLevel.iloc[0]\n",
    "\n",
    "            # Find the corresponding value in df_ts_bs\n",
    "            reduced_temp_value = df_ts_bs[\n",
    "                (df_ts_bs[\"InitialNode\"] == initial_node) &\n",
    "                (df_ts_bs[\"FinalNode\"] == final_node) &\n",
    "                (df_ts_bs[\"LoadLevel\"] == str(reduced_temp_load_level))\n",
    "            ]\n",
    "\n",
    "            if not reduced_temp_value.empty:\n",
    "                # Assign the value to the time series array\n",
    "                fy_ts[i] = reduced_temp_value['GWh'].iloc[0]\n",
    "\n",
    "    # Add the time series for the current node pair to the DataFrame\n",
    "    frame_values[f\"{initial_node}-{final_node}\"] = fy_ts\n",
    "\n",
    "# Print the first node pair's time series as an example\n",
    "first_node_pair = unique_node_pairs[0]\n",
    "first_node_pair_key = f\"{first_node_pair[0]}-{first_node_pair[1]}\"\n",
    "print(f\"Time series for node pair {first_node_pair_key}:\")\n",
    "print(frame_values[first_node_pair_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37aac848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0740160494921053"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fy_ts[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "711269e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01-01 00:00:00+01:00'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_level = all_load_levels[0]\n",
    "load_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea46ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.92351985661828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_bs.GWh.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb4045af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.92351985661828"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_bs[df_ts_bs[\"Circuit\"] == \"eac1\"].GWh.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
