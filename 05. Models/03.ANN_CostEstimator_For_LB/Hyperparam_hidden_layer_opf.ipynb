{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbf752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataLoading\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import NN_classes\n",
    "import training_methods\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81112507",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "folder = \"../Data/RTS24_AC_12w_ext_o_dummy\"\n",
    "all_executions = DataLoading.list_executions(folder=\"../Data/RTS24_AC_12w_ext_o_dummy\",per = period,sc=sc)\n",
    "len(all_executions)\n",
    "executions_start = 0 \n",
    "# executions_end = len(executions)\n",
    "executions_end = 5\n",
    "executions = all_executions[executions_start:executions_end]\n",
    "te_s = 0.3\n",
    "val_s = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78483824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_f_sc01_Network_Existing_Generation_Full_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_101_N_102_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_101_N_103_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_101_N_105_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_102_N_104_cac1_2030.csv\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "dfs_in,dfs_out,dfs_inter = DataLoading.load_data_ext_out(folder,executions,period,sc,[\"PowerOutput\"])\n",
    "dfs_inter_j = DataLoading.join_frames_inter_layer(dfs_inter)\n",
    "dfs_inter_j = DataLoading.trim_columns_to_common(dfs_inter_j)\n",
    "ts_in,ts_out,ts_inter = DataLoading.split_tr_val_te_ext_out(dfs_in,dfs_out,dfs_inter_j,executions,te_s,val_s)\n",
    "d_ft_in, d_ft_out,d_ft_inter = DataLoading.concat_and_normalize_ext_out(ts_in,ts_out,ts_inter,executions)\n",
    "\n",
    "train = TensorDataset(d_ft_in['train'].float(), d_ft_out['train'].float(),d_ft_inter['train'])\n",
    "validation = TensorDataset(d_ft_in['val'].float(), d_ft_out['val'].float(),d_ft_inter['val'].float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d54f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 0), 0, False, 32, 0.000625, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0001157665196355061 valid 8.017855179787148e-06\n",
      "EPOCH 2:\n",
      "LOSS train 1.4496695457882286e-06 valid 5.112103735882556e-06\n",
      "EPOCH 3:\n",
      "LOSS train 9.206998151039475e-07 valid 3.7044410419184715e-06\n",
      "EPOCH 4:\n",
      "LOSS train 6.522277612318483e-07 valid 4.0514614738640375e-06\n",
      "((2, 0), 0, False, 32, 0.0025, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00018161325789418155 valid 1.7960341210709885e-05\n",
      "EPOCH 2:\n",
      "LOSS train 2.8703581365579426e-06 valid 1.9817505744867958e-05\n",
      "EPOCH 3:\n",
      "LOSS train 2.4783788455569797e-06 valid 1.3437755114864558e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.0755777041772362e-06 valid 1.3818088518746663e-05\n",
      "((2, 0), 0, False, 32, 0.01, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00033175492203301675 valid 8.658177102915943e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.5956892090724433e-05 valid 8.486269507557154e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.450353985512878e-05 valid 8.17395412013866e-05\n",
      "EPOCH 4:\n",
      "LOSS train 1.526868196243135e-05 valid 7.981534145073965e-05\n",
      "((2, 0), 0, False, 32, 0.04, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.16929405469040562 valid 0.000453551096143201\n",
      "EPOCH 2:\n",
      "LOSS train 5.96224267349991e-05 valid 5.6323708122363314e-05\n",
      "EPOCH 3:\n",
      "LOSS train 2.7887544751100297e-05 valid 6.312947516562417e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.5244029281563167e-05 valid 6.310424214461818e-05\n",
      "((2, 0), 0, False, 64, 0.000625, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00010371633612433268 valid 5.811657683807425e-05\n",
      "EPOCH 2:\n",
      "LOSS train 2.6549952581136597e-05 valid 1.7275926438742317e-05\n",
      "EPOCH 3:\n",
      "LOSS train 3.8110167679406004e-06 valid 5.882566256332211e-06\n",
      "EPOCH 4:\n",
      "LOSS train 9.802466056640924e-07 valid 4.575416824081913e-06\n",
      "((2, 0), 0, False, 64, 0.0025, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00024195988696520645 valid 6.9915120548103e-05\n",
      "EPOCH 2:\n",
      "LOSS train 2.089037705369871e-05 valid 3.6430767067940906e-05\n",
      "EPOCH 3:\n",
      "LOSS train 3.0969799311719726e-06 valid 8.897127372620162e-06\n",
      "EPOCH 4:\n",
      "LOSS train 2.510558543870426e-06 valid 6.591190413018921e-06\n",
      "((2, 0), 0, False, 64, 0.01, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0005443598512708073 valid 8.899762178771198e-05\n",
      "EPOCH 2:\n",
      "LOSS train 2.082081346404468e-05 valid 8.179186988854781e-05\n",
      "EPOCH 3:\n",
      "LOSS train 2.1449455205571314e-05 valid 6.983117782510817e-05\n",
      "EPOCH 4:\n",
      "LOSS train 1.9775209078747797e-05 valid 8.50674114190042e-05\n",
      "((2, 0), 0, False, 64, 0.04, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.04334082889584402 valid 8.770333806751296e-05\n",
      "EPOCH 2:\n",
      "LOSS train 3.1447950239756515e-05 valid 4.721239020000212e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.9245226962678113e-05 valid 3.886046397383325e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.2026569456083205e-05 valid 4.578956577461213e-05\n",
      "((2, 0), 0, False, 128, 0.000625, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00024234958565709044 valid 7.518801430705935e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.764132566172015e-05 valid 0.00012386655726004392\n",
      "EPOCH 3:\n",
      "LOSS train 4.811695065301238e-06 valid 3.1420484447153285e-05\n",
      "EPOCH 4:\n",
      "LOSS train 3.437995234081528e-06 valid 2.8379237846820615e-05\n",
      "((2, 0), 0, False, 128, 0.0025, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0002985745428942563 valid 1.565188904351089e-05\n",
      "EPOCH 2:\n",
      "LOSS train 3.93944529264445e-06 valid 8.711712325748522e-06\n",
      "EPOCH 3:\n",
      "LOSS train 2.925146203678095e-06 valid 1.8445147361489944e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.9742654719358243e-06 valid 2.217521978309378e-05\n",
      "((2, 0), 0, False, 128, 0.01, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0014366774240544247 valid 0.00019267312018200755\n",
      "EPOCH 2:\n",
      "LOSS train 1.911720926904713e-05 valid 8.184607577277347e-05\n",
      "EPOCH 3:\n",
      "LOSS train 5.163679944075739e-06 valid 1.2971670912520494e-05\n",
      "EPOCH 4:\n",
      "LOSS train 4.287337906324258e-06 valid 7.563830422441242e-06\n",
      "((2, 0), 0, False, 128, 0.04, 4, 0)\n",
      "[172, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 1.8627670614959395 valid 0.0001450184645364061\n",
      "EPOCH 2:\n",
      "LOSS train 6.162179446770703e-05 valid 7.513182936236262e-05\n",
      "EPOCH 3:\n",
      "LOSS train 0.00010064353835382967 valid 9.331165347248316e-05\n",
      "EPOCH 4:\n",
      "LOSS train 0.00011283085047529716 valid 7.332013774430379e-05\n",
      "((3, 0), 0, False, 32, 0.000625, 4, 0)\n",
      "[172, 258, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 1.6807486327152787e-05 valid 1.290233831241494e-05\n",
      "EPOCH 2:\n",
      "LOSS train 8.274668526178333e-07 valid 5.344902092474513e-06\n",
      "EPOCH 3:\n",
      "LOSS train 9.876933074378276e-07 valid 5.254934876575135e-06\n",
      "EPOCH 4:\n",
      "LOSS train 9.187771565037176e-07 valid 5.50345566807664e-06\n",
      "((3, 0), 0, False, 32, 0.0025, 4, 0)\n",
      "[172, 258, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 8.175779756649761e-05 valid 6.590532575501129e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.2258374890766137e-05 valid 4.2358788050478324e-05\n",
      "EPOCH 3:\n",
      "LOSS train 6.6485236312906354e-06 valid 3.0136079658404924e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.4666873014290836e-06 valid 1.792985676729586e-05\n",
      "((3, 0), 0, False, 32, 0.01, 4, 0)\n",
      "[172, 258, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00036335439967554665 valid 8.568185148760676e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.877799998872831e-05 valid 8.135432290146127e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.8832717549975718e-05 valid 8.496283408021554e-05\n",
      "EPOCH 4:\n",
      "LOSS train 1.59492503170908e-05 valid 8.43255766085349e-05\n",
      "((3, 0), 0, False, 32, 0.04, 4, 0)\n",
      "[172, 258, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 1.5726531917051882 valid 0.001036932342685759\n",
      "EPOCH 2:\n",
      "LOSS train 6.944239467365776e-05 valid 0.0002409253502264619\n",
      "EPOCH 3:\n",
      "LOSS train 6.377846452920721e-05 valid 0.00010843715426744893\n",
      "EPOCH 4:\n",
      "LOSS train 6.64493093306283e-05 valid 0.00034023451735265553\n",
      "((3, 0), 0, False, 64, 0.000625, 4, 0)\n",
      "[172, 258, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 5.299920677101808e-05 valid 5.284227881929837e-05\n",
      "EPOCH 2:\n",
      "LOSS train 5.6542509392601105e-06 valid 1.0859639587579295e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.2308871717436887e-06 valid 7.006845407886431e-06\n",
      "EPOCH 4:\n",
      "LOSS train 4.934460974147391e-07 valid 6.848682005511364e-06\n",
      "((3, 0), 0, False, 64, 0.0025, 4, 0)\n",
      "[172, 258, 68, 51]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00010405446182125565 valid 4.305729817133397e-05\n",
      "EPOCH 2:\n",
      "LOSS train 2.1666062802220647e-05 valid 2.4932051019277424e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.2747172197988573e-05 valid 1.2963442713953555e-05\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File trained_models/RTS24_AC_12w_ext_o_dummy/min_val\\model_OE_(3, 0)h_4e_0.0025lr_0dor_0np_False_ro_64bs.pth cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#Train the actual model \u001b[39;00m\n\u001b[0;32m     38\u001b[0m t_start_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 39\u001b[0m train_loss_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_multiple_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfolder_to_save\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     40\u001b[0m t_stop_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#In the following loop, we retreive the models from saved locations and calculate losses \u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\JointResearch\\05. Models\\03.ANN_CostEstimator_For_LB\\training_methods.py:156\u001b[0m, in \u001b[0;36mtrain_multiple_epochs\u001b[1;34m(nb_epochs, model, training_loader, validation_loader, loss_fn, optimizer, model_name, folder, inter)\u001b[0m\n\u001b[0;32m    154\u001b[0m             os\u001b[38;5;241m.\u001b[39mmakedirs(min_val_model_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Create the directory if it doesn't exist\u001b[39;00m\n\u001b[0;32m    155\u001b[0m             min_val_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(min_val_model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_name))\n\u001b[1;32m--> 156\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_val_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     epoch_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# model_path = 'trained_models/{}/all_epochs/model_{}.pth'.format(folder,model_name)if folder is not None:\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File trained_models/RTS24_AC_12w_ext_o_dummy/min_val\\model_OE_(3, 0)h_4e_0.0025lr_0dor_0np_False_ro_64bs.pth cannot be opened."
     ]
    }
   ],
   "source": [
    "i=0\n",
    "nbs_hidden = [(2,0),(3,0),(3,1)]\n",
    "dors = [0]#,0.05,0.1]#,0.05]\n",
    "relu_outs=[False]\n",
    "\n",
    "batch_sizes = [32,64,128]\n",
    "learning_rates = [0.0025*4**i for i in range(-1,3,1)]\n",
    "nbs_e = [4]#,8,12,16,20] # ,8]\n",
    "negative_penalisations = [0]\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "folder_to_save = \"RTS24_AC_12w_ext_o_dummy\"\n",
    "\n",
    "hp_sets = ((nb_h,dor,relu_out,bs,lr,nb_e,np) for nb_h in nbs_hidden for dor in dors for relu_out in relu_outs for bs in batch_sizes for lr in learning_rates for nb_e in nbs_e for np in negative_penalisations)\n",
    "\n",
    "inter_size = dfs_inter_j[\"Network_Existing_Generation_Full\"].shape[1]\n",
    "\n",
    "for hp_set in hp_sets:\n",
    "    print(hp_set)\n",
    "    nb_hidden,dor,relu_out,bs,lr,nb_e,np = hp_set[0],hp_set[1],hp_set[2],hp_set[3],hp_set[4],hp_set[5],hp_set[6]\n",
    "    \n",
    "    #Create training and validation loaders based on batch size\n",
    "    training_loader = DataLoader(train,batch_size=bs)\n",
    "    validation_loader = DataLoader(validation,batch_size=bs)\n",
    "    \n",
    "    #Initialize loss functions\n",
    "    loss_fn = NN_classes.create_custom_loss(alpha=0,beta=1)\n",
    "    loss_t_mse = torch.nn.MSELoss()\n",
    "    \n",
    "    #Create model based on hyperparameter set\n",
    "    m = NN_classes.create_model(nb_hidden,d_ft_in['train'].shape[1],dropout_ratio= dor,relu_out=relu_out,inter = True,inter_size=inter_size)\n",
    "    #Create model name for saving and loading\n",
    "    m_name = f\"OE_{nb_hidden}h_{nb_e}e_{lr}lr_{dor}dor_{np}np_{relu_out}_ro_{bs}bs\"\n",
    "    #Create optimizer based on learning rate \n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "    #Train the actual model \n",
    "    t_start_train = time.perf_counter()\n",
    "    train_loss_1 = training_methods.train_multiple_epochs(nb_e,m,training_loader,validation_loader,loss_fn,optimizer,m_name,folder_to_save,True)[0]\n",
    "    t_stop_train = time.perf_counter()\n",
    "    \n",
    "    #In the following loop, we retreive the models from saved locations and calculate losses \n",
    "    for mt in [\"min_val\",\"all_epochs\"]:\n",
    "        t_start_eval = time.perf_counter()\n",
    "        path = f\"trained_models/{folder_to_save}/{mt}/model_{m_name}.pth\"\n",
    "        \n",
    "        #Retreive model state and set to evaluation mode\n",
    "        m.load_state_dict(torch.load(path))\n",
    "        m.eval()\n",
    "        \n",
    "        #Calculate losses\n",
    "        test_predictions = m(d_ft_in[\"test\"].float())\n",
    "        test_loss = loss_fn(test_predictions[0].squeeze(),d_ft_out[\"test\"],test_predictions[1].squeeze(),d_ft_inter[\"test\"])\n",
    "        test_loss_t_mse = loss_t_mse(test_predictions[0].squeeze(),d_ft_out[\"test\"])\n",
    "\n",
    "\n",
    "        train_predictions = m(d_ft_in[\"train\"].float())\n",
    "        train_loss = loss_fn(train_predictions[0].squeeze(),d_ft_out[\"train\"],train_predictions[1].squeeze(),d_ft_inter[\"train\"])\n",
    "        train_loss_t_mse = loss_t_mse(train_predictions[0].squeeze(),d_ft_out[\"train\"])\n",
    "\n",
    "\n",
    "        validation_prediction = m(d_ft_in[\"val\"].float())\n",
    "        validation_loss = loss_fn(validation_prediction[0].squeeze(),d_ft_out[\"val\"],validation_prediction[1].squeeze(),d_ft_inter[\"val\"])\n",
    "        validation_loss_t_mse = loss_t_mse(validation_prediction[0].squeeze(),d_ft_out[\"val\"])\n",
    "        t_stop_eval = time.perf_counter()\n",
    "        \n",
    "        \n",
    "        #Calculate some calculation times \n",
    "        t_train = t_stop_train - t_start_train\n",
    "        t_eval = t_stop_eval - t_start_eval\n",
    "        \n",
    "        #Finally, save all desired values in a dataframe\n",
    "        r = pd.DataFrame({\"Model_type\": [nb_hidden],\n",
    "                        \"Dor\": dor,\n",
    "                        \"Relu_out\": relu_out,\n",
    "                        \"Batch_size\": bs,\n",
    "                        \"Lr\":lr,\n",
    "                        \"Epochs\": nb_e,\n",
    "                        \"Np\": np,\n",
    "                        \"Min_val\":mt,\n",
    "                        \"Tr_l\":train_loss.item(),\n",
    "                        \"Te_l\":test_loss.item(),\n",
    "                        \"V_l\": validation_loss.item(),\n",
    "                        \"Tr_l_t_mse\":train_loss_t_mse.item(),\n",
    "                        \"Te_l_t_mse\":test_loss_t_mse.item(),\n",
    "                        \"V_l_t_mse\": validation_loss_t_mse.item(),\n",
    "                        \"Tr_l_ret\": train_loss_1.item(),\n",
    "                        \"Train_time\": t_train,\n",
    "                        \"Eval_time\": t_eval\n",
    "                         }\n",
    "                        ,index = [i])\n",
    "        i+=1\n",
    "        results = pd.concat([results,r])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9957d384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
