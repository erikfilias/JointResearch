{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fee9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataLoading\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import NN_classes\n",
    "import training_methods\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc5388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "folder = \"../Data/RTS24_AC_12w_ext_o_dummy\"\n",
    "all_executions = DataLoading.list_executions(folder=\"../Data/RTS24_AC_12w_ext_o_dummy\",per = period,sc=sc)\n",
    "len(all_executions)\n",
    "executions_start = 0 \n",
    "executions_end = len(all_executions)\n",
    "executions = all_executions[executions_start:executions_end]\n",
    "te_s = 0.3\n",
    "val_s = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe33f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_f_sc01_Network_Existing_Generation_Full_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_101_N_102_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_101_N_103_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_101_N_105_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_102_N_104_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_102_N_106_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_103_N_109_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_103_N_124_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_104_N_109_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_105_N_110_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_106_N_108_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_106_N_110_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_107_N_108_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_108_N_109_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_108_N_110_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_109_N_111_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_109_N_112_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_110_N_111_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_110_N_112_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_111_N_113_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_111_N_114_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_112_N_113_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_112_N_123_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_113_N_123_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_114_N_116_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_115_N_116_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_115_N_121_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_115_N_121_cac2_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_115_N_124_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_116_N_117_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_116_N_119_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_117_N_118_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_117_N_122_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_118_N_121_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_118_N_121_cac2_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_119_N_120_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_119_N_120_cac2_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_120_N_123_cac1_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_120_N_123_cac2_2030.csv\n",
      "86\n",
      "input_f_sc01_Network_Line_In_N_121_N_122_cac1_2030.csv\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "dfs_in,dfs_out,dfs_inter = DataLoading.load_data_ext_out(folder,executions,period,sc,[\"PowerOutput\"])\n",
    "dfs_inter_j = DataLoading.join_frames_inter_layer(dfs_inter)\n",
    "dfs_inter_j = DataLoading.trim_columns_to_common(dfs_inter_j)\n",
    "ts_in,ts_out,ts_inter = DataLoading.split_tr_val_te_ext_out(dfs_in,dfs_out,dfs_inter_j,executions,te_s,val_s)\n",
    "d_ft_in, d_ft_out,d_ft_inter = DataLoading.concat_and_normalize_ext_out(ts_in,ts_out,ts_inter,executions)\n",
    "\n",
    "train = TensorDataset(d_ft_in['train'].float(), d_ft_out['train'].float(),d_ft_inter['train'])\n",
    "validation = TensorDataset(d_ft_in['val'].float(), d_ft_out['val'].float(),d_ft_inter['val'].float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c775de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((3, 2), 0, False, 32, 0.000625, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0003701292724234611 valid 9.172188583761454e-06\n",
      "EPOCH 2:\n",
      "LOSS train 1.4808920789863156e-06 valid 7.650974112038966e-06\n",
      "EPOCH 3:\n",
      "LOSS train 1.216020439435784e-06 valid 7.745312359475065e-06\n",
      "EPOCH 4:\n",
      "LOSS train 1.5887459702385783e-06 valid 8.677906407683622e-06\n",
      "((3, 2), 0, False, 32, 0.0025, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0006028931329370164 valid 1.9033628632314503e-05\n",
      "EPOCH 2:\n",
      "LOSS train 3.705200253493011e-06 valid 1.6362111637135968e-05\n",
      "EPOCH 3:\n",
      "LOSS train 2.6335840234384097e-06 valid 1.2521814824140165e-05\n",
      "EPOCH 4:\n",
      "LOSS train 1.8495277298574431e-06 valid 9.322238838649355e-06\n",
      "((3, 2), 0, False, 32, 0.01, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0001457202085643404 valid 8.641240856377408e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.7764181435182868e-05 valid 9.330770262749866e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.9744108456260855e-05 valid 9.44960120250471e-05\n",
      "EPOCH 4:\n",
      "LOSS train 1.7829439119240937e-05 valid 9.478064021095634e-05\n",
      "((3, 2), 0, False, 32, 0.04, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00029200099603905294 valid 7.388257654383779e-05\n",
      "EPOCH 2:\n",
      "LOSS train 3.4287765054737896e-05 valid 7.000111509114504e-05\n",
      "EPOCH 3:\n",
      "LOSS train 4.12383947104701e-05 valid 6.886277697049081e-05\n",
      "EPOCH 4:\n",
      "LOSS train 4.363419054191792e-05 valid 6.86648054397665e-05\n",
      "((3, 2), 0, False, 64, 0.000625, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00017289202279691514 valid 1.4183112398313824e-05\n",
      "EPOCH 2:\n",
      "LOSS train 4.56537199543572e-07 valid 1.182583309855545e-05\n",
      "EPOCH 3:\n",
      "LOSS train 3.163324144633314e-07 valid 1.1783483387262095e-05\n",
      "EPOCH 4:\n",
      "LOSS train 3.7644326698072465e-07 valid 1.0603740520309657e-05\n",
      "((3, 2), 0, False, 64, 0.0025, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 9.769520630975794e-05 valid 0.0001226382883032784\n",
      "EPOCH 2:\n",
      "LOSS train 9.937386253810206e-06 valid 1.724938556435518e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.5761028334362896e-06 valid 1.1872423783643171e-05\n",
      "EPOCH 4:\n",
      "LOSS train 1.165719727391496e-06 valid 1.231645182997454e-05\n",
      "((3, 2), 0, False, 64, 0.01, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0006469409721896267 valid 1.2668471754295751e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.9573321009646044e-06 valid 9.351592780149076e-06\n",
      "EPOCH 3:\n",
      "LOSS train 2.782823080758669e-06 valid 1.4888696568959858e-05\n",
      "EPOCH 4:\n",
      "LOSS train 3.8650927647976146e-06 valid 1.179744958790252e-05\n",
      "((3, 2), 0, False, 64, 0.04, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.022259181168099534 valid 0.0001898446207633242\n",
      "EPOCH 2:\n",
      "LOSS train 1.2026154068174896e-05 valid 0.00019000735483132303\n",
      "EPOCH 3:\n",
      "LOSS train 1.3187828057556129e-05 valid 0.00018955679843202233\n",
      "EPOCH 4:\n",
      "LOSS train 1.556489314476854e-05 valid 0.00018504899344407022\n",
      "((3, 2), 0, False, 128, 0.000625, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0004911611238904248 valid 5.1378669013502076e-05\n",
      "EPOCH 2:\n",
      "LOSS train 1.6478735261572288e-06 valid 9.047543244378176e-06\n",
      "EPOCH 3:\n",
      "LOSS train 1.5810827417418511e-06 valid 1.340518156212056e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.632802105852404e-06 valid 1.3944263628218323e-05\n",
      "((3, 2), 0, False, 128, 0.0025, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.00023898556421842607 valid 8.338744919456076e-06\n",
      "EPOCH 2:\n",
      "LOSS train 7.526166489250236e-06 valid 1.4338354958454147e-05\n",
      "EPOCH 3:\n",
      "LOSS train 1.222217223321161e-05 valid 8.447758773399983e-06\n",
      "EPOCH 4:\n",
      "LOSS train 3.107961823207283e-06 valid 6.5218941927014384e-06\n",
      "((3, 2), 0, False, 128, 0.01, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.0015941576618562845 valid 1.2067230272805318e-05\n",
      "EPOCH 2:\n",
      "LOSS train 2.6819805435152596e-06 valid 2.05063697649166e-05\n",
      "EPOCH 3:\n",
      "LOSS train 3.693946671079628e-06 valid 1.8632066712598316e-05\n",
      "EPOCH 4:\n",
      "LOSS train 2.5712084752399674e-06 valid 2.3819904527044855e-05\n",
      "((3, 2), 0, False, 128, 0.04, 4, 0, 0)\n",
      "[172, 258, 68, 51, 25, 12]\n",
      "EPOCH 1:\n",
      "LOSS train 0.009005361682170983 valid 8.418385550612584e-05\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#Train the actual model \u001b[39;00m\n\u001b[0;32m     40\u001b[0m t_start_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 41\u001b[0m train_loss_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_multiple_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfolder_to_save\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     42\u001b[0m t_stop_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#In the following loop, we retreive the models from saved locations and calculate losses \u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\JointResearch\\05. Models\\03.ANN_CostEstimator_For_LB\\training_methods.py:112\u001b[0m, in \u001b[0;36mtrain_multiple_epochs\u001b[1;34m(nb_epochs, model, training_loader, validation_loader, loss_fn, optimizer, model_name, folder, inter)\u001b[0m\n\u001b[0;32m    110\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inter:\n\u001b[1;32m--> 112\u001b[0m     one_epoch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch_inter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     one_epoch_losses \u001b[38;5;241m=\u001b[39m train_one_epoch(model,training_loader,epoch_number,optimizer,loss_fn)\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\JointResearch\\05. Models\\03.ANN_CostEstimator_For_LB\\training_methods.py:88\u001b[0m, in \u001b[0;36mtrain_one_epoch_inter\u001b[1;34m(model, training_loader, epoch_index, optimizer, loss_fn, f_print)\u001b[0m\n\u001b[0;32m     85\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Adjust learning weights\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Gather data and report\u001b[39;00m\n\u001b[0;32m     91\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\optim\\adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "nbs_hidden = [(3,2)]\n",
    "dors = [0]#,0.05,0.1]#,0.05]\n",
    "relu_outs=[False]\n",
    "\n",
    "batch_sizes = [32,64,128]\n",
    "learning_rates = [0.0025*4**i for i in range(-1,3,1)]\n",
    "nbs_e = [4]#,8,12,16,20] # ,8]\n",
    "negative_penalisations = [0]\n",
    "alphas = [0]#,0.1,0.2,0.4]\n",
    "beta = 1\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "folder_to_save = \"RTS24_AC_12w_ext_o_dummy\"\n",
    "\n",
    "hp_sets = ((nb_h,dor,relu_out,bs,lr,nb_e,np,alpha) for nb_h in nbs_hidden for dor in dors for relu_out in relu_outs for bs in batch_sizes for lr in learning_rates for nb_e in nbs_e for np in negative_penalisations for alpha in alphas)\n",
    "\n",
    "inter_size = dfs_inter_j[\"Network_Existing_Generation_Full\"].shape[1]\n",
    "\n",
    "for hp_set in hp_sets:\n",
    "    print(hp_set)\n",
    "    nb_hidden,dor,relu_out,bs,lr,nb_e,np,alpha = hp_set[0],hp_set[1],hp_set[2],hp_set[3],hp_set[4],hp_set[5],hp_set[6],hp_set[7]\n",
    "    \n",
    "    #Create training and validation loaders based on batch size\n",
    "    training_loader = DataLoader(train,batch_size=bs)\n",
    "    validation_loader = DataLoader(validation,batch_size=bs)\n",
    "    \n",
    "    #Initialize loss functions\n",
    "    loss_fn = NN_classes.create_custom_loss(alpha=alpha,beta=beta)\n",
    "    loss_t_mse = torch.nn.MSELoss()\n",
    "    \n",
    "    #Create model based on hyperparameter set\n",
    "    m = NN_classes.create_model(nb_hidden,d_ft_in['train'].shape[1],dropout_ratio= dor,relu_out=relu_out,inter = True,inter_size=inter_size)\n",
    "    #Create model name for saving and loading\n",
    "    m_name = f\"OE_{nb_hidden}h_{nb_e}e_{lr}lr_{dor}dor_{np}np_{relu_out}_ro_{bs}bs\"\n",
    "    #Create optimizer based on learning rate \n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "    #Train the actual model \n",
    "    t_start_train = time.perf_counter()\n",
    "    train_loss_1 = training_methods.train_multiple_epochs(nb_e,m,training_loader,validation_loader,loss_fn,optimizer,m_name,folder_to_save,True)[0]\n",
    "    t_stop_train = time.perf_counter()\n",
    "    \n",
    "    #In the following loop, we retreive the models from saved locations and calculate losses \n",
    "    for mt in [\"min_val\",\"all_epochs\"]:\n",
    "        t_start_eval = time.perf_counter()\n",
    "        path = f\"trained_models/{folder_to_save}/{mt}/model_{m_name}.pth\"\n",
    "        \n",
    "        #Retreive model state and set to evaluation mode\n",
    "        m.load_state_dict(torch.load(path))\n",
    "        m.eval()\n",
    "        \n",
    "        #Calculate losses\n",
    "        test_predictions = m(d_ft_in[\"test\"].float())\n",
    "        test_loss = loss_fn(test_predictions[0].squeeze(),d_ft_out[\"test\"],test_predictions[1].squeeze(),d_ft_inter[\"test\"])\n",
    "        test_loss_t_mse = loss_t_mse(test_predictions[0].squeeze(),d_ft_out[\"test\"])\n",
    "\n",
    "\n",
    "        train_predictions = m(d_ft_in[\"train\"].float())\n",
    "        train_loss = loss_fn(train_predictions[0].squeeze(),d_ft_out[\"train\"],train_predictions[1].squeeze(),d_ft_inter[\"train\"])\n",
    "        train_loss_t_mse = loss_t_mse(train_predictions[0].squeeze(),d_ft_out[\"train\"])\n",
    "\n",
    "\n",
    "        validation_prediction = m(d_ft_in[\"val\"].float())\n",
    "        validation_loss = loss_fn(validation_prediction[0].squeeze(),d_ft_out[\"val\"],validation_prediction[1].squeeze(),d_ft_inter[\"val\"])\n",
    "        validation_loss_t_mse = loss_t_mse(validation_prediction[0].squeeze(),d_ft_out[\"val\"])\n",
    "        t_stop_eval = time.perf_counter()\n",
    "        \n",
    "        \n",
    "        #Calculate some calculation times \n",
    "        t_train = t_stop_train - t_start_train\n",
    "        t_eval = t_stop_eval - t_start_eval\n",
    "        \n",
    "        #Finally, save all desired values in a dataframe\n",
    "        r = pd.DataFrame({\"Model_type\": [nb_hidden],\n",
    "                        \"Dor\": dor,\n",
    "                        \"Relu_out\": relu_out,\n",
    "                        \"Batch_size\": bs,\n",
    "                        \"Lr\":lr,\n",
    "                        \"Epochs\": nb_e,\n",
    "                        \"Np\": np,\n",
    "                        \"Min_val\":mt,\n",
    "                        \"Tr_l\":train_loss.item(),\n",
    "                        \"Te_l\":test_loss.item(),\n",
    "                        \"V_l\": validation_loss.item(),\n",
    "                        \"Tr_l_t_mse\":train_loss_t_mse.item(),\n",
    "                        \"Te_l_t_mse\":test_loss_t_mse.item(),\n",
    "                        \"V_l_t_mse\": validation_loss_t_mse.item(),\n",
    "                        \"Tr_l_ret\": train_loss_1.item(),\n",
    "                        \"Train_time\": t_train,\n",
    "                        \"Eval_time\": t_eval,\n",
    "                        \"alpha\": alpha, \n",
    "                        \"beta\": beta,\n",
    "                        \"Test size\": te_s,\n",
    "                        \"Val size\": val_s\n",
    "                         }\n",
    "                        ,index = [i])\n",
    "        i+=1\n",
    "        results = pd.concat([results,r])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0079d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"Loss_results_csv/All_Exec_inter_dummy_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
