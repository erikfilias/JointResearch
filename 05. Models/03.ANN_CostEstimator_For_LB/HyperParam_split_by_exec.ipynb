{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb899fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataLoading\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import NN_classes\n",
    "import training_methods\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061f4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "folder = \"../Data/RTS24_AC_12w\"\n",
    "all_executions = DataLoading.list_executions(folder=\"../Data/RTS24_AC_12w\",per = period,sc=sc)\n",
    "executions = all_executions[1:20]\n",
    "te_s = 0.3\n",
    "val_s = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa0d046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_f_sc01_Network_Line_In_N_101_N_102_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_101_N_103_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_101_N_105_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_102_N_104_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_102_N_106_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_103_N_109_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_103_N_124_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_104_N_109_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_105_N_110_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_106_N_108_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_106_N_110_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_107_N_108_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_108_N_109_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_108_N_110_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_109_N_111_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_109_N_112_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_110_N_111_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_110_N_112_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_111_N_113_cac1_2030.csv\n",
      "1227\n"
     ]
    }
   ],
   "source": [
    "dfs_in,dfs_out = DataLoading.load_data(folder,executions,period,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6671c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in,ts_out =  DataLoading.split_tr_val_te_by_exec(dfs_in,dfs_out,executions,te_s,val_s,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93163ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ft_in, d_ft_out,maxs = DataLoading.concat_and_normalize_split_by_exec(ts_in,ts_out,executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f72c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(d_ft_in['train'].float(), d_ft_out['train'].float())\n",
    "validation = TensorDataset(d_ft_in['val'].float(), d_ft_out['val'].float())\n",
    "\n",
    "training_loader = DataLoader(train,batch_size=64)\n",
    "validation_loader = DataLoader(train,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d94194d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001394575834274292\n",
      "  batch 101 loss: 0.0005119901264879445\n",
      "  batch 201 loss: 0.00011239645680689137\n",
      "LOSS train 0.0003327727220430827 valid 0.0006375726661644876\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.836234544811304e-08\n",
      "  batch 101 loss: 3.924097936078397e-05\n",
      "  batch 201 loss: 3.46557675038639e-05\n",
      "LOSS train 7.09232951172726e-05 valid 0.001110503333620727\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.6329082427546383e-06\n",
      "  batch 101 loss: 3.977513157337853e-05\n",
      "  batch 201 loss: 3.201342332090462e-05\n",
      "LOSS train 7.283109234210579e-05 valid 0.0008317824685946107\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0086051042890177e-06\n",
      "  batch 101 loss: 2.7083953690407724e-05\n",
      "  batch 201 loss: 3.0249493679548323e-05\n",
      "LOSS train 6.76004241400873e-05 valid 0.0014173374511301517\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.513476811349392e-05\n",
      "  batch 101 loss: 0.0029855008667800578\n",
      "  batch 201 loss: 0.0018954151717480272\n",
      "LOSS train 0.002257010056645756 valid 0.0021734365727752447\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.168846178799867e-05\n",
      "  batch 101 loss: 0.001287312307395041\n",
      "  batch 201 loss: 0.0008354579698061571\n",
      "LOSS train 0.0009758267824575578 valid 0.0004438562609720975\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.187583664432168e-05\n",
      "  batch 101 loss: 0.0005062607972649857\n",
      "  batch 201 loss: 0.0003544906433671713\n",
      "LOSS train 0.0003870133622489774 valid 0.0003700829402077943\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.7642104588449e-06\n",
      "  batch 101 loss: 0.00019886451678758022\n",
      "  batch 201 loss: 0.00012423555315763224\n",
      "LOSS train 0.00014792232356670027 valid 5.845843406859785e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.005572784692049e-05\n",
      "  batch 101 loss: 0.0034524093731306492\n",
      "  batch 201 loss: 0.002031313922489062\n",
      "LOSS train 0.0023168217906329247 valid 0.00021438725525513291\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.234541212208569e-06\n",
      "  batch 101 loss: 0.000558777376281796\n",
      "  batch 201 loss: 0.0002742619597847806\n",
      "LOSS train 0.00034790324600393824 valid 3.770778130274266e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.527110580354929e-06\n",
      "  batch 101 loss: 8.310353601700626e-05\n",
      "  batch 201 loss: 4.577620602503884e-05\n",
      "LOSS train 5.386856937481516e-05 valid 4.876053026237059e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.2962063010490966e-07\n",
      "  batch 101 loss: 1.6285227334265075e-05\n",
      "  batch 201 loss: 1.184169988391659e-05\n",
      "LOSS train 1.2743846390892294e-05 valid 9.221061191055924e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00037802547216415406\n",
      "  batch 101 loss: 0.00962616822682321\n",
      "  batch 201 loss: 0.0041826122952625154\n",
      "LOSS train 0.0056924449847908795 valid 6.381227285601199e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.2565820943564177e-05\n",
      "  batch 101 loss: 0.0008018431084929035\n",
      "  batch 201 loss: 0.0002644397250696784\n",
      "LOSS train 0.00042246309696012703 valid 1.2716121091216337e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.5692095621488988e-06\n",
      "  batch 101 loss: 6.937539779755753e-05\n",
      "  batch 201 loss: 2.6073945373354946e-05\n",
      "LOSS train 4.0180086706151575e-05 valid 7.637167072971351e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.8396352970739827e-07\n",
      "  batch 101 loss: 1.577425838831914e-05\n",
      "  batch 201 loss: 1.5891675282091456e-05\n",
      "LOSS train 1.5286807461835275e-05 valid 1.6760441212682053e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00041824180632829664\n",
      "  batch 101 loss: 0.015251670554280282\n",
      "  batch 201 loss: 0.002403611781192012\n",
      "LOSS train 0.00671905577559094 valid 3.3287404221482575e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.344090120866894e-06\n",
      "  batch 101 loss: 0.00014763603678147775\n",
      "  batch 201 loss: 2.5688152336442728e-05\n",
      "LOSS train 7.227516049076653e-05 valid 1.8014396118815057e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.515758685854962e-07\n",
      "  batch 101 loss: 2.936008376764221e-05\n",
      "  batch 201 loss: 2.2738524571650486e-05\n",
      "LOSS train 2.514635920366285e-05 valid 2.028590824920684e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.231258678075392e-08\n",
      "  batch 101 loss: 2.379657167239202e-05\n",
      "  batch 201 loss: 2.8038658829245833e-05\n",
      "LOSS train 2.5054856197686352e-05 valid 4.56072848464828e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000160722304135561\n",
      "  batch 101 loss: 0.0005445895974276027\n",
      "  batch 201 loss: 1.5831497834142282e-05\n",
      "LOSS train 0.00026636516182596817 valid 1.4479231140285265e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.2410622477764263e-07\n",
      "  batch 101 loss: 9.35253967782046e-06\n",
      "  batch 201 loss: 8.192488531904018e-06\n",
      "LOSS train 7.805775999300556e-06 valid 1.3355281225813087e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.0014482288388535e-07\n",
      "  batch 101 loss: 1.0019214254697317e-05\n",
      "  batch 201 loss: 7.354136417347945e-06\n",
      "LOSS train 7.549279475997553e-06 valid 1.2895190593553707e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.4368811207532417e-07\n",
      "  batch 101 loss: 9.430348475234496e-06\n",
      "  batch 201 loss: 8.423407540476547e-06\n",
      "LOSS train 7.425537183700306e-06 valid 1.2114129276596941e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.21833312511444e-05\n",
      "  batch 101 loss: 0.0004125765727076214\n",
      "  batch 201 loss: 0.00012981305681023514\n",
      "LOSS train 0.0002638921946110826 valid 6.250042497413233e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.698191721923649e-06\n",
      "  batch 101 loss: 0.00015562844375381247\n",
      "  batch 201 loss: 0.00010083156321343268\n",
      "LOSS train 0.00013391777252637262 valid 4.445173908607103e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.553178055677563e-06\n",
      "  batch 101 loss: 0.0001316671830136329\n",
      "  batch 201 loss: 8.907400348107331e-05\n",
      "LOSS train 0.0001069063564433909 valid 0.0001563022960908711\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.379693466238677e-06\n",
      "  batch 101 loss: 0.00011358361887687352\n",
      "  batch 201 loss: 6.154679133032914e-05\n",
      "LOSS train 8.922049025283238e-05 valid 7.350972737185657e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.3576515056192876e-05\n",
      "  batch 101 loss: 0.0011119857311132364\n",
      "  batch 201 loss: 0.0002954336458060425\n",
      "LOSS train 0.0005972991767211479 valid 3.4819408028852195e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.616433193907142e-06\n",
      "  batch 101 loss: 0.00022023604717105627\n",
      "  batch 201 loss: 0.00018609414662932978\n",
      "LOSS train 0.00018990652378449803 valid 2.1875390302739106e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.2360545699484646e-06\n",
      "  batch 101 loss: 0.0001404571648890851\n",
      "  batch 201 loss: 0.00011695643250277499\n",
      "LOSS train 0.00012046709260562155 valid 1.9087749024038203e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.44526653457433e-06\n",
      "  batch 101 loss: 7.793945624143817e-05\n",
      "  batch 201 loss: 6.189558465848677e-05\n",
      "LOSS train 6.638083824917295e-05 valid 2.7940919608226977e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005519616976380348\n",
      "  batch 101 loss: 0.001446488110232167\n",
      "  batch 201 loss: 0.0006707639913656749\n",
      "LOSS train 0.0011290746789823045 valid 5.063214121037163e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.005554994568229e-06\n",
      "  batch 101 loss: 0.0004437071655411273\n",
      "  batch 201 loss: 0.00034288270529941655\n",
      "LOSS train 0.0003559676684151769 valid 2.5188121071550995e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.4590770297218113e-06\n",
      "  batch 101 loss: 0.0001846474054764258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.00013355228533328044\n",
      "LOSS train 0.0001402114473718036 valid 1.8365422874921933e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.557510202284903e-07\n",
      "  batch 101 loss: 8.391858424147358e-05\n",
      "  batch 201 loss: 4.147581607867323e-05\n",
      "LOSS train 5.298851526473406e-05 valid 5.409151708590798e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00020058611407876016\n",
      "  batch 101 loss: 0.0006038075647666119\n",
      "  batch 201 loss: 9.813552305786289e-05\n",
      "LOSS train 0.0003448561226885984 valid 6.25884422333911e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.0793703626841307e-06\n",
      "  batch 101 loss: 6.720952007526648e-05\n",
      "  batch 201 loss: 6.128602792159654e-05\n",
      "LOSS train 6.380582938921482e-05 valid 5.277977470541373e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.5408076655585317e-07\n",
      "  batch 101 loss: 6.186631666423637e-05\n",
      "  batch 201 loss: 6.261029113375117e-05\n",
      "LOSS train 6.182009067846186e-05 valid 5.340579809853807e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.792488860199228e-07\n",
      "  batch 101 loss: 6.33780893895164e-05\n",
      "  batch 201 loss: 6.390126832229725e-05\n",
      "LOSS train 6.316498731906997e-05 valid 5.384671385399997e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.7643241919577123e-05\n",
      "  batch 101 loss: 3.2627029026457424e-05\n",
      "  batch 201 loss: 1.1628655981894553e-05\n",
      "LOSS train 2.7974734333273883e-05 valid 1.5725494449725375e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.2478372961340935e-08\n",
      "  batch 101 loss: 3.496362527926067e-06\n",
      "  batch 201 loss: 2.43083338972383e-06\n",
      "LOSS train 2.6664483588221576e-06 valid 6.216617293830495e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.6119587346329355e-08\n",
      "  batch 101 loss: 2.1610912310165985e-06\n",
      "  batch 201 loss: 2.1414167116518e-06\n",
      "LOSS train 1.952343027581734e-06 valid 5.220710590947419e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.181680312991375e-08\n",
      "  batch 101 loss: 1.8218542882664224e-06\n",
      "  batch 201 loss: 2.0184256507604913e-06\n",
      "LOSS train 1.7567254288485442e-06 valid 4.25910593548906e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0009979676455259324\n",
      "  batch 101 loss: 0.009082105215638877\n",
      "  batch 201 loss: 0.00409951839945279\n",
      "LOSS train 0.0062256217431004126 valid 3.9878163079265505e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.926638349890709e-05\n",
      "  batch 101 loss: 0.002834910873207264\n",
      "  batch 201 loss: 0.0023014228645479307\n",
      "LOSS train 0.0024701084328846044 valid 5.609563959296793e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.231083111837506e-05\n",
      "  batch 101 loss: 0.0016445986916369293\n",
      "  batch 201 loss: 0.0014414705004310235\n",
      "LOSS train 0.0014294137922478088 valid 0.0002456332731526345\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.696552249602974e-06\n",
      "  batch 101 loss: 0.0009212170846876689\n",
      "  batch 201 loss: 0.000771576498518698\n",
      "LOSS train 0.0007942563719512731 valid 0.00014766324602533132\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00030696604400873187\n",
      "  batch 101 loss: 0.003180321799009107\n",
      "  batch 201 loss: 0.0013343539601191879\n",
      "LOSS train 0.001983952583811645 valid 0.00012568292731884867\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.705357227474451e-06\n",
      "  batch 101 loss: 0.000681899709161371\n",
      "  batch 201 loss: 0.0004798195735202171\n",
      "LOSS train 0.0005215011833337111 valid 1.936651642608922e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.770490245893598e-06\n",
      "  batch 101 loss: 0.0002446821452031145\n",
      "  batch 201 loss: 0.00016863499797182158\n",
      "LOSS train 0.00018289262340288957 valid 2.403164944553282e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.61865812819451e-07\n",
      "  batch 101 loss: 8.028837110032327e-05\n",
      "  batch 201 loss: 5.1405649919615826e-05\n",
      "LOSS train 5.810434684949358e-05 valid 1.3425023098534439e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00027607813477516176\n",
      "  batch 101 loss: 0.003591212178580463\n",
      "  batch 201 loss: 0.0016704247007146478\n",
      "LOSS train 0.00227861095223262 valid 0.00010326697520213202\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.116265965625644e-06\n",
      "  batch 101 loss: 0.0005097863146511372\n",
      "  batch 201 loss: 0.00029111048075719737\n",
      "LOSS train 0.00034574509937646236 valid 5.0569713494041935e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0330961958970875e-06\n",
      "  batch 101 loss: 0.00013705232260690536\n",
      "  batch 201 loss: 0.000107565653634083\n",
      "LOSS train 0.00011447284208564173 valid 5.204971967032179e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.774551391368732e-07\n",
      "  batch 101 loss: 8.559906809750828e-05\n",
      "  batch 201 loss: 7.862122654842096e-05\n",
      "LOSS train 7.950927414600341e-05 valid 5.3558327635983005e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017904644832015038\n",
      "  batch 101 loss: 0.004962863514665514\n",
      "  batch 201 loss: 0.001355199935787823\n",
      "LOSS train 0.0024927457245625386 valid 6.986455991864204e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.010794560192153e-06\n",
      "  batch 101 loss: 0.00018580694959382526\n",
      "  batch 201 loss: 0.00010323635629902128\n",
      "LOSS train 0.00012449409279638313 valid 4.7663394070696086e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.753292392299045e-07\n",
      "  batch 101 loss: 6.024322491612111e-05\n",
      "  batch 201 loss: 5.7177968828909796e-05\n",
      "LOSS train 5.761825953716956e-05 valid 5.115230305818841e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.581753687991295e-07\n",
      "  batch 101 loss: 5.674104793797596e-05\n",
      "  batch 201 loss: 5.720590713281126e-05\n",
      "LOSS train 5.6605241787530336e-05 valid 5.135514584253542e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 9.741121903061867e-05\n",
      "  batch 101 loss: 0.00011185114774207249\n",
      "  batch 201 loss: 3.6241669668015676e-05\n",
      "LOSS train 0.00010235542604552573 valid 6.617012695642188e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.5853187278480617e-08\n",
      "  batch 101 loss: 6.54591182887998e-05\n",
      "  batch 201 loss: 5.1580952424501446e-05\n",
      "LOSS train 5.4104715286984586e-05 valid 0.0001297652197536081\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.1837160097202286e-07\n",
      "  batch 101 loss: 3.970014670812816e-05\n",
      "  batch 201 loss: 4.1307498588594174e-05\n",
      "LOSS train 4.0516151037185e-05 valid 4.644464570446871e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.753678816385218e-08\n",
      "  batch 101 loss: 2.835193135638292e-05\n",
      "  batch 201 loss: 2.852770760569001e-05\n",
      "LOSS train 2.6325613024819976e-05 valid 6.68884240440093e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017964016646146775\n",
      "  batch 101 loss: 0.0006035370903555304\n",
      "  batch 201 loss: 0.00028360288866679183\n",
      "LOSS train 0.0004518123812339825 valid 6.908215254952665e-06\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.3670929658692332e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00020695056387921797\n",
      "  batch 201 loss: 0.00018810025401762686\n",
      "LOSS train 0.00018647054237809932 valid 6.819558620918542e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.282886805711314e-06\n",
      "  batch 101 loss: 0.00014148576461593622\n",
      "  batch 201 loss: 0.00011581277129153023\n",
      "LOSS train 0.00012214081267808777 valid 2.7460637284093536e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.992588583263569e-07\n",
      "  batch 101 loss: 9.17105015469133e-05\n",
      "  batch 201 loss: 7.773310866468819e-05\n",
      "LOSS train 8.095157299510155e-05 valid 5.260132638795767e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00025453863665461543\n",
      "  batch 101 loss: 0.0011954546126071363\n",
      "  batch 201 loss: 0.0006047143926844001\n",
      "LOSS train 0.0008830442267082864 valid 0.00018161296611651778\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.153109912294894e-06\n",
      "  batch 101 loss: 0.00039281829274841586\n",
      "  batch 201 loss: 0.00029180643250583673\n",
      "LOSS train 0.00031735261021848877 valid 3.105598807451315e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.259681205032393e-06\n",
      "  batch 101 loss: 0.00020911997416988014\n",
      "  batch 201 loss: 0.0001631858735345304\n",
      "LOSS train 0.0001716005488547442 valid 7.144871051423252e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.69755313033238e-07\n",
      "  batch 101 loss: 0.00011837957201350946\n",
      "  batch 201 loss: 0.00010457661719556199\n",
      "LOSS train 0.00010971291426574767 valid 0.00010267814650433138\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002879095077514648\n",
      "  batch 101 loss: 0.0018298812973080202\n",
      "  batch 201 loss: 0.0006920295511372387\n",
      "LOSS train 0.0011564450867895392 valid 0.00015330319001805037\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.497610450722277e-06\n",
      "  batch 101 loss: 0.00036115779919782654\n",
      "  batch 201 loss: 0.00026185473892837764\n",
      "LOSS train 0.00028035309448332487 valid 0.00010990611917804927\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.227406215155497e-07\n",
      "  batch 101 loss: 0.00018347354409343098\n",
      "  batch 201 loss: 0.00017004419642034917\n",
      "LOSS train 0.00016792123507925364 valid 5.289729961077683e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.593938011676072e-07\n",
      "  batch 101 loss: 0.00012949263349582908\n",
      "  batch 201 loss: 0.00011311997854136279\n",
      "LOSS train 0.0001169578392011064 valid 5.2100142056588084e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00011344734579324723\n",
      "  batch 101 loss: 0.0005739758658455684\n",
      "  batch 201 loss: 0.00016478384368383557\n",
      "LOSS train 0.00033785902888956737 valid 5.006340506952256e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.097363100503571e-07\n",
      "  batch 101 loss: 8.107653535262216e-05\n",
      "  batch 201 loss: 7.050475758660468e-05\n",
      "LOSS train 7.280135415408623e-05 valid 5.07343647768721e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.5275279262568804e-07\n",
      "  batch 101 loss: 6.601164083804179e-05\n",
      "  batch 201 loss: 6.484966872449149e-05\n",
      "LOSS train 6.498930364641004e-05 valid 5.168640927877277e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.044541856274009e-07\n",
      "  batch 101 loss: 6.434238533074676e-05\n",
      "  batch 201 loss: 6.45235175943526e-05\n",
      "LOSS train 6.38752949154691e-05 valid 5.0926108087878674e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.0722937770187854e-05\n",
      "  batch 101 loss: 0.007448490721471899\n",
      "  batch 201 loss: 0.0004130216490193561\n",
      "LOSS train 0.002910910427751429 valid 0.0011197923449799418\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.404656593687832e-06\n",
      "  batch 101 loss: 0.00019539562568979819\n",
      "  batch 201 loss: 0.000288348127937752\n",
      "LOSS train 0.00019870511188827426 valid 0.0006447985651902854\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.815931897610426e-06\n",
      "  batch 101 loss: 0.00016338722523869364\n",
      "  batch 201 loss: 0.000311002229548194\n",
      "LOSS train 0.00019434604069869197 valid 0.0006371723138727248\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.930221523158252e-06\n",
      "  batch 101 loss: 0.00015329486461496345\n",
      "  batch 201 loss: 0.0002239199439316053\n",
      "LOSS train 0.00015475629662797563 valid 0.0006371630006469786\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.9699290860444307e-05\n",
      "  batch 101 loss: 0.009937907805433497\n",
      "  batch 201 loss: 0.0016317507880739867\n",
      "LOSS train 0.004591034113808156 valid 0.0016196977812796831\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.337198566645384e-05\n",
      "  batch 101 loss: 0.001116423396160826\n",
      "  batch 201 loss: 0.0004991609777789563\n",
      "LOSS train 0.0007030421549423628 valid 0.00019273406360298395\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.110280049033463e-05\n",
      "  batch 101 loss: 0.00022751091099053157\n",
      "  batch 201 loss: 0.00011841754130728077\n",
      "LOSS train 0.00015310284338022442 valid 5.073559077573009e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.8443441735580565e-06\n",
      "  batch 101 loss: 6.976101960390224e-05\n",
      "  batch 201 loss: 3.06750207892037e-05\n",
      "LOSS train 4.377404244330333e-05 valid 1.7901546016219072e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00020232684910297393\n",
      "  batch 101 loss: 0.007509681377559901\n",
      "  batch 201 loss: 0.0019457238272298128\n",
      "LOSS train 0.0037504629048198163 valid 0.0001588039449416101\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.194010445848107e-06\n",
      "  batch 101 loss: 0.00033023314354068133\n",
      "  batch 201 loss: 7.673633823287673e-05\n",
      "LOSS train 0.00016402664735260626 valid 2.6816731406142935e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.8469593487679959e-06\n",
      "  batch 101 loss: 4.774473345150909e-05\n",
      "  batch 201 loss: 1.2891145202047483e-05\n",
      "LOSS train 2.6533980690479712e-05 valid 2.7831354600493796e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.243657455546782e-07\n",
      "  batch 101 loss: 2.6462377957159332e-05\n",
      "  batch 201 loss: 1.5699408984346518e-05\n",
      "LOSS train 2.4575249583974186e-05 valid 1.85377193702152e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017485782504081726\n",
      "  batch 101 loss: 0.012808118693064897\n",
      "  batch 201 loss: 0.001844970941892825\n",
      "LOSS train 0.0055586067986744545 valid 6.264803960220888e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.2215349599719048e-06\n",
      "  batch 101 loss: 0.00015345861611422152\n",
      "  batch 201 loss: 2.8014875069857226e-05\n",
      "LOSS train 7.280086819740799e-05 valid 1.702697409200482e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.8244916645926424e-07\n",
      "  batch 101 loss: 2.3428215513376927e-05\n",
      "  batch 201 loss: 2.942621536703882e-05\n",
      "LOSS train 2.6400905275521912e-05 valid 6.206760735949501e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.134429324651137e-07\n",
      "  batch 101 loss: 2.6441045670253515e-05\n",
      "  batch 201 loss: 2.1298926578765532e-05\n",
      "LOSS train 2.2232377856305188e-05 valid 9.993854291678872e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002481333911418915\n",
      "  batch 101 loss: 0.014914807144086807\n",
      "  batch 201 loss: 0.00048020352489402284\n",
      "LOSS train 0.005744807768675252 valid 9.300625242758542e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.709583302726969e-06\n",
      "  batch 101 loss: 4.4626646572396564e-05\n",
      "  batch 201 loss: 2.7766144930865267e-05\n",
      "LOSS train 3.98453612083708e-05 valid 7.32664339011535e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.9724193154834213e-07\n",
      "  batch 101 loss: 3.525361395077198e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 3.8747176113247405e-05\n",
      "LOSS train 4.344046148630379e-05 valid 2.8415495762601495e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.084995710698422e-07\n",
      "  batch 101 loss: 3.3489210891275435e-05\n",
      "  batch 201 loss: 3.8968689568719125e-05\n",
      "LOSS train 4.208072621142971e-05 valid 3.781074701691978e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.428256303071976e-05\n",
      "  batch 101 loss: 0.001188588150725991\n",
      "  batch 201 loss: 9.952167056326289e-06\n",
      "LOSS train 0.00045910945230126 valid 1.6304671589750797e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.453534372965805e-07\n",
      "  batch 101 loss: 5.872306595051668e-06\n",
      "  batch 201 loss: 2.5579361508221155e-06\n",
      "LOSS train 4.584649877391205e-06 valid 1.294404955842765e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.238678618799895e-07\n",
      "  batch 101 loss: 3.9664170100195405e-06\n",
      "  batch 201 loss: 1.9813236363575014e-06\n",
      "LOSS train 3.670856235383146e-06 valid 1.1871391507156659e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.406266503385268e-07\n",
      "  batch 101 loss: 3.478716540428195e-06\n",
      "  batch 201 loss: 2.0380418824572643e-06\n",
      "LOSS train 3.765457986759931e-06 valid 8.8528249762021e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.24157614260912e-06\n",
      "  batch 101 loss: 0.0016466687276624726\n",
      "  batch 201 loss: 0.00010170413657760947\n",
      "LOSS train 0.0006577972324945329 valid 9.603055514162406e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.619610313558951e-07\n",
      "  batch 101 loss: 5.433651246221416e-05\n",
      "  batch 201 loss: 7.986015149072045e-05\n",
      "LOSS train 7.076352785888658e-05 valid 6.673692405456677e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.268355693668127e-07\n",
      "  batch 101 loss: 8.581808307326356e-05\n",
      "  batch 201 loss: 8.971070679308468e-05\n",
      "LOSS train 8.917634151521104e-05 valid 7.566738349851221e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.053587564267218e-07\n",
      "  batch 101 loss: 9.571968175350776e-05\n",
      "  batch 201 loss: 9.843031696050276e-05\n",
      "LOSS train 9.839486966149587e-05 valid 8.205965423258021e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.7845309600234034e-05\n",
      "  batch 101 loss: 0.0009832098623633102\n",
      "  batch 201 loss: 6.742561796727387e-05\n",
      "LOSS train 0.000421312652256497 valid 6.0387697885744274e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.828899520565756e-07\n",
      "  batch 101 loss: 7.847108657188073e-05\n",
      "  batch 201 loss: 8.400841876209598e-05\n",
      "LOSS train 8.302548838987322e-05 valid 7.211141200968996e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.365930989384651e-07\n",
      "  batch 101 loss: 9.223919455962459e-05\n",
      "  batch 201 loss: 9.595521157507392e-05\n",
      "LOSS train 9.564605833085287e-05 valid 8.073055505519733e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.993957064580172e-07\n",
      "  batch 101 loss: 0.00010146896608603128\n",
      "  batch 201 loss: 0.00010353891289355488\n",
      "LOSS train 0.00010381014422842456 valid 8.551578503102064e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000296374075114727\n",
      "  batch 101 loss: 0.007385135752847418\n",
      "  batch 201 loss: 0.0011939121753675862\n",
      "LOSS train 0.0033892841353814628 valid 0.0004917025216855109\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.243888542987406e-06\n",
      "  batch 101 loss: 0.00020292840559704928\n",
      "  batch 201 loss: 7.171536778059817e-05\n",
      "LOSS train 0.00012064713196662361 valid 5.44612375961151e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.1696370317367837e-07\n",
      "  batch 101 loss: 6.665679891739274e-05\n",
      "  batch 201 loss: 6.876802275201044e-05\n",
      "LOSS train 6.79555263053065e-05 valid 5.764363959315233e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.122225047671236e-07\n",
      "  batch 101 loss: 7.239380108785554e-05\n",
      "  batch 201 loss: 7.474307145912463e-05\n",
      "LOSS train 7.40134046315352e-05 valid 6.18774356553331e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004163716733455658\n",
      "  batch 101 loss: 0.006576639879494905\n",
      "  batch 201 loss: 0.0005249820293829543\n",
      "LOSS train 0.002775263582330582 valid 6.340889376588166e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.613599154865369e-07\n",
      "  batch 101 loss: 6.665195938694524e-05\n",
      "  batch 201 loss: 6.209161799688445e-05\n",
      "LOSS train 6.394869840386534e-05 valid 5.349246202968061e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.840171459363773e-07\n",
      "  batch 101 loss: 6.516806993658975e-05\n",
      "  batch 201 loss: 6.733958590757539e-05\n",
      "LOSS train 6.651663769987416e-05 valid 5.7860288507072255e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.251617742236704e-07\n",
      "  batch 101 loss: 6.824002526172989e-05\n",
      "  batch 201 loss: 7.087188516834431e-05\n",
      "LOSS train 7.019072074645975e-05 valid 6.014792961650528e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0016965803503990174\n",
      "  batch 101 loss: 0.09332689393311738\n",
      "  batch 201 loss: 0.016802347977645696\n",
      "LOSS train 0.04151889023333941 valid 0.0006912265671417117\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.350361414253712e-06\n",
      "  batch 101 loss: 0.00024413709122995898\n",
      "  batch 201 loss: 5.756764208797449e-05\n",
      "LOSS train 0.00012562892662333234 valid 5.095430606161244e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.3605854948982596e-07\n",
      "  batch 101 loss: 5.415691261077882e-05\n",
      "  batch 201 loss: 5.454069961160712e-05\n",
      "LOSS train 5.374648498261758e-05 valid 5.112778671900742e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.584023241070099e-07\n",
      "  batch 101 loss: 5.503580648110074e-05\n",
      "  batch 201 loss: 5.541517260098772e-05\n",
      "LOSS train 5.4636305038588664e-05 valid 5.1267190428916365e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.001982920318841934\n",
      "  batch 101 loss: 0.015046833655796945\n",
      "  batch 201 loss: 0.004766340358182788\n",
      "LOSS train 0.008980129337988986 valid 0.00042479237890802324\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.9241309966892004e-05\n",
      "  batch 101 loss: 0.0029463949205819516\n",
      "  batch 201 loss: 0.002134354985319078\n",
      "LOSS train 0.0022831156844743987 valid 0.00017702385957818478\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0055251186713576e-05\n",
      "  batch 101 loss: 0.0010352667549159379\n",
      "  batch 201 loss: 0.0007706572458846495\n",
      "LOSS train 0.0008226179060672884 valid 3.336600275360979e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.883343496359885e-06\n",
      "  batch 101 loss: 0.00042747919433168137\n",
      "  batch 201 loss: 0.0003023842573020374\n",
      "LOSS train 0.0003279685619811275 valid 1.5485267795156687e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.7764884978532791e-06\n",
      "  batch 101 loss: 0.00010029420406567623\n",
      "  batch 201 loss: 0.0001213440313654246\n",
      "LOSS train 0.00011380298718198395 valid 9.126951772486791e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1846074630739167e-06\n",
      "  batch 101 loss: 0.0001165445059166359\n",
      "  batch 201 loss: 0.00011531126020770443\n",
      "LOSS train 0.00011675711815275426 valid 9.068605868378654e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1746492236852646e-06\n",
      "  batch 101 loss: 0.00011573635882200506\n",
      "  batch 201 loss: 0.00011488825127173641\n",
      "LOSS train 0.00011621183441968655 valid 9.057032002601773e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.172669872175902e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.0001155479196268061\n",
      "  batch 201 loss: 0.00011476270923679977\n",
      "LOSS train 0.00011606774742661787 valid 9.05273700482212e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0019107469916343689\n",
      "  batch 101 loss: 0.03478788926266134\n",
      "  batch 201 loss: 0.010944743012078106\n",
      "LOSS train 0.018422813299743136 valid 0.000912196293938905\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.1066481713205577e-05\n",
      "  batch 101 loss: 0.0012516781507292763\n",
      "  batch 201 loss: 0.00040864225054974666\n",
      "LOSS train 0.0006824986027419779 valid 6.958851736271754e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.8030601495411248e-06\n",
      "  batch 101 loss: 0.00019932839706598315\n",
      "  batch 201 loss: 9.3927280868229e-05\n",
      "LOSS train 0.0001267496553713826 valid 5.094232255942188e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.066369390580803e-07\n",
      "  batch 101 loss: 6.687308454274899e-05\n",
      "  batch 201 loss: 6.503886404971127e-05\n",
      "LOSS train 6.529639766072567e-05 valid 5.2647097618319094e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.887904204428196e-05\n",
      "  batch 101 loss: 0.0003225345781402211\n",
      "  batch 201 loss: 0.00010884747542149853\n",
      "LOSS train 0.0002115627491193147 valid 8.846657874528319e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1664312478387728e-06\n",
      "  batch 101 loss: 0.00011440483002843394\n",
      "  batch 201 loss: 0.00011456153881795217\n",
      "LOSS train 0.00011560413290018894 valid 8.987126057036221e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1389813153073191e-06\n",
      "  batch 101 loss: 0.00011690504384830547\n",
      "  batch 201 loss: 0.00011992666727877576\n",
      "LOSS train 0.00011868517043373666 valid 8.885811257641762e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.2660236097872257e-06\n",
      "  batch 101 loss: 0.00011564848679540774\n",
      "  batch 201 loss: 0.0001149468734880088\n",
      "LOSS train 0.00011629302206324776 valid 9.034278627950698e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00040900684893131257\n",
      "  batch 101 loss: 0.0005353089408163214\n",
      "  batch 201 loss: 6.941711655599647e-05\n",
      "LOSS train 0.0003777472590576218 valid 3.975395520683378e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.989878703374416e-07\n",
      "  batch 101 loss: 8.988525617610322e-06\n",
      "  batch 201 loss: 3.527649429315716e-06\n",
      "LOSS train 5.72975294269385e-06 valid 3.0478336157102603e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.077162197470897e-08\n",
      "  batch 101 loss: 6.2690747211036065e-06\n",
      "  batch 201 loss: 5.634426391480929e-06\n",
      "LOSS train 5.89321227207395e-06 valid 1.6608561054454185e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.303897629957647e-08\n",
      "  batch 101 loss: 7.010335553445657e-06\n",
      "  batch 201 loss: 6.835597997110199e-06\n",
      "LOSS train 6.713333237856591e-06 valid 9.12781342776725e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00024771180003881456\n",
      "  batch 101 loss: 0.0006326812123006676\n",
      "  batch 201 loss: 0.00021310495219950098\n",
      "LOSS train 0.00044563397397470554 valid 7.303577876882628e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.2113217235310004e-06\n",
      "  batch 101 loss: 0.00011636226354312384\n",
      "  batch 201 loss: 8.427434404438827e-05\n",
      "LOSS train 8.81628411828524e-05 valid 3.4946187952300534e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.873387347790413e-07\n",
      "  batch 101 loss: 4.263602738319605e-05\n",
      "  batch 201 loss: 5.3797802929693714e-05\n",
      "LOSS train 5.234996101185411e-05 valid 0.00013065933308098465\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.640828774427064e-07\n",
      "  batch 101 loss: 6.0634008455053846e-05\n",
      "  batch 201 loss: 6.953893820991652e-05\n",
      "LOSS train 6.780545162398947e-05 valid 8.839684596750885e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.138483734801412e-05\n",
      "  batch 101 loss: 0.00035756816319917564\n",
      "  batch 201 loss: 7.685595368457143e-05\n",
      "LOSS train 0.00018740426445959372 valid 0.00016218755627050996\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.587363193626515e-07\n",
      "  batch 101 loss: 6.490115239103033e-05\n",
      "  batch 201 loss: 7.425585899909493e-05\n",
      "LOSS train 7.348517300047223e-05 valid 7.027956598903984e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.167870535340626e-08\n",
      "  batch 101 loss: 9.91389773935225e-05\n",
      "  batch 201 loss: 0.000116044165972653\n",
      "LOSS train 0.00011262013893948668 valid 6.717782525811344e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.327974890358746e-07\n",
      "  batch 101 loss: 0.00012787108569341398\n",
      "  batch 201 loss: 0.00012522192269727838\n",
      "LOSS train 0.00012708660467282637 valid 8.847394201438874e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.623504445888102e-05\n",
      "  batch 101 loss: 0.000723093240376329\n",
      "  batch 201 loss: 0.00010461960904649459\n",
      "LOSS train 0.00033367917921578325 valid 8.576708205509931e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.343873923877254e-07\n",
      "  batch 101 loss: 9.004228078083542e-05\n",
      "  batch 201 loss: 0.00011179402706602559\n",
      "LOSS train 0.00010405023310412393 valid 8.723813516553491e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.146746362792328e-06\n",
      "  batch 101 loss: 0.00011002311441814072\n",
      "  batch 201 loss: 0.00011157609471297291\n",
      "LOSS train 0.00011188651983514988 valid 8.963404252426699e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1747236567316577e-06\n",
      "  batch 101 loss: 0.00011321396073981305\n",
      "  batch 201 loss: 0.00011292038560895889\n",
      "LOSS train 0.00011406752639520027 valid 8.959950355347246e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006486946344375611\n",
      "  batch 101 loss: 0.005898514055879787\n",
      "  batch 201 loss: 0.0006992690666811541\n",
      "LOSS train 0.002722632648731836 valid 5.1564667955972254e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1380838986951858e-06\n",
      "  batch 101 loss: 0.00017887683610751993\n",
      "  batch 201 loss: 0.00011658147351226943\n",
      "LOSS train 0.00013772599852397965 valid 6.319354724837467e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.921882206574083e-07\n",
      "  batch 101 loss: 9.39233111921567e-05\n",
      "  batch 201 loss: 8.836548526687693e-05\n",
      "LOSS train 9.025402377762438e-05 valid 6.914551340742037e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.194511610781774e-07\n",
      "  batch 101 loss: 8.959993155713164e-05\n",
      "  batch 201 loss: 9.21126500452374e-05\n",
      "LOSS train 9.189213008476511e-05 valid 7.602968253195286e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.692084811627865e-05\n",
      "  batch 101 loss: 0.1198308885120059\n",
      "  batch 201 loss: 0.00027652358400246155\n",
      "LOSS train 0.044054070740199784 valid 0.0021221954375505447\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.9165614657104016e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.0005567665042940462\n",
      "  batch 201 loss: 0.0001832452890039349\n",
      "LOSS train 0.000353350696003549 valid 0.0020886966958642006\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.59716671705246e-05\n",
      "  batch 101 loss: 0.0006198380421074034\n",
      "  batch 201 loss: 0.00020435403872170354\n",
      "LOSS train 0.0003601369322381781 valid 0.0021153355482965708\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.488123744726181e-05\n",
      "  batch 101 loss: 0.0008453301915460542\n",
      "  batch 201 loss: 0.0002542031439725179\n",
      "LOSS train 0.0005054444384138781 valid 0.0018586020451039076\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001462587248533964\n",
      "  batch 101 loss: 0.11709503446007147\n",
      "  batch 201 loss: 0.00157985549303703\n",
      "LOSS train 0.043824166362472355 valid 0.00015192906721495092\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.193690113723278e-05\n",
      "  batch 101 loss: 0.0008078990445937962\n",
      "  batch 201 loss: 0.000497339429857675\n",
      "LOSS train 0.0005511363566662918 valid 7.934957830002531e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.2308282495941968e-06\n",
      "  batch 101 loss: 0.00020640885333705227\n",
      "  batch 201 loss: 8.409303733060369e-05\n",
      "LOSS train 0.00011905608545477509 valid 5.065121877123602e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.862662459956482e-07\n",
      "  batch 101 loss: 3.92049998845323e-05\n",
      "  batch 201 loss: 3.0105845080470317e-05\n",
      "LOSS train 2.9060270246304338e-05 valid 7.747764357191045e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00034265730530023573\n",
      "  batch 101 loss: 0.10936568853445351\n",
      "  batch 201 loss: 0.002933851081179455\n",
      "LOSS train 0.04161315961828756 valid 0.00015666478429920971\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.355022774077952e-05\n",
      "  batch 101 loss: 0.0006658108232659288\n",
      "  batch 201 loss: 0.00025243457159376706\n",
      "LOSS train 0.0003624651052542594 valid 5.9195899666519836e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.155351201305166e-06\n",
      "  batch 101 loss: 4.794229458639165e-05\n",
      "  batch 201 loss: 2.0149245597167464e-05\n",
      "LOSS train 2.9012274007116156e-05 valid 9.00096620171098e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.2001246432191693e-07\n",
      "  batch 101 loss: 1.0664290232398344e-05\n",
      "  batch 201 loss: 9.292472417428144e-06\n",
      "LOSS train 9.524229916605158e-06 valid 6.729451342835091e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00034957997500896455\n",
      "  batch 101 loss: 0.11999481576029211\n",
      "  batch 201 loss: 0.0028816471807658673\n",
      "LOSS train 0.045294826735159034 valid 7.889015250839293e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.83493451308459e-06\n",
      "  batch 101 loss: 0.0001733754446831881\n",
      "  batch 201 loss: 3.253587084145693e-05\n",
      "LOSS train 8.36655323717543e-05 valid 2.7841402697958983e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.500548963434994e-07\n",
      "  batch 101 loss: 1.8902561232607696e-05\n",
      "  batch 201 loss: 2.463574824787429e-05\n",
      "LOSS train 2.1258446755855535e-05 valid 1.7958760508918203e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.9296374375699088e-07\n",
      "  batch 101 loss: 1.4854491801088444e-05\n",
      "  batch 201 loss: 1.747244742318799e-05\n",
      "LOSS train 1.6222937747876304e-05 valid 1.000700649456121e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00033595968037843706\n",
      "  batch 101 loss: 0.1275991582777351\n",
      "  batch 201 loss: 0.000926080501958495\n",
      "LOSS train 0.04722454317886128 valid 2.1504090909729712e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.0042341202497484e-06\n",
      "  batch 101 loss: 5.6251309406434305e-05\n",
      "  batch 201 loss: 2.105293478052772e-05\n",
      "LOSS train 3.594352239945563e-05 valid 3.503245170577429e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.489626113965641e-08\n",
      "  batch 101 loss: 2.6135550185699686e-05\n",
      "  batch 201 loss: 4.505970512127533e-05\n",
      "LOSS train 3.710192096490233e-05 valid 4.996922507416457e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.702714356128127e-07\n",
      "  batch 101 loss: 4.19254916596401e-05\n",
      "  batch 201 loss: 4.965926704244339e-05\n",
      "LOSS train 4.616460819639815e-05 valid 3.0328663342515938e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00014509762637317182\n",
      "  batch 101 loss: 0.024954795657565684\n",
      "  batch 201 loss: 0.0023976939988367006\n",
      "LOSS train 0.010289823876964704 valid 6.234613010747125e-06\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.3679360715032086e-08\n",
      "  batch 101 loss: 9.784759253079756e-06\n",
      "  batch 201 loss: 5.260017323962529e-06\n",
      "LOSS train 7.284403554901903e-06 valid 9.47049556998536e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.605549914529547e-07\n",
      "  batch 101 loss: 5.939010484468099e-06\n",
      "  batch 201 loss: 3.865192099397064e-06\n",
      "LOSS train 4.520756674893604e-06 valid 2.9166067179176025e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1201642564628856e-08\n",
      "  batch 101 loss: 3.380398520533845e-06\n",
      "  batch 201 loss: 3.119975362224636e-06\n",
      "LOSS train 3.2928673592638564e-06 valid 5.873710506421048e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.497327540069819e-05\n",
      "  batch 101 loss: 0.01929780935155577\n",
      "  batch 201 loss: 0.00020556812718666606\n",
      "LOSS train 0.007185298283123813 valid 1.3077454241283704e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.475165456417017e-07\n",
      "  batch 101 loss: 3.170346968090598e-05\n",
      "  batch 201 loss: 1.1276967339881594e-05\n",
      "LOSS train 1.7546128176695092e-05 valid 2.713395588216372e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.212418278053519e-08\n",
      "  batch 101 loss: 9.08794036973859e-06\n",
      "  batch 201 loss: 6.753509593124818e-06\n",
      "LOSS train 6.880157033783323e-06 valid 2.759204107860569e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.3086313376552424e-08\n",
      "  batch 101 loss: 1.0531336998838015e-05\n",
      "  batch 201 loss: 7.78343390692271e-06\n",
      "LOSS train 8.295404164653355e-06 valid 5.052035703556612e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017348544672131537\n",
      "  batch 101 loss: 0.05667371195978376\n",
      "  batch 201 loss: 0.000778817893260566\n",
      "LOSS train 0.021123999536626505 valid 5.318859621183947e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.7081579648656773e-07\n",
      "  batch 101 loss: 6.397320343239699e-05\n",
      "  batch 201 loss: 6.692552170534327e-05\n",
      "LOSS train 6.596603915878094e-05 valid 5.71579766983632e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.988496584701352e-07\n",
      "  batch 101 loss: 7.206374913494073e-05\n",
      "  batch 201 loss: 7.539923143667693e-05\n",
      "LOSS train 7.460510743420364e-05 valid 6.349739123834297e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.559455505339429e-07\n",
      "  batch 101 loss: 8.150332905643154e-05\n",
      "  batch 201 loss: 8.541383002011571e-05\n",
      "LOSS train 8.487017518309719e-05 valid 7.259051199071109e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.452570669353008e-05\n",
      "  batch 101 loss: 0.04998807835625484\n",
      "  batch 201 loss: 0.0007216723276360426\n",
      "LOSS train 0.018616289774586337 valid 1.818361306504812e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.8867387047503144e-07\n",
      "  batch 101 loss: 3.2896128768697966e-05\n",
      "  batch 201 loss: 3.3374989543517584e-05\n",
      "LOSS train 3.322880042398851e-05 valid 1.808301567507442e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.6518227969063446e-07\n",
      "  batch 101 loss: 3.4259957706126445e-05\n",
      "  batch 201 loss: 3.363901985721895e-05\n",
      "LOSS train 3.4073813632138616e-05 valid 1.7171403669635765e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.0759986000484786e-07\n",
      "  batch 101 loss: 3.481905368971638e-05\n",
      "  batch 201 loss: 3.643047654804832e-05\n",
      "LOSS train 3.5739806549334276e-05 valid 1.627521305636037e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.035261485725641e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.005754436559491296\n",
      "  batch 201 loss: 0.00011253094365201832\n",
      "LOSS train 0.0022559062263765193 valid 8.023683039937168e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.892374509945512e-07\n",
      "  batch 101 loss: 0.0001260224954859268\n",
      "  batch 201 loss: 0.0001222746533213126\n",
      "LOSS train 0.00012107235411938649 valid 5.20052490173839e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.261820762010757e-07\n",
      "  batch 101 loss: 0.00010142972198934786\n",
      "  batch 201 loss: 8.734480517546218e-05\n",
      "LOSS train 8.930185364989408e-05 valid 9.343666170025244e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.3792523431184234e-08\n",
      "  batch 101 loss: 7.260754221988464e-05\n",
      "  batch 201 loss: 6.588944291820554e-05\n",
      "LOSS train 6.642635672371078e-05 valid 0.0001289426872972399\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006445062160491944\n",
      "  batch 101 loss: 0.0011798063106880363\n",
      "  batch 201 loss: 0.0001320395953393927\n",
      "LOSS train 0.000722878025716048 valid 4.06627259508241e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.3481403483601755e-08\n",
      "  batch 101 loss: 1.7177729828290465e-05\n",
      "  batch 201 loss: 7.086754959573227e-06\n",
      "LOSS train 9.832771849505161e-06 valid 5.116833108331775e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2412292562657966e-08\n",
      "  batch 101 loss: 4.044414927477646e-06\n",
      "  batch 201 loss: 2.49169958280504e-06\n",
      "LOSS train 3.1115667139296346e-06 valid 3.978606855525868e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.3984155177458886e-08\n",
      "  batch 101 loss: 3.4478634141521526e-06\n",
      "  batch 201 loss: 2.443247198300469e-06\n",
      "LOSS train 2.7106121734836477e-06 valid 6.419897545129061e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.9470530096441506e-05\n",
      "  batch 101 loss: 0.014193564856395825\n",
      "  batch 201 loss: 0.00021272884630889167\n",
      "LOSS train 0.0053160378179649805 valid 3.651452061603777e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.7387544580269607e-07\n",
      "  batch 101 loss: 5.835168590238027e-05\n",
      "  batch 201 loss: 2.949314316538221e-05\n",
      "LOSS train 4.329512021852416e-05 valid 8.213678665924817e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3396488793659955e-06\n",
      "  batch 101 loss: 0.00010874048023651995\n",
      "  batch 201 loss: 0.00012915667947709152\n",
      "LOSS train 0.00012302252924620497 valid 6.761505210306495e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.801351603120566e-07\n",
      "  batch 101 loss: 0.00012756057275055356\n",
      "  batch 201 loss: 0.00012028676655290838\n",
      "LOSS train 0.00012178319280915758 valid 5.1193437684560195e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00013744206167757512\n",
      "  batch 101 loss: 0.000992913505292563\n",
      "  batch 201 loss: 0.00012257633358444764\n",
      "LOSS train 0.00048473474076537646 valid 7.67844685469754e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.543337475595763e-08\n",
      "  batch 101 loss: 7.750270353426458e-05\n",
      "  batch 201 loss: 6.429955976500423e-05\n",
      "LOSS train 6.680034153725082e-05 valid 0.00014460596139542758\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.826393028954044e-07\n",
      "  batch 101 loss: 5.75024824561865e-05\n",
      "  batch 201 loss: 5.835865262213247e-05\n",
      "LOSS train 5.7339632814772054e-05 valid 0.00018789873865898699\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.343713928596117e-07\n",
      "  batch 101 loss: 6.024529044907467e-05\n",
      "  batch 201 loss: 6.366910397900938e-05\n",
      "LOSS train 6.237606136145613e-05 valid 0.00023723446065559983\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00047423426061868665\n",
      "  batch 101 loss: 0.024864604914328084\n",
      "  batch 201 loss: 0.0009470934030832723\n",
      "LOSS train 0.009712935169136804 valid 0.00010533248132560402\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.6982754934579132e-06\n",
      "  batch 101 loss: 0.000169076671518269\n",
      "  batch 201 loss: 0.0001217408726188296\n",
      "LOSS train 0.00013985024155432595 valid 9.437550033908337e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2387044262140989e-06\n",
      "  batch 101 loss: 0.00011023895031144093\n",
      "  batch 201 loss: 0.00011244444797313235\n",
      "LOSS train 0.00011411435308427277 valid 8.941104169934988e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1538729449966922e-06\n",
      "  batch 101 loss: 0.00012308216030248786\n",
      "  batch 201 loss: 0.00012488287375958862\n",
      "LOSS train 0.00012587448608301102 valid 7.106917473720387e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0025402116775512695\n",
      "  batch 101 loss: 0.016860327318245254\n",
      "  batch 201 loss: 0.00010457498948198917\n",
      "LOSS train 0.007174871453010186 valid 8.868960867403075e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1370234278729185e-06\n",
      "  batch 101 loss: 0.00011033043508632546\n",
      "  batch 201 loss: 0.00011112606732865515\n",
      "LOSS train 0.00011398189851990284 valid 8.419041841989383e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0369748633820563e-06\n",
      "  batch 101 loss: 0.0001248581956679118\n",
      "  batch 201 loss: 0.0001252660735713107\n",
      "LOSS train 0.00012594392889542634 valid 5.921810952713713e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.537843026104383e-07\n",
      "  batch 101 loss: 0.0001220743546787162\n",
      "  batch 201 loss: 0.00011244681882317308\n",
      "LOSS train 0.00011395113296808405 valid 5.527857138076797e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.839671172201634e-05\n",
      "  batch 101 loss: 0.011527682986126138\n",
      "  batch 201 loss: 8.519617173760707e-05\n",
      "LOSS train 0.004288981924703429 valid 5.933301872573793e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.161521130503388e-08\n",
      "  batch 101 loss: 5.8818911418256904e-05\n",
      "  batch 201 loss: 6.126011711671709e-05\n",
      "LOSS train 6.496117281287443e-05 valid 5.056621739640832e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.626260175020434e-07\n",
      "  batch 101 loss: 0.00011705948284884471\n",
      "  batch 201 loss: 0.0001249077351070582\n",
      "LOSS train 0.00012324673284496676 valid 7.75612861616537e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.413167572347447e-07\n",
      "  batch 101 loss: 0.00012779148804838768\n",
      "  batch 201 loss: 0.000123919468069289\n",
      "LOSS train 0.00012515556090417101 valid 5.291689740261063e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00028350574895739554\n",
      "  batch 101 loss: 0.007111451088276226\n",
      "  batch 201 loss: 0.00025108299632847775\n",
      "LOSS train 0.002840923441835379 valid 3.713852493092418e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4492572518065571e-06\n",
      "  batch 101 loss: 9.485801907430868e-05\n",
      "  batch 201 loss: 7.032316487311619e-05\n",
      "LOSS train 7.946661085892689e-05 valid 0.00017732428386807442\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0162571561522782e-06\n",
      "  batch 101 loss: 8.014638258828199e-05\n",
      "  batch 201 loss: 7.175601265771547e-05\n",
      "LOSS train 7.229561467513802e-05 valid 9.945363854058087e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1655615708150436e-07\n",
      "  batch 101 loss: 6.929357547960535e-05\n",
      "  batch 201 loss: 7.128901360374584e-05\n",
      "LOSS train 7.007233513595499e-05 valid 9.207463153870776e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00023758742958307266\n",
      "  batch 101 loss: 0.013940167616819963\n",
      "  batch 201 loss: 0.0002184900184511207\n",
      "LOSS train 0.005291576724850309 valid 6.51756563456729e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.641569780185818e-07\n",
      "  batch 101 loss: 9.087486183716465e-05\n",
      "  batch 201 loss: 9.549008144858817e-05\n",
      "LOSS train 9.62414615886594e-05 valid 8.570985664846376e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0481724166311324e-06\n",
      "  batch 101 loss: 0.000111364774104743\n",
      "  batch 201 loss: 0.00011770258600563466\n",
      "LOSS train 0.00011794038046134999 valid 8.435355266556144e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0644562280504033e-06\n",
      "  batch 101 loss: 0.00012711290552800848\n",
      "  batch 201 loss: 0.0001255969293583803\n",
      "LOSS train 0.00012672247841445352 valid 5.798571146442555e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001624608226120472\n",
      "  batch 101 loss: 0.010038388452667277\n",
      "  batch 201 loss: 0.00011423015872424003\n",
      "LOSS train 0.0038040679417783076 valid 8.147848711814731e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.848393528955058e-07\n",
      "  batch 101 loss: 0.00010166903928165993\n",
      "  batch 201 loss: 0.00011175991769817983\n",
      "LOSS train 0.00011129653539331317 valid 8.689257083460689e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.115480117732659e-06\n",
      "  batch 101 loss: 0.00012591824483422444\n",
      "  batch 201 loss: 0.00012587708307364664\n",
      "LOSS train 0.000126377645263025 valid 5.6643199059180915e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.865786468144506e-07\n",
      "  batch 101 loss: 0.00012046568648202083\n",
      "  batch 201 loss: 0.00010975793493457786\n",
      "LOSS train 0.000111475210315601 valid 5.807343404740095e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.6108338022604586e-05\n",
      "  batch 101 loss: 0.011870112620563304\n",
      "  batch 201 loss: 7.726821736923739e-05\n",
      "LOSS train 0.004405541998036221 valid 7.250913768075407e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.489067840855569e-07\n",
      "  batch 101 loss: 9.920897816527941e-05\n",
      "  batch 201 loss: 0.00011008409031092014\n",
      "LOSS train 0.00010934386202009861 valid 8.75730111147277e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1347137478878721e-06\n",
      "  batch 101 loss: 0.0001255050730998164\n",
      "  batch 201 loss: 0.00012660524382908988\n",
      "LOSS train 0.00012778369092413227 valid 5.811338996863924e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.248713932815007e-07\n",
      "  batch 101 loss: 0.0001215515399871947\n",
      "  batch 201 loss: 0.0001115008873489387\n",
      "LOSS train 0.00011307927052832264 valid 5.634027547785081e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002411643974483013\n",
      "  batch 101 loss: 2.069895470886113\n",
      "  batch 201 loss: 0.0004778484787857451\n",
      "LOSS train 0.7585097614439638 valid 0.001389703364111483\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.160398919135332e-05\n",
      "  batch 101 loss: 0.0010152464383918413\n",
      "  batch 201 loss: 0.0001818860741559547\n",
      "LOSS train 0.0004873074199933845 valid 0.0014279303140938282\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.3740748185664416e-05\n",
      "  batch 101 loss: 0.0011675206129712025\n",
      "  batch 201 loss: 0.0002210944310081686\n",
      "LOSS train 0.0005309237023289998 valid 0.001138740568421781\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.516605658456683e-05\n",
      "  batch 101 loss: 0.0014810213585269593\n",
      "  batch 201 loss: 0.0002961206638656222\n",
      "LOSS train 0.0007032122259116167 valid 0.0011186995543539524\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00022447440773248672\n",
      "  batch 101 loss: 2.0838921181706245\n",
      "  batch 201 loss: 0.0023534562264103443\n",
      "LOSS train 0.7647362442134075 valid 0.0010719706770032644\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.7271082615479827e-05\n",
      "  batch 101 loss: 0.0016607883665710687\n",
      "  batch 201 loss: 0.0006412979916785844\n",
      "LOSS train 0.0009521137003619701 valid 0.0004474796587601304\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.7626486048102375e-06\n",
      "  batch 101 loss: 0.00046663558307045603\n",
      "  batch 201 loss: 0.00013531346230593043\n",
      "LOSS train 0.0002470621588638209 valid 7.437960448442027e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.97062161937356e-06\n",
      "  batch 101 loss: 0.00012374270327200065\n",
      "  batch 201 loss: 3.600110634579323e-05\n",
      "LOSS train 6.567881257649209e-05 valid 2.696956471481826e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006927986443042755\n",
      "  batch 101 loss: 1.9811944815749303\n",
      "  batch 201 loss: 0.0037628440686967224\n",
      "LOSS train 0.7278972731633692 valid 0.0017141345888376236\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.036967366933823e-05\n",
      "  batch 101 loss: 0.0024200903336168266\n",
      "  batch 201 loss: 0.000341285310278181\n",
      "LOSS train 0.0010894106932301262 valid 0.0009764068527147174\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.429467651993036e-05\n",
      "  batch 101 loss: 0.0005646447364415508\n",
      "  batch 201 loss: 3.542438060321729e-05\n",
      "LOSS train 0.0002458341139892262 valid 6.631688302149996e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.209752707742154e-06\n",
      "  batch 101 loss: 0.00016189907590160145\n",
      "  batch 201 loss: 1.3651346248479968e-05\n",
      "LOSS train 6.931531518539853e-05 valid 3.038932482013479e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00025246841832995417\n",
      "  batch 101 loss: 2.0977063772734255\n",
      "  batch 201 loss: 0.005974123314954341\n",
      "LOSS train 0.7710084278821338 valid 0.0009176161256618798\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.234003394842148e-05\n",
      "  batch 101 loss: 0.0011231808993034066\n",
      "  batch 201 loss: 8.969372447609203e-05\n",
      "LOSS train 0.00048089974425638104 valid 8.672541298437864e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.712164031341672e-06\n",
      "  batch 101 loss: 9.617920474738639e-05\n",
      "  batch 201 loss: 2.0583676528076465e-05\n",
      "LOSS train 5.103407699237693e-05 valid 2.1185725927352905e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1323510261718185e-06\n",
      "  batch 101 loss: 2.6926396583348832e-05\n",
      "  batch 201 loss: 2.2304433266526757e-05\n",
      "LOSS train 2.3903115931346664e-05 valid 1.63226795848459e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00027236778289079665\n",
      "  batch 101 loss: 2.172881665430032\n",
      "  batch 201 loss: 0.0038789455394726245\n",
      "LOSS train 0.7975247460627466 valid 7.943534728838131e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.976620108820498e-06\n",
      "  batch 101 loss: 0.00021090264439408202\n",
      "  batch 201 loss: 2.8105139190301997e-05\n",
      "LOSS train 9.743129133548858e-05 valid 3.039099283341784e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0251024832541589e-07\n",
      "  batch 101 loss: 2.4516670760021952e-05\n",
      "  batch 201 loss: 3.4468488847778645e-05\n",
      "LOSS train 3.8513816899457206e-05 valid 2.796456465148367e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.4892962099111174e-07\n",
      "  batch 101 loss: 3.362289176948252e-05\n",
      "  batch 201 loss: 3.815067680534412e-05\n",
      "LOSS train 3.409419098253095e-05 valid 3.9323702367255464e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.314047590829432e-06\n",
      "  batch 101 loss: 1.8571411177363553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 2.4803413303970956e-05\n",
      "LOSS train 0.680285205741769 valid 8.66066875460092e-06\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.267349585366901e-08\n",
      "  batch 101 loss: 8.449761279223367e-06\n",
      "  batch 201 loss: 1.4998786654984997e-05\n",
      "LOSS train 1.103613542719132e-05 valid 3.7760171380796237e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1701133644237415e-08\n",
      "  batch 101 loss: 5.748940334598274e-05\n",
      "  batch 201 loss: 0.00017847589786356365\n",
      "LOSS train 0.00011473221268138265 valid 5.408512606663862e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.540333520708373e-08\n",
      "  batch 101 loss: 0.00014820174290548495\n",
      "  batch 201 loss: 6.88432357480906e-05\n",
      "LOSS train 0.00011504711308725912 valid 1.4333167200675234e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003929849341511726\n",
      "  batch 101 loss: 0.1744627830911304\n",
      "  batch 201 loss: 7.438958006787288e-05\n",
      "LOSS train 0.0640982449203667 valid 6.790593033656478e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.51433108234778e-07\n",
      "  batch 101 loss: 9.081371460297305e-05\n",
      "  batch 201 loss: 0.00010115216045221587\n",
      "LOSS train 0.00010041176495619249 valid 8.850609447108582e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1371666914783418e-06\n",
      "  batch 101 loss: 0.00011885784530591082\n",
      "  batch 201 loss: 0.00012377958372269404\n",
      "LOSS train 0.0001238972773169305 valid 7.002137135714293e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.94863881310448e-07\n",
      "  batch 101 loss: 0.00012649761517764092\n",
      "  batch 201 loss: 0.00011856362892558537\n",
      "LOSS train 0.00011974405856937745 valid 5.2008861530339345e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.0402522534132003e-05\n",
      "  batch 101 loss: 0.5482145354897319\n",
      "  batch 201 loss: 6.525495427013083e-05\n",
      "LOSS train 0.20086296917043292 valid 5.512896677828394e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.3876865674974396e-07\n",
      "  batch 101 loss: 6.898210613144329e-05\n",
      "  batch 201 loss: 7.339204201343818e-05\n",
      "LOSS train 7.242117652865654e-05 valid 6.300325912889093e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.447149644372985e-07\n",
      "  batch 101 loss: 8.14692743665546e-05\n",
      "  batch 201 loss: 8.653852125917183e-05\n",
      "LOSS train 8.592141464830023e-05 valid 7.489672134397551e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.906693255994469e-07\n",
      "  batch 101 loss: 9.630030807670664e-05\n",
      "  batch 201 loss: 0.00010183409419028067\n",
      "LOSS train 0.00010177848852287749 valid 8.711152622709051e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0008045657724142075\n",
      "  batch 101 loss: 0.906620872759031\n",
      "  batch 201 loss: 6.177590079232686e-05\n",
      "LOSS train 0.3324286676565337 valid 5.331488500814885e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.7575289752567186e-07\n",
      "  batch 101 loss: 6.434213463762717e-05\n",
      "  batch 201 loss: 6.740990706020966e-05\n",
      "LOSS train 6.644791752285115e-05 valid 5.755286110797897e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.097473695059307e-07\n",
      "  batch 101 loss: 7.278839050286478e-05\n",
      "  batch 201 loss: 7.628462145021331e-05\n",
      "LOSS train 7.550082487203312e-05 valid 6.43827734165825e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.757676601409912e-07\n",
      "  batch 101 loss: 8.275549709651386e-05\n",
      "  batch 201 loss: 8.689134745964112e-05\n",
      "LOSS train 8.638364940515746e-05 valid 7.417814049404114e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.833516225218773e-05\n",
      "  batch 101 loss: 0.8670625829421987\n",
      "  batch 201 loss: 6.33526011711183e-05\n",
      "LOSS train 0.3176731416902971 valid 5.3536336054094136e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.84188060706947e-07\n",
      "  batch 101 loss: 6.49697972494323e-05\n",
      "  batch 201 loss: 6.821429700721637e-05\n",
      "LOSS train 6.724888979765254e-05 valid 5.821000013384037e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.274410068523139e-07\n",
      "  batch 101 loss: 7.39424562698332e-05\n",
      "  batch 201 loss: 7.765271555399523e-05\n",
      "LOSS train 7.688537696248248e-05 valid 6.572300480911508e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.051101420074702e-07\n",
      "  batch 101 loss: 8.457098779899752e-05\n",
      "  batch 201 loss: 8.893881921039792e-05\n",
      "LOSS train 8.848316235340768e-05 valid 7.623570854775608e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0011360038816928862\n",
      "  batch 101 loss: 0.14009752000884873\n",
      "  batch 201 loss: 7.255261059071927e-05\n",
      "LOSS train 0.05178309120518138 valid 7.23310440662317e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.409173460677266e-07\n",
      "  batch 101 loss: 9.712506460573422e-05\n",
      "  batch 201 loss: 0.00010843056015261254\n",
      "LOSS train 0.00010765088763736251 valid 8.795170288067311e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1275631550233812e-06\n",
      "  batch 101 loss: 0.00012505088492957838\n",
      "  batch 201 loss: 0.00012585963926426303\n",
      "LOSS train 0.00012599002454658732 valid 5.6009041145443916e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.657905446947552e-07\n",
      "  batch 101 loss: 0.00011915591262777525\n",
      "  batch 201 loss: 0.00010684827273166775\n",
      "LOSS train 0.00010848738769494717 valid 6.425539322663099e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.4344310620799661e-05\n",
      "  batch 101 loss: 0.1809222837779089\n",
      "  batch 201 loss: 0.0003959524328092812\n",
      "LOSS train 0.06643905223409292 valid 2.2985925170360133e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.337024776963517e-07\n",
      "  batch 101 loss: 2.5199462338605372e-05\n",
      "  batch 201 loss: 2.449679848723463e-05\n",
      "LOSS train 2.5056724716239096e-05 valid 2.352484079892747e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.1727242710767314e-07\n",
      "  batch 101 loss: 2.4916504305565467e-05\n",
      "  batch 201 loss: 2.5774884346674298e-05\n",
      "LOSS train 2.555347222220913e-05 valid 2.659731762832962e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.936493885703385e-07\n",
      "  batch 101 loss: 2.7560002295103913e-05\n",
      "  batch 201 loss: 2.792141713143792e-05\n",
      "LOSS train 2.7550925763171775e-05 valid 2.5803257813095115e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004280503839254379\n",
      "  batch 101 loss: 0.1509166241956973\n",
      "  batch 201 loss: 7.320511853322387e-05\n",
      "LOSS train 0.05548730204509078 valid 7.316601113416255e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.572590741096064e-07\n",
      "  batch 101 loss: 9.82975786030238e-05\n",
      "  batch 201 loss: 0.0001097118606273284\n",
      "LOSS train 0.00010891022991703832 valid 8.722714119357988e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1149646161356941e-06\n",
      "  batch 101 loss: 0.000125827064986197\n",
      "  batch 201 loss: 0.00012570027542437855\n",
      "LOSS train 0.00012585415654418048 valid 5.4238618758972734e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.093836832907982e-07\n",
      "  batch 101 loss: 0.0001172976413795368\n",
      "  batch 201 loss: 0.00010449683935121357\n",
      "LOSS train 0.00010620423109025728 valid 6.737155490554869e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00028798883780837057\n",
      "  batch 101 loss: 0.43624178466615376\n",
      "  batch 201 loss: 6.893963019138028e-05\n",
      "LOSS train 0.1599440396223724 valid 5.751425851485692e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.086910823592916e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 7.397877962830534e-05\n",
      "  batch 201 loss: 7.988102311628608e-05\n",
      "LOSS train 7.894217081632836e-05 valid 6.996993761276826e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.938225462567061e-07\n",
      "  batch 101 loss: 9.099668796352489e-05\n",
      "  batch 201 loss: 9.752369921670833e-05\n",
      "LOSS train 9.717082684260059e-05 valid 8.507876191288233e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0772890527732671e-06\n",
      "  batch 101 loss: 0.00011003481265646542\n",
      "  batch 201 loss: 0.00011556623295405188\n",
      "LOSS train 0.00011599799346915225 valid 8.762137440498918e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005780395120382309\n",
      "  batch 101 loss: 0.11336269191331666\n",
      "  batch 201 loss: 0.00011609395927735022\n",
      "LOSS train 0.0418130113800174 valid 8.764627273194492e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.2900505680590869e-06\n",
      "  batch 101 loss: 0.00013550607294746442\n",
      "  batch 201 loss: 0.00013500539344931894\n",
      "LOSS train 0.00013416282308087283 valid 5.2417795814108104e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.6977828131057324e-07\n",
      "  batch 101 loss: 0.00011456480191554875\n",
      "  batch 201 loss: 9.770406808456755e-05\n",
      "LOSS train 9.983023865694096e-05 valid 8.567553595639765e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.372809715074254e-08\n",
      "  batch 101 loss: 7.623516024295895e-05\n",
      "  batch 201 loss: 6.730535649239755e-05\n",
      "LOSS train 6.83853006765462e-05 valid 0.00012838092516176403\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.115794388577342e-05\n",
      "  batch 101 loss: 15.823501640395916\n",
      "  batch 201 loss: 0.0001442502983536542\n",
      "LOSS train 5.7962268647858295 valid 9.109813254326582e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.554927495017182e-08\n",
      "  batch 101 loss: 3.067195341145634e-05\n",
      "  batch 201 loss: 8.33358765180492e-05\n",
      "LOSS train 6.989323619330744e-05 valid 0.0002757697075139731\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0291359649272635e-06\n",
      "  batch 101 loss: 0.00010869994197264532\n",
      "  batch 201 loss: 8.667601772685885e-05\n",
      "LOSS train 9.13513512938359e-05 valid 0.00011324156366754323\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0053449841507245e-07\n",
      "  batch 101 loss: 6.301264873627588e-05\n",
      "  batch 201 loss: 5.460319456005891e-05\n",
      "LOSS train 5.663721601324921e-05 valid 7.909553096396849e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00028718002140522004\n",
      "  batch 101 loss: 10.417004956020973\n",
      "  batch 201 loss: 0.005370698609622196\n",
      "LOSS train 3.8189918127758666 valid 0.0007522315718233585\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.0285764262080194e-05\n",
      "  batch 101 loss: 0.0032369737219414673\n",
      "  batch 201 loss: 0.002240911633707583\n",
      "LOSS train 0.0024388911676526603 valid 0.0004411045811139047\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.9445423968136312e-05\n",
      "  batch 101 loss: 0.001273339508625213\n",
      "  batch 201 loss: 0.0008320125999307493\n",
      "LOSS train 0.0009153743917472689 valid 0.00021448300685733557\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.308849991299212e-06\n",
      "  batch 101 loss: 0.0003175345527051832\n",
      "  batch 201 loss: 0.00020999075315558002\n",
      "LOSS train 0.0002283629541684954 valid 7.297978299902752e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006158021092414856\n",
      "  batch 101 loss: 14.91903535780264\n",
      "  batch 201 loss: 0.015679126721806824\n",
      "LOSS train 5.472320245109386 valid 0.00011601665028138086\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.039872437715531e-05\n",
      "  batch 101 loss: 0.0037313875288236885\n",
      "  batch 201 loss: 0.0028115797496866433\n",
      "LOSS train 0.003028552017631794 valid 8.33205776871182e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.5420605670660734e-05\n",
      "  batch 101 loss: 0.0019378770614275709\n",
      "  batch 201 loss: 0.0013022648979676887\n",
      "LOSS train 0.0014471038474510305 valid 5.395451807999052e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1043339036405086e-05\n",
      "  batch 101 loss: 0.0007049893768271431\n",
      "  batch 201 loss: 0.00047661203308962285\n",
      "LOSS train 0.0005308496854276543 valid 0.0002043802523985505\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.10316652758047e-06\n",
      "  batch 101 loss: 0.7366507131770368\n",
      "  batch 201 loss: 6.224528350685432e-05\n",
      "LOSS train 0.26987595750774296 valid 5.472542397910729e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.2574658436933533e-07\n",
      "  batch 101 loss: 6.791268258439231e-05\n",
      "  batch 201 loss: 7.198293692454172e-05\n",
      "LOSS train 7.10377617063623e-05 valid 6.161701458040625e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.124887295300141e-07\n",
      "  batch 101 loss: 7.941615220488529e-05\n",
      "  batch 201 loss: 8.421034032380703e-05\n",
      "LOSS train 8.349594697439244e-05 valid 7.2393479058519e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.421447273576633e-07\n",
      "  batch 101 loss: 9.330142890121352e-05\n",
      "  batch 201 loss: 9.845643585094876e-05\n",
      "LOSS train 9.833086351794412e-05 valid 8.482011617161334e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.341889336705208e-05\n",
      "  batch 101 loss: 6.819725882878993\n",
      "  batch 201 loss: 0.0036756534734740855\n",
      "LOSS train 2.499571406827302 valid 0.00020228515495546162\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.265623182523996e-07\n",
      "  batch 101 loss: 0.00011311566343920276\n",
      "  batch 201 loss: 0.0004394109269424007\n",
      "LOSS train 0.00021806542909728243 valid 5.154364407644607e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.684675175463781e-07\n",
      "  batch 101 loss: 5.9261999285808995e-05\n",
      "  batch 201 loss: 5.957114373813965e-05\n",
      "LOSS train 5.905655697271149e-05 valid 5.237627919996157e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.3613941923249514e-07\n",
      "  batch 101 loss: 6.0956971310588415e-05\n",
      "  batch 201 loss: 6.222411601811473e-05\n",
      "LOSS train 6.128680852004399e-05 valid 5.340993811842054e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.264214541763067e-05\n",
      "  batch 101 loss: 0.0009093153028470624\n",
      "  batch 201 loss: 2.8716016634007246e-05\n",
      "LOSS train 0.00037181635758938667 valid 0.00047422017087228596\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.563652116805315e-05\n",
      "  batch 101 loss: 0.00021925777327737705\n",
      "  batch 201 loss: 1.6623595089413358e-05\n",
      "LOSS train 0.0001069118950466633 valid 0.00047656954848207533\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.3796427994966508e-05\n",
      "  batch 101 loss: 0.0002830030525467464\n",
      "  batch 201 loss: 1.647927602107302e-05\n",
      "LOSS train 0.00013016435945073247 valid 0.0004701661819126457\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.4449157062917948e-05\n",
      "  batch 101 loss: 0.0002506844227775673\n",
      "  batch 201 loss: 1.382746952629077e-05\n",
      "LOSS train 0.00011803261737260329 valid 0.0004728210042230785\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.7325665578246116e-05\n",
      "  batch 101 loss: 0.0002491037418576525\n",
      "  batch 201 loss: 1.2721504361934421e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.00011759626719475862 valid 0.00047436068416573107\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.7920373249799012e-05\n",
      "  batch 101 loss: 0.0002481382960860401\n",
      "  batch 201 loss: 1.2604252440269192e-05\n",
      "LOSS train 0.00011654425477108017 valid 0.00047203435678966343\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.7176160365343094e-05\n",
      "  batch 101 loss: 0.00024455022176539387\n",
      "  batch 201 loss: 1.2665668601243851e-05\n",
      "LOSS train 0.0001140768224467381 valid 0.0004672037030104548\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.567588118836284e-05\n",
      "  batch 101 loss: 0.00023972433940258497\n",
      "  batch 201 loss: 1.263084528602576e-05\n",
      "LOSS train 0.00011095619950027127 valid 0.00045926557504571974\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00010949384421110153\n",
      "  batch 101 loss: 0.002646983191370964\n",
      "  batch 201 loss: 0.001846798756159842\n",
      "LOSS train 0.0020771501912059936 valid 0.0006062532775104046\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.0967754535377027e-05\n",
      "  batch 101 loss: 0.0011955490347463637\n",
      "  batch 201 loss: 0.0007307170043350197\n",
      "LOSS train 0.0008541952278985277 valid 0.00010819538147188723\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.299808737821877e-06\n",
      "  batch 101 loss: 0.000430471969593782\n",
      "  batch 201 loss: 0.0002950780247920193\n",
      "LOSS train 0.00031853554553510927 valid 6.153407593956217e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.59469626750797e-06\n",
      "  batch 101 loss: 0.00017194189960719085\n",
      "  batch 201 loss: 0.00010231241525616496\n",
      "LOSS train 0.0001224145626410673 valid 9.967545338440686e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.001565976068378e-06\n",
      "  batch 101 loss: 9.539788175970898e-05\n",
      "  batch 201 loss: 3.1166471089818514e-05\n",
      "LOSS train 5.35623873971224e-05 valid 1.0469689186720643e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.659303522203118e-07\n",
      "  batch 101 loss: 2.093157334456919e-05\n",
      "  batch 201 loss: 1.2449228361219866e-05\n",
      "LOSS train 1.542206791782519e-05 valid 9.537039659335278e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.213236469600816e-08\n",
      "  batch 101 loss: 1.4474631402663363e-05\n",
      "  batch 201 loss: 9.01525828112426e-06\n",
      "LOSS train 1.1963831383458882e-05 valid 1.8194550648331642e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.5325210521696137e-07\n",
      "  batch 101 loss: 8.012406327679855e-06\n",
      "  batch 201 loss: 6.042192411541691e-06\n",
      "LOSS train 6.986301685760453e-06 valid 4.735090897156624e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002959915809333324\n",
      "  batch 101 loss: 0.005142827092204243\n",
      "  batch 201 loss: 0.0031533277651760727\n",
      "LOSS train 0.003722145738960295 valid 0.0001783952466212213\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.770858885720372e-05\n",
      "  batch 101 loss: 0.0013052278145914897\n",
      "  batch 201 loss: 0.0006853361451067031\n",
      "LOSS train 0.0008451821006499334 valid 0.00017218042921740562\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.862839800305665e-06\n",
      "  batch 101 loss: 0.0002486447765841149\n",
      "  batch 201 loss: 0.0001325508815352805\n",
      "LOSS train 0.00016309753218493014 valid 2.4428680262644775e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.384520672028884e-07\n",
      "  batch 101 loss: 5.3976838516973656e-05\n",
      "  batch 201 loss: 2.856475281078019e-05\n",
      "LOSS train 3.537587994014424e-05 valid 1.939222784130834e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.103281414951198e-07\n",
      "  batch 101 loss: 1.6027105825742183e-05\n",
      "  batch 201 loss: 1.1324704819344334e-05\n",
      "LOSS train 1.2548588763207596e-05 valid 4.344125500210794e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.0914783312473445e-08\n",
      "  batch 101 loss: 1.0203825750068063e-05\n",
      "  batch 201 loss: 8.483732926833909e-06\n",
      "LOSS train 8.864031023665284e-06 valid 1.2315627827774733e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0578588444332126e-07\n",
      "  batch 101 loss: 1.1756168339616124e-05\n",
      "  batch 201 loss: 1.7917315742579375e-05\n",
      "LOSS train 1.5159219965392704e-05 valid 5.6232206588902045e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.794269898411585e-08\n",
      "  batch 101 loss: 8.639533032237523e-06\n",
      "  batch 201 loss: 1.0774278457574838e-05\n",
      "LOSS train 1.0936232470674226e-05 valid 8.310375960718375e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00013028260320425034\n",
      "  batch 101 loss: 0.007509575267322361\n",
      "  batch 201 loss: 0.0030185700103174894\n",
      "LOSS train 0.00419705973928726 valid 0.00014864011609461159\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.790523231960834e-06\n",
      "  batch 101 loss: 0.00046472144982544704\n",
      "  batch 201 loss: 0.00013796070001262706\n",
      "LOSS train 0.0002408433303418407 valid 1.1616229130595457e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.659428178565578e-07\n",
      "  batch 101 loss: 3.741703211744607e-05\n",
      "  batch 201 loss: 1.6811157120173448e-05\n",
      "LOSS train 2.3963154088603968e-05 valid 2.380194746365305e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.6326979675795884e-07\n",
      "  batch 101 loss: 1.480724867860772e-05\n",
      "  batch 201 loss: 1.169663182054137e-05\n",
      "LOSS train 1.2857434620898511e-05 valid 1.4118941180640832e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.7398342505621255e-08\n",
      "  batch 101 loss: 1.2435733324309695e-05\n",
      "  batch 201 loss: 1.4081954275297903e-05\n",
      "LOSS train 1.3462213222231388e-05 valid 1.5028818779683206e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.025904556532623e-08\n",
      "  batch 101 loss: 1.883554916275898e-05\n",
      "  batch 201 loss: 2.5506781810236134e-05\n",
      "LOSS train 2.3381900525533644e-05 valid 1.3624823623104021e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.1209781304351054e-08\n",
      "  batch 101 loss: 1.978324923584296e-05\n",
      "  batch 201 loss: 1.8780774000788368e-05\n",
      "LOSS train 1.8361140647380707e-05 valid 9.646515536587685e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.005478553561261e-08\n",
      "  batch 101 loss: 1.6792909300420432e-05\n",
      "  batch 201 loss: 2.3064924184836856e-05\n",
      "LOSS train 1.9233360234342827e-05 valid 1.5540883396170102e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000420752614736557\n",
      "  batch 101 loss: 0.016638718633912503\n",
      "  batch 201 loss: 0.0029451964038889854\n",
      "LOSS train 0.007452190963834125 valid 2.266188857902307e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.217502428218722e-06\n",
      "  batch 101 loss: 0.00014122633891020087\n",
      "  batch 201 loss: 2.8514813238871283e-05\n",
      "LOSS train 6.951583934293119e-05 valid 1.5022545085230377e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3644858881889377e-07\n",
      "  batch 101 loss: 2.4353633430109768e-05\n",
      "  batch 201 loss: 2.362073875247006e-05\n",
      "LOSS train 2.4510515261651594e-05 valid 1.7192363884532824e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.200855967908865e-07\n",
      "  batch 101 loss: 2.3695826184848558e-05\n",
      "  batch 201 loss: 3.0121581373805385e-05\n",
      "LOSS train 2.6890484314574615e-05 valid 3.714871490956284e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.061111995833926e-08\n",
      "  batch 101 loss: 2.0751284491780097e-05\n",
      "  batch 201 loss: 2.239727758023946e-05\n",
      "LOSS train 2.2425286052623296e-05 valid 1.8515545889385976e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2891692676930689e-07\n",
      "  batch 101 loss: 3.1134084651966986e-05\n",
      "  batch 201 loss: 2.303387667325296e-05\n",
      "LOSS train 2.7471481006191242e-05 valid 6.208233389770612e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.0835794202866965e-07\n",
      "  batch 101 loss: 2.6006882276305987e-05\n",
      "  batch 201 loss: 3.691214579248481e-05\n",
      "LOSS train 3.682441943538957e-05 valid 8.881824760464951e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.286997864255682e-07\n",
      "  batch 101 loss: 4.653542867799843e-05\n",
      "  batch 201 loss: 6.662719339146861e-05\n",
      "LOSS train 5.814078843156624e-05 valid 8.537880785297602e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00012881169095635414\n",
      "  batch 101 loss: 0.00041804471700288557\n",
      "  batch 201 loss: 3.261175149873452e-05\n",
      "LOSS train 0.00021489910590424607 valid 5.426525967777707e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.061323801986873e-07\n",
      "  batch 101 loss: 1.2288275425760276e-05\n",
      "  batch 201 loss: 2.0984763180251774e-05\n",
      "LOSS train 1.4566012593426448e-05 valid 5.215681449044496e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.825872696936131e-07\n",
      "  batch 101 loss: 1.2710702921481243e-05\n",
      "  batch 201 loss: 1.9855119873568583e-05\n",
      "LOSS train 1.519541133585325e-05 valid 4.9209982535103336e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.285605923039839e-07\n",
      "  batch 101 loss: 1.4564769623746087e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 1.9010940386294804e-05\n",
      "LOSS train 1.4612341625550324e-05 valid 5.023682024329901e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.004319685511291e-07\n",
      "  batch 101 loss: 1.419796497657444e-05\n",
      "  batch 201 loss: 1.797499294411864e-05\n",
      "LOSS train 1.3841307495384658e-05 valid 6.132412818260491e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0934937563433778e-07\n",
      "  batch 101 loss: 1.789963754049495e-05\n",
      "  batch 201 loss: 1.656595197829347e-05\n",
      "LOSS train 1.4756410415815474e-05 valid 4.182081829640083e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.953582538291812e-07\n",
      "  batch 101 loss: 2.8589486729515555e-05\n",
      "  batch 201 loss: 2.002691566218573e-05\n",
      "LOSS train 2.0102951162155415e-05 valid 3.7678742955904454e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.0270249883178623e-07\n",
      "  batch 101 loss: 2.574253083992062e-05\n",
      "  batch 201 loss: 1.8103872769188456e-05\n",
      "LOSS train 1.844047596433074e-05 valid 3.5002263757633045e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003044765815138817\n",
      "  batch 101 loss: 0.0008009535296514514\n",
      "  batch 201 loss: 5.753097702836385e-05\n",
      "LOSS train 0.0004417081362632979 valid 3.27294364979025e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.805843855137937e-07\n",
      "  batch 101 loss: 3.3231784773306575e-05\n",
      "  batch 201 loss: 3.336541854878305e-05\n",
      "LOSS train 3.561101260483832e-05 valid 2.2110401914687827e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.5535998904379085e-07\n",
      "  batch 101 loss: 2.390158570051426e-05\n",
      "  batch 201 loss: 2.6150691719522002e-05\n",
      "LOSS train 2.6290558168141987e-05 valid 2.0177365513518453e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.6005955078289844e-07\n",
      "  batch 101 loss: 1.9553383772290545e-05\n",
      "  batch 201 loss: 2.1731326455665112e-05\n",
      "LOSS train 2.2745853616287183e-05 valid 1.8511631424189545e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.874211011454463e-07\n",
      "  batch 101 loss: 1.5736048585495154e-05\n",
      "  batch 201 loss: 1.572326863424678e-05\n",
      "LOSS train 1.691092515745331e-05 valid 2.7247318939771503e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.2611191525356843e-07\n",
      "  batch 101 loss: 1.3793680536764442e-05\n",
      "  batch 201 loss: 1.3016413140576332e-05\n",
      "LOSS train 1.4715609110610854e-05 valid 2.14719202631386e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.3856367331754881e-07\n",
      "  batch 101 loss: 9.286876111218589e-06\n",
      "  batch 201 loss: 1.0037131842182134e-05\n",
      "LOSS train 1.0253632303046464e-05 valid 2.0545692677842453e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.201707143802195e-08\n",
      "  batch 101 loss: 7.21717433862068e-06\n",
      "  batch 201 loss: 1.158326948825561e-05\n",
      "LOSS train 9.683300699439964e-06 valid 8.578723281971179e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003476502001285553\n",
      "  batch 101 loss: 0.0011767686193343253\n",
      "  batch 201 loss: 0.0004763203690527007\n",
      "LOSS train 0.0008354960827667764 valid 6.731237226631492e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.4513513674028217e-06\n",
      "  batch 101 loss: 0.00035391645884374156\n",
      "  batch 201 loss: 0.0003269815137900878\n",
      "LOSS train 0.0003250223624344315 valid 7.227761670947075e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.625070385169238e-06\n",
      "  batch 101 loss: 0.00025656038866145537\n",
      "  batch 201 loss: 0.00021353898046072572\n",
      "LOSS train 0.0002218308642053731 valid 4.241645001457073e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.4863937394693493e-06\n",
      "  batch 101 loss: 0.00015397630268125794\n",
      "  batch 201 loss: 0.00012716771554551086\n",
      "LOSS train 0.00013052375599174358 valid 4.724133395939134e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.2207565305288881e-06\n",
      "  batch 101 loss: 8.786187019723002e-05\n",
      "  batch 201 loss: 6.901546195877018e-05\n",
      "LOSS train 7.136358766022971e-05 valid 1.8299571820534766e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.5763401431031524e-07\n",
      "  batch 101 loss: 4.28353505776613e-05\n",
      "  batch 201 loss: 3.357252257046639e-05\n",
      "LOSS train 3.5759851556037206e-05 valid 8.246564902947284e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.2216481738723813e-07\n",
      "  batch 101 loss: 2.5776770094125823e-05\n",
      "  batch 201 loss: 1.6437292642876856e-05\n",
      "LOSS train 1.9523655980628306e-05 valid 9.86120448942529e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.678031346993521e-08\n",
      "  batch 101 loss: 9.066932514087966e-06\n",
      "  batch 201 loss: 7.1362115659212575e-06\n",
      "LOSS train 7.179093235010488e-06 valid 1.884050652734004e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.92700345441699e-05\n",
      "  batch 101 loss: 0.0008537172067735809\n",
      "  batch 201 loss: 0.0003759739812812768\n",
      "LOSS train 0.0005401395186236054 valid 9.850342757999897e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.8283756799064577e-06\n",
      "  batch 101 loss: 0.00021133955888217316\n",
      "  batch 201 loss: 0.00017283753433730453\n",
      "LOSS train 0.00017173323007287704 valid 8.127788169076666e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.566604133695364e-07\n",
      "  batch 101 loss: 8.873630853486248e-05\n",
      "  batch 201 loss: 7.261150356498547e-05\n",
      "LOSS train 6.93459118897758e-05 valid 3.10825853375718e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.101718539255671e-07\n",
      "  batch 101 loss: 2.6367521031716022e-05\n",
      "  batch 201 loss: 3.4661033373595275e-05\n",
      "LOSS train 3.877714958216596e-05 valid 5.9833859268110245e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.698166569345631e-07\n",
      "  batch 101 loss: 6.74517458446644e-05\n",
      "  batch 201 loss: 6.291083496307693e-05\n",
      "LOSS train 6.536601855732576e-05 valid 5.517656609299593e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.402754711918533e-07\n",
      "  batch 101 loss: 6.689175137125858e-05\n",
      "  batch 201 loss: 6.695206894619332e-05\n",
      "LOSS train 6.633552578559596e-05 valid 5.503631473402493e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.3581843783613295e-07\n",
      "  batch 101 loss: 6.669267992492678e-05\n",
      "  batch 201 loss: 6.678542384179309e-05\n",
      "LOSS train 6.616063952579403e-05 valid 5.4971384088275954e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.3373656808398666e-07\n",
      "  batch 101 loss: 6.657225735580141e-05\n",
      "  batch 201 loss: 6.668312126748787e-05\n",
      "LOSS train 6.605376389889122e-05 valid 5.4930827900534496e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001098620891571045\n",
      "  batch 101 loss: 0.0025274258962599563\n",
      "  batch 201 loss: 0.0011667130858404563\n",
      "LOSS train 0.0015891251125886368 valid 4.599376188707538e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.920107407495379e-06\n",
      "  batch 101 loss: 0.0005304247862659394\n",
      "  batch 201 loss: 0.0003211254146299325\n",
      "LOSS train 0.0003636290279072931 valid 3.513022602419369e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.1788722844794393e-06\n",
      "  batch 101 loss: 0.00012092211938579566\n",
      "  batch 201 loss: 8.081763829977718e-05\n",
      "LOSS train 9.496098669153684e-05 valid 4.827451630262658e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.364041524240747e-07\n",
      "  batch 101 loss: 5.989298681924993e-05\n",
      "  batch 201 loss: 5.7857603860611564e-05\n",
      "LOSS train 5.8289683155112385e-05 valid 4.141136378166266e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.4617077946895735e-07\n",
      "  batch 101 loss: 5.6550124768364184e-05\n",
      "  batch 201 loss: 5.310438945343776e-05\n",
      "LOSS train 5.3608917355948494e-05 valid 2.6107554731424898e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.177700273226947e-07\n",
      "  batch 101 loss: 4.521612876942527e-05\n",
      "  batch 201 loss: 3.736824202405842e-05\n",
      "LOSS train 3.8354564252246176e-05 valid 1.3381742064666469e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1452322723926045e-07\n",
      "  batch 101 loss: 2.8804087612570584e-05\n",
      "  batch 201 loss: 2.7019262568046542e-05\n",
      "LOSS train 2.6962981555631578e-05 valid 1.2618823348020669e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.518725735484623e-08\n",
      "  batch 101 loss: 2.5972398532303487e-05\n",
      "  batch 201 loss: 2.3168540210463106e-05\n",
      "LOSS train 2.4785174343708274e-05 valid 1.4608072888222523e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.4732006548001664e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00010729939893053598\n",
      "  batch 201 loss: 1.663073221720879e-05\n",
      "LOSS train 4.74170535818176e-05 valid 1.511526988906553e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.9441420135990485e-08\n",
      "  batch 101 loss: 6.838668825537298e-06\n",
      "  batch 201 loss: 4.455829457867822e-06\n",
      "LOSS train 4.777768609291769e-06 valid 8.487585546390619e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.422142402901955e-09\n",
      "  batch 101 loss: 2.866479009355771e-06\n",
      "  batch 201 loss: 2.170696416641249e-06\n",
      "LOSS train 2.2637946681214043e-06 valid 5.356633664632682e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.387953360193933e-09\n",
      "  batch 101 loss: 2.548432289302127e-06\n",
      "  batch 201 loss: 1.9464415942138657e-06\n",
      "LOSS train 2.0588562548894784e-06 valid 5.1922202146670315e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.041159619802784e-09\n",
      "  batch 101 loss: 2.4880913586855513e-06\n",
      "  batch 201 loss: 1.9056870858946695e-06\n",
      "LOSS train 2.04636023994141e-06 valid 4.592891855281778e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.0970929755276305e-09\n",
      "  batch 101 loss: 2.673738969178885e-06\n",
      "  batch 201 loss: 2.0717210955467636e-06\n",
      "LOSS train 2.183216360035225e-06 valid 3.393346560187638e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.79477113358007e-09\n",
      "  batch 101 loss: 2.29645648161636e-06\n",
      "  batch 201 loss: 1.7985149497690146e-06\n",
      "LOSS train 1.8498689546850107e-06 valid 2.54055544246512e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1878568102474674e-08\n",
      "  batch 101 loss: 2.0567697366402627e-06\n",
      "  batch 201 loss: 1.5048273462525686e-06\n",
      "LOSS train 1.6767807523743386e-06 valid 1.6801324136395124e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.78929840028286e-06\n",
      "  batch 101 loss: 0.00019416820699007077\n",
      "  batch 201 loss: 0.0001241878963992349\n",
      "LOSS train 0.0001497292240366313 valid 5.794523167423904e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.384828106500208e-07\n",
      "  batch 101 loss: 0.0001075159515676205\n",
      "  batch 201 loss: 9.750710160005838e-05\n",
      "LOSS train 9.898202454382038e-05 valid 5.7305212976643816e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.431997801177204e-07\n",
      "  batch 101 loss: 8.310564518978936e-05\n",
      "  batch 201 loss: 8.577592724577698e-05\n",
      "LOSS train 8.318228156185596e-05 valid 5.597068229690194e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.736441380577162e-07\n",
      "  batch 101 loss: 7.954443424750934e-05\n",
      "  batch 201 loss: 7.81063708018337e-05\n",
      "LOSS train 7.787865270207949e-05 valid 5.5532338592456654e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.350432184059173e-07\n",
      "  batch 101 loss: 7.585437670059037e-05\n",
      "  batch 201 loss: 7.628569072039682e-05\n",
      "LOSS train 7.493340672892919e-05 valid 5.594300455413759e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.142592272022739e-07\n",
      "  batch 101 loss: 7.391833167275764e-05\n",
      "  batch 201 loss: 7.267629689522437e-05\n",
      "LOSS train 7.230721851992578e-05 valid 5.623622564598918e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.024124038754963e-07\n",
      "  batch 101 loss: 7.176125368459906e-05\n",
      "  batch 201 loss: 7.12788077089499e-05\n",
      "LOSS train 7.077108366435587e-05 valid 5.5954355048015714e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.841437112190761e-07\n",
      "  batch 101 loss: 7.053595746583596e-05\n",
      "  batch 201 loss: 7.071423471643356e-05\n",
      "LOSS train 7.013033475745126e-05 valid 5.611220694845542e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.948022473603487e-05\n",
      "  batch 101 loss: 0.0012321709515526892\n",
      "  batch 201 loss: 0.0005539895271067508\n",
      "LOSS train 0.0007767615347419228 valid 0.00010273596126353368\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.9551162151619793e-06\n",
      "  batch 101 loss: 0.00027426007873145866\n",
      "  batch 201 loss: 0.00022643171905656345\n",
      "LOSS train 0.00023644678150205582 valid 7.700733112869784e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.9629005691967905e-06\n",
      "  batch 101 loss: 0.00017853880803158972\n",
      "  batch 201 loss: 0.00015202620135823964\n",
      "LOSS train 0.00015815095419770758 valid 6.283479160629213e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.952441905625165e-07\n",
      "  batch 101 loss: 0.00012131148527259938\n",
      "  batch 201 loss: 0.00010853811361812405\n",
      "LOSS train 0.0001105546665705946 valid 6.00538078288082e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0951261356240138e-06\n",
      "  batch 101 loss: 8.941230319578608e-05\n",
      "  batch 201 loss: 7.965071225044085e-05\n",
      "LOSS train 8.100205556459784e-05 valid 3.525708962115459e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.1454535676166415e-07\n",
      "  batch 101 loss: 6.97038249745674e-05\n",
      "  batch 201 loss: 6.992378932409338e-05\n",
      "LOSS train 6.942318576452452e-05 valid 4.112112947041169e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.211801130324603e-07\n",
      "  batch 101 loss: 6.165645115288498e-05\n",
      "  batch 201 loss: 5.785257530078525e-05\n",
      "LOSS train 5.647188342727165e-05 valid 2.1961424863548018e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.9260751287220047e-07\n",
      "  batch 101 loss: 3.893787984452501e-05\n",
      "  batch 201 loss: 3.725662357282999e-05\n",
      "LOSS train 3.7461876879302716e-05 valid 1.695598621154204e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0018501622974872588\n",
      "  batch 101 loss: 0.024567810269072652\n",
      "  batch 201 loss: 0.013523083911277354\n",
      "LOSS train 0.017394209942429056 valid 0.0004037625913042575\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0001064663752913475\n",
      "  batch 101 loss: 0.008295968780294061\n",
      "  batch 201 loss: 0.006153254967648536\n",
      "LOSS train 0.00659946293396118 valid 0.00019256677478551865\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.84154948592186e-05\n",
      "  batch 101 loss: 0.003825965642463416\n",
      "  batch 201 loss: 0.0029196005163248627\n",
      "LOSS train 0.0031075750284865773 valid 7.875991286709905e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.6119730425998568e-05\n",
      "  batch 101 loss: 0.0018696189543697982\n",
      "  batch 201 loss: 0.0014345406246138736\n",
      "LOSS train 0.0015148130482601704 valid 0.00014520130935125053\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.473618089221418e-05\n",
      "  batch 101 loss: 0.0009729148496990092\n",
      "  batch 201 loss: 0.0007494063163176179\n",
      "LOSS train 0.0008015138583876971 valid 8.416563650825992e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.276114869862795e-06\n",
      "  batch 101 loss: 0.0005074907781090587\n",
      "  batch 201 loss: 0.00044411193710402585\n",
      "LOSS train 0.0004437834279967349 valid 5.5141292250482365e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.844451857730746e-06\n",
      "  batch 101 loss: 0.00029937904328107833\n",
      "  batch 201 loss: 0.0002588983642635867\n",
      "LOSS train 0.00026905467167548706 valid 5.807328489026986e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.8276562807150185e-06\n",
      "  batch 101 loss: 0.000187186464536353\n",
      "  batch 201 loss: 0.00016275428693916184\n",
      "LOSS train 0.00016637971769078487 valid 5.0368682423140854e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0016232155263423919\n",
      "  batch 101 loss: 0.05969537414610386\n",
      "  batch 201 loss: 0.03475498056039214\n",
      "LOSS train 0.04171371878885524 valid 0.013021251186728477\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00020227214321494102\n",
      "  batch 101 loss: 0.0191294164955616\n",
      "  batch 201 loss: 0.012779988022521139\n",
      "LOSS train 0.014057590719994717 valid 0.004864633083343506\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.743072066456079e-05\n",
      "  batch 101 loss: 0.006086623647715897\n",
      "  batch 201 loss: 0.0036103685013949872\n",
      "LOSS train 0.00419734789641922 valid 0.0009146835072897375\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.645713346078992e-05\n",
      "  batch 101 loss: 0.001622836841852404\n",
      "  batch 201 loss: 0.00108202897827141\n",
      "LOSS train 0.0012102439381683676 valid 0.00029111496405676007\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.629338651895523e-06\n",
      "  batch 101 loss: 0.0006567501800600439\n",
      "  batch 201 loss: 0.0004626611992716789\n",
      "LOSS train 0.000509438548627695 valid 0.0001429476251360029\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.2526523389387875e-06\n",
      "  batch 101 loss: 0.00029732222043094225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.00022591114407987333\n",
      "LOSS train 0.00023999582950410436 valid 8.839728980092332e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.3604329433292151e-06\n",
      "  batch 101 loss: 0.0001442908899844042\n",
      "  batch 201 loss: 0.0001137436572025763\n",
      "LOSS train 0.000119520889005292 valid 7.796514546498656e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.0655249904375524e-07\n",
      "  batch 101 loss: 7.821052322469768e-05\n",
      "  batch 201 loss: 6.507331703687668e-05\n",
      "LOSS train 6.767577595269774e-05 valid 6.435481191147119e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.241946317255497e-05\n",
      "  batch 101 loss: 6.16342726016228e-05\n",
      "  batch 201 loss: 2.069693101816483e-05\n",
      "LOSS train 5.323467207295375e-05 valid 2.901038715208415e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3120213679940206e-08\n",
      "  batch 101 loss: 1.2709306434146583e-05\n",
      "  batch 201 loss: 6.468199588880453e-06\n",
      "LOSS train 7.507120444911679e-06 valid 1.62149638072151e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.736381467613683e-09\n",
      "  batch 101 loss: 1.678978906483053e-06\n",
      "  batch 201 loss: 1.4958306185519631e-06\n",
      "LOSS train 1.5873409236768394e-06 valid 1.3397515203905641e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.738714096674812e-09\n",
      "  batch 101 loss: 1.4202902445958897e-06\n",
      "  batch 201 loss: 1.3540674106593542e-06\n",
      "LOSS train 1.4216314398570816e-06 valid 1.0596892252578982e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.733078131062939e-09\n",
      "  batch 101 loss: 9.914458392756841e-07\n",
      "  batch 201 loss: 1.0017192022360178e-06\n",
      "LOSS train 1.0419677791386318e-06 valid 1.1308770808682311e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.75109288800013e-09\n",
      "  batch 101 loss: 1.0071460521032805e-06\n",
      "  batch 201 loss: 8.398677844922986e-07\n",
      "LOSS train 8.519971420176365e-07 valid 6.616921837121481e-07\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.9616987856352352e-09\n",
      "  batch 101 loss: 6.979383051231025e-07\n",
      "  batch 201 loss: 8.667276335927454e-07\n",
      "LOSS train 9.524228213228605e-07 valid 1.0627500159898773e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0857040706468978e-08\n",
      "  batch 101 loss: 1.319294358523848e-06\n",
      "  batch 201 loss: 1.5015326418676977e-06\n",
      "LOSS train 1.4372881189555778e-06 valid 1.054854465110111e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004697910696268082\n",
      "  batch 101 loss: 0.0023870225506834684\n",
      "  batch 201 loss: 0.000526095776585862\n",
      "LOSS train 0.0013548416683502366 valid 8.060089749051258e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.5968865267932416e-06\n",
      "  batch 101 loss: 0.00035071292280917986\n",
      "  batch 201 loss: 0.0002750189308426343\n",
      "LOSS train 0.00030323509396618445 valid 7.837906741769984e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.4967172066681088e-06\n",
      "  batch 101 loss: 0.00024103884170472155\n",
      "  batch 201 loss: 0.00022228837944567202\n",
      "LOSS train 0.00022287231117027262 valid 2.3783524738973938e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5908214845694601e-06\n",
      "  batch 101 loss: 0.00018486633503925987\n",
      "  batch 201 loss: 0.0001564368915569503\n",
      "LOSS train 0.00016062145871165696 valid 4.018343679490499e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.335788838332519e-06\n",
      "  batch 101 loss: 0.00013189662728109398\n",
      "  batch 201 loss: 0.00011212902962142834\n",
      "LOSS train 0.00011659466172238017 valid 5.5546308431075886e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.045886766514741e-07\n",
      "  batch 101 loss: 8.778352505032671e-05\n",
      "  batch 201 loss: 7.634737095941091e-05\n",
      "LOSS train 7.695370970642272e-05 valid 3.644633397925645e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.895903111901134e-07\n",
      "  batch 101 loss: 5.711542105927947e-05\n",
      "  batch 201 loss: 4.9240003609156705e-05\n",
      "LOSS train 5.091032005274871e-05 valid 1.0789985026349314e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.0941005863714963e-07\n",
      "  batch 101 loss: 3.747795226445305e-05\n",
      "  batch 201 loss: 3.300614378531464e-05\n",
      "LOSS train 3.387008436530468e-05 valid 1.2896330190415028e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.5910252588801085e-06\n",
      "  batch 101 loss: 0.00012593243849551072\n",
      "  batch 201 loss: 6.95950108274701e-05\n",
      "LOSS train 8.913351910237514e-05 valid 5.373546446207911e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.0277584048453716e-07\n",
      "  batch 101 loss: 6.519366370412172e-05\n",
      "  batch 201 loss: 6.556332155923883e-05\n",
      "LOSS train 6.491256775943206e-05 valid 5.4427629947895184e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.1686253098305316e-07\n",
      "  batch 101 loss: 6.578630473086378e-05\n",
      "  batch 201 loss: 6.611517221244867e-05\n",
      "LOSS train 6.540739002378029e-05 valid 5.4651151003781706e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.286784314899705e-07\n",
      "  batch 101 loss: 6.611942825657024e-05\n",
      "  batch 201 loss: 6.628675555475638e-05\n",
      "LOSS train 6.563668852316072e-05 valid 5.474024874274619e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.276679101167247e-07\n",
      "  batch 101 loss: 6.6180066060042e-05\n",
      "  batch 201 loss: 6.629960606005625e-05\n",
      "LOSS train 6.567447179481578e-05 valid 5.475572106661275e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.667249959311448e-07\n",
      "  batch 101 loss: 6.638947750161605e-05\n",
      "  batch 201 loss: 6.637786562350811e-05\n",
      "LOSS train 6.582927982803777e-05 valid 5.480717300088145e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.2916974052786827e-07\n",
      "  batch 101 loss: 6.634201785345795e-05\n",
      "  batch 201 loss: 6.644716325354238e-05\n",
      "LOSS train 6.581272007832466e-05 valid 5.4803138482384384e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.2837538785533977e-07\n",
      "  batch 101 loss: 6.62663850653189e-05\n",
      "  batch 201 loss: 6.64137413696153e-05\n",
      "LOSS train 6.580483540390214e-05 valid 5.4902622650843114e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00029799949377775194\n",
      "  batch 101 loss: 0.0017060798889724537\n",
      "  batch 201 loss: 0.000792124253930524\n",
      "LOSS train 0.0011754497921310926 valid 0.00013442934141494334\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.6077970657497645e-06\n",
      "  batch 101 loss: 0.0004085613756615203\n",
      "  batch 201 loss: 0.0002991972154995892\n",
      "LOSS train 0.0003210891061846249 valid 4.4949654693482444e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.5244494716171175e-06\n",
      "  batch 101 loss: 0.0001864743189071305\n",
      "  batch 201 loss: 0.00017688910811557433\n",
      "LOSS train 0.0001797100963286762 valid 5.874759517610073e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.489991548936814e-07\n",
      "  batch 101 loss: 0.00014023040021129418\n",
      "  batch 201 loss: 0.00012930368589877616\n",
      "LOSS train 0.00013473377998124281 valid 8.152452937792987e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.3458596367854626e-06\n",
      "  batch 101 loss: 0.00012136472125348518\n",
      "  batch 201 loss: 0.00011271581581240753\n",
      "LOSS train 0.00011438605845433569 valid 8.335818711202592e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.447889169678092e-07\n",
      "  batch 101 loss: 9.962391466615372e-05\n",
      "  batch 201 loss: 9.19535255889059e-05\n",
      "LOSS train 9.400947688819266e-05 valid 7.162530528148636e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.260303340852261e-07\n",
      "  batch 101 loss: 8.703354109456995e-05\n",
      "  batch 201 loss: 8.02064112485823e-05\n",
      "LOSS train 8.08814703361596e-05 valid 5.9562753449426964e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.860386929474771e-07\n",
      "  batch 101 loss: 7.012739747551678e-05\n",
      "  batch 201 loss: 6.633411530856392e-05\n",
      "LOSS train 6.555454622988084e-05 valid 4.339444785728119e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.026273429393768e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.0005429196584736929\n",
      "  batch 201 loss: 0.0001818451330473181\n",
      "LOSS train 0.00032255141199489666 valid 0.00010151851893169805\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3280331040732563e-06\n",
      "  batch 101 loss: 0.00011142511873913464\n",
      "  batch 201 loss: 8.737257599932491e-05\n",
      "LOSS train 9.579041404618699e-05 valid 6.577459862455726e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.798841812065803e-07\n",
      "  batch 101 loss: 7.3315851868756e-05\n",
      "  batch 201 loss: 6.88007256576384e-05\n",
      "LOSS train 6.954259114846226e-05 valid 5.5647920817136765e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.235996311763301e-07\n",
      "  batch 101 loss: 6.727468660756131e-05\n",
      "  batch 201 loss: 6.629348077694885e-05\n",
      "LOSS train 6.605143372349304e-05 valid 5.512834832188673e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.211371197015978e-07\n",
      "  batch 101 loss: 6.581439831279567e-05\n",
      "  batch 201 loss: 6.639800945777096e-05\n",
      "LOSS train 6.549560296265647e-05 valid 5.5185588280437514e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.2961793951690196e-07\n",
      "  batch 101 loss: 6.573482215571858e-05\n",
      "  batch 201 loss: 6.611923433410993e-05\n",
      "LOSS train 6.541361475876742e-05 valid 5.530924318009056e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.2212133848806844e-07\n",
      "  batch 101 loss: 6.598907543775567e-05\n",
      "  batch 201 loss: 6.603038521461712e-05\n",
      "LOSS train 6.547677459501166e-05 valid 5.538105688174255e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.350077870185487e-07\n",
      "  batch 101 loss: 6.565751677953813e-05\n",
      "  batch 201 loss: 6.603009004265914e-05\n",
      "LOSS train 6.528097956839574e-05 valid 5.3616382501786575e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00012509110383689402\n",
      "  batch 101 loss: 0.004824441363853111\n",
      "  batch 201 loss: 0.00015613933953318338\n",
      "LOSS train 0.0018799193163421487 valid 0.00017914865748025477\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.077679063309915e-07\n",
      "  batch 101 loss: 3.8518081153142704e-05\n",
      "  batch 201 loss: 3.127072959614452e-05\n",
      "LOSS train 3.225038669317102e-05 valid 0.00015743088442832232\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.253318158793263e-07\n",
      "  batch 101 loss: 4.081144156998562e-05\n",
      "  batch 201 loss: 3.14647127754597e-05\n",
      "LOSS train 3.89781359420743e-05 valid 0.00026118376990780234\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1932839697692544e-06\n",
      "  batch 101 loss: 8.632201814180008e-05\n",
      "  batch 201 loss: 4.0948761860590824e-05\n",
      "LOSS train 5.6914417596489836e-05 valid 5.420995512395166e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.364797405287391e-08\n",
      "  batch 101 loss: 6.748607333292966e-05\n",
      "  batch 201 loss: 2.855232175875244e-05\n",
      "LOSS train 5.3269213262099137e-05 valid 0.0001637810782995075\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.919703057268635e-07\n",
      "  batch 101 loss: 0.0001695798335231302\n",
      "  batch 201 loss: 4.872366294762287e-05\n",
      "LOSS train 0.00012406791585522863 valid 0.00048260990297421813\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.289438365958631e-06\n",
      "  batch 101 loss: 0.0004638047262096734\n",
      "  batch 201 loss: 3.355169335691244e-05\n",
      "LOSS train 0.00020355407409774522 valid 0.00021880569693166763\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.5067757815122605e-06\n",
      "  batch 101 loss: 0.0003964448366286888\n",
      "  batch 201 loss: 2.959086162263702e-05\n",
      "LOSS train 0.00018136079650140103 valid 0.00038542484981007874\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00028155643492937086\n",
      "  batch 101 loss: 0.005621386338025332\n",
      "  batch 201 loss: 0.0017505402333335951\n",
      "LOSS train 0.0030560304347644032 valid 0.0007395052816718817\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.121427096426487e-05\n",
      "  batch 101 loss: 0.0006464523507747799\n",
      "  batch 201 loss: 0.00050034539817716\n",
      "LOSS train 0.0004722952228440347 valid 9.925910853780806e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.444722435437143e-06\n",
      "  batch 101 loss: 0.00017221431207872228\n",
      "  batch 201 loss: 0.00011395774856282515\n",
      "LOSS train 0.0001158288765982567 valid 2.131431392626837e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1451077443780378e-06\n",
      "  batch 101 loss: 4.8278586082233235e-05\n",
      "  batch 201 loss: 2.179773504849436e-05\n",
      "LOSS train 3.0108828212131553e-05 valid 9.725129530124832e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.1015552192693576e-07\n",
      "  batch 101 loss: 1.9171033818565776e-05\n",
      "  batch 201 loss: 2.3295025744118903e-05\n",
      "LOSS train 1.9428383319001904e-05 valid 4.546845502773067e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.3936713003204204e-07\n",
      "  batch 101 loss: 3.54847379480816e-05\n",
      "  batch 201 loss: 7.55566124030338e-05\n",
      "LOSS train 0.00011620571668212866 valid 3.2988577004289255e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.6521632864605633e-07\n",
      "  batch 101 loss: 9.245109184575995e-05\n",
      "  batch 201 loss: 0.00017999598878986944\n",
      "LOSS train 0.00012870389426034674 valid 4.503793752519414e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.1973786715534515e-07\n",
      "  batch 101 loss: 0.00020698810553312796\n",
      "  batch 201 loss: 0.00010000023014754333\n",
      "LOSS train 0.00023810637909320821 valid 3.2934924092842266e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006986040621995926\n",
      "  batch 101 loss: 0.006798467398621142\n",
      "  batch 201 loss: 0.0019822264282265676\n",
      "LOSS train 0.0036803771510989756 valid 0.00013479353219736367\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.505542551167309e-06\n",
      "  batch 101 loss: 0.0003431783065025229\n",
      "  batch 201 loss: 0.00011862454222864471\n",
      "LOSS train 0.00018350934156582559 valid 1.6682575733284466e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.485153451445512e-07\n",
      "  batch 101 loss: 2.421442790364381e-05\n",
      "  batch 201 loss: 1.1948154722176695e-05\n",
      "LOSS train 1.7120499256174758e-05 valid 7.724397619313095e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.656065695802681e-08\n",
      "  batch 101 loss: 1.2673967828504829e-05\n",
      "  batch 201 loss: 1.2692698674072744e-05\n",
      "LOSS train 1.3265944138992458e-05 valid 3.5544037473300705e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.4307246349053456e-08\n",
      "  batch 101 loss: 2.6999298023611117e-05\n",
      "  batch 201 loss: 3.980205674906756e-05\n",
      "LOSS train 3.391853407297093e-05 valid 4.440636075742077e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.1261818094208136e-08\n",
      "  batch 101 loss: 0.00011962306687337332\n",
      "  batch 201 loss: 0.00026316150474485766\n",
      "LOSS train 0.00016904468902927437 valid 1.9443699784460478e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.684610444703139e-07\n",
      "  batch 101 loss: 0.00017908254044868955\n",
      "  batch 201 loss: 0.00017480440133113006\n",
      "LOSS train 0.00018121693954646496 valid 1.0174609087698627e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.2207432519062423e-07\n",
      "  batch 101 loss: 0.00011694879500737443\n",
      "  batch 201 loss: 0.00027781700458945124\n",
      "LOSS train 0.0001938835233863173 valid 6.948890222702175e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00032688487321138384\n",
      "  batch 101 loss: 0.010770370864775032\n",
      "  batch 201 loss: 0.0017079739487962798\n",
      "LOSS train 0.0047733947064773595 valid 4.078364872839302e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.7385959401726723e-06\n",
      "  batch 101 loss: 0.00010746039224613923\n",
      "  batch 201 loss: 3.098401722581912e-05\n",
      "LOSS train 5.752877544618835e-05 valid 5.3896321333013475e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.379589417017996e-07\n",
      "  batch 101 loss: 2.6062633910441946e-05\n",
      "  batch 201 loss: 2.1277580742662394e-05\n",
      "LOSS train 2.4755047508280614e-05 valid 8.580740541219711e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.440027623786591e-08\n",
      "  batch 101 loss: 1.586105719979969e-05\n",
      "  batch 201 loss: 1.9513515728704077e-05\n",
      "LOSS train 1.8452734559518113e-05 valid 1.4321629350888543e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.3277498257812112e-07\n",
      "  batch 101 loss: 3.999676919193007e-05\n",
      "  batch 201 loss: 4.5685671116189044e-05\n",
      "LOSS train 4.105390719784767e-05 valid 6.457280505856033e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0024691619037184e-07\n",
      "  batch 101 loss: 8.896904007997364e-05\n",
      "  batch 201 loss: 9.851450200585531e-05\n",
      "LOSS train 0.00015935672970807745 valid 0.000803136732429266\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0479870252311229e-05\n",
      "  batch 101 loss: 0.00028837041858423615\n",
      "  batch 201 loss: 7.589973934045702e-05\n",
      "LOSS train 0.00020833691187929353 valid 0.00018937130516860634\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.4454915546812116e-06\n",
      "  batch 101 loss: 0.00012199707460240461\n",
      "  batch 201 loss: 0.00018349437124925316\n",
      "LOSS train 0.00017918770107503123 valid 2.451104774081614e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003815290331840515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.01373852459480986\n",
      "  batch 201 loss: 0.000331088293241919\n",
      "LOSS train 0.005303230822884984 valid 2.560188113420736e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.0360157466493548e-06\n",
      "  batch 101 loss: 4.691162912422442e-05\n",
      "  batch 201 loss: 3.627223868534202e-05\n",
      "LOSS train 4.2899975118742965e-05 valid 6.603272777283564e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0158565419260413e-06\n",
      "  batch 101 loss: 3.136648974759737e-05\n",
      "  batch 201 loss: 3.548836307800229e-05\n",
      "LOSS train 3.302782261682842e-05 valid 2.6999903639080003e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.4850079828174784e-07\n",
      "  batch 101 loss: 5.849275560649403e-05\n",
      "  batch 201 loss: 7.756268848424952e-05\n",
      "LOSS train 7.30207797320103e-05 valid 1.6098516425699927e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.199723141733557e-07\n",
      "  batch 101 loss: 0.00016795704027572356\n",
      "  batch 201 loss: 0.00019649787380330964\n",
      "LOSS train 0.0002162485257381027 valid 0.00021624487999361008\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.6438984787091614e-06\n",
      "  batch 101 loss: 0.00030565257704438407\n",
      "  batch 201 loss: 0.0001972441866655572\n",
      "LOSS train 0.00024975746954967044 valid 1.9099996279692277e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.266484994441271e-07\n",
      "  batch 101 loss: 0.00017690240223600996\n",
      "  batch 201 loss: 0.00016825150027216295\n",
      "LOSS train 0.00019657459231047685 valid 8.25771494419314e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.9964635430369525e-06\n",
      "  batch 101 loss: 0.00028523387338282193\n",
      "  batch 201 loss: 0.00032447503861476434\n",
      "LOSS train 0.0002677591971901882 valid 2.209625017712824e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.4766414687037466e-05\n",
      "  batch 101 loss: 0.0030248664782789093\n",
      "  batch 201 loss: 1.4791585979310184e-05\n",
      "LOSS train 0.0011350943526266307 valid 8.965603228716645e-06\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.1157081795972774e-08\n",
      "  batch 101 loss: 3.2506802116927247e-06\n",
      "  batch 201 loss: 3.882746359806788e-06\n",
      "LOSS train 3.161408507501939e-06 valid 9.194398444378749e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.806450412317645e-08\n",
      "  batch 101 loss: 2.509624517301745e-06\n",
      "  batch 201 loss: 3.7479204402757204e-06\n",
      "LOSS train 2.8340814362730607e-06 valid 5.418127329903655e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.325362740724813e-08\n",
      "  batch 101 loss: 2.3661715562184325e-06\n",
      "  batch 201 loss: 3.3115651717707807e-06\n",
      "LOSS train 2.605478022799253e-06 valid 4.02036539526307e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.0717543520731852e-08\n",
      "  batch 101 loss: 2.4421152468789842e-06\n",
      "  batch 201 loss: 3.256662439810043e-06\n",
      "LOSS train 2.5996131326286685e-06 valid 3.563002337614307e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.7519398625154282e-08\n",
      "  batch 101 loss: 2.434102252948378e-06\n",
      "  batch 201 loss: 3.1740072361685634e-06\n",
      "LOSS train 2.5420546936758858e-06 valid 3.245184416300617e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.5603610563630354e-08\n",
      "  batch 101 loss: 2.4058863149889476e-06\n",
      "  batch 201 loss: 3.087155292007537e-06\n",
      "LOSS train 2.484567002760568e-06 valid 3.043729975615861e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.5209077446343143e-08\n",
      "  batch 101 loss: 2.383102508929369e-06\n",
      "  batch 201 loss: 3.027878138084361e-06\n",
      "LOSS train 2.4472637894982304e-06 valid 2.895124907809077e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00043444376438856125\n",
      "  batch 101 loss: 0.0021333196545310785\n",
      "  batch 201 loss: 0.0003712738004105631\n",
      "LOSS train 0.0012143019190701595 valid 2.313719960511662e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.7715216381475328e-06\n",
      "  batch 101 loss: 0.00022693137449095958\n",
      "  batch 201 loss: 0.00014309531419712585\n",
      "LOSS train 0.00016323227113982297 valid 1.2898354725621175e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.366138015640899e-07\n",
      "  batch 101 loss: 6.717723848851165e-05\n",
      "  batch 201 loss: 4.5349639804044274e-05\n",
      "LOSS train 4.864975503701167e-05 valid 3.209282658644952e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.380175909725949e-07\n",
      "  batch 101 loss: 2.0392699618696496e-05\n",
      "  batch 201 loss: 1.119047461656919e-05\n",
      "LOSS train 1.3727729526760744e-05 valid 2.2387655917555094e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.877149199775886e-07\n",
      "  batch 101 loss: 7.17471581879181e-06\n",
      "  batch 201 loss: 1.5377634587139254e-05\n",
      "LOSS train 1.322990993537962e-05 valid 3.7529185647144914e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.6466769819962794e-08\n",
      "  batch 101 loss: 6.246621153479736e-05\n",
      "  batch 201 loss: 0.00011984912894376976\n",
      "LOSS train 9.975103286781935e-05 valid 9.084492194233462e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.177363665192388e-06\n",
      "  batch 101 loss: 0.00012036852711105439\n",
      "  batch 201 loss: 0.00011855098079990967\n",
      "LOSS train 0.00012023891305936338 valid 9.105414937948808e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1809360876213759e-06\n",
      "  batch 101 loss: 0.00011846910500025843\n",
      "  batch 201 loss: 0.0001170886935881299\n",
      "LOSS train 0.00011862122374080109 valid 9.095020504901186e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.0119682885706426e-05\n",
      "  batch 101 loss: 0.004908968581530644\n",
      "  batch 201 loss: 5.845658959515276e-05\n",
      "LOSS train 0.0018421463372803935 valid 5.2478826546575874e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.40861406584736e-07\n",
      "  batch 101 loss: 6.1678179727096e-05\n",
      "  batch 201 loss: 6.392625207809033e-05\n",
      "LOSS train 6.298445953692557e-05 valid 5.494136348715983e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.3277101212879644e-07\n",
      "  batch 101 loss: 6.758810053270281e-05\n",
      "  batch 201 loss: 6.991741433466814e-05\n",
      "LOSS train 6.908211204702909e-05 valid 5.848555520060472e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.347109254216775e-07\n",
      "  batch 101 loss: 7.378946134849685e-05\n",
      "  batch 201 loss: 7.626687468473392e-05\n",
      "LOSS train 7.555789554380314e-05 valid 6.314797792583704e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.480170122813433e-07\n",
      "  batch 101 loss: 8.039168015557152e-05\n",
      "  batch 201 loss: 8.293332042285329e-05\n",
      "LOSS train 8.239947919469409e-05 valid 6.864255556138232e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.66705343266949e-07\n",
      "  batch 101 loss: 8.716078626548551e-05\n",
      "  batch 201 loss: 8.958467632055544e-05\n",
      "LOSS train 8.928161921905665e-05 valid 7.431609265040606e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.79527215147391e-07\n",
      "  batch 101 loss: 9.364383947740862e-05\n",
      "  batch 201 loss: 9.573465998300889e-05\n",
      "LOSS train 9.570560860333649e-05 valid 7.938297494547442e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.747523290570826e-07\n",
      "  batch 101 loss: 9.935401445659408e-05\n",
      "  batch 201 loss: 0.00010095340870350356\n",
      "LOSS train 0.00010121129947311858 valid 8.331670687766746e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.001071433573961258\n",
      "  batch 101 loss: 0.0022387363319285214\n",
      "  batch 201 loss: 0.00019156190610374323\n",
      "LOSS train 0.001304468612436925 valid 5.099217014503665e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.425873339641839e-07\n",
      "  batch 101 loss: 6.241758943360764e-05\n",
      "  batch 201 loss: 7.68849502219382e-05\n",
      "LOSS train 6.988637924123495e-05 valid 5.803109161206521e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.442764449981042e-07\n",
      "  batch 101 loss: 7.46701867592492e-05\n",
      "  batch 201 loss: 7.77092332691609e-05\n",
      "LOSS train 7.710474509981945e-05 valid 6.564836075995117e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.350616942858323e-07\n",
      "  batch 101 loss: 8.167569129682306e-05\n",
      "  batch 201 loss: 8.348288943238913e-05\n",
      "LOSS train 8.366346850548308e-05 valid 5.4202540923142806e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.591649434994906e-07\n",
      "  batch 101 loss: 8.521506667023005e-05\n",
      "  batch 201 loss: 9.020489256045039e-05\n",
      "LOSS train 8.847170422620362e-05 valid 6.807916361140087e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.065400081453845e-07\n",
      "  batch 101 loss: 8.687031959624392e-05\n",
      "  batch 201 loss: 8.382366940992369e-05\n",
      "LOSS train 8.192029316023264e-05 valid 4.388695379020646e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.284377387695713e-08\n",
      "  batch 101 loss: 7.788955753881056e-05\n",
      "  batch 201 loss: 9.466429463941494e-05\n",
      "LOSS train 7.886588134653767e-05 valid 5.5832839279901236e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.988696597749367e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 4.6144962593075436e-05\n",
      "  batch 201 loss: 5.218685663862743e-05\n",
      "LOSS train 4.846776678065438e-05 valid 3.022369673999492e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000354030579328537\n",
      "  batch 101 loss: 0.006493928509007674\n",
      "  batch 201 loss: 0.0001812269454080706\n",
      "LOSS train 0.0025826138593811766 valid 1.5224645721900743e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3861847037333063e-07\n",
      "  batch 101 loss: 2.9513960316762678e-05\n",
      "  batch 201 loss: 5.823337807214557e-05\n",
      "LOSS train 4.894426426486568e-05 valid 5.475004218169488e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.2655461584217847e-07\n",
      "  batch 101 loss: 6.71658691499033e-05\n",
      "  batch 201 loss: 6.943387229057407e-05\n",
      "LOSS train 6.859699648481889e-05 valid 5.8126654039369896e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.252243863651528e-07\n",
      "  batch 101 loss: 7.32025913475809e-05\n",
      "  batch 201 loss: 7.562726581454626e-05\n",
      "LOSS train 7.490928107685642e-05 valid 6.261035741772503e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.356924859574065e-07\n",
      "  batch 101 loss: 7.966467351479878e-05\n",
      "  batch 201 loss: 8.217458164835989e-05\n",
      "LOSS train 8.162255455864153e-05 valid 6.796882371418178e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.527433626819402e-07\n",
      "  batch 101 loss: 8.635140392016183e-05\n",
      "  batch 201 loss: 8.877713229367145e-05\n",
      "LOSS train 8.844622789933215e-05 valid 7.36079309717752e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.658476144773886e-07\n",
      "  batch 101 loss: 9.283668846819637e-05\n",
      "  batch 201 loss: 9.496537067434474e-05\n",
      "LOSS train 9.490116788803569e-05 valid 7.875478331698105e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.631750435801222e-07\n",
      "  batch 101 loss: 9.863119493729754e-05\n",
      "  batch 201 loss: 0.00010029305450416359\n",
      "LOSS train 0.0001005134730567845 valid 8.28363627078943e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004207798093557358\n",
      "  batch 101 loss: 0.0008466786910639713\n",
      "  batch 201 loss: 2.31951688749632e-05\n",
      "LOSS train 0.0004761993399604982 valid 1.5575764336972497e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.030760232533794e-08\n",
      "  batch 101 loss: 6.917413903408942e-06\n",
      "  batch 201 loss: 3.029712589466271e-06\n",
      "LOSS train 4.806798354867009e-06 valid 1.2141741535742767e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.975850970367901e-08\n",
      "  batch 101 loss: 2.167345174370894e-06\n",
      "  batch 201 loss: 1.992492268243495e-06\n",
      "LOSS train 2.720550013247616e-06 valid 1.486263226979645e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.7464832328405464e-08\n",
      "  batch 101 loss: 2.026122846103817e-06\n",
      "  batch 201 loss: 2.2296725258286186e-06\n",
      "LOSS train 2.7425923897284615e-06 valid 2.497063542250544e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.249626605698722e-09\n",
      "  batch 101 loss: 2.2249186497447227e-06\n",
      "  batch 201 loss: 2.3177667974039197e-06\n",
      "LOSS train 2.8464438638252015e-06 valid 2.3800124836270697e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.708275001685251e-09\n",
      "  batch 101 loss: 2.5880064123384727e-06\n",
      "  batch 201 loss: 2.3903153341109373e-06\n",
      "LOSS train 3.196907618506378e-06 valid 1.3838320228387602e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.7388828129915054e-08\n",
      "  batch 101 loss: 2.6414974576027817e-06\n",
      "  batch 201 loss: 2.4182872802214206e-06\n",
      "LOSS train 2.9694983327954605e-06 valid 3.0145683922455646e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.8409212973201646e-08\n",
      "  batch 101 loss: 2.6455605114250603e-06\n",
      "  batch 201 loss: 2.864898000609628e-06\n",
      "LOSS train 3.030009680932815e-06 valid 3.7917725421721116e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.038892410695553e-05\n",
      "  batch 101 loss: 0.0005366838398913387\n",
      "  batch 201 loss: 0.00011924794378501247\n",
      "LOSS train 0.00028853360199652104 valid 6.089242742746137e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.318703526630998e-08\n",
      "  batch 101 loss: 9.283571272590052e-05\n",
      "  batch 201 loss: 0.00012038953348110226\n",
      "LOSS train 0.00011050868165874228 valid 8.781423821346834e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0918588668573648e-06\n",
      "  batch 101 loss: 0.0001179665505696903\n",
      "  batch 201 loss: 0.00011539765896145582\n",
      "LOSS train 0.00011710523642038788 valid 8.85847257450223e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1403985263314098e-06\n",
      "  batch 101 loss: 0.0001142470934235007\n",
      "  batch 201 loss: 0.00011302722440973412\n",
      "LOSS train 0.00011445003850738285 valid 8.64921894390136e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1054222704842686e-06\n",
      "  batch 101 loss: 0.00011216590112553604\n",
      "  batch 201 loss: 0.00011032737044502028\n",
      "LOSS train 0.00011198211090716511 valid 8.467400766676292e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0850467515410856e-06\n",
      "  batch 101 loss: 0.00010966306247951251\n",
      "  batch 201 loss: 0.00010881348262046231\n",
      "LOSS train 0.00011032084958951467 valid 8.464404527330771e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0806637146743015e-06\n",
      "  batch 101 loss: 0.0001092602668188647\n",
      "  batch 201 loss: 0.00010776246674595313\n",
      "LOSS train 0.0001093062796493268 valid 8.030505705391988e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0180882236454637e-06\n",
      "  batch 101 loss: 0.00010825861579064622\n",
      "  batch 201 loss: 0.00010638238352953522\n",
      "LOSS train 0.00010848667001326102 valid 8.175634138751775e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0013864833116531373\n",
      "  batch 101 loss: 0.01140718901064247\n",
      "  batch 201 loss: 0.004491920174332336\n",
      "LOSS train 0.006945392358263498 valid 0.0001367680379189551\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.5158604364842176e-05\n",
      "  batch 101 loss: 0.0010710372778703458\n",
      "  batch 201 loss: 0.0003948411562305409\n",
      "LOSS train 0.0005879072674101085 valid 4.5688684622291476e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3727454643230886e-06\n",
      "  batch 101 loss: 0.00011806765873188851\n",
      "  batch 201 loss: 8.233709748310502e-05\n",
      "LOSS train 8.986367984873588e-05 valid 2.342377592867706e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.464149944600649e-07\n",
      "  batch 101 loss: 5.580764334808919e-05\n",
      "  batch 201 loss: 4.490504143177532e-05\n",
      "LOSS train 4.7191808361552855e-05 valid 1.816367330320645e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.184873953112401e-07\n",
      "  batch 101 loss: 3.6065886088181285e-05\n",
      "  batch 201 loss: 3.396844635972229e-05\n",
      "LOSS train 3.434133357473418e-05 valid 1.8933887986349873e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.660697595681995e-07\n",
      "  batch 101 loss: 3.217458351173263e-05\n",
      "  batch 201 loss: 3.154465071474988e-05\n",
      "LOSS train 3.129370846984588e-05 valid 1.8191603885497898e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.110174995730631e-07\n",
      "  batch 101 loss: 3.048568482427072e-05\n",
      "  batch 201 loss: 3.0779815756432075e-05\n",
      "LOSS train 3.0663763243951725e-05 valid 2.2645786884822883e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.611858821590431e-07\n",
      "  batch 101 loss: 3.182253005434177e-05\n",
      "  batch 201 loss: 2.981147780701576e-05\n",
      "LOSS train 3.148387045607356e-05 valid 1.751974741637241e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.0702420733869076e-05\n",
      "  batch 101 loss: 0.0006046163256542058\n",
      "  batch 201 loss: 0.0001514861988471239\n",
      "LOSS train 0.0003187637523176938 valid 9.195928578265011e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.2772317859344184e-06\n",
      "  batch 101 loss: 0.00011755623702811136\n",
      "  batch 201 loss: 0.00011657189134211876\n",
      "LOSS train 0.00011674538716423017 valid 8.732042624615133e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1165902105858549e-06\n",
      "  batch 101 loss: 0.00010969637836410584\n",
      "  batch 201 loss: 0.00011059127961516425\n",
      "LOSS train 0.00011135643309017014 valid 8.92392490641214e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.149821764556691e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.0001127017165637767\n",
      "  batch 201 loss: 0.00011262542213756888\n",
      "LOSS train 0.00011369031731820899 valid 8.990479545900598e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.161266991402954e-06\n",
      "  batch 101 loss: 0.00011394645857478735\n",
      "  batch 201 loss: 0.00011352770482858432\n",
      "LOSS train 0.00011470381396803023 valid 9.017482079798356e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1658985749818385e-06\n",
      "  batch 101 loss: 0.000114556451376302\n",
      "  batch 201 loss: 0.00011398665570851563\n",
      "LOSS train 0.00011521424115497148 valid 9.030361252371222e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1681049363687634e-06\n",
      "  batch 101 loss: 0.00011488651512024717\n",
      "  batch 201 loss: 0.00011424099122223197\n",
      "LOSS train 0.00011549548456337889 valid 9.037180279847234e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1692729458445683e-06\n",
      "  batch 101 loss: 0.00011507705431313298\n",
      "  batch 201 loss: 0.00011439022093895801\n",
      "LOSS train 0.00011565986708885894 valid 9.041047451319173e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0012580758333206176\n",
      "  batch 101 loss: 0.016464674226008356\n",
      "  batch 201 loss: 0.001958018364966847\n",
      "LOSS train 0.007364186991859849 valid 5.220662569627166e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.08589922497049e-06\n",
      "  batch 101 loss: 0.00024008018132008147\n",
      "  batch 201 loss: 0.00012197811869555153\n",
      "LOSS train 0.00015792099823027077 valid 5.35127728653606e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.863946666475385e-07\n",
      "  batch 101 loss: 8.029466207517543e-05\n",
      "  batch 201 loss: 7.06976204219245e-05\n",
      "LOSS train 7.346182980618056e-05 valid 5.446473733172752e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.712473310064524e-07\n",
      "  batch 101 loss: 6.961264241454047e-05\n",
      "  batch 201 loss: 7.104367971805914e-05\n",
      "LOSS train 7.035293841136247e-05 valid 5.795286051579751e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.305611193762161e-07\n",
      "  batch 101 loss: 7.378627936759586e-05\n",
      "  batch 201 loss: 7.558389899713802e-05\n",
      "LOSS train 7.482644254456059e-05 valid 6.119139288784936e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.250155274756252e-07\n",
      "  batch 101 loss: 7.828889943994e-05\n",
      "  batch 201 loss: 8.055539309680171e-05\n",
      "LOSS train 7.996525957070591e-05 valid 6.596879393327981e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.138830551411956e-07\n",
      "  batch 101 loss: 8.413467901846161e-05\n",
      "  batch 201 loss: 8.64613872818154e-05\n",
      "LOSS train 8.604813531883504e-05 valid 7.102275412762538e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.328320109285414e-07\n",
      "  batch 101 loss: 9.021861697874556e-05\n",
      "  batch 201 loss: 9.230624959172929e-05\n",
      "LOSS train 9.219561500505913e-05 valid 7.625628495588899e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003101781196892261\n",
      "  batch 101 loss: 0.00010221553767905789\n",
      "  batch 201 loss: 2.3931035080408947e-05\n",
      "LOSS train 0.00016183113734352558 valid 4.277947027730988e-06\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.923338666339987e-09\n",
      "  batch 101 loss: 1.5162314352892281e-05\n",
      "  batch 201 loss: 1.091345806969457e-05\n",
      "LOSS train 1.139171862838512e-05 valid 5.0448284127924126e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.297687716345536e-08\n",
      "  batch 101 loss: 7.763213332054875e-06\n",
      "  batch 201 loss: 1.0536503187665858e-05\n",
      "LOSS train 7.980259644402258e-06 valid 2.5261417704314226e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.4230632662875e-09\n",
      "  batch 101 loss: 4.388804359507504e-06\n",
      "  batch 201 loss: 4.938103916458659e-06\n",
      "LOSS train 4.974671867590743e-06 valid 1.18122134153964e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.9421500837779604e-07\n",
      "  batch 101 loss: 5.540804273778122e-06\n",
      "  batch 201 loss: 4.291220073611157e-06\n",
      "LOSS train 4.719725471555638e-06 valid 3.6945668853149982e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.0019819986555375e-09\n",
      "  batch 101 loss: 3.5918854628391728e-06\n",
      "  batch 201 loss: 3.879541357321159e-06\n",
      "LOSS train 3.7426729984072122e-06 valid 2.2239580630412092e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.502735795445914e-09\n",
      "  batch 101 loss: 6.3181289849012505e-06\n",
      "  batch 201 loss: 3.4286606359046345e-06\n",
      "LOSS train 4.538591933718162e-06 valid 1.997517983909347e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.139792061621847e-08\n",
      "  batch 101 loss: 3.7722889837255026e-06\n",
      "  batch 201 loss: 3.856584361585646e-06\n",
      "LOSS train 8.93114216411806e-06 valid 9.541613690089434e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00011926606297492982\n",
      "  batch 101 loss: 0.0005669430051057134\n",
      "  batch 201 loss: 0.00012166766451628064\n",
      "LOSS train 0.00031291118802283355 valid 5.934664295637049e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.5276359994895756e-07\n",
      "  batch 101 loss: 4.3873191989405315e-05\n",
      "  batch 201 loss: 3.591546162624581e-05\n",
      "LOSS train 3.956689635323038e-05 valid 7.454081060132012e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.922955774120056e-08\n",
      "  batch 101 loss: 3.8856988380757686e-05\n",
      "  batch 201 loss: 5.367570168800739e-05\n",
      "LOSS train 4.526093852751269e-05 valid 0.0001466847024857998\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.25254222843796e-07\n",
      "  batch 101 loss: 5.360544120549093e-05\n",
      "  batch 201 loss: 7.069688726460299e-05\n",
      "LOSS train 6.71685416359201e-05 valid 6.703535473207012e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.710512833597022e-08\n",
      "  batch 101 loss: 9.899240863887826e-05\n",
      "  batch 201 loss: 0.00010781978988347874\n",
      "LOSS train 0.00010897906031751075 valid 6.754024070687592e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.394031126750633e-07\n",
      "  batch 101 loss: 0.0001274962888862774\n",
      "  batch 201 loss: 0.00012534879993040705\n",
      "LOSS train 0.00012722640997045402 valid 8.676370634930208e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.104675466194749e-06\n",
      "  batch 101 loss: 0.00012496393087360502\n",
      "  batch 201 loss: 0.00012225233677099824\n",
      "LOSS train 0.00012427107987797662 valid 9.040234726853669e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1700624600052834e-06\n",
      "  batch 101 loss: 0.00012147149361680931\n",
      "  batch 201 loss: 0.00011945794649648178\n",
      "LOSS train 0.00012121246752781273 valid 9.098247392103076e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.456489304080606e-06\n",
      "  batch 101 loss: 0.0002613583139464026\n",
      "  batch 201 loss: 6.265747034376545e-05\n",
      "LOSS train 0.00013962078408993019 valid 9.065306221600622e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.6512221817683895e-08\n",
      "  batch 101 loss: 6.3621001681895e-05\n",
      "  batch 201 loss: 8.695714845771363e-05\n",
      "LOSS train 8.723688811316553e-05 valid 6.373639189405367e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.46698463242501e-07\n",
      "  batch 101 loss: 0.00012692214792309642\n",
      "  batch 201 loss: 0.00012325753705056286\n",
      "LOSS train 0.00012509981678976556 valid 9.087791113415733e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1779748456319794e-06\n",
      "  batch 101 loss: 0.00012075132722372928\n",
      "  batch 201 loss: 0.00011856963826289757\n",
      "LOSS train 0.00012033604632602247 valid 9.111488179769367e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1819608334917575e-06\n",
      "  batch 101 loss: 0.00011818509298223035\n",
      "  batch 201 loss: 0.0001167740526898342\n",
      "LOSS train 0.00011829826114693781 valid 9.092450636671856e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1787003313656896e-06\n",
      "  batch 101 loss: 0.00011698150008896846\n",
      "  batch 201 loss: 0.00011588472240475767\n",
      "LOSS train 0.00011730445888757365 valid 9.076721471501514e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.176031946670264e-06\n",
      "  batch 101 loss: 0.00011634688140645722\n",
      "  batch 201 loss: 0.00011540006680206716\n",
      "LOSS train 0.00011676752241588215 valid 9.066313941730186e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.174254939542152e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00011598619422670709\n",
      "  batch 201 loss: 0.00011511827538811303\n",
      "LOSS train 0.00011645730965199372 valid 9.05966735444963e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005055690556764603\n",
      "  batch 101 loss: 0.0033182346454123037\n",
      "  batch 201 loss: 0.000665197731286753\n",
      "LOSS train 0.0017440823536202475 valid 0.00014338179607875645\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.906790759880096e-06\n",
      "  batch 101 loss: 0.0002428527138545178\n",
      "  batch 201 loss: 0.00019889428513124584\n",
      "LOSS train 0.00021048803537535642 valid 5.522829087567516e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0513812594581395e-06\n",
      "  batch 101 loss: 0.0001390473607716558\n",
      "  batch 201 loss: 9.073256300325739e-05\n",
      "LOSS train 0.00011695207172041069 valid 6.14702730672434e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.449852662626654e-07\n",
      "  batch 101 loss: 8.65774796147889e-05\n",
      "  batch 201 loss: 0.00010261779978122832\n",
      "LOSS train 9.597380525954597e-05 valid 7.99156041466631e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.810831397771836e-07\n",
      "  batch 101 loss: 9.97330323798451e-05\n",
      "  batch 201 loss: 0.00010141799943198748\n",
      "LOSS train 0.00010172910107078782 valid 8.395566692342982e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0554114123806358e-06\n",
      "  batch 101 loss: 0.0001048592007384741\n",
      "  batch 201 loss: 0.0001059513407636814\n",
      "LOSS train 0.00010652176861860205 valid 8.670933311805129e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.102784735849127e-06\n",
      "  batch 101 loss: 0.00010843889566729103\n",
      "  batch 201 loss: 0.00010905987719127097\n",
      "LOSS train 0.00010979671536992327 valid 8.834415348246694e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.134752674261108e-06\n",
      "  batch 101 loss: 0.00011095814200302811\n",
      "  batch 201 loss: 0.00011101066643561807\n",
      "LOSS train 0.00011198368052948734 valid 8.921692642616108e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001422324124723673\n",
      "  batch 101 loss: 0.001183632407191908\n",
      "  batch 201 loss: 0.00013998707287100844\n",
      "LOSS train 0.0005611557649273305 valid 5.117203909321688e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.2569587094476446e-07\n",
      "  batch 101 loss: 0.0001054457813791032\n",
      "  batch 201 loss: 0.00010953574211157502\n",
      "LOSS train 0.00010868995289247456 valid 8.62431843415834e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.136001810664311e-06\n",
      "  batch 101 loss: 0.00011131729888575137\n",
      "  batch 201 loss: 0.00011198091912831387\n",
      "LOSS train 0.00011273680632793679 valid 8.846684795571491e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1730958067346364e-06\n",
      "  batch 101 loss: 0.00011385076890405798\n",
      "  batch 201 loss: 0.00011327308786462708\n",
      "LOSS train 0.00011443615897400837 valid 8.900356624508277e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1387142149033025e-06\n",
      "  batch 101 loss: 0.00011411131293016296\n",
      "  batch 201 loss: 0.00011378368106505832\n",
      "LOSS train 0.00011491540967202313 valid 9.006368782138452e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1706928489729761e-06\n",
      "  batch 101 loss: 0.00011461578689988983\n",
      "  batch 201 loss: 0.00011410335593268427\n",
      "LOSS train 0.0001152395922344489 valid 9.007118933368474e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.165142166428268e-06\n",
      "  batch 101 loss: 0.00011492893107629244\n",
      "  batch 201 loss: 0.00011437094112466184\n",
      "LOSS train 0.00011558018588699276 valid 9.002594742923975e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1703054042300209e-06\n",
      "  batch 101 loss: 0.00011507732613551979\n",
      "  batch 201 loss: 0.00011442278144102147\n",
      "LOSS train 0.00011567238349102192 valid 9.012623195303604e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0008435530215501786\n",
      "  batch 101 loss: 0.08940668082061165\n",
      "  batch 201 loss: 0.0005497321310576808\n",
      "LOSS train 0.03328776297958829 valid 0.0005916468217037618\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.8967277137562634e-05\n",
      "  batch 101 loss: 0.0003247917213184337\n",
      "  batch 201 loss: 0.0001909701793340446\n",
      "LOSS train 0.00022717161499631635 valid 0.0005802630330435932\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.984264235943556e-05\n",
      "  batch 101 loss: 0.00039229277792628635\n",
      "  batch 201 loss: 0.00020944651484853695\n",
      "LOSS train 0.0002658784143081503 valid 0.0005899418029002845\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1670422973111272e-05\n",
      "  batch 101 loss: 0.0007340404598744499\n",
      "  batch 201 loss: 0.00026658748328486584\n",
      "LOSS train 0.0004031583660804784 valid 0.0005010406603105366\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.6220728866755962e-05\n",
      "  batch 101 loss: 0.0006632633613844519\n",
      "  batch 201 loss: 0.0004348386002936877\n",
      "LOSS train 0.00046246515748033586 valid 0.000507438147906214\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.9029665272682904e-05\n",
      "  batch 101 loss: 0.0012532080529945233\n",
      "  batch 201 loss: 0.0003595940279274146\n",
      "LOSS train 0.0006839214695230025 valid 0.0015730514423921704\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.836889638681896e-07\n",
      "  batch 101 loss: 0.006614840307811391\n",
      "  batch 201 loss: 0.0018088736145364236\n",
      "LOSS train 0.0031610387794609156 valid 0.0012084133923053741\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.3050372041761876e-05\n",
      "  batch 101 loss: 0.007370332888531266\n",
      "  batch 201 loss: 0.00045286001503427544\n",
      "LOSS train 0.002943592821929747 valid 0.0015435634413734078\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00014057999476790428\n",
      "  batch 101 loss: 0.12044906721799635\n",
      "  batch 201 loss: 0.0020083893957780676\n",
      "LOSS train 0.04529880262436277 valid 0.0003256065247114748\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.757857320830226e-05\n",
      "  batch 101 loss: 0.0009518729930277914\n",
      "  batch 201 loss: 0.0005106786327087321\n",
      "LOSS train 0.0006190550163573322 valid 0.0002082799474010244\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.966123865917325e-06\n",
      "  batch 101 loss: 0.00026211694865196477\n",
      "  batch 201 loss: 9.929955594998319e-05\n",
      "LOSS train 0.00014715010050604045 valid 3.855219983961433e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.7283691451884807e-06\n",
      "  batch 101 loss: 7.77964338340098e-05\n",
      "  batch 201 loss: 3.4656242751225366e-05\n",
      "LOSS train 4.5813242915036234e-05 valid 2.1734902475145645e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1865093256346882e-06\n",
      "  batch 101 loss: 4.993320695120929e-05\n",
      "  batch 201 loss: 1.29174397989118e-05\n",
      "LOSS train 2.647654241377745e-05 valid 1.0809867490024772e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.3631308320327663e-07\n",
      "  batch 101 loss: 4.379370911010483e-05\n",
      "  batch 201 loss: 1.9898018028925434e-05\n",
      "LOSS train 3.426411139043388e-05 valid 5.3118161304155365e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.375870675081387e-07\n",
      "  batch 101 loss: 0.00010757475200534828\n",
      "  batch 201 loss: 0.00417292021634239\n",
      "LOSS train 0.001879503184827027 valid 0.0024088809732347727\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.5943159125745297e-05\n",
      "  batch 101 loss: 0.003199132286317763\n",
      "  batch 201 loss: 0.004101032264152309\n",
      "LOSS train 0.0033202382698248956 valid 0.00012073157995473593\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0008616963773965835\n",
      "  batch 101 loss: 0.09685530069516972\n",
      "  batch 201 loss: 0.002327278722077608\n",
      "LOSS train 0.036936473658507954 valid 5.843512190040201e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.782325942069291e-06\n",
      "  batch 101 loss: 0.0005338132113683969\n",
      "  batch 201 loss: 0.00014841852607787586\n",
      "LOSS train 0.0002690390110895487 valid 9.589429828338325e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.43235966283828e-06\n",
      "  batch 101 loss: 5.598072933935328e-05\n",
      "  batch 201 loss: 1.4901350868967712e-05\n",
      "LOSS train 3.134322313958914e-05 valid 5.294526999932714e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.530225563328713e-07\n",
      "  batch 101 loss: 1.5154984691889694e-05\n",
      "  batch 201 loss: 1.1630622900611342e-05\n",
      "LOSS train 1.3341069330009627e-05 valid 7.29124167264672e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.339606210938655e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 1.3372468355328238e-05\n",
      "  batch 201 loss: 1.7573850063854478e-05\n",
      "LOSS train 1.7576152584550425e-05 valid 7.83784798841225e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.561000868212431e-08\n",
      "  batch 101 loss: 4.8212730298473616e-05\n",
      "  batch 201 loss: 0.0018401816115601833\n",
      "LOSS train 0.0011260403913290443 valid 0.00031174623291008174\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.2985864779911936e-06\n",
      "  batch 101 loss: 0.004669118125311797\n",
      "  batch 201 loss: 0.0010508188294261346\n",
      "LOSS train 0.0030385172158209333 valid 0.0004045272071380168\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.155734834261239e-06\n",
      "  batch 101 loss: 0.0014235396929143463\n",
      "  batch 201 loss: 0.0031723221675201783\n",
      "LOSS train 0.0020829942485704788 valid 0.0010577880311757326\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006152542307972908\n",
      "  batch 101 loss: 0.11120288339676336\n",
      "  batch 201 loss: 0.002341052169795148\n",
      "LOSS train 0.0419540750549342 valid 8.602829620940611e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.8068248219788075e-06\n",
      "  batch 101 loss: 0.00018628200750754332\n",
      "  batch 201 loss: 2.559042764005426e-05\n",
      "LOSS train 8.468081011245146e-05 valid 2.4342851247638464e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.167692092480138e-07\n",
      "  batch 101 loss: 1.7663296625869405e-05\n",
      "  batch 201 loss: 2.1094597502724356e-05\n",
      "LOSS train 2.1361752673521963e-05 valid 1.900663301057648e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.3708584447158502e-07\n",
      "  batch 101 loss: 1.565306539532685e-05\n",
      "  batch 201 loss: 1.555358879386404e-05\n",
      "LOSS train 1.8340342962185192e-05 valid 1.9253939171903767e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0521567674004473e-07\n",
      "  batch 101 loss: 2.8954053700545046e-05\n",
      "  batch 201 loss: 4.19295198889813e-05\n",
      "LOSS train 3.709980668872126e-05 valid 7.106171324267052e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.202240107697434e-08\n",
      "  batch 101 loss: 8.002579223784779e-05\n",
      "  batch 201 loss: 0.00030050401978769513\n",
      "LOSS train 0.0002152317865351999 valid 0.0002676467120181769\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.121948200510815e-06\n",
      "  batch 101 loss: 0.005238916873895505\n",
      "  batch 201 loss: 0.005827199450577609\n",
      "LOSS train 0.00438287883755551 valid 0.00015360784891527146\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.103754133917391e-06\n",
      "  batch 101 loss: 0.00019354092029061576\n",
      "  batch 201 loss: 0.0026829249792535846\n",
      "LOSS train 0.0017609481949845789 valid 0.0014151319628581405\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004284515231847763\n",
      "  batch 101 loss: 0.11822005053050816\n",
      "  batch 201 loss: 0.0006588693700905424\n",
      "LOSS train 0.04372083448564169 valid 0.0001050190840032883\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.204955861903727e-06\n",
      "  batch 101 loss: 9.759332903740869e-05\n",
      "  batch 201 loss: 2.2142455702578445e-05\n",
      "LOSS train 5.302303742070392e-05 valid 6.418706470867619e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.1041152396937834e-07\n",
      "  batch 101 loss: 3.786544694321492e-05\n",
      "  batch 201 loss: 6.380371337399993e-05\n",
      "LOSS train 4.7214613051694e-05 valid 1.9845621864078566e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.395802948740311e-07\n",
      "  batch 101 loss: 2.8450168751987804e-05\n",
      "  batch 201 loss: 3.020447019025596e-05\n",
      "LOSS train 3.205264426766014e-05 valid 3.566074155969545e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.763341373996809e-07\n",
      "  batch 101 loss: 8.320248326072033e-05\n",
      "  batch 201 loss: 8.160038068126596e-05\n",
      "LOSS train 8.5392312351796e-05 valid 2.64624432020355e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.0570276319631374e-07\n",
      "  batch 101 loss: 0.00011331610569868644\n",
      "  batch 201 loss: 0.0007964484094918589\n",
      "LOSS train 0.0006941858658807417 valid 0.003151617245748639\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.6226392257958654e-05\n",
      "  batch 101 loss: 0.002539282047218876\n",
      "  batch 201 loss: 0.005193092059344053\n",
      "LOSS train 0.003609114802378953 valid 0.001106876297853887\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1263057822361588e-05\n",
      "  batch 101 loss: 0.002850667299062479\n",
      "  batch 201 loss: 0.0016665655115502887\n",
      "LOSS train 0.003275938605102489 valid 0.016838567331433296\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00021071186289191247\n",
      "  batch 101 loss: 0.016140792827827682\n",
      "  batch 201 loss: 6.766435688859929e-05\n",
      "LOSS train 0.006033449846522955 valid 6.110664253355935e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.003275484545156e-07\n",
      "  batch 101 loss: 8.031519551877864e-05\n",
      "  batch 201 loss: 8.794315336672298e-05\n",
      "LOSS train 8.707309161730673e-05 valid 7.863801147323102e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.610163397155701e-07\n",
      "  batch 101 loss: 0.00010211336535803639\n",
      "  batch 201 loss: 0.00010921551725886048\n",
      "LOSS train 0.00010918067715141038 valid 8.949103357736021e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1541567073436454e-06\n",
      "  batch 101 loss: 0.0001215231627418234\n",
      "  batch 201 loss: 0.00012417827516912893\n",
      "LOSS train 0.00012503096285039174 valid 7.368622027570382e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.673653064761311e-07\n",
      "  batch 101 loss: 0.0001275890257380752\n",
      "  batch 201 loss: 0.0001227371043583503\n",
      "LOSS train 0.0001241668430309546 valid 5.20797329954803e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.217000630684197e-07\n",
      "  batch 101 loss: 0.00011563449972300077\n",
      "  batch 201 loss: 0.00010629531627046163\n",
      "LOSS train 0.000107732556462963 valid 5.9347170463297516e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.6210008147463665e-08\n",
      "  batch 101 loss: 9.533752567847387e-05\n",
      "  batch 201 loss: 8.662198520937636e-05\n",
      "LOSS train 8.753441786495633e-05 valid 8.552346844226122e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.1547199341730445e-08\n",
      "  batch 101 loss: 7.746614341385793e-05\n",
      "  batch 201 loss: 7.147435611841502e-05\n",
      "LOSS train 7.175635713403088e-05 valid 0.00011204524344066158\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006365641206502915\n",
      "  batch 101 loss: 0.026993041700679895\n",
      "  batch 201 loss: 4.270573843314196e-05\n",
      "LOSS train 0.010146442904619234 valid 2.3215980036184192e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.0650024453061634e-07\n",
      "  batch 101 loss: 2.9381656788700637e-05\n",
      "  batch 201 loss: 3.531958799385393e-05\n",
      "LOSS train 3.531147332242177e-05 valid 7.892439316492528e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.2354910217691213e-07\n",
      "  batch 101 loss: 8.121030373388294e-05\n",
      "  batch 201 loss: 5.662996390356056e-05\n",
      "LOSS train 7.676374079688359e-05 valid 8.09717967058532e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0037807805929332e-06\n",
      "  batch 101 loss: 0.00010314235934856697\n",
      "  batch 201 loss: 0.00010869864013443475\n",
      "LOSS train 0.00010890087739177207 valid 8.963237632997334e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1565873137442395e-06\n",
      "  batch 101 loss: 0.00011921901796085876\n",
      "  batch 201 loss: 0.00012216902248411544\n",
      "LOSS train 0.00012314103127026172 valid 8.081465784925967e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0009251855080946e-06\n",
      "  batch 101 loss: 0.00012775565681693023\n",
      "  batch 201 loss: 0.00012536738433027494\n",
      "LOSS train 0.00012683734930714886 valid 5.8606587117537856e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.378784408094361e-07\n",
      "  batch 101 loss: 0.00012260005879056736\n",
      "  batch 201 loss: 0.0001151487973447729\n",
      "LOSS train 0.00011667192549649061 valid 5.173328099772334e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.38040004458162e-07\n",
      "  batch 101 loss: 0.00010632876882368691\n",
      "  batch 201 loss: 9.740045640228345e-05\n",
      "LOSS train 9.855705156210189e-05 valid 6.892813689773902e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00011323276907205581\n",
      "  batch 101 loss: 0.004938508117967331\n",
      "  batch 201 loss: 0.0005581573563392795\n",
      "LOSS train 0.0020816029722729563 valid 8.432944014202803e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.0640294203767553e-06\n",
      "  batch 101 loss: 0.00011438595201440193\n",
      "  batch 201 loss: 0.00012319632272522085\n",
      "LOSS train 0.00012198804938457581 valid 6.661316729150712e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.242041465360671e-07\n",
      "  batch 101 loss: 0.00012505876163572792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.00011477988633942005\n",
      "LOSS train 0.00011617289324071813 valid 5.559670535149053e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.479703642980894e-08\n",
      "  batch 101 loss: 9.816645141285108e-05\n",
      "  batch 201 loss: 8.658906281766576e-05\n",
      "LOSS train 8.806759958303114e-05 valid 9.030068758875132e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.4165026338305324e-08\n",
      "  batch 101 loss: 7.450585799915643e-05\n",
      "  batch 201 loss: 6.805617384316065e-05\n",
      "LOSS train 6.847724411199501e-05 valid 0.00012195861927466467\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.680914283497259e-07\n",
      "  batch 101 loss: 6.213006527787001e-05\n",
      "  batch 201 loss: 5.942873668004722e-05\n",
      "LOSS train 5.9147706314760377e-05 valid 0.000147235143231228\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.968603621411603e-07\n",
      "  batch 101 loss: 5.751885424757575e-05\n",
      "  batch 201 loss: 5.724836671959111e-05\n",
      "LOSS train 5.653963889454018e-05 valid 0.0001728395582176745\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.430330591276288e-07\n",
      "  batch 101 loss: 5.8017750013164005e-05\n",
      "  batch 201 loss: 5.9515175476008156e-05\n",
      "LOSS train 5.849785376004704e-05 valid 0.00020303258497733623\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003150799497961998\n",
      "  batch 101 loss: 0.004563660551826843\n",
      "  batch 201 loss: 0.0002695241367572976\n",
      "LOSS train 0.0019143765801439487 valid 8.631631499156356e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.0990513692377135e-06\n",
      "  batch 101 loss: 0.00011824143729199932\n",
      "  batch 201 loss: 0.00012508028489435218\n",
      "LOSS train 0.00012376136636859197 valid 5.953155050519854e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.616042835754342e-07\n",
      "  batch 101 loss: 0.00012140294638811611\n",
      "  batch 201 loss: 0.00010890055141658194\n",
      "LOSS train 0.00011060875673744401 valid 6.232938903849572e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.3605537080584327e-08\n",
      "  batch 101 loss: 9.136758339764128e-05\n",
      "  batch 201 loss: 8.063754953809622e-05\n",
      "LOSS train 8.193742914355115e-05 valid 0.00010010458208853379\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.619305961270584e-08\n",
      "  batch 101 loss: 6.99760290967788e-05\n",
      "  batch 201 loss: 6.464259207859868e-05\n",
      "LOSS train 6.485951464474922e-05 valid 0.00013022025814279914\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.080550984828733e-07\n",
      "  batch 101 loss: 5.999550596243353e-05\n",
      "  batch 201 loss: 5.813462833259564e-05\n",
      "LOSS train 5.771085186606364e-05 valid 0.00015551334945484996\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.42676394211594e-07\n",
      "  batch 101 loss: 5.720265295735771e-05\n",
      "  batch 201 loss: 5.759883911707675e-05\n",
      "LOSS train 5.67782130179534e-05 valid 0.00018292809545528144\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.038451490690931e-07\n",
      "  batch 101 loss: 5.9125008231717405e-05\n",
      "  batch 201 loss: 6.115955732184375e-05\n",
      "LOSS train 6.005057937102057e-05 valid 0.00021526135969907045\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00010542631149291992\n",
      "  batch 101 loss: 0.05786228943621609\n",
      "  batch 201 loss: 5.9553354003583084e-05\n",
      "LOSS train 0.02127118189941489 valid 5.333257286110893e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.7643676478182895e-07\n",
      "  batch 101 loss: 6.440235092668445e-05\n",
      "  batch 201 loss: 6.747658851054439e-05\n",
      "LOSS train 6.651332904809914e-05 valid 5.7592558732721955e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.108310142531991e-07\n",
      "  batch 101 loss: 7.284776795586367e-05\n",
      "  batch 201 loss: 7.632558118984889e-05\n",
      "LOSS train 7.554141412557052e-05 valid 6.43794919596985e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.756949005648494e-07\n",
      "  batch 101 loss: 8.27217412893333e-05\n",
      "  batch 201 loss: 8.678572525695927e-05\n",
      "LOSS train 8.627460331162526e-05 valid 7.397111767204478e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.728756802156567e-07\n",
      "  batch 101 loss: 9.456420470769444e-05\n",
      "  batch 201 loss: 9.905919506081773e-05\n",
      "LOSS train 9.899237055202193e-05 valid 8.45930990180932e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.06870211311616e-06\n",
      "  batch 101 loss: 0.0001079890721183574\n",
      "  batch 201 loss: 0.00011211480019284182\n",
      "LOSS train 0.00011267188622372696 valid 8.990763308247551e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1613147944444791e-06\n",
      "  batch 101 loss: 0.00012066654643717811\n",
      "  batch 201 loss: 0.00012268267870183536\n",
      "LOSS train 0.00012388368839064186 valid 8.109165355563164e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.005955709842965e-06\n",
      "  batch 101 loss: 0.00012768685230867048\n",
      "  batch 201 loss: 0.00012558164787265013\n",
      "LOSS train 0.00012716501601020547 valid 6.11362120253034e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0007644636183977128\n",
      "  batch 101 loss: 0.009141984518428216\n",
      "  batch 201 loss: 1.7929962542666544e-05\n",
      "LOSS train 0.00363886129763066 valid 5.0288872444070876e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.639907380507793e-08\n",
      "  batch 101 loss: 1.4054138682695339e-05\n",
      "  batch 201 loss: 1.1156846277913245e-05\n",
      "LOSS train 1.2428847346171883e-05 valid 1.1560818165889941e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.4416406202144572e-08\n",
      "  batch 101 loss: 1.0436194604608318e-05\n",
      "  batch 201 loss: 6.211247981013912e-06\n",
      "LOSS train 7.273542303897097e-06 valid 1.0641439075698145e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.3563784452562685e-08\n",
      "  batch 101 loss: 3.4778547171754325e-06\n",
      "  batch 201 loss: 2.9972466435879143e-06\n",
      "LOSS train 2.94208147875809e-06 valid 9.33993487706175e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.730228738480946e-08\n",
      "  batch 101 loss: 2.2125301221365135e-06\n",
      "  batch 201 loss: 2.0624236724131605e-06\n",
      "LOSS train 2.097718909411701e-06 valid 4.272816568118287e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.1568882857536664e-08\n",
      "  batch 101 loss: 2.257839093289249e-06\n",
      "  batch 201 loss: 2.228013209304436e-06\n",
      "LOSS train 2.1599353512986023e-06 valid 7.799172635714058e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.6935532484203576e-08\n",
      "  batch 101 loss: 2.4114636721606077e-06\n",
      "  batch 201 loss: 2.334514697963641e-06\n",
      "LOSS train 2.239113304374972e-06 valid 4.2679371290432755e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.24778932533809e-08\n",
      "  batch 101 loss: 2.5952954310071163e-06\n",
      "  batch 201 loss: 2.3129030569180033e-06\n",
      "LOSS train 2.404335319179637e-06 valid 2.2853553218737943e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.001336279809474945\n",
      "  batch 101 loss: 0.006210917813587002\n",
      "  batch 201 loss: 0.001069641749636503\n",
      "LOSS train 0.0032407134115871217 valid 2.314092307642568e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.6281986609101296e-06\n",
      "  batch 101 loss: 0.00011739663092157571\n",
      "  batch 201 loss: 0.00011144925508233428\n",
      "LOSS train 0.00010767065899453749 valid 0.0002080033445963636\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0020859190262855e-06\n",
      "  batch 101 loss: 7.845145692044752e-05\n",
      "  batch 201 loss: 6.637722237883281e-05\n",
      "LOSS train 7.002138124331701e-05 valid 0.00016993959434330463\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.116959073347971e-07\n",
      "  batch 101 loss: 6.087781876885856e-05\n",
      "  batch 201 loss: 5.9509820189305174e-05\n",
      "LOSS train 5.887088936199292e-05 valid 0.0001809233071980998\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.244654312264174e-07\n",
      "  batch 101 loss: 5.690243734534306e-05\n",
      "  batch 201 loss: 5.714657337648532e-05\n",
      "LOSS train 5.6689431836448855e-05 valid 0.00019006662478204817\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.163095531519503e-07\n",
      "  batch 101 loss: 5.9926963208454256e-05\n",
      "  batch 201 loss: 6.236492784182701e-05\n",
      "LOSS train 6.124651642391152e-05 valid 0.00021550370729528368\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.871728303143755e-07\n",
      "  batch 101 loss: 6.497323594430782e-05\n",
      "  batch 201 loss: 6.880292498635754e-05\n",
      "LOSS train 6.777380318476973e-05 valid 0.00025129690766334534\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.083162278519012e-06\n",
      "  batch 101 loss: 7.337264774378128e-05\n",
      "  batch 201 loss: 7.457749553168468e-05\n",
      "LOSS train 7.288956576453379e-05 valid 0.0002645709319040179\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0010878819227218629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00730069512850605\n",
      "  batch 201 loss: 0.00047097914983169176\n",
      "LOSS train 0.0032746824171769793 valid 7.976532651809976e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.458850061288104e-07\n",
      "  batch 101 loss: 8.910348814424652e-05\n",
      "  batch 201 loss: 0.00010651187898019998\n",
      "LOSS train 0.00010030820874321045 valid 5.574989700107835e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.045763711881591e-08\n",
      "  batch 101 loss: 9.760814213450431e-05\n",
      "  batch 201 loss: 8.327671543838733e-05\n",
      "LOSS train 8.54531512658345e-05 valid 9.89642139757052e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.168640422605677e-08\n",
      "  batch 101 loss: 7.026442715186931e-05\n",
      "  batch 201 loss: 6.388109757494931e-05\n",
      "LOSS train 6.443151945211454e-05 valid 0.00013483615475706756\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.308331931999419e-07\n",
      "  batch 101 loss: 5.918519179431314e-05\n",
      "  batch 201 loss: 5.770798260357424e-05\n",
      "LOSS train 5.7215270845766e-05 valid 0.00015995270223356783\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.661361915874295e-07\n",
      "  batch 101 loss: 5.7538634365528196e-05\n",
      "  batch 201 loss: 5.8365118309211536e-05\n",
      "LOSS train 5.744717924992387e-05 valid 0.00019240648543927819\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.965067248325795e-07\n",
      "  batch 101 loss: 6.075843482449273e-05\n",
      "  batch 201 loss: 6.3286488614267e-05\n",
      "LOSS train 6.208077383361519e-05 valid 0.00022804955369792879\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.922534132376313e-07\n",
      "  batch 101 loss: 6.656174450199615e-05\n",
      "  batch 201 loss: 7.003446531030022e-05\n",
      "LOSS train 6.871079614152705e-05 valid 0.00026046199491247535\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000941733568906784\n",
      "  batch 101 loss: 0.005291897977003828\n",
      "  batch 201 loss: 0.0001250385773164453\n",
      "LOSS train 0.002362649295935296 valid 7.995589839993045e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.0475464659975842e-06\n",
      "  batch 101 loss: 0.0001274795873871426\n",
      "  batch 201 loss: 0.00011961086706151036\n",
      "LOSS train 0.00012012867575077298 valid 5.335985770216212e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0079103958560154e-07\n",
      "  batch 101 loss: 0.00010021668276522178\n",
      "  batch 201 loss: 8.607625382410333e-05\n",
      "LOSS train 8.806990450423091e-05 valid 9.295138443121687e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.994352250127122e-08\n",
      "  batch 101 loss: 7.217053638669313e-05\n",
      "  batch 201 loss: 6.576897610443666e-05\n",
      "LOSS train 6.623159531367018e-05 valid 0.00012600122136063874\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.0099816538277083e-07\n",
      "  batch 101 loss: 6.0149530374928874e-05\n",
      "  batch 201 loss: 5.816724197131862e-05\n",
      "LOSS train 5.777764350642052e-05 valid 0.00015428249025717378\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.4949240216519686e-07\n",
      "  batch 101 loss: 5.728747330778106e-05\n",
      "  batch 201 loss: 5.774514815982457e-05\n",
      "LOSS train 5.6921996343067646e-05 valid 0.00018145843932870775\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.141356814419851e-07\n",
      "  batch 101 loss: 5.9669175540193466e-05\n",
      "  batch 201 loss: 6.189631682218533e-05\n",
      "LOSS train 6.0775598833157554e-05 valid 0.00021733094763476402\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.375101267825812e-07\n",
      "  batch 101 loss: 6.503751202103558e-05\n",
      "  batch 201 loss: 6.812926532631991e-05\n",
      "LOSS train 6.701299449041838e-05 valid 0.0002494539658073336\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0009239134192466736\n",
      "  batch 101 loss: 0.004827783211330825\n",
      "  batch 201 loss: 4.9011951223292275e-05\n",
      "LOSS train 0.0021417301770933535 valid 6.0488931922009215e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1263874512223993e-07\n",
      "  batch 101 loss: 0.00011740580839898484\n",
      "  batch 201 loss: 0.00012130604891638085\n",
      "LOSS train 0.00011693645530867998 valid 5.358358612284064e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.332045920018572e-08\n",
      "  batch 101 loss: 9.971475311090216e-05\n",
      "  batch 201 loss: 8.530169225650752e-05\n",
      "LOSS train 8.742713760390234e-05 valid 9.674028115114197e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.40447660771315e-08\n",
      "  batch 101 loss: 7.119495521692442e-05\n",
      "  batch 201 loss: 6.501455809939217e-05\n",
      "LOSS train 6.538817781272503e-05 valid 0.00013161724200472236\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.1502737581613474e-07\n",
      "  batch 101 loss: 5.977937812986056e-05\n",
      "  batch 201 loss: 5.785430731350516e-05\n",
      "LOSS train 5.7493842024751546e-05 valid 0.00015958132280502468\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.643538366304711e-07\n",
      "  batch 101 loss: 5.724175939235465e-05\n",
      "  batch 201 loss: 5.801156684583475e-05\n",
      "LOSS train 5.715012649312358e-05 valid 0.0001901279465528205\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.475963916978799e-07\n",
      "  batch 101 loss: 6.022750131023713e-05\n",
      "  batch 201 loss: 6.258795174062471e-05\n",
      "LOSS train 6.145499614481545e-05 valid 0.000225344774662517\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.739186548860744e-07\n",
      "  batch 101 loss: 6.594638430669875e-05\n",
      "  batch 201 loss: 6.921829340512886e-05\n",
      "LOSS train 6.792576442128534e-05 valid 0.0002585821785032749\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003429519012570381\n",
      "  batch 101 loss: 0.019440874872983613\n",
      "  batch 201 loss: 1.5734298718541594e-05\n",
      "LOSS train 0.007258200274434426 valid 1.8904005628428422e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.573187081608921e-08\n",
      "  batch 101 loss: 3.8974262001545415e-06\n",
      "  batch 201 loss: 2.4632178519468084e-06\n",
      "LOSS train 3.0593019336457756e-06 valid 2.9678892587980954e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3289292155604927e-08\n",
      "  batch 101 loss: 2.7655710518814656e-06\n",
      "  batch 201 loss: 3.1158014017051983e-06\n",
      "LOSS train 2.9781094313907303e-06 valid 3.073183279411751e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1632508858383517e-08\n",
      "  batch 101 loss: 3.86303699912105e-06\n",
      "  batch 201 loss: 5.145399788943905e-06\n",
      "LOSS train 4.68882282835017e-06 valid 4.211040504742414e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.469761269225273e-08\n",
      "  batch 101 loss: 6.6139181308244585e-06\n",
      "  batch 201 loss: 1.1627721636386924e-05\n",
      "LOSS train 8.389605631571732e-06 valid 9.13018266146537e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.6542380762984976e-07\n",
      "  batch 101 loss: 7.445242547987618e-06\n",
      "  batch 201 loss: 1.174958262367909e-05\n",
      "LOSS train 8.562509092771107e-06 valid 6.3624984250054695e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0289468264090828e-07\n",
      "  batch 101 loss: 6.77722348655152e-06\n",
      "  batch 201 loss: 1.1500436516485024e-05\n",
      "LOSS train 8.176402251398604e-06 valid 5.329206942406017e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.608556643390329e-08\n",
      "  batch 101 loss: 6.389738807683898e-06\n",
      "  batch 201 loss: 1.0799130474765662e-05\n",
      "LOSS train 7.797876995755693e-06 valid 5.105876425659517e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003365803509950638\n",
      "  batch 101 loss: 0.010779800923264702\n",
      "  batch 201 loss: 0.0001405139983035042\n",
      "LOSS train 0.004145097376456447 valid 9.349048923468217e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.793259358848445e-07\n",
      "  batch 101 loss: 6.18620659224689e-05\n",
      "  batch 201 loss: 5.1812938991133706e-05\n",
      "LOSS train 5.934422790312885e-05 valid 0.00010078536433866248\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1741763046302367e-07\n",
      "  batch 101 loss: 6.648783138643921e-05\n",
      "  batch 201 loss: 9.228051942045568e-05\n",
      "LOSS train 8.963532985405067e-05 valid 5.074793807580136e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.127204763586633e-07\n",
      "  batch 101 loss: 0.00011649758816929534\n",
      "  batch 201 loss: 8.237370968799951e-05\n",
      "LOSS train 9.363242021715247e-05 valid 9.582625352777541e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.274004135775613e-08\n",
      "  batch 101 loss: 7.568099285208518e-05\n",
      "  batch 201 loss: 7.751319446015259e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 7.506447232050723e-05 valid 0.00010244515578961\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.815385626803618e-08\n",
      "  batch 101 loss: 7.050576572964929e-05\n",
      "  batch 201 loss: 6.519998601902444e-05\n",
      "LOSS train 6.690280833320089e-05 valid 0.00010797222785186023\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0620664397720248e-07\n",
      "  batch 101 loss: 6.704200672402294e-05\n",
      "  batch 201 loss: 6.304122014284985e-05\n",
      "LOSS train 6.296643207639508e-05 valid 0.00013294540985953063\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.215094900748227e-07\n",
      "  batch 101 loss: 5.951834408961076e-05\n",
      "  batch 201 loss: 5.799351298833244e-05\n",
      "LOSS train 5.748800051601776e-05 valid 0.00015565766079816967\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00020829504355788231\n",
      "  batch 101 loss: 0.07939643280464224\n",
      "  batch 201 loss: 0.001067170527530834\n",
      "LOSS train 0.029752679783130242 valid 0.00018344749696552753\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.052141543477774e-06\n",
      "  batch 101 loss: 0.0005499843833968043\n",
      "  batch 201 loss: 0.0004097459913464263\n",
      "LOSS train 0.000438364716717929 valid 6.399673293344676e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.8794267564080657e-06\n",
      "  batch 101 loss: 0.00026471021767065394\n",
      "  batch 201 loss: 0.0001979855300305644\n",
      "LOSS train 0.00020634740974942578 valid 9.07126086531207e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.806428766343743e-07\n",
      "  batch 101 loss: 0.00012164838521130151\n",
      "  batch 201 loss: 0.00012958254606928676\n",
      "LOSS train 0.00012772406971834954 valid 6.007288538967259e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.89294858300127e-07\n",
      "  batch 101 loss: 0.00012850388793594902\n",
      "  batch 201 loss: 0.0001260820658171724\n",
      "LOSS train 0.000126747615094922 valid 7.862294296501204e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2225874525029213e-06\n",
      "  batch 101 loss: 0.00011967677474785887\n",
      "  batch 201 loss: 0.0001164994168721023\n",
      "LOSS train 0.00011840321055817665 valid 7.922016084194183e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0375653801020234e-06\n",
      "  batch 101 loss: 0.00011737431164419831\n",
      "  batch 201 loss: 0.00010938319378510642\n",
      "LOSS train 0.00011286314983051905 valid 4.9300648242933676e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.368533649947495e-07\n",
      "  batch 101 loss: 0.00010775577690992577\n",
      "  batch 201 loss: 0.00010451507865127496\n",
      "LOSS train 0.00011160375154529222 valid 8.39864369481802e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.3342113494873045e-05\n",
      "  batch 101 loss: 0.016630054833658505\n",
      "  batch 201 loss: 7.351587595621822e-05\n",
      "LOSS train 0.006154589723733714 valid 6.768267485313118e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.575086056021974e-07\n",
      "  batch 101 loss: 8.783925141415239e-05\n",
      "  batch 201 loss: 9.577621175594686e-05\n",
      "LOSS train 9.521919937944383e-05 valid 8.464215352432802e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.080447545973584e-06\n",
      "  batch 101 loss: 0.00011027619620051609\n",
      "  batch 201 loss: 0.0001170882643788218\n",
      "LOSS train 0.00011706650101563681 valid 8.548953337594867e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.091220838134177e-06\n",
      "  batch 101 loss: 0.00012679253196722583\n",
      "  batch 201 loss: 0.0001259005053987039\n",
      "LOSS train 0.00012694207491148062 valid 5.978994886390865e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.813972893520258e-07\n",
      "  batch 101 loss: 0.00012299534697376657\n",
      "  batch 201 loss: 0.00011473584234863665\n",
      "LOSS train 0.00011623772871101146 valid 5.258842429611832e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1187372365384363e-07\n",
      "  batch 101 loss: 0.00010370599834118366\n",
      "  batch 201 loss: 9.405225206990053e-05\n",
      "LOSS train 9.523297450811527e-05 valid 7.482260116375983e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.3658539046446094e-08\n",
      "  batch 101 loss: 8.338007670886327e-05\n",
      "  batch 201 loss: 7.615568900519065e-05\n",
      "LOSS train 7.669701941915677e-05 valid 0.00010336827835999429\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.852565770212096e-08\n",
      "  batch 101 loss: 6.888793902135149e-05\n",
      "  batch 201 loss: 6.461054026772217e-05\n",
      "LOSS train 6.458419841862282e-05 valid 0.00012752915790770203\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.019198007881641e-05\n",
      "  batch 101 loss: 0.022403738146422256\n",
      "  batch 201 loss: 7.585934301914676e-05\n",
      "LOSS train 0.008269277393849271 valid 6.004602255416103e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.965634773019701e-07\n",
      "  batch 101 loss: 8.476845994664472e-05\n",
      "  batch 201 loss: 9.224035033184918e-05\n",
      "LOSS train 9.12779099656294e-05 valid 8.007210271898657e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.948101069312543e-07\n",
      "  batch 101 loss: 0.00010618697618042461\n",
      "  batch 201 loss: 0.00011317662424801256\n",
      "LOSS train 0.00011328718694697842 valid 8.843503019306809e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1359374184394254e-06\n",
      "  batch 101 loss: 0.000124554826251142\n",
      "  batch 201 loss: 0.00012588927099329794\n",
      "LOSS train 0.00012672336266682528 valid 6.695579941151664e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.314763206522912e-07\n",
      "  batch 101 loss: 0.00012615636727446146\n",
      "  batch 201 loss: 0.00011951287205079097\n",
      "LOSS train 0.00012104252986095688 valid 5.088932084618136e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.0952100385329686e-07\n",
      "  batch 101 loss: 0.00011044308507507594\n",
      "  batch 201 loss: 0.00010046593416973337\n",
      "LOSS train 0.00010190717742031895 valid 6.626563117606565e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.4970451047702228e-08\n",
      "  batch 101 loss: 8.937585476815002e-05\n",
      "  batch 201 loss: 8.146674309045921e-05\n",
      "LOSS train 8.212276429897565e-05 valid 9.422062430530787e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.60828493689769e-08\n",
      "  batch 101 loss: 7.311021301575237e-05\n",
      "  batch 201 loss: 6.801505273415387e-05\n",
      "LOSS train 6.813809161793713e-05 valid 0.0001197507226606831\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.2694439394399524e-06\n",
      "  batch 101 loss: 2.1644965204241453\n",
      "  batch 201 loss: 0.0007238519259772147\n",
      "LOSS train 0.7931664236994938 valid 0.001424403628334403\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.087869241833687e-05\n",
      "  batch 101 loss: 0.0012864623285054222\n",
      "  batch 201 loss: 0.00011365607863353944\n",
      "LOSS train 0.0005521747458587825 valid 0.0013300954597070813\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.150760687887668e-05\n",
      "  batch 101 loss: 0.0012814226418845465\n",
      "  batch 201 loss: 8.137702670012459e-05\n",
      "LOSS train 0.0005347273500783209 valid 0.0014676022110506892\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.972500097006559e-05\n",
      "  batch 101 loss: 0.0017553714210043836\n",
      "  batch 201 loss: 0.00014325579468504656\n",
      "LOSS train 0.0007248030637278478 valid 0.001278693787753582\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.404818639159202e-05\n",
      "  batch 101 loss: 0.004477236441307469\n",
      "  batch 201 loss: 0.0002783591930210605\n",
      "LOSS train 0.0017839304958189688 valid 0.0012560180621221662\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.049666691571474e-05\n",
      "  batch 101 loss: 0.00244211625375101\n",
      "  batch 201 loss: 5.709559815159082e-05\n",
      "LOSS train 0.00099128861418169 valid 0.0013899789191782475\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.354040302336216e-05\n",
      "  batch 101 loss: 0.007296236764304922\n",
      "  batch 201 loss: 0.002701276982043055\n",
      "LOSS train 0.016432948114009083 valid 0.044737815856933594\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0005245335772633553\n",
      "  batch 101 loss: 0.05128619290655479\n",
      "  batch 201 loss: 0.04752201280905865\n",
      "LOSS train 0.04702774716501513 valid 0.0077905734069645405\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0012840013206005096\n",
      "  batch 101 loss: 1.9281946990382857\n",
      "  batch 201 loss: 0.0023493208177387715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.7080717325562802 valid 0.0023758569732308388\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.2725951168686155e-05\n",
      "  batch 101 loss: 0.0019955214083893225\n",
      "  batch 201 loss: 0.0006390825231210328\n",
      "LOSS train 0.001084257892909504 valid 0.000695068622007966\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.096624277532101e-05\n",
      "  batch 101 loss: 0.001173818867537193\n",
      "  batch 201 loss: 0.00017131238611909795\n",
      "LOSS train 0.000522736928003777 valid 0.00023650976072531193\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.7054855125024914e-05\n",
      "  batch 101 loss: 0.0005166707369971845\n",
      "  batch 201 loss: 4.178368826615042e-05\n",
      "LOSS train 0.00021888796419218472 valid 0.00010307542834198102\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.4479496106505396e-06\n",
      "  batch 101 loss: 0.00035179094953491586\n",
      "  batch 201 loss: 2.8351405599096325e-05\n",
      "LOSS train 0.00014905994267182604 valid 5.6784461776260287e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.674580413848161e-06\n",
      "  batch 101 loss: 0.00022394565794456867\n",
      "  batch 201 loss: 3.588680048324022e-05\n",
      "LOSS train 0.000107262442407863 valid 2.492361090844497e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2175326992291958e-06\n",
      "  batch 101 loss: 0.0005843431433686419\n",
      "  batch 201 loss: 0.0910996524809525\n",
      "LOSS train 0.04670841486890805 valid 0.012046937830746174\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00016121694818139077\n",
      "  batch 101 loss: 0.008174046791973524\n",
      "  batch 201 loss: 0.012313487653591438\n",
      "LOSS train 0.035104472142328244 valid 0.011587976478040218\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0010937879979610442\n",
      "  batch 101 loss: 1.9376729242852888\n",
      "  batch 201 loss: 0.003358720736578107\n",
      "LOSS train 0.7119551903903808 valid 0.0005849167937412858\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.788391826674342e-05\n",
      "  batch 101 loss: 0.0012845864507835358\n",
      "  batch 201 loss: 0.00031964065972715615\n",
      "LOSS train 0.0006374349484378779 valid 0.0002766258257906884\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2348965974524617e-05\n",
      "  batch 101 loss: 0.000221726652871439\n",
      "  batch 201 loss: 2.4384868629567792e-05\n",
      "LOSS train 9.998774407321411e-05 valid 2.009817399084568e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0449816181790083e-06\n",
      "  batch 101 loss: 3.772543950617546e-05\n",
      "  batch 201 loss: 1.691645247547058e-05\n",
      "LOSS train 2.28217283133928e-05 valid 1.0005393960454967e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.664161365828477e-07\n",
      "  batch 101 loss: 2.4656923937982355e-05\n",
      "  batch 201 loss: 1.7347129387417225e-05\n",
      "LOSS train 1.9472285621871114e-05 valid 6.584530638065189e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.1851359381107616e-08\n",
      "  batch 101 loss: 2.5883443372549662e-05\n",
      "  batch 201 loss: 2.4143424432168104e-05\n",
      "LOSS train 2.5508206273206178e-05 valid 1.0828374797711149e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.1943352445960045e-08\n",
      "  batch 101 loss: 8.709727859240957e-05\n",
      "  batch 201 loss: 0.040019213053669775\n",
      "LOSS train 0.05549442619872441 valid 0.09338896721601486\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0007589694857597351\n",
      "  batch 101 loss: 0.011070353546238039\n",
      "  batch 201 loss: 0.006882835016294848\n",
      "LOSS train 0.03406687527182836 valid 0.1394776999950409\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.002233468145132065\n",
      "  batch 101 loss: 1.8682409663312136\n",
      "  batch 201 loss: 0.005071925494121388\n",
      "LOSS train 0.687374723012322 valid 0.0007247859612107277\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.87049825116992e-05\n",
      "  batch 101 loss: 0.0008867542723601219\n",
      "  batch 201 loss: 6.5155601096194e-05\n",
      "LOSS train 0.0003778837218529062 valid 5.798132042400539e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.7610428514890375e-06\n",
      "  batch 101 loss: 6.28589724738049e-05\n",
      "  batch 201 loss: 1.9374417856852233e-05\n",
      "LOSS train 3.5657442296037897e-05 valid 2.1531590391532518e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.265523163368925e-07\n",
      "  batch 101 loss: 1.8500670573757816e-05\n",
      "  batch 201 loss: 2.4456844068936335e-05\n",
      "LOSS train 1.942202964731626e-05 valid 1.8207130779046565e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.283535417926032e-08\n",
      "  batch 101 loss: 2.7263889162441046e-05\n",
      "  batch 201 loss: 3.677097439776844e-05\n",
      "LOSS train 2.865427983447545e-05 valid 1.9143210010952316e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0883728464250453e-07\n",
      "  batch 101 loss: 5.3159200062964375e-05\n",
      "  batch 201 loss: 5.8755305567501636e-05\n",
      "LOSS train 7.946655383977233e-05 valid 3.627869227784686e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.5482782297767697e-07\n",
      "  batch 101 loss: 0.0016791884984559146\n",
      "  batch 201 loss: 0.16537551284476648\n",
      "LOSS train 0.06865718381907625 valid 0.002010442316532135\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.3579481318593024e-05\n",
      "  batch 101 loss: 0.004010248156337184\n",
      "  batch 201 loss: 0.00043467062980198537\n",
      "LOSS train 0.04434491145558231 valid 0.005538977216929197\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00035292111337184904\n",
      "  batch 101 loss: 2.10292790081352\n",
      "  batch 201 loss: 0.004366799741983413\n",
      "LOSS train 0.7721413956005629 valid 0.0005400159279815853\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.182747729122639e-05\n",
      "  batch 101 loss: 0.0005777475821014378\n",
      "  batch 201 loss: 3.0482762203973833e-05\n",
      "LOSS train 0.000248740851895071 valid 2.762099393294193e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.5604575057514014e-07\n",
      "  batch 101 loss: 3.063308249238617e-05\n",
      "  batch 201 loss: 3.2291072852785876e-05\n",
      "LOSS train 3.7530365519963e-05 valid 2.25408894038992e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.28129792958498e-07\n",
      "  batch 101 loss: 3.40541581317666e-05\n",
      "  batch 201 loss: 4.734366806587786e-05\n",
      "LOSS train 5.453317565201153e-05 valid 0.00010943648521788418\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.148966738488525e-07\n",
      "  batch 101 loss: 3.860649155740248e-05\n",
      "  batch 201 loss: 5.9200670766585975e-05\n",
      "LOSS train 5.877175080735096e-05 valid 0.0001700738212093711\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2858370610047132e-06\n",
      "  batch 101 loss: 0.00022898091810930055\n",
      "  batch 201 loss: 0.00023508636757469504\n",
      "LOSS train 0.0002973398818356631 valid 2.8034943170496263e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.561598224332557e-07\n",
      "  batch 101 loss: 0.00022299107344224466\n",
      "  batch 201 loss: 0.06237256658168917\n",
      "LOSS train 0.04608186635790104 valid 0.001711477292701602\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.42601340264082e-05\n",
      "  batch 101 loss: 0.017679374356521293\n",
      "  batch 201 loss: 0.04797065973980352\n",
      "LOSS train 0.0347255546869983 valid 0.10846472531557083\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003319085389375687\n",
      "  batch 101 loss: 0.46552476915664553\n",
      "  batch 201 loss: 0.017239472237374685\n",
      "LOSS train 0.1776415148262755 valid 6.395616946974769e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.662633677478879e-07\n",
      "  batch 101 loss: 7.525249681293644e-05\n",
      "  batch 201 loss: 7.500945614992816e-05\n",
      "LOSS train 7.596211996095228e-05 valid 6.467280763899907e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.821822898928076e-07\n",
      "  batch 101 loss: 8.385278228161042e-05\n",
      "  batch 201 loss: 8.932449844905932e-05\n",
      "LOSS train 8.876796988301026e-05 valid 7.774359255563468e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.444110037293285e-07\n",
      "  batch 101 loss: 9.990348793280646e-05\n",
      "  batch 201 loss: 0.00010562466872727328\n",
      "LOSS train 0.00010570296614867322 valid 8.891485049389303e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.144229026976973e-06\n",
      "  batch 101 loss: 0.00011673452182151323\n",
      "  batch 201 loss: 0.00012054949051957919\n",
      "LOSS train 0.00012136355717533771 valid 8.294385770568624e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0393362026661634e-06\n",
      "  batch 101 loss: 0.00012742750564655127\n",
      "  batch 201 loss: 0.00012558969357201021\n",
      "LOSS train 0.00012687694897048403 valid 5.861145837116055e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.380056973081082e-07\n",
      "  batch 101 loss: 0.00012229180774852465\n",
      "  batch 201 loss: 0.00011385386013444076\n",
      "LOSS train 0.0001153144439149234 valid 5.328908810042776e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.723537914396729e-08\n",
      "  batch 101 loss: 0.00010248572751947905\n",
      "  batch 201 loss: 9.245388495116912e-05\n",
      "LOSS train 9.365290207344161e-05 valid 7.836810982553288e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.883935230784118e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.5053385224350267\n",
      "  batch 201 loss: 6.814056463554152e-05\n",
      "LOSS train 0.18514864581303822 valid 5.554591552936472e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.5178487198427317e-07\n",
      "  batch 101 loss: 6.991843188188795e-05\n",
      "  batch 201 loss: 7.460587374680472e-05\n",
      "LOSS train 7.36380747844373e-05 valid 6.424504681490362e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.727094296365976e-07\n",
      "  batch 101 loss: 8.3250259997385e-05\n",
      "  batch 201 loss: 8.862209082735717e-05\n",
      "LOSS train 8.804977742062837e-05 valid 7.703526352997869e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.311703615821898e-07\n",
      "  batch 101 loss: 9.900060924110221e-05\n",
      "  batch 201 loss: 0.00010468476055393694\n",
      "LOSS train 0.00010472950047172632 valid 8.85565095813945e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1380386422388255e-06\n",
      "  batch 101 loss: 0.00011576294969643185\n",
      "  batch 201 loss: 0.00011976647436199527\n",
      "LOSS train 0.00012054750548785482 valid 8.416701894020662e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0611453762976452e-06\n",
      "  batch 101 loss: 0.00012710779752211465\n",
      "  batch 201 loss: 0.00012576637168081105\n",
      "LOSS train 0.0001270403879863062 valid 6.0301958001218736e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.807842535432428e-07\n",
      "  batch 101 loss: 0.0001233092758661769\n",
      "  batch 201 loss: 0.0001152721705670956\n",
      "LOSS train 0.00011673142651925312 valid 5.235144999460317e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1825829460576642e-07\n",
      "  batch 101 loss: 0.00010428705770095802\n",
      "  batch 201 loss: 9.419459603179803e-05\n",
      "LOSS train 9.543078450525129e-05 valid 7.579551311209798e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.3918869234621525e-05\n",
      "  batch 101 loss: 0.46414612381014875\n",
      "  batch 201 loss: 0.0061809309141563065\n",
      "LOSS train 0.17231697717662534 valid 5.5623091611778364e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.5415024942485614e-07\n",
      "  batch 101 loss: 7.085669110892923e-05\n",
      "  batch 201 loss: 7.587670490011078e-05\n",
      "LOSS train 7.48944054306536e-05 valid 6.558165478054434e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.020506745902821e-07\n",
      "  batch 101 loss: 8.511709017511749e-05\n",
      "  batch 201 loss: 9.079382129129953e-05\n",
      "LOSS train 9.027134109144907e-05 valid 7.919718336779624e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.71334593486972e-07\n",
      "  batch 101 loss: 0.00010177807348327406\n",
      "  batch 201 loss: 0.00010755255591107016\n",
      "LOSS train 0.00010770011714980466 valid 8.943933789851144e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1532673670444637e-06\n",
      "  batch 101 loss: 0.00011866066709956158\n",
      "  batch 201 loss: 0.00012202478980782416\n",
      "LOSS train 0.00012290120637841866 valid 8.009865268832073e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.878724085865542e-07\n",
      "  batch 101 loss: 0.0001278258052354886\n",
      "  batch 201 loss: 0.00012493415700760125\n",
      "LOSS train 0.00012624633542714453 valid 5.5557393352501094e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.5213717385195197e-07\n",
      "  batch 101 loss: 0.00011993309396757468\n",
      "  batch 201 loss: 0.00011077332013542218\n",
      "LOSS train 0.00011223216459576769 valid 5.585038888966665e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.217179361556191e-08\n",
      "  batch 101 loss: 9.879707815713346e-05\n",
      "  batch 201 loss: 8.897890839989486e-05\n",
      "LOSS train 9.009414349713549e-05 valid 8.367957343580201e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00014937286265194417\n",
      "  batch 101 loss: 1.7789648388337809\n",
      "  batch 201 loss: 0.0001460947368195775\n",
      "LOSS train 0.6517584980643706 valid 5.200886516831815e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.1804349418962376e-07\n",
      "  batch 101 loss: 5.994779615321022e-05\n",
      "  batch 201 loss: 6.183308602885517e-05\n",
      "LOSS train 6.0915477911044284e-05 valid 5.378063360694796e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.931991523131728e-07\n",
      "  batch 101 loss: 6.495205138890014e-05\n",
      "  batch 201 loss: 6.701569705910515e-05\n",
      "LOSS train 6.617253078090201e-05 valid 5.6556298659415916e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.818094748770818e-07\n",
      "  batch 101 loss: 7.058500598759565e-05\n",
      "  batch 201 loss: 7.301574602479377e-05\n",
      "LOSS train 7.226229983923706e-05 valid 6.081079845898785e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.931972191319801e-07\n",
      "  batch 101 loss: 7.737073960925044e-05\n",
      "  batch 201 loss: 8.030044279621506e-05\n",
      "LOSS train 7.969423883891661e-05 valid 6.707907596137375e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.340827869484202e-07\n",
      "  batch 101 loss: 8.57679564433056e-05\n",
      "  batch 201 loss: 8.926945650728158e-05\n",
      "LOSS train 8.891378169269895e-05 valid 7.557147182524204e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.035371476784348e-07\n",
      "  batch 101 loss: 9.611787149879091e-05\n",
      "  batch 201 loss: 0.00010007754115576973\n",
      "LOSS train 0.00010012691684142994 valid 8.494313806295395e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0748935164883732e-06\n",
      "  batch 101 loss: 0.00010822296233016004\n",
      "  batch 201 loss: 0.000112028179286483\n",
      "LOSS train 0.00011264543951847956 valid 8.99434817256406e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00012177691794931889\n",
      "  batch 101 loss: 0.971813503965459\n",
      "  batch 201 loss: 6.335543981549563e-05\n",
      "LOSS train 0.35605915255634096 valid 5.318642797647044e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.707295036292635e-07\n",
      "  batch 101 loss: 6.396969941306452e-05\n",
      "  batch 201 loss: 6.69337435374473e-05\n",
      "LOSS train 6.597402279822036e-05 valid 5.717641397495754e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.993627953808754e-07\n",
      "  batch 101 loss: 7.2107696587409e-05\n",
      "  batch 201 loss: 7.547760586476215e-05\n",
      "LOSS train 7.4685004344976e-05 valid 6.360931001836434e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.584718357771635e-07\n",
      "  batch 101 loss: 8.168552969664233e-05\n",
      "  batch 201 loss: 8.568046858954403e-05\n",
      "LOSS train 8.514376417550897e-05 valid 7.295110117411241e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.530675404472277e-07\n",
      "  batch 101 loss: 9.337073249753303e-05\n",
      "  batch 201 loss: 9.79205638827807e-05\n",
      "LOSS train 9.781045205256018e-05 valid 8.384265674976632e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0553799802437425e-06\n",
      "  batch 101 loss: 0.00010704175456851318\n",
      "  batch 201 loss: 0.00011143001944361685\n",
      "LOSS train 0.00011193571635571337 valid 8.985248132376e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1603692109929397e-06\n",
      "  batch 101 loss: 0.00012050281224048831\n",
      "  batch 201 loss: 0.00012278465552128636\n",
      "LOSS train 0.00012391645600494389 valid 7.994559564394876e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.850732749328017e-07\n",
      "  batch 101 loss: 0.00012781937434340308\n",
      "  batch 201 loss: 0.00012518750878484752\n",
      "LOSS train 0.00012664624311508758 valid 5.7578236010158435e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.915507812052965e-05\n",
      "  batch 101 loss: 0.0007210498640947094\n",
      "  batch 201 loss: 5.3091004173211334e-05\n",
      "LOSS train 0.0003067421480776898 valid 5.976502507110126e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.4037179830193055e-08\n",
      "  batch 101 loss: 3.446341668677633e-05\n",
      "  batch 201 loss: 3.25818314010462e-05\n",
      "LOSS train 3.188068900372262e-05 valid 5.642200994770974e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.671896815329092e-08\n",
      "  batch 101 loss: 2.8745664527605184e-05\n",
      "  batch 201 loss: 2.909975879617832e-05\n",
      "LOSS train 2.870669330161782e-05 valid 7.495977479266003e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.3526243947126205e-08\n",
      "  batch 101 loss: 3.16273561142566e-05\n",
      "  batch 201 loss: 3.1458349529600585e-05\n",
      "LOSS train 3.111928662223356e-05 valid 7.933995220810175e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.9043407064600613e-08\n",
      "  batch 101 loss: 3.283369470693742e-05\n",
      "  batch 201 loss: 3.493241463047525e-05\n",
      "LOSS train 3.461340812375069e-05 valid 6.261945236474276e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.2692615857522467e-08\n",
      "  batch 101 loss: 4.079102569392035e-05\n",
      "  batch 201 loss: 4.427810854082281e-05\n",
      "LOSS train 4.361013486239048e-05 valid 5.242018596618436e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1643423022178467e-07\n",
      "  batch 101 loss: 4.89867334306382e-05\n",
      "  batch 201 loss: 4.993945781166076e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 4.98947118752194e-05 valid 5.095727101434022e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.8876196918427014e-07\n",
      "  batch 101 loss: 5.182689886623848e-05\n",
      "  batch 201 loss: 5.143432594934438e-05\n",
      "LOSS train 5.1790794457967535e-05 valid 5.088624675408937e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00156966432929039\n",
      "  batch 101 loss: 0.06836553109082161\n",
      "  batch 201 loss: 0.0011420014928444288\n",
      "LOSS train 0.026140404917263393 valid 4.648518734029494e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.0466388377826663e-06\n",
      "  batch 101 loss: 0.0001302882712207065\n",
      "  batch 201 loss: 5.962738797279598e-05\n",
      "LOSS train 8.263077873816522e-05 valid 7.510849536629394e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.1150683096493594e-07\n",
      "  batch 101 loss: 4.532377891109718e-05\n",
      "  batch 201 loss: 4.5699418928961675e-05\n",
      "LOSS train 4.493775822127299e-05 valid 0.00010281029244652018\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.894175486289896e-07\n",
      "  batch 101 loss: 4.698661753309352e-05\n",
      "  batch 201 loss: 4.706987632516757e-05\n",
      "LOSS train 4.682923833325521e-05 valid 0.00013145660341251642\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.6660738260252403e-07\n",
      "  batch 101 loss: 4.9760368142415246e-05\n",
      "  batch 201 loss: 5.1636300988775473e-05\n",
      "LOSS train 5.089518562573632e-05 valid 0.00017298079910688102\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.914064604439773e-07\n",
      "  batch 101 loss: 5.6441231771486854e-05\n",
      "  batch 201 loss: 6.1000215357580604e-05\n",
      "LOSS train 6.009059104066109e-05 valid 0.00023474593763239682\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0297692642780021e-06\n",
      "  batch 101 loss: 6.900672232632132e-05\n",
      "  batch 201 loss: 7.413611672745901e-05\n",
      "LOSS train 7.337958954857783e-05 valid 0.000257155392318964\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1085048754466698e-06\n",
      "  batch 101 loss: 7.710194089781908e-05\n",
      "  batch 201 loss: 7.570434861918329e-05\n",
      "LOSS train 7.604005134748309e-05 valid 0.0001794988347683102\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006844651699066162\n",
      "  batch 101 loss: 0.01619985420672492\n",
      "  batch 201 loss: 6.22502486976373e-05\n",
      "LOSS train 0.006226147723536364 valid 0.00012078694271622226\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.630228871363215e-07\n",
      "  batch 101 loss: 6.100299185391123e-05\n",
      "  batch 201 loss: 5.7191203815705194e-05\n",
      "LOSS train 5.8201229686328456e-05 valid 0.00020082417177036405\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.192894943524152e-07\n",
      "  batch 101 loss: 6.346587504197032e-05\n",
      "  batch 201 loss: 7.189519065093464e-05\n",
      "LOSS train 7.030158714428996e-05 valid 0.0002960210549645126\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.2619339395314455e-06\n",
      "  batch 101 loss: 8.265616300832334e-05\n",
      "  batch 201 loss: 8.190105781068269e-05\n",
      "LOSS train 8.13478128883027e-05 valid 0.00018543389160186052\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.218134538154117e-07\n",
      "  batch 101 loss: 6.639141088726319e-05\n",
      "  batch 201 loss: 5.492390622862331e-05\n",
      "LOSS train 5.761245868418153e-05 valid 9.533479897072539e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.935586159466766e-08\n",
      "  batch 101 loss: 4.395180660480946e-05\n",
      "  batch 201 loss: 3.877892962520946e-05\n",
      "LOSS train 3.995174740281812e-05 valid 7.348052895395085e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2434502423275261e-08\n",
      "  batch 101 loss: 3.579617257685186e-05\n",
      "  batch 201 loss: 3.385721892897209e-05\n",
      "LOSS train 3.4257008065449907e-05 valid 6.095444769016467e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.8760118766513187e-08\n",
      "  batch 101 loss: 3.455015998184763e-05\n",
      "  batch 201 loss: 3.411866367628136e-05\n",
      "LOSS train 3.391691307825274e-05 valid 5.177399725653231e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0017310424149036407\n",
      "  batch 101 loss: 0.13016873452966138\n",
      "  batch 201 loss: 8.541828548231933e-05\n",
      "LOSS train 0.04837118995502957 valid 8.069572504609823e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.98763061943464e-07\n",
      "  batch 101 loss: 0.00010800255862704944\n",
      "  batch 201 loss: 0.00011969178856475083\n",
      "LOSS train 0.00011811470582558749 valid 7.716342952335253e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.269626025343314e-07\n",
      "  batch 101 loss: 0.0001277126862635214\n",
      "  batch 201 loss: 0.00011954322837027575\n",
      "LOSS train 0.00012043044024606958 valid 5.284459257381968e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0225700862065424e-07\n",
      "  batch 101 loss: 0.00010109215004263206\n",
      "  batch 201 loss: 8.762176554569123e-05\n",
      "LOSS train 8.938824156251234e-05 valid 9.108638187171891e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.5745413192198615e-08\n",
      "  batch 101 loss: 7.31518781867635e-05\n",
      "  batch 201 loss: 6.616788172095767e-05\n",
      "LOSS train 6.675189500448731e-05 valid 0.00012880834401585162\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.01062375708716e-07\n",
      "  batch 101 loss: 6.0123670532448156e-05\n",
      "  batch 201 loss: 5.796543930216558e-05\n",
      "LOSS train 5.7651607000568286e-05 valid 0.00015989305393304676\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.6815472412854435e-07\n",
      "  batch 101 loss: 5.725919108897415e-05\n",
      "  batch 201 loss: 5.837642332949145e-05\n",
      "LOSS train 5.7542966432983464e-05 valid 0.00019951375725213438\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.086486610001885e-07\n",
      "  batch 101 loss: 6.190872848435447e-05\n",
      "  batch 201 loss: 6.605147249530319e-05\n",
      "LOSS train 6.482833921825328e-05 valid 0.00025694709620438516\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0009686268121004105\n",
      "  batch 101 loss: 0.17329459273416434\n",
      "  batch 201 loss: 0.0001800814485613955\n",
      "LOSS train 0.06393189795787191 valid 7.871666457504034e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1291411647107453e-06\n",
      "  batch 101 loss: 0.0001148364739765384\n",
      "  batch 201 loss: 0.00011955941410178639\n",
      "LOSS train 0.00012030944038840825 valid 8.344621892319992e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0483160440344363e-06\n",
      "  batch 101 loss: 0.00012764298428010078\n",
      "  batch 201 loss: 0.00012378761486758094\n",
      "LOSS train 0.00012415986884214167 valid 5.09502315253485e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.3531189071945846e-07\n",
      "  batch 101 loss: 0.0001099285962209251\n",
      "  batch 201 loss: 9.617371969227407e-05\n",
      "LOSS train 9.803361041474421e-05 valid 7.919729978311807e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.8815247813108728e-08\n",
      "  batch 101 loss: 7.991148341261578e-05\n",
      "  batch 201 loss: 7.125880219518876e-05\n",
      "LOSS train 7.213759095973882e-05 valid 0.00011793746671173722\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.4953730897104834e-07\n",
      "  batch 101 loss: 6.316870607179226e-05\n",
      "  batch 201 loss: 5.970837235281579e-05\n",
      "LOSS train 5.9613645779809435e-05 valid 0.0001485112588852644\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.038226714124903e-07\n",
      "  batch 101 loss: 5.738456259251734e-05\n",
      "  batch 201 loss: 5.735281504712475e-05\n",
      "LOSS train 5.668147387451434e-05 valid 0.0001824280188884586\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.00794340041466e-07\n",
      "  batch 101 loss: 5.924831983008971e-05\n",
      "  batch 201 loss: 6.217787529863016e-05\n",
      "LOSS train 6.108548685038581e-05 valid 0.0002319466439075768\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00021671760827302934\n",
      "  batch 101 loss: 3.7200052990626657\n",
      "  batch 201 loss: 7.311823194868339e-05\n",
      "LOSS train 1.363379299573027 valid 7.460162305505946e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.4599747121101247e-07\n",
      "  batch 101 loss: 8.47621096625062e-06\n",
      "  batch 201 loss: 4.9685624588846625e-06\n",
      "LOSS train 6.888724384548651e-06 valid 7.0219261942838784e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1204373549844604e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 3.696356415758828e-06\n",
      "  batch 201 loss: 2.0654261778929596e-06\n",
      "LOSS train 3.608722801284921e-06 valid 1.0737044249253813e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.7246778952539898e-07\n",
      "  batch 101 loss: 3.1141415803404014e-06\n",
      "  batch 201 loss: 1.9852695687916366e-06\n",
      "LOSS train 3.2981659285248594e-06 valid 6.492905413324479e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.048438758123666e-08\n",
      "  batch 101 loss: 2.4043049192812303e-06\n",
      "  batch 201 loss: 2.035178522419301e-06\n",
      "LOSS train 3.2941526144969885e-06 valid 4.914637884212425e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.9858276775485137e-08\n",
      "  batch 101 loss: 2.825306785751991e-06\n",
      "  batch 201 loss: 2.4580124703277307e-06\n",
      "LOSS train 3.6977498562909213e-06 valid 1.1820156942121685e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.607689046068117e-07\n",
      "  batch 101 loss: 3.5134538273950966e-06\n",
      "  batch 201 loss: 2.2937572863668265e-06\n",
      "LOSS train 4.0367989179180815e-06 valid 1.2547881851787679e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.0961551854270511e-07\n",
      "  batch 101 loss: 3.3622535471522496e-06\n",
      "  batch 201 loss: 2.4550613720464298e-06\n",
      "LOSS train 3.790825893581094e-06 valid 1.0251403182337526e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005732283368706703\n",
      "  batch 101 loss: 4.6543807366513645\n",
      "  batch 201 loss: 0.0055542699474608525\n",
      "LOSS train 1.7080669170399576 valid 0.0002112778165610507\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.5841206768527626e-05\n",
      "  batch 101 loss: 0.002239318152624037\n",
      "  batch 201 loss: 0.001603051565612077\n",
      "LOSS train 0.0016952807617426082 valid 0.0002898139937315136\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.33295688405633e-06\n",
      "  batch 101 loss: 0.0006624710947016866\n",
      "  batch 201 loss: 0.0004471362535969092\n",
      "LOSS train 0.00048689450377024 valid 0.00010212753113592044\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.524646156933159e-07\n",
      "  batch 101 loss: 0.0002383598896994954\n",
      "  batch 201 loss: 0.0001691304545283856\n",
      "LOSS train 0.00018716649224305188 valid 7.493879093090072e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1391939915483818e-06\n",
      "  batch 101 loss: 0.00010834050998255407\n",
      "  batch 201 loss: 8.848201857290405e-05\n",
      "LOSS train 9.3554729763847e-05 valid 6.0888858570251614e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.147025851532817e-07\n",
      "  batch 101 loss: 7.716139050899073e-05\n",
      "  batch 201 loss: 7.517000933148665e-05\n",
      "LOSS train 7.537378736336099e-05 valid 5.961204078630544e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.641373718390241e-07\n",
      "  batch 101 loss: 7.496080895180057e-05\n",
      "  batch 201 loss: 7.625318153714033e-05\n",
      "LOSS train 7.577418304101942e-05 valid 6.240238144528121e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.323584966594353e-07\n",
      "  batch 101 loss: 7.925798636051695e-05\n",
      "  batch 201 loss: 8.165116880263667e-05\n",
      "LOSS train 8.116502780360664e-05 valid 6.771668995497748e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.819158464670181e-05\n",
      "  batch 101 loss: 66.301753756369\n",
      "  batch 201 loss: 0.0060650891973637044\n",
      "LOSS train 24.28973895868017 valid 0.003034870373085141\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.180262796580792e-05\n",
      "  batch 101 loss: 0.004034375696210191\n",
      "  batch 201 loss: 0.0033654191088862717\n",
      "LOSS train 0.003551486371282911 valid 0.0034011497627943754\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.685535164549947e-05\n",
      "  batch 101 loss: 0.002830630230018869\n",
      "  batch 201 loss: 0.0021825627103680746\n",
      "LOSS train 0.002371488360990003 valid 0.001130397547967732\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.7506810147315265e-05\n",
      "  batch 101 loss: 0.0015888493007514626\n",
      "  batch 201 loss: 0.001324340092833154\n",
      "LOSS train 0.0013695725050265305 valid 8.833673200570047e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.380493334494531e-06\n",
      "  batch 101 loss: 0.000978249168547336\n",
      "  batch 201 loss: 0.0008035302584175952\n",
      "LOSS train 0.0008427874169580215 valid 4.7668774641351774e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.396276389248669e-06\n",
      "  batch 101 loss: 0.0005918544252926949\n",
      "  batch 201 loss: 0.0004700020498421509\n",
      "LOSS train 0.0004969748041307683 valid 6.276743079070002e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.2537805964238943e-06\n",
      "  batch 101 loss: 0.0003658993751741946\n",
      "  batch 201 loss: 0.0002862072107382119\n",
      "LOSS train 0.0003084862270949395 valid 0.00015068189532030374\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.570830110926181e-06\n",
      "  batch 101 loss: 0.00019372356407984626\n",
      "  batch 201 loss: 0.00014992685290053488\n",
      "LOSS train 0.0001597436872383856 valid 6.078342630644329e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005989944562315941\n",
      "  batch 101 loss: 3.444827030543238\n",
      "  batch 201 loss: 0.0007196443088719206\n",
      "LOSS train 1.2623385991028668 valid 5.149201751919463e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.877102451748215e-07\n",
      "  batch 101 loss: 5.7449805171927434e-05\n",
      "  batch 201 loss: 5.871019839105429e-05\n",
      "LOSS train 5.7835600969672455e-05 valid 5.232424518908374e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.3369378797942774e-07\n",
      "  batch 101 loss: 6.071686409995891e-05\n",
      "  batch 201 loss: 6.205552817846182e-05\n",
      "LOSS train 6.121773702154195e-05 valid 5.3594354540109634e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.863541496684775e-07\n",
      "  batch 101 loss: 6.425456162105547e-05\n",
      "  batch 201 loss: 6.579094421795162e-05\n",
      "LOSS train 6.498900433436888e-05 valid 5.549472916754894e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.5020893594482916e-07\n",
      "  batch 101 loss: 6.837577417172725e-05\n",
      "  batch 201 loss: 7.020408493190189e-05\n",
      "LOSS train 6.945344647057617e-05 valid 5.8329762396169826e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.306100501911715e-07\n",
      "  batch 101 loss: 7.336792904879985e-05\n",
      "  batch 201 loss: 7.558260489076929e-05\n",
      "LOSS train 7.491679088454789e-05 valid 6.250699516385794e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 6.333051715046168e-07\n",
      "  batch 101 loss: 7.955514897503235e-05\n",
      "  batch 201 loss: 8.224792531109415e-05\n",
      "LOSS train 8.172636378834389e-05 valid 6.847012264188379e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.631449261680245e-07\n",
      "  batch 101 loss: 8.729418034363335e-05\n",
      "  batch 201 loss: 9.051627511325932e-05\n",
      "LOSS train 9.023618675420728e-05 valid 7.636257214471698e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.85071898624301e-05\n",
      "  batch 101 loss: 36.38796469038353\n",
      "  batch 201 loss: 0.007980173439718782\n",
      "LOSS train 13.332984107045027 valid 0.00028526014648377895\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.2813569996505974e-05\n",
      "  batch 101 loss: 0.0024562915752176194\n",
      "  batch 201 loss: 0.0013462416303809733\n",
      "LOSS train 0.0016033992825004344 valid 0.00012228154810145497\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.211211486719549e-06\n",
      "  batch 101 loss: 0.0004023307045281399\n",
      "  batch 201 loss: 0.00020379133362439462\n",
      "LOSS train 0.0002599352817844272 valid 6.044026304152794e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0224366997135803e-06\n",
      "  batch 101 loss: 0.00010613107806420886\n",
      "  batch 201 loss: 7.58841904826113e-05\n",
      "LOSS train 9.164988612597288e-05 valid 7.999216904863715e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0270028724335135e-06\n",
      "  batch 101 loss: 6.929279868927551e-05\n",
      "  batch 201 loss: 6.490826662229665e-05\n",
      "LOSS train 6.552387671762094e-05 valid 5.208210495766252e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.180034036631696e-07\n",
      "  batch 101 loss: 6.092070394515758e-05\n",
      "  batch 201 loss: 6.197327194968239e-05\n",
      "LOSS train 6.062894766521726e-05 valid 5.189107105252333e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.099571040365845e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 6.076202885196835e-05\n",
      "  batch 201 loss: 6.107619904469175e-05\n",
      "LOSS train 6.01613316672435e-05 valid 5.209857044974342e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.436140781966969e-07\n",
      "  batch 101 loss: 6.084264562559838e-05\n",
      "  batch 201 loss: 6.1469293814298e-05\n",
      "LOSS train 6.067458349413851e-05 valid 5.251225229585543e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.0340864537283779e-05\n",
      "  batch 101 loss: 0.00042466890968171354\n",
      "  batch 201 loss: 0.00014222666563910025\n",
      "LOSS train 0.0002775821967105789 valid 0.0009519557352177799\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.6839827876538037e-05\n",
      "  batch 101 loss: 9.747534445750717e-05\n",
      "  batch 201 loss: 5.585441487824028e-05\n",
      "LOSS train 0.00013831745937149052 valid 0.0017556286184117198\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.703203819692135e-05\n",
      "  batch 101 loss: 0.00015555515390815343\n",
      "  batch 201 loss: 5.2108781194419865e-05\n",
      "LOSS train 0.00015935151751762287 valid 0.001532376860268414\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.1613710559904574e-05\n",
      "  batch 101 loss: 0.00013750679263580424\n",
      "  batch 201 loss: 4.886776099056078e-05\n",
      "LOSS train 0.00014781082613466917 valid 0.001303490367718041\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.774236443452537e-05\n",
      "  batch 101 loss: 0.00012450369152702478\n",
      "  batch 201 loss: 4.71699414356408e-05\n",
      "LOSS train 0.00014088223889176157 valid 0.001148105482570827\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.6356579726561905e-05\n",
      "  batch 101 loss: 0.00012427978062817146\n",
      "  batch 201 loss: 4.672336704174995e-05\n",
      "LOSS train 0.00014176504389079193 valid 0.0011020771926268935\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.7255013808608055e-05\n",
      "  batch 101 loss: 0.0001354900419914884\n",
      "  batch 201 loss: 4.756559978432051e-05\n",
      "LOSS train 0.0001495486252547663 valid 0.0011697827139869332\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.0118444226682186e-05\n",
      "  batch 101 loss: 0.00015936394501977702\n",
      "  batch 201 loss: 5.0305819759159934e-05\n",
      "LOSS train 0.00016649527600957998 valid 0.0014127575559541583\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.5651552714407444e-05\n",
      "  batch 101 loss: 0.00019999042662504962\n",
      "  batch 201 loss: 5.512032416049806e-05\n",
      "LOSS train 0.0002002700183790707 valid 0.002003998728469014\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.5504305269569156e-05\n",
      "  batch 101 loss: 0.00024106379559583503\n",
      "  batch 201 loss: 5.6279709208411075e-05\n",
      "LOSS train 0.00024023650179639757 valid 0.0023739191237837076\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.8969251327216626e-05\n",
      "  batch 101 loss: 0.00020430310449455645\n",
      "  batch 201 loss: 5.036883960571003e-05\n",
      "LOSS train 0.00022120271937056953 valid 0.0018780712271109223\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.7967756614089014e-05\n",
      "  batch 101 loss: 0.0001348209473587758\n",
      "  batch 201 loss: 4.5291598821961544e-05\n",
      "LOSS train 0.00017669237023880914 valid 0.001631933730095625\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0017320868372917176\n",
      "  batch 101 loss: 0.006959841544739902\n",
      "  batch 201 loss: 0.0023056467447895557\n",
      "LOSS train 0.004565309096492772 valid 0.0010088473791256547\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.267001662403345e-05\n",
      "  batch 101 loss: 0.0018605080130510033\n",
      "  batch 201 loss: 0.0014521161594893783\n",
      "LOSS train 0.0015519111634286686 valid 0.0004980569356121123\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.4771122951060533e-05\n",
      "  batch 101 loss: 0.0010971304058330134\n",
      "  batch 201 loss: 0.000927447360008955\n",
      "LOSS train 0.0009560022411881622 valid 0.00032285109045915306\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.5181293282657865e-06\n",
      "  batch 101 loss: 0.0006815911576268264\n",
      "  batch 201 loss: 0.00047488928801612927\n",
      "LOSS train 0.0005307173577197845 valid 0.000193003099411726\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.486002726480365e-06\n",
      "  batch 101 loss: 0.0003559581871377304\n",
      "  batch 201 loss: 0.00025470841879723596\n",
      "LOSS train 0.00027847163205528834 valid 7.949800055939704e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.738858456723392e-06\n",
      "  batch 101 loss: 0.0001942638749460457\n",
      "  batch 201 loss: 0.00011755512139643542\n",
      "LOSS train 0.0001409251921085919 valid 6.128879613243043e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.999739268096164e-07\n",
      "  batch 101 loss: 8.332123776199297e-05\n",
      "  batch 201 loss: 6.157479963803781e-05\n",
      "LOSS train 6.750485506647517e-05 valid 4.259998968336731e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.772730557713657e-07\n",
      "  batch 101 loss: 4.4773021663786494e-05\n",
      "  batch 201 loss: 3.309931029434665e-05\n",
      "LOSS train 3.422411085481584e-05 valid 1.55464731506072e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.721929195104167e-07\n",
      "  batch 101 loss: 2.5781398398976308e-05\n",
      "  batch 201 loss: 1.4920095959496393e-05\n",
      "LOSS train 1.9128505465522432e-05 valid 1.9484023141558282e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.2311462089419365e-07\n",
      "  batch 101 loss: 1.1984543230028066e-05\n",
      "  batch 201 loss: 9.176173791729526e-06\n",
      "LOSS train 9.68653629347117e-06 valid 3.537327074809582e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1233070836169645e-07\n",
      "  batch 101 loss: 9.045757274179777e-06\n",
      "  batch 201 loss: 6.7052428835268075e-06\n",
      "LOSS train 7.347428019897545e-06 valid 8.307129974127747e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.373958512995159e-08\n",
      "  batch 101 loss: 7.259552387495205e-06\n",
      "  batch 201 loss: 6.315126000799864e-06\n",
      "LOSS train 6.781990567192441e-06 valid 3.7118368254596135e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.001251605749130249\n",
      "  batch 101 loss: 0.007053225024137646\n",
      "  batch 201 loss: 0.003441264689899981\n",
      "LOSS train 0.005172580901888155 valid 0.0010003839852288365\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.484754219651222e-05\n",
      "  batch 101 loss: 0.00228988271439448\n",
      "  batch 201 loss: 0.0015397572424262762\n",
      "LOSS train 0.0017593168042047502 valid 0.0011958961840718985\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.5520691890269516e-05\n",
      "  batch 101 loss: 0.0010029961747932247\n",
      "  batch 201 loss: 0.0005262953348574229\n",
      "LOSS train 0.0006850219369314153 valid 0.00042992373346351087\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.9681183621287344e-05\n",
      "  batch 101 loss: 0.00032820902197272517\n",
      "  batch 201 loss: 0.00015615551026712638\n",
      "LOSS train 0.00022138122343070185 valid 0.00028398711583577096\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0846022050827741e-05\n",
      "  batch 101 loss: 0.00013853768938133727\n",
      "  batch 201 loss: 4.687861746788258e-05\n",
      "LOSS train 8.117905626965357e-05 valid 4.770739906234667e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.2358849421143533e-06\n",
      "  batch 101 loss: 5.195833723519172e-05\n",
      "  batch 201 loss: 1.6697714772817563e-05\n",
      "LOSS train 3.013448107488133e-05 valid 3.4031603718176484e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.5685409016441553e-06\n",
      "  batch 101 loss: 2.2888815551596052e-05\n",
      "  batch 201 loss: 9.581020415225793e-06\n",
      "LOSS train 1.4581696860582952e-05 valid 2.1368765374063514e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.386988727375865e-07\n",
      "  batch 101 loss: 1.3030756065290916e-05\n",
      "  batch 201 loss: 7.810948070527956e-06\n",
      "LOSS train 9.74241672235118e-06 valid 8.148591405188199e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.44180737354327e-07\n",
      "  batch 101 loss: 9.318797968944637e-06\n",
      "  batch 201 loss: 7.080561670136376e-06\n",
      "LOSS train 7.899489158399031e-06 valid 4.247964170644991e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.561801688396372e-08\n",
      "  batch 101 loss: 7.005145429275217e-06\n",
      "  batch 201 loss: 6.500062158920627e-06\n",
      "LOSS train 6.884823539701676e-06 valid 1.0344611837354023e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 8.434028131887316e-08\n",
      "  batch 101 loss: 8.960226443832653e-06\n",
      "  batch 201 loss: 1.4313943956949516e-05\n",
      "LOSS train 1.2070066587002257e-05 valid 5.272348062135279e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.6710831662057898e-08\n",
      "  batch 101 loss: 1.0398297473557249e-05\n",
      "  batch 201 loss: 8.467299222729707e-06\n",
      "LOSS train 9.562103869546049e-06 valid 1.298575534747215e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00031991057097911833\n",
      "  batch 101 loss: 0.00918407842516899\n",
      "  batch 201 loss: 0.0038765303359832616\n",
      "LOSS train 0.005301281268880686 valid 0.00013469734403770417\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4622757444158196e-05\n",
      "  batch 101 loss: 0.000647903330391273\n",
      "  batch 201 loss: 0.00021194221248151734\n",
      "LOSS train 0.0003426283250246009 valid 1.9683879145304672e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.8392314086668194e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 4.8512803732592144e-05\n",
      "  batch 201 loss: 1.9504482716001802e-05\n",
      "LOSS train 2.9329083950110393e-05 valid 1.3213955753599294e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.8085196390748024e-07\n",
      "  batch 101 loss: 1.851550234732713e-05\n",
      "  batch 201 loss: 1.371692612337938e-05\n",
      "LOSS train 1.5327853408309285e-05 valid 1.4128934708423913e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.813525710138493e-08\n",
      "  batch 101 loss: 1.2278108986265579e-05\n",
      "  batch 201 loss: 1.227825476689759e-05\n",
      "LOSS train 1.2448257770228714e-05 valid 2.3490996682085097e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.268804776889738e-08\n",
      "  batch 101 loss: 1.39882081361975e-05\n",
      "  batch 201 loss: 1.3299074475980888e-05\n",
      "LOSS train 1.5791268998284414e-05 valid 3.67284010280855e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.410457662132103e-07\n",
      "  batch 101 loss: 2.2661973616777686e-05\n",
      "  batch 201 loss: 2.6864686410590367e-05\n",
      "LOSS train 2.4058515918190323e-05 valid 1.0507947081350721e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.3013520401727875e-07\n",
      "  batch 101 loss: 1.2795109366834367e-05\n",
      "  batch 201 loss: 1.5888516602444726e-05\n",
      "LOSS train 1.6748356140255348e-05 valid 1.6162555766641162e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.0740757463499904e-07\n",
      "  batch 101 loss: 1.3054442213160655e-05\n",
      "  batch 201 loss: 1.3431664640393138e-05\n",
      "LOSS train 1.473895151617405e-05 valid 1.665929266891908e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.779674443649128e-08\n",
      "  batch 101 loss: 1.575154576130444e-05\n",
      "  batch 201 loss: 2.2121523938949396e-05\n",
      "LOSS train 1.9166778237720146e-05 valid 1.437345054000616e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.1455918613355607e-07\n",
      "  batch 101 loss: 3.267086593950808e-05\n",
      "  batch 201 loss: 2.0010088289836857e-05\n",
      "LOSS train 2.3274603084649448e-05 valid 1.0432447197672445e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.5218453124107324e-08\n",
      "  batch 101 loss: 2.1502009283267397e-05\n",
      "  batch 201 loss: 2.3032733970467234e-05\n",
      "LOSS train 2.2667425638569795e-05 valid 9.103889169637114e-06\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003576943278312683\n",
      "  batch 101 loss: 0.013967058593407274\n",
      "  batch 201 loss: 0.0015537170844618232\n",
      "LOSS train 0.005872532270093757 valid 4.133727998123504e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.88682126160711e-06\n",
      "  batch 101 loss: 9.890630954942025e-05\n",
      "  batch 201 loss: 2.972604596379824e-05\n",
      "LOSS train 5.626410118719376e-05 valid 2.0509580281213857e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.8692873204126955e-07\n",
      "  batch 101 loss: 2.6049892967421328e-05\n",
      "  batch 201 loss: 2.717369875881559e-05\n",
      "LOSS train 2.688165868709466e-05 valid 6.893028330523521e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.4356884750886823e-07\n",
      "  batch 101 loss: 2.753369542915607e-05\n",
      "  batch 201 loss: 2.3340640100286693e-05\n",
      "LOSS train 2.505802298327957e-05 valid 3.147199095110409e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.344414032355417e-08\n",
      "  batch 101 loss: 2.9623905952576024e-05\n",
      "  batch 201 loss: 2.6217972044833005e-05\n",
      "LOSS train 2.9938142383648634e-05 valid 0.00010123690299224108\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.63816138310358e-07\n",
      "  batch 101 loss: 4.3085711458843436e-05\n",
      "  batch 201 loss: 5.151360232503066e-05\n",
      "LOSS train 5.107194877319128e-05 valid 0.0001103861941373907\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.3588290534680707e-07\n",
      "  batch 101 loss: 4.4620318799388767e-05\n",
      "  batch 201 loss: 5.5455376732425065e-05\n",
      "LOSS train 4.945304819903824e-05 valid 7.503441884182394e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.515268170100171e-07\n",
      "  batch 101 loss: 5.649868769069144e-05\n",
      "  batch 201 loss: 5.5780572870389734e-05\n",
      "LOSS train 5.364621178919301e-05 valid 3.1952993595041335e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 8.944322871684562e-08\n",
      "  batch 101 loss: 3.597091897518112e-05\n",
      "  batch 201 loss: 4.031115128782403e-05\n",
      "LOSS train 3.7825495929366845e-05 valid 2.1854726583114825e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.5955049093463458e-07\n",
      "  batch 101 loss: 2.900696201777464e-05\n",
      "  batch 201 loss: 4.295187429761427e-05\n",
      "LOSS train 4.13571418513519e-05 valid 2.254780883959029e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.9242841517552733e-07\n",
      "  batch 101 loss: 3.8480271578009705e-05\n",
      "  batch 201 loss: 4.362960496564483e-05\n",
      "LOSS train 4.52986266861774e-05 valid 4.687997716246173e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.081743049435317e-07\n",
      "  batch 101 loss: 3.8333574325406515e-05\n",
      "  batch 201 loss: 3.952347883569018e-05\n",
      "LOSS train 4.011788533906648e-05 valid 2.006997419812251e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.1716854320839044e-06\n",
      "  batch 101 loss: 0.0003555673283784699\n",
      "  batch 201 loss: 4.184555470601481e-05\n",
      "LOSS train 0.00015060033497058193 valid 4.916468242299743e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.512643393652979e-08\n",
      "  batch 101 loss: 7.02494279835264e-06\n",
      "  batch 201 loss: 2.8087781700492087e-05\n",
      "LOSS train 1.5055423257691696e-05 valid 4.056431498611346e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2918450238430523e-08\n",
      "  batch 101 loss: 3.973991128418674e-06\n",
      "  batch 201 loss: 2.2632586849624657e-05\n",
      "LOSS train 1.0678758014806829e-05 valid 3.78521581296809e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5422737078552016e-08\n",
      "  batch 101 loss: 3.954569190369739e-06\n",
      "  batch 201 loss: 2.253846300988016e-05\n",
      "LOSS train 1.0770172674918721e-05 valid 3.924053453374654e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.652526174846571e-08\n",
      "  batch 101 loss: 3.6919252116263125e-06\n",
      "  batch 201 loss: 2.0998013097823788e-05\n",
      "LOSS train 1.015205190254834e-05 valid 3.2912932510953397e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.8814606619343976e-08\n",
      "  batch 101 loss: 3.249638760962625e-06\n",
      "  batch 201 loss: 1.9513257074521563e-05\n",
      "LOSS train 9.481631413483801e-06 valid 2.7835736545966938e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2644730986721697e-08\n",
      "  batch 101 loss: 2.9875773731191656e-06\n",
      "  batch 201 loss: 1.779742937252138e-05\n",
      "LOSS train 8.69740334500343e-06 valid 2.419360498606693e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.2436213410182972e-08\n",
      "  batch 101 loss: 2.724096135580112e-06\n",
      "  batch 201 loss: 1.648335869347761e-05\n",
      "LOSS train 8.078883374342018e-06 valid 2.1415276933112182e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.5263887007677114e-08\n",
      "  batch 101 loss: 2.4650835675288362e-06\n",
      "  batch 201 loss: 1.5027022248546018e-05\n",
      "LOSS train 7.445809251648092e-06 valid 1.8695860489970073e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.7036352346622152e-08\n",
      "  batch 101 loss: 2.261447660316662e-06\n",
      "  batch 201 loss: 1.296724291165674e-05\n",
      "LOSS train 6.188450306110645e-06 valid 2.0671359379775822e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2457195225579198e-07\n",
      "  batch 101 loss: 2.8895387382021907e-06\n",
      "  batch 201 loss: 7.1096771029033336e-06\n",
      "LOSS train 4.479913783210321e-06 valid 1.0319625289412215e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.0293998684574035e-08\n",
      "  batch 101 loss: 1.6252888580936543e-06\n",
      "  batch 201 loss: 6.2340262599036575e-06\n",
      "LOSS train 3.625777881739057e-06 valid 9.238057828042656e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.5324683412909504e-05\n",
      "  batch 101 loss: 0.0005703564217037638\n",
      "  batch 201 loss: 8.85026395553723e-05\n",
      "LOSS train 0.00027511358700224435 valid 9.927638893714175e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.7231656238436698e-06\n",
      "  batch 101 loss: 7.170012497226708e-05\n",
      "  batch 201 loss: 6.303201371338218e-05\n",
      "LOSS train 6.691486733927624e-05 valid 7.39909301046282e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0165564890485256e-06\n",
      "  batch 101 loss: 5.8328906961833125e-05\n",
      "  batch 201 loss: 5.266582254989771e-05\n",
      "LOSS train 5.360111019346179e-05 valid 5.741409768234007e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0693183867260814e-06\n",
      "  batch 101 loss: 4.8116428097273456e-05\n",
      "  batch 201 loss: 4.3502695980350836e-05\n",
      "LOSS train 4.5376812036194194e-05 valid 0.00010462813952472061\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.4550160267390311e-06\n",
      "  batch 101 loss: 4.27843370471237e-05\n",
      "  batch 201 loss: 2.898397387980367e-05\n",
      "LOSS train 3.5062185143099904e-05 valid 6.758532981621101e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0020882473327219e-06\n",
      "  batch 101 loss: 2.5252729283238296e-05\n",
      "  batch 201 loss: 2.5174969487125054e-05\n",
      "LOSS train 2.3715296535286414e-05 valid 1.1143881238240283e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.3148091461043804e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 1.5272134678525617e-05\n",
      "  batch 201 loss: 1.5117553898562619e-05\n",
      "LOSS train 1.4445591503171115e-05 valid 1.1657386494334787e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.6023512216634117e-07\n",
      "  batch 101 loss: 1.0375627125540632e-05\n",
      "  batch 201 loss: 1.2009523043161608e-05\n",
      "LOSS train 1.0916954751014317e-05 valid 7.052231467241654e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.6031006452976726e-07\n",
      "  batch 101 loss: 8.282110163690959e-06\n",
      "  batch 201 loss: 9.970094797608908e-06\n",
      "LOSS train 9.00019388246376e-06 valid 6.9296274887165055e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 8.197488568839617e-08\n",
      "  batch 101 loss: 7.495947290863114e-06\n",
      "  batch 201 loss: 8.800651260116865e-06\n",
      "LOSS train 7.733688681955988e-06 valid 1.3407959158939775e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.267308263981249e-07\n",
      "  batch 101 loss: 7.488726203064288e-06\n",
      "  batch 201 loss: 8.950234754365738e-06\n",
      "LOSS train 8.073051941416548e-06 valid 1.0370855306973681e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.818191412894521e-07\n",
      "  batch 101 loss: 7.944497338030487e-06\n",
      "  batch 201 loss: 8.591206102437354e-06\n",
      "LOSS train 8.221824738952502e-06 valid 7.349443421844626e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001473113242536783\n",
      "  batch 101 loss: 0.0006984110423945822\n",
      "  batch 201 loss: 0.0003498286532703787\n",
      "LOSS train 0.0005197397584284079 valid 6.539937749039382e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.0709654199890793e-06\n",
      "  batch 101 loss: 0.00026558354264125225\n",
      "  batch 201 loss: 0.0002400020553614013\n",
      "LOSS train 0.0002409789415721137 valid 6.756263610441238e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2724021507892757e-06\n",
      "  batch 101 loss: 0.00018745123306871392\n",
      "  batch 201 loss: 0.0001387527856422821\n",
      "LOSS train 0.00014988422751626692 valid 3.7557943869614974e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.188223339151591e-07\n",
      "  batch 101 loss: 9.413216746906983e-05\n",
      "  batch 201 loss: 8.063769771979423e-05\n",
      "LOSS train 8.316034912710605e-05 valid 2.2291245841188356e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.917630136944354e-07\n",
      "  batch 101 loss: 5.072350631962763e-05\n",
      "  batch 201 loss: 3.9047149239195275e-05\n",
      "LOSS train 4.345008331392986e-05 valid 1.3964410754851997e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.794569005956873e-07\n",
      "  batch 101 loss: 3.001560183292895e-05\n",
      "  batch 201 loss: 2.044422183644201e-05\n",
      "LOSS train 2.3349670416978486e-05 valid 1.6972107914625667e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 6.613001460209488e-07\n",
      "  batch 101 loss: 1.9039865496779384e-05\n",
      "  batch 201 loss: 1.4877783780775643e-05\n",
      "LOSS train 1.5864595043040228e-05 valid 1.2109981071262155e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.540381607715972e-07\n",
      "  batch 101 loss: 1.4901405302225612e-05\n",
      "  batch 201 loss: 1.2309455375998369e-05\n",
      "LOSS train 1.3009114877687875e-05 valid 1.3133692846167833e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.846069714403711e-07\n",
      "  batch 101 loss: 1.2766750651280744e-05\n",
      "  batch 201 loss: 1.2430017015958583e-05\n",
      "LOSS train 1.2344843910866006e-05 valid 9.389107617607806e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.4613043681019917e-07\n",
      "  batch 101 loss: 1.3481961734669313e-05\n",
      "  batch 201 loss: 1.2609498855908897e-05\n",
      "LOSS train 1.2468039873829017e-05 valid 8.267295925179496e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.504596315906383e-07\n",
      "  batch 101 loss: 1.215754669146918e-05\n",
      "  batch 201 loss: 1.1563532088985085e-05\n",
      "LOSS train 1.161144055520495e-05 valid 7.634745998075232e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.1004834454506637e-07\n",
      "  batch 101 loss: 1.1726392019681952e-05\n",
      "  batch 201 loss: 1.2049249858137045e-05\n",
      "LOSS train 1.1567243983326089e-05 valid 7.344463483605068e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 9.914888069033623e-05\n",
      "  batch 101 loss: 0.0003947101213998394\n",
      "  batch 201 loss: 0.00010144433281311649\n",
      "LOSS train 0.00023691520939895375 valid 0.00010537767957430333\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.717477375175804e-07\n",
      "  batch 101 loss: 7.959375167047255e-05\n",
      "  batch 201 loss: 8.147182920765772e-05\n",
      "LOSS train 7.546356424250789e-05 valid 4.682992948801257e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.386938962852582e-07\n",
      "  batch 101 loss: 5.951468384409963e-05\n",
      "  batch 201 loss: 5.664915636771184e-05\n",
      "LOSS train 5.729178006971539e-05 valid 3.793829455389641e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.0871178498491644e-07\n",
      "  batch 101 loss: 5.303877516780631e-05\n",
      "  batch 201 loss: 4.653235062960448e-05\n",
      "LOSS train 4.752183161847728e-05 valid 1.2870535101683345e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0243003089271951e-07\n",
      "  batch 101 loss: 3.4087305372167976e-05\n",
      "  batch 201 loss: 2.6039272947855353e-05\n",
      "LOSS train 2.6645347548388672e-05 valid 5.4368747441913e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.4490424241084836e-08\n",
      "  batch 101 loss: 1.32336738874983e-05\n",
      "  batch 201 loss: 1.3840828118532045e-05\n",
      "LOSS train 1.3825687332196522e-05 valid 6.089524958952097e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.141110937576741e-08\n",
      "  batch 101 loss: 1.2169193408908541e-05\n",
      "  batch 201 loss: 1.46018748091592e-05\n",
      "LOSS train 1.4079579888621017e-05 valid 7.466041097359266e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.1127642614592334e-08\n",
      "  batch 101 loss: 1.3871619067913343e-05\n",
      "  batch 201 loss: 1.4853527176796887e-05\n",
      "LOSS train 1.492978015139903e-05 valid 8.591151527070906e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.742729404621059e-08\n",
      "  batch 101 loss: 1.598345045977112e-05\n",
      "  batch 201 loss: 1.6779428821678267e-05\n",
      "LOSS train 1.6383943241863487e-05 valid 1.003587203740608e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.683807219407754e-08\n",
      "  batch 101 loss: 1.705973274056305e-05\n",
      "  batch 201 loss: 1.7246795495111654e-05\n",
      "LOSS train 1.7771956476032853e-05 valid 8.03474358690437e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.450523869716562e-08\n",
      "  batch 101 loss: 1.5190474097721563e-05\n",
      "  batch 201 loss: 1.6307600248524067e-05\n",
      "LOSS train 1.5536540321392797e-05 valid 8.51698041515192e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.162088660246809e-08\n",
      "  batch 101 loss: 1.7401503394012254e-05\n",
      "  batch 201 loss: 1.896273724639741e-05\n",
      "LOSS train 1.8237290032921475e-05 valid 9.895763469103258e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.898533388972282e-05\n",
      "  batch 101 loss: 0.0012535798690805678\n",
      "  batch 201 loss: 0.00021558720225584694\n",
      "LOSS train 0.0005948739248123651 valid 6.530962855322286e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.212108982144855e-06\n",
      "  batch 101 loss: 9.848896426774445e-05\n",
      "  batch 201 loss: 9.046372897614674e-05\n",
      "LOSS train 8.503199581233548e-05 valid 4.906250978820026e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.5226286854594945e-07\n",
      "  batch 101 loss: 5.912639315283741e-05\n",
      "  batch 201 loss: 5.8829058943956624e-05\n",
      "LOSS train 5.843410477383182e-05 valid 4.3291569454595447e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.299525244277902e-07\n",
      "  batch 101 loss: 5.7897443762158216e-05\n",
      "  batch 201 loss: 5.555801539230742e-05\n",
      "LOSS train 5.576816804835992e-05 valid 2.6879573852056637e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.305711677763611e-07\n",
      "  batch 101 loss: 5.223415089858463e-05\n",
      "  batch 201 loss: 4.463929620897033e-05\n",
      "LOSS train 4.6667576390020604e-05 valid 2.3480668460251763e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.4009557162353303e-07\n",
      "  batch 101 loss: 3.601636024995969e-05\n",
      "  batch 201 loss: 2.7164802872903238e-05\n",
      "LOSS train 3.0130861543325293e-05 valid 1.0769031177915167e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.727245924295857e-08\n",
      "  batch 101 loss: 2.4342258748220046e-05\n",
      "  batch 201 loss: 2.4434968424884572e-05\n",
      "LOSS train 2.4122654231644283e-05 valid 1.1097931746917311e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.602752131992019e-08\n",
      "  batch 101 loss: 2.3844183909886852e-05\n",
      "  batch 201 loss: 2.1030745742791623e-05\n",
      "LOSS train 2.203961770565235e-05 valid 1.4148997252050322e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 7.246998393384274e-08\n",
      "  batch 101 loss: 2.6719101920207323e-05\n",
      "  batch 201 loss: 2.5569345948497356e-05\n",
      "LOSS train 2.604759067799689e-05 valid 1.4573713997378945e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 9.264051186619327e-08\n",
      "  batch 101 loss: 2.9012484314989706e-05\n",
      "  batch 201 loss: 2.9683482896416536e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 2.8251378377314518e-05 valid 1.3910489542467985e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 8.013007573026698e-08\n",
      "  batch 101 loss: 2.5446150399375256e-05\n",
      "  batch 201 loss: 2.9019400963079533e-05\n",
      "LOSS train 2.7245879430785743e-05 valid 1.6073126971605234e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1857477147714235e-07\n",
      "  batch 101 loss: 2.9180997989897152e-05\n",
      "  batch 201 loss: 2.9188643011366367e-05\n",
      "LOSS train 2.928491015974122e-05 valid 1.5060250007081777e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00011012151837348938\n",
      "  batch 101 loss: 0.00010917243304675139\n",
      "  batch 201 loss: 6.570407106892161e-05\n",
      "LOSS train 0.0001181575843110205 valid 0.00016596150817349553\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.099848592886701e-07\n",
      "  batch 101 loss: 4.0797917504278305e-05\n",
      "  batch 201 loss: 3.3015742664019856e-05\n",
      "LOSS train 3.4084335631729326e-05 valid 8.108105248538777e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.4606221157009714e-07\n",
      "  batch 101 loss: 2.1674802515008195e-05\n",
      "  batch 201 loss: 1.836775537981339e-05\n",
      "LOSS train 1.8652438560214552e-05 valid 4.307484778109938e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.6983271861099635e-08\n",
      "  batch 101 loss: 1.19388419562938e-05\n",
      "  batch 201 loss: 9.756485756611255e-06\n",
      "LOSS train 9.90659311839455e-06 valid 1.5548426745226607e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.70775841374416e-09\n",
      "  batch 101 loss: 5.414141818960161e-06\n",
      "  batch 201 loss: 4.320482130992787e-06\n",
      "LOSS train 4.426567937153134e-06 valid 3.7835784496564884e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.101303946095868e-08\n",
      "  batch 101 loss: 3.0835931471528965e-06\n",
      "  batch 201 loss: 2.895540074518976e-06\n",
      "LOSS train 2.88341063832953e-06 valid 2.8583690436789766e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 6.736939667462138e-08\n",
      "  batch 101 loss: 3.027702388465059e-06\n",
      "  batch 201 loss: 3.0542404573452587e-06\n",
      "LOSS train 3.020320709282591e-06 valid 5.04675608681282e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0664757610356901e-07\n",
      "  batch 101 loss: 3.6762044763349878e-06\n",
      "  batch 201 loss: 3.5121815596994567e-06\n",
      "LOSS train 3.5413959708737806e-06 valid 6.313512585620629e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.2572794730658643e-07\n",
      "  batch 101 loss: 4.102483947576729e-06\n",
      "  batch 201 loss: 3.811146233232421e-06\n",
      "LOSS train 3.873141226556685e-06 valid 6.580527497135336e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.2942601642862428e-07\n",
      "  batch 101 loss: 4.310339773780925e-06\n",
      "  batch 201 loss: 4.008034365909907e-06\n",
      "LOSS train 4.0573711193777244e-06 valid 6.602521352760959e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2864266864198724e-07\n",
      "  batch 101 loss: 4.4174231426552525e-06\n",
      "  batch 201 loss: 4.118221379343367e-06\n",
      "LOSS train 4.155041224654326e-06 valid 6.5744038693082985e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.2631177014554852e-07\n",
      "  batch 101 loss: 4.588356106722813e-06\n",
      "  batch 201 loss: 4.117561615970544e-06\n",
      "LOSS train 4.252625502875249e-06 valid 6.51778600513353e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006856926530599594\n",
      "  batch 101 loss: 0.005161380896170158\n",
      "  batch 201 loss: 0.0032140679995063693\n",
      "LOSS train 0.004079732860224458 valid 8.785165118752047e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.582180064171553e-06\n",
      "  batch 101 loss: 0.0021165783873584587\n",
      "  batch 201 loss: 0.001648123368358938\n",
      "LOSS train 0.001682608519518115 valid 7.251104398164898e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.376469005364924e-06\n",
      "  batch 101 loss: 0.0010264214440394426\n",
      "  batch 201 loss: 0.0006065506265804288\n",
      "LOSS train 0.000691714885014778 valid 1.829469510994386e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.8750227647833526e-06\n",
      "  batch 101 loss: 0.00023532769711891887\n",
      "  batch 201 loss: 0.0001616410418500891\n",
      "LOSS train 0.00018096704954900198 valid 3.5637447581393644e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.05247148592025e-06\n",
      "  batch 101 loss: 0.00011972614520345814\n",
      "  batch 201 loss: 7.966598925122525e-05\n",
      "LOSS train 9.42207964096899e-05 valid 3.1562161893816665e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.4034329797141253e-06\n",
      "  batch 101 loss: 7.738878059171839e-05\n",
      "  batch 201 loss: 9.163697517578839e-05\n",
      "LOSS train 9.134799196604884e-05 valid 6.209858111105859e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.06868595443666e-07\n",
      "  batch 101 loss: 9.20739536468318e-05\n",
      "  batch 201 loss: 8.973648826213321e-05\n",
      "LOSS train 8.865356420966027e-05 valid 5.9106860135216266e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.226325811236165e-07\n",
      "  batch 101 loss: 8.549905080144526e-05\n",
      "  batch 201 loss: 8.387136085730162e-05\n",
      "LOSS train 8.305881380156512e-05 valid 5.825469270348549e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 6.18495760136284e-07\n",
      "  batch 101 loss: 8.18008513579116e-05\n",
      "  batch 201 loss: 8.048410761148262e-05\n",
      "LOSS train 8.021443643770415e-05 valid 5.911085827392526e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 6.173746078275145e-07\n",
      "  batch 101 loss: 7.856988574530987e-05\n",
      "  batch 201 loss: 7.721093917098187e-05\n",
      "LOSS train 7.745117424110837e-05 valid 5.867409345228225e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.090054401080124e-07\n",
      "  batch 101 loss: 7.498283920085668e-05\n",
      "  batch 201 loss: 7.587348414745066e-05\n",
      "LOSS train 7.48523485033616e-05 valid 5.8994781284127384e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.328243034658954e-07\n",
      "  batch 101 loss: 7.477153282252402e-05\n",
      "  batch 201 loss: 7.396387483368017e-05\n",
      "LOSS train 7.394641631065866e-05 valid 5.913092536502518e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0010379629582166672\n",
      "  batch 101 loss: 0.05165638010948896\n",
      "  batch 201 loss: 0.029303284753113987\n",
      "LOSS train 0.03450361773671903 valid 0.01302271243184805\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00014012466184794902\n",
      "  batch 101 loss: 0.009180419454351068\n",
      "  batch 201 loss: 0.004150281322654337\n",
      "LOSS train 0.0054437869593872935 valid 0.0013344542821869254\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.6254460206255317e-05\n",
      "  batch 101 loss: 0.0008468961443577428\n",
      "  batch 201 loss: 0.0003174283813132206\n",
      "LOSS train 0.0004711632877659699 valid 0.00010617511725286022\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.430409902241081e-06\n",
      "  batch 101 loss: 8.19806851905014e-05\n",
      "  batch 201 loss: 6.0216936999495376e-05\n",
      "LOSS train 6.66295222250123e-05 valid 5.20198154845275e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.186149842804298e-07\n",
      "  batch 101 loss: 5.33480247213447e-05\n",
      "  batch 201 loss: 5.325521351551288e-05\n",
      "LOSS train 5.250283947211073e-05 valid 5.094112202641554e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.655752723512705e-07\n",
      "  batch 101 loss: 5.2906282789990655e-05\n",
      "  batch 201 loss: 5.301743223753874e-05\n",
      "LOSS train 5.236072988220471e-05 valid 5.09259152750019e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.3051547032082454e-07\n",
      "  batch 101 loss: 5.350697601897991e-05\n",
      "  batch 201 loss: 5.362736093047715e-05\n",
      "LOSS train 5.274402097618291e-05 valid 5.0937604100909084e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.3283399059437215e-07\n",
      "  batch 101 loss: 5.38297495131701e-05\n",
      "  batch 201 loss: 5.364257337532763e-05\n",
      "LOSS train 5.301185907701571e-05 valid 5.096096356282942e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.3723674530629068e-07\n",
      "  batch 101 loss: 5.38259139375441e-05\n",
      "  batch 201 loss: 5.446952007332584e-05\n",
      "LOSS train 5.343510080183811e-05 valid 5.0978582294192165e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.40140943787992e-07\n",
      "  batch 101 loss: 5.453688101624721e-05\n",
      "  batch 201 loss: 5.414975470557692e-05\n",
      "LOSS train 5.3639257516190215e-05 valid 5.103101648273878e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.4751103410380893e-07\n",
      "  batch 101 loss: 5.4409890426541094e-05\n",
      "  batch 201 loss: 5.4630548675049795e-05\n",
      "LOSS train 5.39077730839684e-05 valid 5.107367178425193e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.526275238778908e-07\n",
      "  batch 101 loss: 5.484603767399676e-05\n",
      "  batch 201 loss: 5.496731545463263e-05\n",
      "LOSS train 5.427788730210543e-05 valid 5.114114173920825e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0014271526038646697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.036481432467699054\n",
      "  batch 201 loss: 0.011765480530448258\n",
      "LOSS train 0.02064476894289801 valid 0.0017341045895591378\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.559544242918492e-05\n",
      "  batch 101 loss: 0.007408104538917541\n",
      "  batch 201 loss: 0.005181857293937355\n",
      "LOSS train 0.0056955333178242045 valid 0.0006489641382358968\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.340987488627434e-05\n",
      "  batch 101 loss: 0.0029397303063888104\n",
      "  batch 201 loss: 0.0019391281809657812\n",
      "LOSS train 0.002159608616288956 valid 0.00015098937728907913\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.369781426154077e-06\n",
      "  batch 101 loss: 0.0009445687054540031\n",
      "  batch 201 loss: 0.000604990849387832\n",
      "LOSS train 0.0006703703596867321 valid 4.154006819589995e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.6662222808226942e-06\n",
      "  batch 101 loss: 0.0002655311498529045\n",
      "  batch 201 loss: 0.00017479843489127234\n",
      "LOSS train 0.0001929849866748235 valid 2.5428011213080026e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.588893251726404e-07\n",
      "  batch 101 loss: 9.232806976797292e-05\n",
      "  batch 201 loss: 6.874712935314164e-05\n",
      "LOSS train 7.444918991738995e-05 valid 2.325461719010491e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.510076880455017e-07\n",
      "  batch 101 loss: 5.320498160472198e-05\n",
      "  batch 201 loss: 4.2640769752324556e-05\n",
      "LOSS train 4.576594850092718e-05 valid 2.1191921405261382e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.2438401578692717e-07\n",
      "  batch 101 loss: 4.145993146721594e-05\n",
      "  batch 201 loss: 3.555322569809505e-05\n",
      "LOSS train 3.6458471849016614e-05 valid 1.7785821910365485e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.066645149374381e-07\n",
      "  batch 101 loss: 3.3485911590105385e-05\n",
      "  batch 201 loss: 3.0207627537492955e-05\n",
      "LOSS train 3.084826875947529e-05 valid 1.423427602276206e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.3928607333800756e-07\n",
      "  batch 101 loss: 3.0219790160117556e-05\n",
      "  batch 201 loss: 2.626607959427929e-05\n",
      "LOSS train 2.777830189058607e-05 valid 1.1450937563495245e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.2852482288726607e-07\n",
      "  batch 101 loss: 2.6943740126625927e-05\n",
      "  batch 201 loss: 2.4276653098240784e-05\n",
      "LOSS train 2.4913321591663384e-05 valid 9.10738617676543e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.427032839274034e-07\n",
      "  batch 101 loss: 2.3140917282944428e-05\n",
      "  batch 201 loss: 2.226222980652892e-05\n",
      "LOSS train 2.2753806559447537e-05 valid 8.083051397989038e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.184004850685597e-05\n",
      "  batch 101 loss: 0.001600909458938986\n",
      "  batch 201 loss: 0.00028120418166508896\n",
      "LOSS train 0.0007324432859178283 valid 5.110389247420244e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.618017555912957e-07\n",
      "  batch 101 loss: 7.232669051518314e-05\n",
      "  batch 201 loss: 6.386756485881051e-05\n",
      "LOSS train 6.599521097313376e-05 valid 5.1510640332708135e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.889586539822631e-07\n",
      "  batch 101 loss: 5.948649973106512e-05\n",
      "  batch 201 loss: 6.040236580702185e-05\n",
      "LOSS train 5.952944426538594e-05 valid 5.263057755655609e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.4763856092467905e-07\n",
      "  batch 101 loss: 6.135282962532073e-05\n",
      "  batch 201 loss: 6.19826491947606e-05\n",
      "LOSS train 6.121137917384309e-05 valid 5.31341320311185e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.6865541915176435e-07\n",
      "  batch 101 loss: 6.267135568123194e-05\n",
      "  batch 201 loss: 6.318405761703617e-05\n",
      "LOSS train 6.244465690782577e-05 valid 5.3553823818219826e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.8484246033476666e-07\n",
      "  batch 101 loss: 6.366596581756311e-05\n",
      "  batch 201 loss: 6.408496702533739e-05\n",
      "LOSS train 6.337117994397496e-05 valid 5.3887575631961226e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.97054900531657e-07\n",
      "  batch 101 loss: 6.440465945161123e-05\n",
      "  batch 201 loss: 6.475046436207776e-05\n",
      "LOSS train 6.405673364151014e-05 valid 5.4143987654242665e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.061077197548002e-07\n",
      "  batch 101 loss: 6.494600714177068e-05\n",
      "  batch 201 loss: 6.523615382320714e-05\n",
      "LOSS train 6.455770408171365e-05 valid 5.433629485196434e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.127304418943822e-07\n",
      "  batch 101 loss: 6.533881924951857e-05\n",
      "  batch 201 loss: 6.558756141203048e-05\n",
      "LOSS train 6.492050588582433e-05 valid 5.447813236969523e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.1753090044949205e-07\n",
      "  batch 101 loss: 6.56219267511915e-05\n",
      "  batch 201 loss: 6.584035249943554e-05\n",
      "LOSS train 6.518166039160407e-05 valid 5.458152372739278e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.209901817375794e-07\n",
      "  batch 101 loss: 6.582511065062136e-05\n",
      "  batch 201 loss: 6.602157101951888e-05\n",
      "LOSS train 6.536895221577338e-05 valid 5.4656418797094375e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.234736843500286e-07\n",
      "  batch 101 loss: 6.597056418286229e-05\n",
      "  batch 201 loss: 6.615121516915678e-05\n",
      "LOSS train 6.550297852992939e-05 valid 5.4710395488655195e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.736192852258683e-05\n",
      "  batch 101 loss: 6.375230926209951e-05\n",
      "  batch 201 loss: 1.4198385038071138e-05\n",
      "LOSS train 5.5345778627929825e-05 valid 1.13710420919233e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1144130667162244e-08\n",
      "  batch 101 loss: 4.571180188719382e-06\n",
      "  batch 201 loss: 2.3727666261663673e-06\n",
      "LOSS train 3.0076525722539946e-06 valid 4.817622084374307e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.9202982457500184e-08\n",
      "  batch 101 loss: 2.0255527235235602e-06\n",
      "  batch 201 loss: 2.5959879486947556e-06\n",
      "LOSS train 2.1647592582054138e-06 valid 3.0570543003705097e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.3164959682399059e-08\n",
      "  batch 101 loss: 1.928663505310624e-06\n",
      "  batch 201 loss: 2.242724372365501e-06\n",
      "LOSS train 1.991468663912854e-06 valid 2.308761395397596e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.741329000054975e-09\n",
      "  batch 101 loss: 2.2562015301730297e-06\n",
      "  batch 201 loss: 2.395276555304804e-06\n",
      "LOSS train 2.128608071695458e-06 valid 2.1713951809942955e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.357729489536723e-09\n",
      "  batch 101 loss: 1.823525142725657e-06\n",
      "  batch 201 loss: 2.088180080903612e-06\n",
      "LOSS train 1.8045886202888961e-06 valid 2.9034049475740176e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.847944172885036e-09\n",
      "  batch 101 loss: 1.740626080675156e-06\n",
      "  batch 201 loss: 3.170236673213367e-06\n",
      "LOSS train 2.2237968302233104e-06 valid 2.273366590088699e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.067872166364395e-09\n",
      "  batch 101 loss: 1.46331101262831e-06\n",
      "  batch 201 loss: 1.630806077912439e-06\n",
      "LOSS train 1.433434966778115e-06 valid 3.48991807186394e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 7.136968633858487e-09\n",
      "  batch 101 loss: 1.838142122210229e-06\n",
      "  batch 201 loss: 1.9322358919282577e-06\n",
      "LOSS train 1.9983310961698163e-06 valid 7.275455118360696e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.7232540560362394e-08\n",
      "  batch 101 loss: 1.6012249494679054e-06\n",
      "  batch 201 loss: 1.4561394917222969e-06\n",
      "LOSS train 1.3762623228077801e-06 valid 2.5675137749203714e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.896241480561002e-09\n",
      "  batch 101 loss: 1.7661552594461227e-06\n",
      "  batch 201 loss: 1.4510837719683423e-06\n",
      "LOSS train 1.5213735788984362e-06 valid 3.8648140616714954e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.041582653575461e-09\n",
      "  batch 101 loss: 1.4639474008504294e-06\n",
      "  batch 201 loss: 1.7391789116061318e-06\n",
      "LOSS train 1.5111022689355165e-06 valid 3.3140472623927053e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017634401097893715\n",
      "  batch 101 loss: 0.0006379323200962971\n",
      "  batch 201 loss: 0.00021621236286591738\n",
      "LOSS train 0.0004164803410006513 valid 4.5355744077824056e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4077402011025697e-06\n",
      "  batch 101 loss: 0.0001279213766611065\n",
      "  batch 201 loss: 9.643743131164228e-05\n",
      "LOSS train 0.00010308124816193136 valid 1.5930665540508926e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.218780617928133e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 6.82967798820755e-05\n",
      "  batch 201 loss: 5.2670362256321825e-05\n",
      "LOSS train 5.59533981929598e-05 valid 2.22954749915516e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.8420730561483654e-07\n",
      "  batch 101 loss: 3.640181626906269e-05\n",
      "  batch 201 loss: 2.76177252362686e-05\n",
      "LOSS train 2.9205597420247576e-05 valid 6.749446583853569e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.0640569346142e-07\n",
      "  batch 101 loss: 1.846570332418196e-05\n",
      "  batch 201 loss: 1.3979075683892006e-05\n",
      "LOSS train 1.4790308725570115e-05 valid 3.2159873626369517e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.214349691115785e-08\n",
      "  batch 101 loss: 9.24824671301394e-06\n",
      "  batch 201 loss: 7.490380839954014e-06\n",
      "LOSS train 7.66726601514598e-06 valid 2.259122311443207e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.400947990594431e-08\n",
      "  batch 101 loss: 5.4657196483276494e-06\n",
      "  batch 201 loss: 4.458928029862363e-06\n",
      "LOSS train 4.712229613457796e-06 valid 1.9058309135289164e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.903222477674717e-08\n",
      "  batch 101 loss: 3.723431173625613e-06\n",
      "  batch 201 loss: 3.4611617354585178e-06\n",
      "LOSS train 3.4148981063437876e-06 valid 2.5021311103046173e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1440956768637989e-08\n",
      "  batch 101 loss: 2.758623314491615e-06\n",
      "  batch 201 loss: 2.5102008510202724e-06\n",
      "LOSS train 2.526800807511927e-06 valid 3.63533536074101e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.9745758562712584e-09\n",
      "  batch 101 loss: 2.170362834874595e-06\n",
      "  batch 201 loss: 2.013737205288635e-06\n",
      "LOSS train 2.0028503229241323e-06 valid 1.018389298224065e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.2830550834623864e-09\n",
      "  batch 101 loss: 1.991263564491419e-06\n",
      "  batch 201 loss: 2.0613726779572516e-06\n",
      "LOSS train 1.9500192068821704e-06 valid 1.2698318414550158e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.232729674593429e-09\n",
      "  batch 101 loss: 1.7180613157563584e-06\n",
      "  batch 201 loss: 2.1756588370180908e-06\n",
      "LOSS train 1.9496375496008933e-06 valid 1.6882455611266778e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.176340880803764e-06\n",
      "  batch 101 loss: 8.560218911952688e-05\n",
      "  batch 201 loss: 6.278549008129631e-05\n",
      "LOSS train 7.421621276513352e-05 valid 5.6516695622121915e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.5662240154342727e-07\n",
      "  batch 101 loss: 6.742829824361251e-05\n",
      "  batch 201 loss: 6.791324220102979e-05\n",
      "LOSS train 6.686354314403813e-05 valid 5.496521043824032e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.293329402571544e-07\n",
      "  batch 101 loss: 6.662182414402196e-05\n",
      "  batch 201 loss: 6.665280250672367e-05\n",
      "LOSS train 6.605184256135038e-05 valid 5.4888500017113984e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.310489384806715e-07\n",
      "  batch 101 loss: 6.653463872680732e-05\n",
      "  batch 201 loss: 6.646518839261262e-05\n",
      "LOSS train 6.593552903463465e-05 valid 5.496121593751013e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.328353315941058e-07\n",
      "  batch 101 loss: 6.649018989719479e-05\n",
      "  batch 201 loss: 6.658303666881693e-05\n",
      "LOSS train 6.594464174178519e-05 valid 5.491964111570269e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.324819383327849e-07\n",
      "  batch 101 loss: 6.64357012919936e-05\n",
      "  batch 201 loss: 6.644195558692445e-05\n",
      "LOSS train 6.587837865298329e-05 valid 5.488350143423304e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.325986446929164e-07\n",
      "  batch 101 loss: 6.634969533479306e-05\n",
      "  batch 201 loss: 6.652219617535593e-05\n",
      "LOSS train 6.588035105548672e-05 valid 5.486235022544861e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.3060972529929133e-07\n",
      "  batch 101 loss: 6.62911191375315e-05\n",
      "  batch 201 loss: 6.637557055000798e-05\n",
      "LOSS train 6.578127396086539e-05 valid 5.489815885084681e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.346193964011036e-07\n",
      "  batch 101 loss: 6.631750135966286e-05\n",
      "  batch 201 loss: 6.644266499733931e-05\n",
      "LOSS train 6.584700511186863e-05 valid 5.497951860888861e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.3399813876021653e-07\n",
      "  batch 101 loss: 5.713065009786078e-05\n",
      "  batch 201 loss: 6.805934003750735e-05\n",
      "LOSS train 6.308979221939275e-05 valid 5.494710057973862e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.340869782026857e-07\n",
      "  batch 101 loss: 6.651162753769313e-05\n",
      "  batch 201 loss: 6.669863999377413e-05\n",
      "LOSS train 6.6035708298578e-05 valid 5.494748620549217e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.3296782678226007e-07\n",
      "  batch 101 loss: 6.641766158281826e-05\n",
      "  batch 201 loss: 6.657632224687404e-05\n",
      "LOSS train 6.591981592287866e-05 valid 5.493063872563653e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000106881782412529\n",
      "  batch 101 loss: 0.0008968641917454079\n",
      "  batch 201 loss: 0.0003752139453717973\n",
      "LOSS train 0.0005774338889164312 valid 4.401822297950275e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.2532408183906227e-06\n",
      "  batch 101 loss: 0.0001654465647879988\n",
      "  batch 201 loss: 0.00015262431574228686\n",
      "LOSS train 0.00015188727599337113 valid 7.281745638465509e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.113897249335423e-07\n",
      "  batch 101 loss: 0.00011185519146238221\n",
      "  batch 201 loss: 9.704579577373806e-05\n",
      "LOSS train 0.00010189694819015436 valid 7.26058569853194e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.070018406608142e-06\n",
      "  batch 101 loss: 9.400667786394479e-05\n",
      "  batch 201 loss: 8.774529198490199e-05\n",
      "LOSS train 8.954560669089348e-05 valid 6.050741285434924e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.79066872887779e-07\n",
      "  batch 101 loss: 8.654940600536065e-05\n",
      "  batch 201 loss: 8.410677981373737e-05\n",
      "LOSS train 8.196766964749339e-05 valid 5.8516860008239746e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.391655915649608e-07\n",
      "  batch 101 loss: 7.186548526533443e-05\n",
      "  batch 201 loss: 7.028745303614415e-05\n",
      "LOSS train 6.950522442704637e-05 valid 5.373916792450473e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.205638080951757e-07\n",
      "  batch 101 loss: 6.509136627755652e-05\n",
      "  batch 201 loss: 6.199179968916723e-05\n",
      "LOSS train 6.251924104694125e-05 valid 5.337448965292424e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.66474518564064e-07\n",
      "  batch 101 loss: 5.690418706763012e-05\n",
      "  batch 201 loss: 5.5146274480648575e-05\n",
      "LOSS train 5.444745559480364e-05 valid 3.641455987235531e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.060767969349399e-07\n",
      "  batch 101 loss: 4.1136978543363513e-05\n",
      "  batch 201 loss: 4.1469535426585934e-05\n",
      "LOSS train 4.06361197493981e-05 valid 1.732338387228083e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.3136500456312206e-07\n",
      "  batch 101 loss: 3.243332686906797e-05\n",
      "  batch 201 loss: 2.4744845650275237e-05\n",
      "LOSS train 2.6729405830930785e-05 valid 8.899801287043374e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2481443263823168e-07\n",
      "  batch 101 loss: 2.007720222536591e-05\n",
      "  batch 201 loss: 2.121309318681597e-05\n",
      "LOSS train 2.038371438328339e-05 valid 6.976227723498596e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 8.381874067708849e-08\n",
      "  batch 101 loss: 1.891391918888985e-05\n",
      "  batch 201 loss: 2.1458671105847316e-05\n",
      "LOSS train 1.9977672346802858e-05 valid 8.873692422639579e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003129285201430321\n",
      "  batch 101 loss: 0.004103625430725515\n",
      "  batch 201 loss: 0.001645345349679701\n",
      "LOSS train 0.002478560528098759 valid 0.00020989659242331982\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.434916915372014e-06\n",
      "  batch 101 loss: 0.0006688699952792376\n",
      "  batch 201 loss: 0.00045438360379193907\n",
      "LOSS train 0.0005030001058126374 valid 5.177647472009994e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.1484521857928486e-06\n",
      "  batch 101 loss: 0.0002571550363791175\n",
      "  batch 201 loss: 0.00019259084190707655\n",
      "LOSS train 0.00020714236072954574 valid 5.266966763883829e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.3183722330722959e-06\n",
      "  batch 101 loss: 0.00013502507612429327\n",
      "  batch 201 loss: 0.00011484015598398401\n",
      "LOSS train 0.00011785652580765466 valid 5.2067065553274006e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.600654887733981e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 9.074524386960547e-05\n",
      "  batch 201 loss: 7.84779644527589e-05\n",
      "LOSS train 8.169293224644927e-05 valid 4.306925620767288e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.802596933790483e-07\n",
      "  batch 101 loss: 6.887942960929649e-05\n",
      "  batch 201 loss: 6.532889641675865e-05\n",
      "LOSS train 6.508264234251148e-05 valid 3.55999763996806e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.591495988075621e-07\n",
      "  batch 101 loss: 5.976473755254119e-05\n",
      "  batch 201 loss: 5.1430307335067484e-05\n",
      "LOSS train 5.254134993808357e-05 valid 2.5912448109011166e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.3389080524793826e-07\n",
      "  batch 101 loss: 4.13955387648457e-05\n",
      "  batch 201 loss: 4.238068946506246e-05\n",
      "LOSS train 4.1296283254915236e-05 valid 1.9486795281409286e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.952082493517082e-07\n",
      "  batch 101 loss: 3.6986386539865635e-05\n",
      "  batch 201 loss: 3.9199619091050406e-05\n",
      "LOSS train 3.7728864950729274e-05 valid 2.167717320844531e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.996546779992059e-07\n",
      "  batch 101 loss: 3.713082539889001e-05\n",
      "  batch 201 loss: 3.8539948509423997e-05\n",
      "LOSS train 3.7428147840191974e-05 valid 2.522131944715511e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.0737250451929868e-07\n",
      "  batch 101 loss: 3.95216215565597e-05\n",
      "  batch 201 loss: 3.804609031703876e-05\n",
      "LOSS train 3.827558935255506e-05 valid 2.1641239072778262e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.0530844267341307e-07\n",
      "  batch 101 loss: 3.6988941189974867e-05\n",
      "  batch 201 loss: 3.695749840517237e-05\n",
      "LOSS train 3.685775413442161e-05 valid 2.160320946131833e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.0102516282349824e-05\n",
      "  batch 101 loss: 0.006533953153575567\n",
      "  batch 201 loss: 0.0002077406681382854\n",
      "LOSS train 0.002507704919437293 valid 0.0010574307525530457\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.6983324894681574e-06\n",
      "  batch 101 loss: 6.500695909153364e-05\n",
      "  batch 201 loss: 0.00021710529864549244\n",
      "LOSS train 0.0001498767792302285 valid 0.0014560341369360685\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.4948252141475677e-06\n",
      "  batch 101 loss: 8.825599631222759e-05\n",
      "  batch 201 loss: 0.00017026689754970903\n",
      "LOSS train 0.0001258376094911633 valid 0.0016014243010431528\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.673278890550137e-06\n",
      "  batch 101 loss: 9.285956615713075e-05\n",
      "  batch 201 loss: 0.00016931986332792802\n",
      "LOSS train 0.00014102345671544953 valid 0.0018192138522863388\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.94827569834888e-06\n",
      "  batch 101 loss: 8.48869668379848e-05\n",
      "  batch 201 loss: 0.00043339017581729423\n",
      "LOSS train 0.0002528533964190028 valid 0.0008809667197056115\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.2986588394123825e-08\n",
      "  batch 101 loss: 6.830977571439689e-05\n",
      "  batch 201 loss: 0.0002234035249966837\n",
      "LOSS train 0.00015023388920452994 valid 0.0008881270769052207\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.5436709620407784e-07\n",
      "  batch 101 loss: 0.0001086872046539611\n",
      "  batch 201 loss: 0.00017660655799204506\n",
      "LOSS train 0.00016946032652677976 valid 0.0008831156301312149\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1333908332744612e-06\n",
      "  batch 101 loss: 0.0001597981717895891\n",
      "  batch 201 loss: 0.00027789560367637024\n",
      "LOSS train 0.0002302999630617892 valid 0.0010890820994973183\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 9.911511733662337e-07\n",
      "  batch 101 loss: 0.00010854887171262817\n",
      "  batch 201 loss: 0.0002896605416344755\n",
      "LOSS train 0.00022511364977617632 valid 0.0007925853133201599\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.3727172851504296e-08\n",
      "  batch 101 loss: 7.650970886061259e-05\n",
      "  batch 201 loss: 0.0001683428949252175\n",
      "LOSS train 0.00017568959625948545 valid 0.0010696998797357082\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.6440047299256546e-07\n",
      "  batch 101 loss: 8.750465763341708e-05\n",
      "  batch 201 loss: 0.0001744786139192911\n",
      "LOSS train 0.0002100733577262439 valid 0.002003733767196536\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.7194346077740193e-06\n",
      "  batch 101 loss: 0.00012836205754979346\n",
      "  batch 201 loss: 0.00015657588366423168\n",
      "LOSS train 0.00019944662097824944 valid 0.0018885788740590215\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002903673052787781\n",
      "  batch 101 loss: 0.004592347942525521\n",
      "  batch 201 loss: 0.0015241554524982348\n",
      "LOSS train 0.0025840110490704124 valid 0.0002111450448865071\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3174840714782477e-05\n",
      "  batch 101 loss: 0.000523313122394029\n",
      "  batch 201 loss: 0.0002687786107708234\n",
      "LOSS train 0.0003410828059527259 valid 0.00012239193893037736\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.402893923223019e-06\n",
      "  batch 101 loss: 0.0002306916954330518\n",
      "  batch 201 loss: 4.6761279463680694e-05\n",
      "LOSS train 0.0001121549707882018 valid 2.7644842703011818e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.2721168352290987e-06\n",
      "  batch 101 loss: 9.922905071107379e-05\n",
      "  batch 201 loss: 1.5315929231292104e-05\n",
      "LOSS train 4.591159745526193e-05 valid 1.971424171642866e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.012954640435055e-07\n",
      "  batch 101 loss: 6.685518744234287e-05\n",
      "  batch 201 loss: 1.717052348340076e-05\n",
      "LOSS train 4.4532908492368696e-05 valid 3.568622560123913e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.456765211420134e-07\n",
      "  batch 101 loss: 8.735640935356059e-05\n",
      "  batch 201 loss: 0.00018943152807878504\n",
      "LOSS train 0.0001674298455144285 valid 0.00019156096095684916\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.6517007315997034e-06\n",
      "  batch 101 loss: 0.00010614135283049109\n",
      "  batch 201 loss: 0.00022838676980882155\n",
      "LOSS train 0.00015048932123585933 valid 7.103048119461164e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.588311953237281e-07\n",
      "  batch 101 loss: 0.0001131088506326705\n",
      "  batch 201 loss: 0.00031166075676082984\n",
      "LOSS train 0.0001818603601823403 valid 7.280179943336407e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 8.103547770588193e-08\n",
      "  batch 101 loss: 0.00016817436727251334\n",
      "  batch 201 loss: 0.0001383700141832378\n",
      "LOSS train 0.00013752742704407586 valid 0.0002011624164879322\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.1824209145270286e-06\n",
      "  batch 101 loss: 0.00030506019128552\n",
      "  batch 201 loss: 9.736488997077685e-05\n",
      "LOSS train 0.00017513794259001848 valid 7.173772610258311e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.444501195801422e-07\n",
      "  batch 101 loss: 0.0004863093915719219\n",
      "  batch 201 loss: 4.6658769053919966e-05\n",
      "LOSS train 0.0002042397077616859 valid 2.2403030015993863e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.479952051246073e-08\n",
      "  batch 101 loss: 7.988798210362803e-05\n",
      "  batch 201 loss: 0.0003681226768412671\n",
      "LOSS train 0.00018180741900796553 valid 1.011055883282097e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00045394301414489744\n",
      "  batch 101 loss: 0.006711643619928509\n",
      "  batch 201 loss: 0.002066369813983329\n",
      "LOSS train 0.00355888538554246 valid 0.0001636185625102371\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.491913904435933e-06\n",
      "  batch 101 loss: 0.00030135101449559444\n",
      "  batch 201 loss: 9.674085180449765e-05\n",
      "LOSS train 0.0001613967195978911 valid 3.176198515575379e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.652014954946935e-06\n",
      "  batch 101 loss: 6.097627471717715e-05\n",
      "  batch 201 loss: 1.613935444765957e-05\n",
      "LOSS train 3.277044085831428e-05 valid 9.302149010181893e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.309208816266619e-07\n",
      "  batch 101 loss: 1.364111762882203e-05\n",
      "  batch 201 loss: 1.2928036557013912e-05\n",
      "LOSS train 1.7332657035285092e-05 valid 2.931596100097522e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.4396591723198072e-07\n",
      "  batch 101 loss: 2.612638448681537e-05\n",
      "  batch 201 loss: 5.3599632940404264e-05\n",
      "LOSS train 4.1636816318621124e-05 valid 7.377661677310243e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.002708763233386e-07\n",
      "  batch 101 loss: 0.0003158292717398581\n",
      "  batch 201 loss: 0.00017482155270954537\n",
      "LOSS train 0.00020359502170468814 valid 3.946003926103003e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.3499207600252702e-07\n",
      "  batch 101 loss: 0.00015102154415217229\n",
      "  batch 201 loss: 0.00017809576224408374\n",
      "LOSS train 0.0001588543534405919 valid 4.8693425924284384e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.1649513402953745e-07\n",
      "  batch 101 loss: 0.00015587891119139385\n",
      "  batch 201 loss: 7.575430754059199e-05\n",
      "LOSS train 0.0002879946059059902 valid 0.00023356858582701534\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.2320824791677297e-06\n",
      "  batch 101 loss: 0.00020840378586399312\n",
      "  batch 201 loss: 3.6106277018461694e-05\n",
      "LOSS train 0.00010662566815438204 valid 1.3419857168628369e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.2412373507686424e-07\n",
      "  batch 101 loss: 9.419912081739313e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.000381143984686787\n",
      "LOSS train 0.00021133720119306107 valid 3.5717053833650425e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.290799112524837e-07\n",
      "  batch 101 loss: 7.755999451092066e-05\n",
      "  batch 201 loss: 0.00012515042724771773\n",
      "LOSS train 0.00012749676788965627 valid 1.3452349776343908e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 8.559765774407424e-08\n",
      "  batch 101 loss: 9.283214901643078e-05\n",
      "  batch 201 loss: 0.00032871004578282736\n",
      "LOSS train 0.00018891953931458936 valid 6.706442218273878e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00024601109325885775\n",
      "  batch 101 loss: 0.010329051986336707\n",
      "  batch 201 loss: 0.0013483673124574124\n",
      "LOSS train 0.004456809471626152 valid 0.00015451091167051345\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1281748302280902e-05\n",
      "  batch 101 loss: 0.00014756863766706373\n",
      "  batch 201 loss: 2.6475513514014893e-05\n",
      "LOSS train 7.626043644939692e-05 valid 1.3040104022365995e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.0903731638099997e-07\n",
      "  batch 101 loss: 2.353795188582808e-05\n",
      "  batch 201 loss: 1.901076545664182e-05\n",
      "LOSS train 1.930139042387664e-05 valid 1.1297574928903487e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.4582138798432426e-08\n",
      "  batch 101 loss: 1.6501418551797544e-05\n",
      "  batch 201 loss: 2.4745185946812853e-05\n",
      "LOSS train 2.1003653773232645e-05 valid 1.5246083421516232e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.5361733757308687e-08\n",
      "  batch 101 loss: 5.086360501991294e-05\n",
      "  batch 201 loss: 7.518738045746432e-05\n",
      "LOSS train 8.543512013192822e-05 valid 2.200541530328337e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.679114524857141e-07\n",
      "  batch 101 loss: 8.15169232464541e-05\n",
      "  batch 201 loss: 0.0003145950072848791\n",
      "LOSS train 0.0002034037622715148 valid 0.00021557977015618235\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.5884859496727585e-06\n",
      "  batch 101 loss: 0.0001062159822868125\n",
      "  batch 201 loss: 0.0003403771217108442\n",
      "LOSS train 0.00018526660941404525 valid 0.00015577218437101692\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.480667317286134e-06\n",
      "  batch 101 loss: 0.0002011948010294873\n",
      "  batch 201 loss: 0.00021603311308354022\n",
      "LOSS train 0.0001803873570019937 valid 2.8417254725354724e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.732804179890081e-07\n",
      "  batch 101 loss: 0.0001353067182299128\n",
      "  batch 201 loss: 0.00019057862942645443\n",
      "LOSS train 0.00018743186066432573 valid 8.759147021919489e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.645782948704437e-07\n",
      "  batch 101 loss: 0.0002567049781555397\n",
      "  batch 201 loss: 0.00018268464148604835\n",
      "LOSS train 0.00022498973175104418 valid 5.465156937134452e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.723025919403881e-07\n",
      "  batch 101 loss: 0.0001960311219590949\n",
      "  batch 201 loss: 0.0001986713729093026\n",
      "LOSS train 0.00019117119350434782 valid 1.969828736037016e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.2718136683106423e-07\n",
      "  batch 101 loss: 0.00021520009731830215\n",
      "  batch 201 loss: 0.00022449246114774723\n",
      "LOSS train 0.00018489406014211184 valid 1.8800674297381192e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0016735194623470307\n",
      "  batch 101 loss: 0.017808874752372503\n",
      "  batch 201 loss: 0.0007329243847198086\n",
      "LOSS train 0.0074240430105499315 valid 1.6464124200865626e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.313777367817238e-06\n",
      "  batch 101 loss: 7.094512669937103e-05\n",
      "  batch 201 loss: 2.327080809209292e-05\n",
      "LOSS train 4.25481436813686e-05 valid 2.689055327209644e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.004706614883616e-08\n",
      "  batch 101 loss: 2.8213857435730462e-05\n",
      "  batch 201 loss: 3.28521017672756e-05\n",
      "LOSS train 3.167801378034437e-05 valid 2.1421374185592867e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.747980604704935e-07\n",
      "  batch 101 loss: 2.9140737774469015e-05\n",
      "  batch 201 loss: 2.9711731322095148e-05\n",
      "LOSS train 2.950544282508824e-05 valid 3.991642006440088e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.98367613647133e-08\n",
      "  batch 101 loss: 4.696219955803826e-05\n",
      "  batch 201 loss: 5.851316072039481e-05\n",
      "LOSS train 9.513578273042215e-05 valid 0.00010306490730727091\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.042724221013486e-07\n",
      "  batch 101 loss: 0.0001557078707446635\n",
      "  batch 201 loss: 9.024476677041093e-05\n",
      "LOSS train 0.00012315617370584552 valid 0.00014164384629111737\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.8502170860301703e-06\n",
      "  batch 101 loss: 0.00015831173715923796\n",
      "  batch 201 loss: 0.00013134167422322208\n",
      "LOSS train 0.00018511773419299722 valid 2.348895577597432e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.257741476176306e-07\n",
      "  batch 101 loss: 0.00026197847042567444\n",
      "  batch 201 loss: 0.00022034724961486062\n",
      "LOSS train 0.0002732144974608353 valid 2.3126694941311143e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 7.929610728751868e-07\n",
      "  batch 101 loss: 0.00016825050735860714\n",
      "  batch 201 loss: 0.00015529173841059675\n",
      "LOSS train 0.0002456197960602547 valid 0.0002164122270187363\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.794132695067674e-06\n",
      "  batch 101 loss: 0.00021129055860001246\n",
      "  batch 201 loss: 0.00024023756646784022\n",
      "LOSS train 0.00024613896672542066 valid 0.00012562141637317836\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.4052634651307017e-06\n",
      "  batch 101 loss: 0.0002265048704975925\n",
      "  batch 201 loss: 0.00021540189920415286\n",
      "LOSS train 0.00025117569252154187 valid 1.9468436221359298e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.468640978913754e-07\n",
      "  batch 101 loss: 0.00019247753198214923\n",
      "  batch 201 loss: 0.00048186606974923054\n",
      "LOSS train 0.00028256767551690143 valid 1.9290662748971954e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00035416845232248305\n",
      "  batch 101 loss: 0.0013258918978226574\n",
      "  batch 201 loss: 1.1422486914511864e-05\n",
      "LOSS train 0.0006215649614985993 valid 8.102223546302412e-06\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.63461606916826e-08\n",
      "  batch 101 loss: 4.49664860028065e-06\n",
      "  batch 201 loss: 2.7645369567608213e-06\n",
      "LOSS train 3.3222493434388004e-06 valid 4.936761797580402e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.679117409978062e-08\n",
      "  batch 101 loss: 2.278752652955518e-06\n",
      "  batch 201 loss: 2.464521799083741e-06\n",
      "LOSS train 2.4530369704644817e-06 valid 4.408004770084517e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.046438789373497e-08\n",
      "  batch 101 loss: 2.3099836278106524e-06\n",
      "  batch 201 loss: 2.6871128892480554e-06\n",
      "LOSS train 2.3947539234133074e-06 valid 6.0760739870602265e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.798408776376163e-08\n",
      "  batch 101 loss: 2.782354357862005e-06\n",
      "  batch 201 loss: 2.6051472408994415e-06\n",
      "LOSS train 2.62941663009268e-06 valid 6.733414465998067e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.641382580914069e-08\n",
      "  batch 101 loss: 2.604884407304553e-06\n",
      "  batch 201 loss: 2.7660961281839036e-06\n",
      "LOSS train 2.770233550447323e-06 valid 4.582049314194592e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.193217020860175e-08\n",
      "  batch 101 loss: 2.8492739853902547e-06\n",
      "  batch 201 loss: 3.229641884558987e-06\n",
      "LOSS train 3.0148240785764434e-06 valid 8.801393960311543e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.3920624041929841e-07\n",
      "  batch 101 loss: 2.8304033288861776e-06\n",
      "  batch 201 loss: 2.5669941018691132e-06\n",
      "LOSS train 2.624479208700308e-06 valid 9.686560588306747e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.2229970707267058e-07\n",
      "  batch 101 loss: 3.0704442114881657e-06\n",
      "  batch 201 loss: 2.8617567792821317e-06\n",
      "LOSS train 2.8105405022065013e-06 valid 7.080774594214745e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 8.053392775764224e-08\n",
      "  batch 101 loss: 3.868885346776097e-06\n",
      "  batch 201 loss: 3.067768049760389e-06\n",
      "LOSS train 3.2762427824684893e-06 valid 5.883082849322818e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.951345312700142e-08\n",
      "  batch 101 loss: 4.099752043771332e-06\n",
      "  batch 201 loss: 3.22733927362151e-06\n",
      "LOSS train 3.5027369178697837e-06 valid 4.605406957125524e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.978496458032169e-08\n",
      "  batch 101 loss: 4.643822527370389e-06\n",
      "  batch 201 loss: 3.213534475889901e-06\n",
      "LOSS train 3.6268545687342144e-06 valid 4.884917416347889e-06\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.348992904648185e-06\n",
      "  batch 101 loss: 0.0006874599847651552\n",
      "  batch 201 loss: 6.625116212489956e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.00029450588875082454 valid 7.607421139255166e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.083812619792298e-07\n",
      "  batch 101 loss: 9.118060195362432e-05\n",
      "  batch 201 loss: 9.308055943165528e-05\n",
      "LOSS train 9.356172396820634e-05 valid 8.0974365118891e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0035392188001424e-06\n",
      "  batch 101 loss: 0.00010107728014645545\n",
      "  batch 201 loss: 0.00010456148990897418\n",
      "LOSS train 0.00010431631533756712 valid 8.618749416200444e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0967942216666415e-06\n",
      "  batch 101 loss: 0.00010811987261263311\n",
      "  batch 201 loss: 0.00010905496763882638\n",
      "LOSS train 0.000109764661709795 valid 8.848767902236432e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1368485138518735e-06\n",
      "  batch 101 loss: 0.00011132880602417572\n",
      "  batch 201 loss: 0.00011146970057893669\n",
      "LOSS train 0.00011244320722797443 valid 8.945740410126746e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1535787780303508e-06\n",
      "  batch 101 loss: 0.00011300179778942266\n",
      "  batch 201 loss: 0.00011275261204872322\n",
      "LOSS train 0.00011386103481888709 valid 8.99108563316986e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1613710375968367e-06\n",
      "  batch 101 loss: 0.00011393246787179123\n",
      "  batch 201 loss: 0.0001134778037450701\n",
      "LOSS train 0.00011465982954151653 valid 9.014354145620018e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1653621186269447e-06\n",
      "  batch 101 loss: 0.00011447696407230978\n",
      "  batch 201 loss: 0.00011390728303894094\n",
      "LOSS train 0.00011513170331145192 valid 9.027191117638722e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1675619316520169e-06\n",
      "  batch 101 loss: 0.00011480753579803604\n",
      "  batch 201 loss: 0.00011417041513965387\n",
      "LOSS train 0.00011542028178619631 valid 9.034667164087296e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.16884293674957e-06\n",
      "  batch 101 loss: 0.00011501380176412112\n",
      "  batch 201 loss: 0.00011433567164573333\n",
      "LOSS train 0.00011560129087135445 valid 9.039200813276693e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1696189176291228e-06\n",
      "  batch 101 loss: 0.00011514502487159462\n",
      "  batch 201 loss: 0.00011444133740639018\n",
      "LOSS train 0.00011571691947422603 valid 9.042028978001326e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1701026232913136e-06\n",
      "  batch 101 loss: 0.0001152297905866817\n",
      "  batch 201 loss: 0.00011450987627796394\n",
      "LOSS train 0.00011579185837124466 valid 9.043819591170177e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00045283868908882143\n",
      "  batch 101 loss: 0.0019855114530946596\n",
      "  batch 201 loss: 0.0003174081280303653\n",
      "LOSS train 0.0010636461249551815 valid 1.9189061276847497e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.6161458916030824e-06\n",
      "  batch 101 loss: 0.00014818334875599248\n",
      "  batch 201 loss: 7.823754891433055e-05\n",
      "LOSS train 9.464219238331043e-05 valid 1.5689436622778885e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1540306877577677e-06\n",
      "  batch 101 loss: 3.78112033877187e-05\n",
      "  batch 201 loss: 9.943590873717767e-06\n",
      "LOSS train 1.9445508403167456e-05 valid 6.445082362915855e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.091218968620524e-07\n",
      "  batch 101 loss: 7.234228014169731e-05\n",
      "  batch 201 loss: 9.671971298757853e-05\n",
      "LOSS train 8.943321131128692e-05 valid 8.27660333015956e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0361506429035216e-06\n",
      "  batch 101 loss: 0.00010369153584520063\n",
      "  batch 201 loss: 0.00010517059505332326\n",
      "LOSS train 0.00010561922714083139 valid 8.633859397377819e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.099442015402019e-06\n",
      "  batch 101 loss: 0.00010805151889769604\n",
      "  batch 201 loss: 0.00010871496603442665\n",
      "LOSS train 0.00010946873803194959 valid 8.820077346172184e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1318810720695182e-06\n",
      "  batch 101 loss: 0.00011075405867416065\n",
      "  batch 201 loss: 0.00011089527642411667\n",
      "LOSS train 0.00011184503714403135 valid 8.918120147427544e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1488227028166875e-06\n",
      "  batch 101 loss: 0.00011242935487018713\n",
      "  batch 201 loss: 0.00011224423004051687\n",
      "LOSS train 0.00011331779098613479 valid 8.971091301646084e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1579365673242137e-06\n",
      "  batch 101 loss: 0.0001134786231946805\n",
      "  batch 201 loss: 0.00011309010284733745\n",
      "LOSS train 0.00011424176647478908 valid 9.000820136861876e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1630406515905633e-06\n",
      "  batch 101 loss: 0.00011414461205674797\n",
      "  batch 201 loss: 0.00011362824779439506\n",
      "LOSS train 0.00011482956883514733 valid 9.018175478558987e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.166017391369678e-06\n",
      "  batch 101 loss: 0.00011457272417715103\n",
      "  batch 201 loss: 0.0001139749752965713\n",
      "LOSS train 0.0001152082224794599 valid 9.02867250260897e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1678152077365666e-06\n",
      "  batch 101 loss: 0.0001148508480343935\n",
      "  batch 201 loss: 0.00011420069571528302\n",
      "LOSS train 0.00011545467250331613 valid 9.035191760631278e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00031583376228809355\n",
      "  batch 101 loss: 0.002666334578534588\n",
      "  batch 201 loss: 0.0006644115815288387\n",
      "LOSS train 0.0014404380125174429 valid 6.886024493724108e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.4214790028054266e-06\n",
      "  batch 101 loss: 0.00019370762187463696\n",
      "  batch 201 loss: 8.706493899808265e-05\n",
      "LOSS train 0.00011382255644550088 valid 7.775844096613582e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.0731709557585416e-07\n",
      "  batch 101 loss: 1.7388366240993492e-05\n",
      "  batch 201 loss: 1.1957225347032363e-05\n",
      "LOSS train 1.4407157674203527e-05 valid 1.617385532881599e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.940836672380101e-08\n",
      "  batch 101 loss: 3.0091035308146276e-05\n",
      "  batch 201 loss: 9.612200798471804e-05\n",
      "LOSS train 7.396624687525162e-05 valid 8.395856275456026e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0587602446321398e-06\n",
      "  batch 101 loss: 9.098951363199603e-05\n",
      "  batch 201 loss: 0.00010738223609337183\n",
      "LOSS train 0.00010227829326478364 valid 8.737235475564376e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.117493593483232e-06\n",
      "  batch 101 loss: 0.0001095246714237419\n",
      "  batch 201 loss: 0.00010993490995190314\n",
      "LOSS train 0.00011079006779587311 valid 8.878045628080145e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.141908869612962e-06\n",
      "  batch 101 loss: 0.00011172568699464591\n",
      "  batch 201 loss: 0.00011169162913887476\n",
      "LOSS train 0.00011271081982919476 valid 8.950731717050076e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1544370499905198e-06\n",
      "  batch 101 loss: 0.00011306420003734274\n",
      "  batch 201 loss: 0.0001127625057914372\n",
      "LOSS train 0.00011388223162020575 valid 8.989908383227885e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.16116862045601e-06\n",
      "  batch 101 loss: 0.00011389385021288945\n",
      "  batch 201 loss: 0.00011342870580108411\n",
      "LOSS train 0.00011461080633258102 valid 9.01202583918348e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.164963177870959e-06\n",
      "  batch 101 loss: 0.00011441737931590979\n",
      "  batch 201 loss: 0.00011385068654334418\n",
      "LOSS train 0.00011507208176190184 valid 9.02506144484505e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1671963875414804e-06\n",
      "  batch 101 loss: 0.00011475280214710892\n",
      "  batch 201 loss: 0.00011412190674093382\n",
      "LOSS train 0.00011536842811231412 valid 9.032995149027556e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1685567733366042e-06\n",
      "  batch 101 loss: 0.0001149702762893412\n",
      "  batch 201 loss: 0.00011429822948088031\n",
      "LOSS train 0.00011556100928542437 valid 9.037971904035658e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.902073251083493e-05\n",
      "  batch 101 loss: 0.0008324600077867217\n",
      "  batch 201 loss: 7.225541367915867e-05\n",
      "LOSS train 0.0003659680944532165 valid 6.42099985270761e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.719281373079867e-07\n",
      "  batch 101 loss: 0.0002103067418761384\n",
      "  batch 201 loss: 8.750747345402487e-05\n",
      "LOSS train 0.00013366474219278827 valid 7.517095218645409e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.959089609561488e-07\n",
      "  batch 101 loss: 9.572478849577237e-05\n",
      "  batch 201 loss: 9.915166683299503e-05\n",
      "LOSS train 9.89987765488034e-05 valid 8.304027142003179e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0410618415335194e-06\n",
      "  batch 101 loss: 0.00010417589665735249\n",
      "  batch 201 loss: 0.00010583405184718231\n",
      "LOSS train 0.00010627257423925001 valid 8.685760258231312e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1085191363235935e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.0001088705878186147\n",
      "  batch 201 loss: 0.00010949152054081424\n",
      "LOSS train 0.0001102853706093051 valid 8.8617300207261e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1390902363928035e-06\n",
      "  batch 101 loss: 0.00011148268273274198\n",
      "  batch 201 loss: 0.00011153191354111413\n",
      "LOSS train 0.00011252732217549287 valid 8.945890294853598e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1536035890458152e-06\n",
      "  batch 101 loss: 0.0001129820609034482\n",
      "  batch 201 loss: 0.00011271225543779906\n",
      "LOSS train 0.00011382330083531725 valid 8.988765330286697e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.160973042715341e-06\n",
      "  batch 101 loss: 0.00011387311718777938\n",
      "  batch 201 loss: 0.00011341938021530495\n",
      "LOSS train 0.00011459872673867305 valid 9.01204111869447e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1649659427348525e-06\n",
      "  batch 101 loss: 0.00011441860875152087\n",
      "  batch 201 loss: 0.00011385523432608124\n",
      "LOSS train 0.00011507613118087048 valid 9.025375766213983e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1672509572235867e-06\n",
      "  batch 101 loss: 0.00011476051546708277\n",
      "  batch 201 loss: 0.00011412996061352487\n",
      "LOSS train 0.00011537674015357046 valid 9.033348760567605e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1686165089486166e-06\n",
      "  batch 101 loss: 0.00011497875144357294\n",
      "  batch 201 loss: 0.00011430603369859682\n",
      "LOSS train 0.00011556926984684445 valid 9.038262942340225e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1694587010424584e-06\n",
      "  batch 101 loss: 0.00011511990301244168\n",
      "  batch 201 loss: 0.00011442030184667829\n",
      "LOSS train 0.00011569413595836252 valid 9.041372686624527e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00029315821826457976\n",
      "  batch 101 loss: 0.00023831401843608547\n",
      "  batch 201 loss: 3.53084829225736e-05\n",
      "LOSS train 0.00021419810296835178 valid 3.771366027649492e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.028417151857866e-08\n",
      "  batch 101 loss: 1.5549435725006335e-05\n",
      "  batch 201 loss: 1.0293239460281712e-05\n",
      "LOSS train 1.1402398486418464e-05 valid 2.191438397858292e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.228138328064233e-07\n",
      "  batch 101 loss: 5.284876392011028e-06\n",
      "  batch 201 loss: 3.3151630144345744e-06\n",
      "LOSS train 3.849161193372457e-06 valid 6.024585218256107e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.959183444152587e-08\n",
      "  batch 101 loss: 2.335271449283027e-06\n",
      "  batch 201 loss: 2.4845213724233874e-06\n",
      "LOSS train 2.4034944240735466e-06 valid 8.385476576222572e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.5610554328304714e-07\n",
      "  batch 101 loss: 2.710050408296638e-06\n",
      "  batch 201 loss: 2.6425355957826467e-06\n",
      "LOSS train 2.6043065287115167e-06 valid 4.84392467114958e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.228749720728956e-08\n",
      "  batch 101 loss: 2.487848833254702e-06\n",
      "  batch 201 loss: 2.890091024312369e-06\n",
      "LOSS train 2.6545540925746118e-06 valid 5.0030612328555435e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.113742635236122e-08\n",
      "  batch 101 loss: 2.6051361268741857e-06\n",
      "  batch 201 loss: 2.6732047422228786e-06\n",
      "LOSS train 2.5071253015109102e-06 valid 3.2142588679562323e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.3088589336548465e-08\n",
      "  batch 101 loss: 2.5328040325689473e-06\n",
      "  batch 201 loss: 2.690327138736848e-06\n",
      "LOSS train 2.6015192312921908e-06 valid 3.2468728932144586e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.536680080491351e-08\n",
      "  batch 101 loss: 2.655193837739489e-06\n",
      "  batch 201 loss: 2.7220681685946602e-06\n",
      "LOSS train 2.518118724708321e-06 valid 3.196158786522574e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.489694108793628e-08\n",
      "  batch 101 loss: 2.9908959925961654e-06\n",
      "  batch 201 loss: 2.78644004950479e-06\n",
      "LOSS train 2.7938460696904153e-06 valid 3.5033781387028284e-06\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.7945974327158184e-08\n",
      "  batch 101 loss: 3.099516371065647e-06\n",
      "  batch 201 loss: 3.222714728678966e-06\n",
      "LOSS train 3.135809819653602e-06 valid 4.408865606819745e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.7359835662064145e-08\n",
      "  batch 101 loss: 3.924000692165919e-06\n",
      "  batch 201 loss: 3.5440133240172146e-06\n",
      "LOSS train 3.6196391977977486e-06 valid 4.86252065456938e-06\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.001375649720430374\n",
      "  batch 101 loss: 0.0065988217480480674\n",
      "  batch 201 loss: 0.0024022241943748666\n",
      "LOSS train 0.004246062382922641 valid 0.0002125597675330937\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.832725713029504e-05\n",
      "  batch 101 loss: 0.0011224712620605715\n",
      "  batch 201 loss: 0.0007632878265576437\n",
      "LOSS train 0.0008205597669175305 valid 0.0001211191774928011\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.288114189170301e-06\n",
      "  batch 101 loss: 0.0003637413580145221\n",
      "  batch 201 loss: 0.00023319796324358321\n",
      "LOSS train 0.00026517169673032906 valid 0.00014476636715698987\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5827265451662242e-06\n",
      "  batch 101 loss: 0.00013048436248936924\n",
      "  batch 201 loss: 8.651400618873594e-05\n",
      "LOSS train 9.899222885449643e-05 valid 0.00010748081695055589\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.565952258417383e-07\n",
      "  batch 101 loss: 8.351534441771946e-05\n",
      "  batch 201 loss: 0.00014328006900541368\n",
      "LOSS train 0.00012151378110009205 valid 7.184840796981007e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0285490134265275e-06\n",
      "  batch 101 loss: 0.00013886866692701006\n",
      "  batch 201 loss: 0.00013173195759236478\n",
      "LOSS train 0.0001351671163751561 valid 7.834368443582207e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.065988908521831e-06\n",
      "  batch 101 loss: 0.00013069978754856493\n",
      "  batch 201 loss: 0.00012713983210005608\n",
      "LOSS train 0.00012931133161619206 valid 8.26707182568498e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0346977069275453e-06\n",
      "  batch 101 loss: 0.00012255569363048835\n",
      "  batch 201 loss: 0.00010965189899593497\n",
      "LOSS train 0.00011511978665764248 valid 8.794648601906374e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1302214261377231e-06\n",
      "  batch 101 loss: 0.0001104642812288148\n",
      "  batch 201 loss: 0.00011005094405788896\n",
      "LOSS train 0.00011108627697718149 valid 8.862558024702594e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1335765884723513e-06\n",
      "  batch 101 loss: 0.00011110026883613955\n",
      "  batch 201 loss: 0.00011094873885753032\n",
      "LOSS train 0.00011196163385435307 valid 8.90719165909104e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1445190466474742e-06\n",
      "  batch 101 loss: 0.00011212461656981532\n",
      "  batch 201 loss: 0.00011178961881313398\n",
      "LOSS train 0.0001128651708104088 valid 8.941309351939708e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1526419257279485e-06\n",
      "  batch 101 loss: 0.00011286581767819826\n",
      "  batch 201 loss: 0.00011248411993207697\n",
      "LOSS train 0.00011361496488734826 valid 8.975920354714617e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0009841786324977875\n",
      "  batch 101 loss: 0.008737401347607374\n",
      "  batch 201 loss: 0.002633704647887498\n",
      "LOSS train 0.00477649437433327 valid 0.00010169632878387347\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.821955950930714e-06\n",
      "  batch 101 loss: 0.0003958665319078136\n",
      "  batch 201 loss: 0.00021135627357580234\n",
      "LOSS train 0.0002645795070731478 valid 3.7240512028802186e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.829510625218972e-07\n",
      "  batch 101 loss: 0.00013021970280533424\n",
      "  batch 201 loss: 0.00011071079661633121\n",
      "LOSS train 0.00010909981638478412 valid 6.288313306868076e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.907670467626304e-07\n",
      "  batch 101 loss: 8.24785742588574e-05\n",
      "  batch 201 loss: 8.126758326397976e-05\n",
      "LOSS train 8.185840512614892e-05 valid 6.825607852078974e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.067256956361234e-07\n",
      "  batch 101 loss: 8.388918956597991e-05\n",
      "  batch 201 loss: 8.615141494374257e-05\n",
      "LOSS train 8.582331026159392e-05 valid 7.356862624874339e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.904569793026894e-07\n",
      "  batch 101 loss: 9.017629445224884e-05\n",
      "  batch 201 loss: 9.266077151551144e-05\n",
      "LOSS train 9.214169555253072e-05 valid 7.938654016470537e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.471055818721652e-07\n",
      "  batch 101 loss: 9.433540710688249e-05\n",
      "  batch 201 loss: 9.350420076771115e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 9.549768105732119e-05 valid 7.910999556770548e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.147720993496478e-07\n",
      "  batch 101 loss: 9.706763338954261e-05\n",
      "  batch 201 loss: 9.752495525390259e-05\n",
      "LOSS train 9.781274824933625e-05 valid 7.953329622978345e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 9.04091793927364e-07\n",
      "  batch 101 loss: 0.0001000232299156778\n",
      "  batch 201 loss: 9.848196356642802e-05\n",
      "LOSS train 0.00010056836232008755 valid 8.382538362639025e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1732837447198109e-06\n",
      "  batch 101 loss: 0.00010459635089262065\n",
      "  batch 201 loss: 0.00010330925807750191\n",
      "LOSS train 0.0001051092897883098 valid 8.512990461895242e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.0652728815330192e-06\n",
      "  batch 101 loss: 0.00010525786057883124\n",
      "  batch 201 loss: 0.00010320116530692757\n",
      "LOSS train 0.00010470584070581593 valid 8.428803994320333e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.0369758820161224e-06\n",
      "  batch 101 loss: 0.00010574523349532683\n",
      "  batch 201 loss: 0.00010577686655778962\n",
      "LOSS train 0.00010558274959457309 valid 7.880652992753312e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00122312530875206\n",
      "  batch 101 loss: 0.01594394939020276\n",
      "  batch 201 loss: 0.005071015954017639\n",
      "LOSS train 0.008837140152902913 valid 7.724245369900018e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4544726582244039e-05\n",
      "  batch 101 loss: 0.0016033110587159172\n",
      "  batch 201 loss: 0.000913550230616238\n",
      "LOSS train 0.0010615166118061476 valid 5.469750612974167e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.948279434349388e-06\n",
      "  batch 101 loss: 0.0003586359988548793\n",
      "  batch 201 loss: 0.00021691137328161858\n",
      "LOSS train 0.0002570945523338539 valid 0.00010278733680024743\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.7948687309399248e-06\n",
      "  batch 101 loss: 0.00014950991755540598\n",
      "  batch 201 loss: 0.00013379239712776325\n",
      "LOSS train 0.00013221802522414794 valid 6.910101365065202e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.49237185320817e-07\n",
      "  batch 101 loss: 9.222625001712004e-05\n",
      "  batch 201 loss: 9.039646814017033e-05\n",
      "LOSS train 9.125067619453604e-05 valid 7.208867464214563e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.947941387305037e-07\n",
      "  batch 101 loss: 9.210991537202062e-05\n",
      "  batch 201 loss: 9.287161981319514e-05\n",
      "LOSS train 9.313032205682248e-05 valid 7.638855458935723e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.445064642932266e-07\n",
      "  batch 101 loss: 9.631031475691998e-05\n",
      "  batch 201 loss: 9.830235349113537e-05\n",
      "LOSS train 9.82247902061234e-05 valid 8.105901360977441e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0139571531908586e-06\n",
      "  batch 101 loss: 0.00010117678506730954\n",
      "  batch 201 loss: 0.0001022823483612001\n",
      "LOSS train 0.00010186204750178169 valid 8.177861309377477e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.019796764012426e-06\n",
      "  batch 101 loss: 0.0001021211929673882\n",
      "  batch 201 loss: 0.00010337559148808851\n",
      "LOSS train 0.00010375500665287081 valid 8.484831778332591e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0733831732068211e-06\n",
      "  batch 101 loss: 0.00010581392910012255\n",
      "  batch 201 loss: 0.00010654968274195653\n",
      "LOSS train 0.0001071970756979248 valid 8.690023241797462e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1092906061094254e-06\n",
      "  batch 101 loss: 0.00010865311234880436\n",
      "  batch 201 loss: 0.00010901964441927702\n",
      "LOSS train 0.00010984424391093496 valid 8.825772238196805e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1328686377964914e-06\n",
      "  batch 101 loss: 0.00011075513845327123\n",
      "  batch 201 loss: 0.00011080438544809112\n",
      "LOSS train 0.00011176875858619903 valid 8.91047457116656e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00029199302196502685\n",
      "  batch 101 loss: 0.006684838366927579\n",
      "  batch 201 loss: 0.0004506890874472447\n",
      "LOSS train 0.0027554301538387604 valid 7.379760791081935e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.322068606503308e-07\n",
      "  batch 101 loss: 8.961604438809445e-05\n",
      "  batch 201 loss: 7.350735090767557e-05\n",
      "LOSS train 7.885172665707644e-05 valid 5.9244586736895144e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.543302904698066e-07\n",
      "  batch 101 loss: 7.539798329162295e-05\n",
      "  batch 201 loss: 7.869624583236146e-05\n",
      "LOSS train 7.793687117531916e-05 valid 6.581911293324083e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.07186627550982e-07\n",
      "  batch 101 loss: 8.411547147943566e-05\n",
      "  batch 201 loss: 8.717859622493052e-05\n",
      "LOSS train 8.67007132637476e-05 valid 7.279036071849987e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.499262185068801e-07\n",
      "  batch 101 loss: 9.216643515628675e-05\n",
      "  batch 201 loss: 9.471409762909388e-05\n",
      "LOSS train 9.457373187452061e-05 valid 7.887942774686962e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.654770838096738e-07\n",
      "  batch 101 loss: 9.893569079395093e-05\n",
      "  batch 201 loss: 0.00010078898804977143\n",
      "LOSS train 0.00010099680318053421 valid 8.335803431691602e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0467418178450317e-06\n",
      "  batch 101 loss: 0.0001041243665406455\n",
      "  batch 201 loss: 0.00010528237624498615\n",
      "LOSS train 0.00010579808622653064 valid 8.625505142845213e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.097977947210893e-06\n",
      "  batch 101 loss: 0.00010783015317826994\n",
      "  batch 201 loss: 0.0001084112944579374\n",
      "LOSS train 0.00010916798870243754 valid 8.798905764706433e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1282107152510435e-06\n",
      "  batch 101 loss: 0.00011036307636459241\n",
      "  batch 201 loss: 0.00011051647921192398\n",
      "LOSS train 0.00011144718371457242 valid 8.899297972675413e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1455771164037288e-06\n",
      "  batch 101 loss: 0.00011205589974736086\n",
      "  batch 201 loss: 0.00011191094166790094\n",
      "LOSS train 0.00011296171946202531 valid 8.957297541201115e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1555661330930888e-06\n",
      "  batch 101 loss: 0.00011317728259882642\n",
      "  batch 201 loss: 0.00011283046148818698\n",
      "LOSS train 0.00011396219248024075 valid 8.991330832941458e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1614136019488797e-06\n",
      "  batch 101 loss: 0.00011391884520435269\n",
      "  batch 201 loss: 0.00011343720688074655\n",
      "LOSS train 0.00011462301775803752 valid 9.011787915369496e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.671943373978138e-05\n",
      "  batch 101 loss: 0.0007140790770705507\n",
      "  batch 201 loss: 3.430034957034422e-05\n",
      "LOSS train 0.00029690666243924825 valid 3.546965308487415e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.4552374422200957e-08\n",
      "  batch 101 loss: 1.8642990602302235e-05\n",
      "  batch 201 loss: 1.1978033748505368e-05\n",
      "LOSS train 1.3372952548477922e-05 valid 1.5830017218831927e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0602589100017212e-07\n",
      "  batch 101 loss: 4.034054027926004e-06\n",
      "  batch 201 loss: 1.8621132070961722e-06\n",
      "LOSS train 2.6443558976674192e-06 valid 2.6715517833508784e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.33063178206794e-08\n",
      "  batch 101 loss: 1.750166472049841e-06\n",
      "  batch 201 loss: 1.5402104429540486e-06\n",
      "LOSS train 1.5963338613273962e-06 valid 1.993189925997285e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.864646603484289e-08\n",
      "  batch 101 loss: 1.5910328805546214e-06\n",
      "  batch 201 loss: 1.5144113611142985e-06\n",
      "LOSS train 1.5738939997443315e-06 valid 1.7023774034896633e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.307450813532341e-08\n",
      "  batch 101 loss: 1.4091651750902655e-06\n",
      "  batch 201 loss: 1.2916475195368094e-06\n",
      "LOSS train 1.2813187676068418e-06 valid 1.144404791375564e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.408637424712651e-09\n",
      "  batch 101 loss: 1.3214948133821735e-06\n",
      "  batch 201 loss: 1.1984428675759773e-06\n",
      "LOSS train 1.179373262219782e-06 valid 1.0124784921572427e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.9474766683488265e-09\n",
      "  batch 101 loss: 1.0557376899100746e-06\n",
      "  batch 201 loss: 9.649158360502953e-07\n",
      "LOSS train 1.057642275785948e-06 valid 1.1831542678919504e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 8.94339791557286e-09\n",
      "  batch 101 loss: 1.45712632189543e-06\n",
      "  batch 201 loss: 1.6888398054959453e-06\n",
      "LOSS train 5.643100840135821e-06 valid 2.366882199567044e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0782341632875613e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 3.603670191409947e-06\n",
      "  batch 201 loss: 1.544050621760107e-06\n",
      "LOSS train 2.207694272180141e-06 valid 9.526318081043428e-07\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.038405556158978e-09\n",
      "  batch 101 loss: 1.043656090331524e-06\n",
      "  batch 201 loss: 8.676659235362649e-07\n",
      "LOSS train 1.0769977198938183e-06 valid 1.3416845376923447e-06\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.157631004389259e-08\n",
      "  batch 101 loss: 1.2951783113379633e-06\n",
      "  batch 201 loss: 7.880601819465483e-07\n",
      "LOSS train 1.2560453282232144e-06 valid 1.4666892411696608e-06\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004083611816167831\n",
      "  batch 101 loss: 0.0014609766664216296\n",
      "  batch 201 loss: 0.0003930902988940943\n",
      "LOSS train 0.0009018237925997693 valid 0.00014380407810676843\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.106425672536716e-06\n",
      "  batch 101 loss: 0.0002021317614708096\n",
      "  batch 201 loss: 0.00012580150625581153\n",
      "LOSS train 0.00014302729761813028 valid 1.2006735232716892e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.083000385435298e-07\n",
      "  batch 101 loss: 6.238688058147091e-05\n",
      "  batch 201 loss: 5.846161095178104e-05\n",
      "LOSS train 5.979605094037588e-05 valid 0.00012323970440775156\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.067711077164859e-07\n",
      "  batch 101 loss: 6.843744669822627e-05\n",
      "  batch 201 loss: 5.83209572960186e-05\n",
      "LOSS train 6.850939268085209e-05 valid 0.00014353690494317561\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.9887905839132145e-07\n",
      "  batch 101 loss: 8.913853373542225e-05\n",
      "  batch 201 loss: 0.00010818457141112959\n",
      "LOSS train 0.0001040059825609805 valid 7.087011181283742e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.663444896228611e-07\n",
      "  batch 101 loss: 0.00012789385432142807\n",
      "  batch 201 loss: 0.00012471238482021364\n",
      "LOSS train 0.00012677084924812818 valid 8.66693226271309e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1524873116286471e-06\n",
      "  batch 101 loss: 0.0001235270597436511\n",
      "  batch 201 loss: 0.00012098112240096271\n",
      "LOSS train 0.00012293394075452055 valid 9.026013140100986e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1881258978974074e-06\n",
      "  batch 101 loss: 0.00012033428083384479\n",
      "  batch 201 loss: 0.00011821526046446707\n",
      "LOSS train 0.00011987730785835909 valid 9.01048188097775e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.172471820609644e-06\n",
      "  batch 101 loss: 0.00011694736277945595\n",
      "  batch 201 loss: 0.00011536613847511035\n",
      "LOSS train 0.00011682550818674024 valid 8.901186083676293e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1654967966023833e-06\n",
      "  batch 101 loss: 0.00011522770772444346\n",
      "  batch 201 loss: 0.00011347558601414676\n",
      "LOSS train 0.00011512487401411914 valid 8.799580245977268e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1553870717762038e-06\n",
      "  batch 101 loss: 0.0001135214373476856\n",
      "  batch 201 loss: 0.00011109603555155445\n",
      "LOSS train 0.00011412745656703559 valid 9.063826291821897e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1694788554450498e-06\n",
      "  batch 101 loss: 0.00011570939863929653\n",
      "  batch 201 loss: 0.00011491076945958411\n",
      "LOSS train 0.00011622077190252177 valid 9.053153189597651e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.82514763623476e-05\n",
      "  batch 101 loss: 9.073031528373576e-05\n",
      "  batch 201 loss: 0.000116226016540395\n",
      "LOSS train 0.00012187446163648935 valid 9.147238597506657e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1674877168843523e-06\n",
      "  batch 101 loss: 0.00011655888415532445\n",
      "  batch 201 loss: 0.00011549019627523194\n",
      "LOSS train 0.00011684668159527424 valid 9.078026778297499e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1762591748265549e-06\n",
      "  batch 101 loss: 0.00011580536781139017\n",
      "  batch 201 loss: 0.00011490347976916837\n",
      "LOSS train 0.000116257939048568 valid 9.059177682502195e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.173037016997114e-06\n",
      "  batch 101 loss: 0.00011559367503423346\n",
      "  batch 201 loss: 0.00011479730748220618\n",
      "LOSS train 0.00011610384972010958 valid 9.053661051439121e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.172094125649892e-06\n",
      "  batch 101 loss: 0.00011549119819676435\n",
      "  batch 201 loss: 0.00011472895291490203\n",
      "LOSS train 0.00011600961696916577 valid 9.050601511262357e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.171569965663366e-06\n",
      "  batch 101 loss: 0.00011543213666413976\n",
      "  batch 201 loss: 0.00011471215381021693\n",
      "LOSS train 0.00011599022410212543 valid 9.049750951817259e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1714240827132016e-06\n",
      "  batch 101 loss: 0.0001154356019350189\n",
      "  batch 201 loss: 0.00011467846121945513\n",
      "LOSS train 0.00011597462489739732 valid 9.048902575159445e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.171279072877951e-06\n",
      "  batch 101 loss: 0.00011540877611764699\n",
      "  batch 201 loss: 0.00011466384032956967\n",
      "LOSS train 0.0001159513961556638 valid 9.048140054801479e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1711484694387765e-06\n",
      "  batch 101 loss: 0.00011540775250921342\n",
      "  batch 201 loss: 0.00011466275658477798\n",
      "LOSS train 0.00011595676405669183 valid 9.048008359968662e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1711262050084769e-06\n",
      "  batch 101 loss: 0.00011540435283279748\n",
      "  batch 201 loss: 0.00011465191526866648\n",
      "LOSS train 0.0001159468380711752 valid 9.04777116375044e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.171085168607533e-06\n",
      "  batch 101 loss: 0.00010590551796155977\n",
      "  batch 201 loss: 9.243835548488732e-05\n",
      "LOSS train 0.00010478013268141864 valid 9.086047793971375e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1776288010878489e-06\n",
      "  batch 101 loss: 0.0001167118142785739\n",
      "  batch 201 loss: 0.00011571082394596033\n",
      "LOSS train 0.00011710672626807307 valid 9.072437387658283e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.309637032449246e-05\n",
      "  batch 101 loss: 0.0004350103365504765\n",
      "  batch 201 loss: 8.970314017460623e-05\n",
      "LOSS train 0.00024265339431085755 valid 7.72643179516308e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.910719770938158e-07\n",
      "  batch 101 loss: 0.00011500944225986131\n",
      "  batch 201 loss: 0.00011393774826245817\n",
      "LOSS train 0.00011521474236338447 valid 9.02222964214161e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1490040924400092e-06\n",
      "  batch 101 loss: 0.00011466035987780288\n",
      "  batch 201 loss: 0.00011423149640961583\n",
      "LOSS train 0.00011538430438363004 valid 9.093677363125607e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1786576214944944e-06\n",
      "  batch 101 loss: 0.00011510113525105226\n",
      "  batch 201 loss: 0.0001147789837668256\n",
      "LOSS train 0.00011594186315577005 valid 9.109030361287296e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.178970342152752e-06\n",
      "  batch 101 loss: 0.00011518889552974088\n",
      "  batch 201 loss: 0.00011437455286397835\n",
      "LOSS train 0.00011577346426139685 valid 9.045171464094892e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2026111653540283e-06\n",
      "  batch 101 loss: 0.00011557334103656558\n",
      "  batch 201 loss: 0.00011459488630265469\n",
      "LOSS train 0.0001160746960096569 valid 9.061824675882235e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.181933912448585e-06\n",
      "  batch 101 loss: 0.00011555970440269902\n",
      "  batch 201 loss: 0.00011451229066722135\n",
      "LOSS train 0.00011578653305416196 valid 9.00153027032502e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.158315862994641e-06\n",
      "  batch 101 loss: 0.00011549698371311478\n",
      "  batch 201 loss: 0.00011468555935863378\n",
      "LOSS train 0.00011607021208542459 valid 9.047694766195491e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1726998491212727e-06\n",
      "  batch 101 loss: 0.00011540897023564866\n",
      "  batch 201 loss: 0.0001145320558862295\n",
      "LOSS train 0.00011588544648512842 valid 9.058382420334965e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.17281248094514e-06\n",
      "  batch 101 loss: 0.0001152676648069928\n",
      "  batch 201 loss: 0.00011471393728044177\n",
      "LOSS train 0.00011587147172372336 valid 9.059346484718844e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1736660962924361e-06\n",
      "  batch 101 loss: 0.00011553980133726328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.00011479171795002686\n",
      "LOSS train 0.00011512257543522903 valid 8.980194252217188e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1553828517207875e-06\n",
      "  batch 101 loss: 0.00011555045420834631\n",
      "  batch 201 loss: 0.0001148030294768887\n",
      "LOSS train 0.00011600149568286704 valid 9.029664943227544e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006940187513828277\n",
      "  batch 101 loss: 0.004952141008106992\n",
      "  batch 201 loss: 0.0006752526835771277\n",
      "LOSS train 0.002387221591421761 valid 5.1145303586963564e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4608202036470175e-06\n",
      "  batch 101 loss: 0.00018254271111800335\n",
      "  batch 201 loss: 0.00012311208232858916\n",
      "LOSS train 0.00014085785944402626 valid 6.853372178738937e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.901363278506323e-07\n",
      "  batch 101 loss: 9.681850952347304e-05\n",
      "  batch 201 loss: 9.174072020414315e-05\n",
      "LOSS train 9.341403873581456e-05 valid 7.08464503986761e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.651762618683278e-07\n",
      "  batch 101 loss: 9.116581250964373e-05\n",
      "  batch 201 loss: 9.174378006719052e-05\n",
      "LOSS train 9.209985352251247e-05 valid 7.307362102437764e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.021276491694152e-07\n",
      "  batch 101 loss: 9.476786035975238e-05\n",
      "  batch 201 loss: 9.685906326353688e-05\n",
      "LOSS train 9.677152102027228e-05 valid 8.129033813020214e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.025639066938311e-06\n",
      "  batch 101 loss: 0.00010084353056527106\n",
      "  batch 201 loss: 0.00010059425449242099\n",
      "LOSS train 0.00010155704770812295 valid 8.234370034188032e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0724065214162692e-06\n",
      "  batch 101 loss: 0.00010396297848046743\n",
      "  batch 201 loss: 0.00010270459863136239\n",
      "LOSS train 0.0001037914633413423 valid 7.931634172564372e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0515115718590095e-06\n",
      "  batch 101 loss: 0.00010259931068645756\n",
      "  batch 201 loss: 9.958229720353984e-05\n",
      "LOSS train 0.00010215152726828526 valid 7.67950841691345e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.0300671419827268e-06\n",
      "  batch 101 loss: 9.784299224065763e-05\n",
      "  batch 201 loss: 0.00010044484728183534\n",
      "LOSS train 0.00010013333947240725 valid 8.631089440314099e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0986815323121847e-06\n",
      "  batch 101 loss: 0.00010466168135565113\n",
      "  batch 201 loss: 9.976039799596493e-05\n",
      "LOSS train 0.0001016951160759646 valid 7.888842083048075e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.0435935109853744e-06\n",
      "  batch 101 loss: 9.576048511405588e-05\n",
      "  batch 201 loss: 8.978571091290632e-05\n",
      "LOSS train 9.810896907459213e-05 valid 8.909859752748162e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.155766804004088e-06\n",
      "  batch 101 loss: 0.00011768545267841546\n",
      "  batch 201 loss: 0.00011636846182284443\n",
      "LOSS train 0.00011788071455821276 valid 9.050361404661089e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001513074245303869\n",
      "  batch 101 loss: 0.11429335295968485\n",
      "  batch 201 loss: 9.629944190692186e-05\n",
      "LOSS train 0.04198563808073138 valid 0.0002319240156793967\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.5264924149960279e-06\n",
      "  batch 101 loss: 8.725434585358017e-05\n",
      "  batch 201 loss: 9.614024639745367e-05\n",
      "LOSS train 8.616000893103414e-05 valid 0.00045657678856514394\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0823656339198351e-07\n",
      "  batch 101 loss: 0.0001410121967592204\n",
      "  batch 201 loss: 7.563123248246483e-05\n",
      "LOSS train 9.714219385846713e-05 valid 0.0002301293279742822\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.582368172938004e-07\n",
      "  batch 101 loss: 0.0001428089770661245\n",
      "  batch 201 loss: 9.9959901880311e-05\n",
      "LOSS train 0.00011514754680774786 valid 0.0002526641183067113\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.213595720008016e-07\n",
      "  batch 101 loss: 0.0001817517406539082\n",
      "  batch 201 loss: 9.787476510382476e-05\n",
      "LOSS train 0.00013704713630628354 valid 0.00020781195780728012\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2251092994119971e-06\n",
      "  batch 101 loss: 0.0003089095646544138\n",
      "  batch 201 loss: 0.00014280891110558967\n",
      "LOSS train 0.00024822061830024055 valid 0.000173209176864475\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.562482211738825e-06\n",
      "  batch 101 loss: 0.0010596101789883505\n",
      "  batch 201 loss: 0.0035186083381267964\n",
      "LOSS train 0.0021794560960166735 valid 0.00016487175889778882\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.3775233421474696e-06\n",
      "  batch 101 loss: 0.001690190107383387\n",
      "  batch 201 loss: 0.002649060446565272\n",
      "LOSS train 0.0028158493854782748 valid 0.0005142364534549415\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.206394052947871e-07\n",
      "  batch 101 loss: 0.0004378190177885699\n",
      "  batch 201 loss: 0.002022652136884062\n",
      "LOSS train 0.002815498831139702 valid 0.0013674511574208736\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0728660272434354e-05\n",
      "  batch 101 loss: 0.0008323473415475746\n",
      "  batch 201 loss: 0.0017701661339197016\n",
      "LOSS train 0.0017998074367274607 valid 0.0009314077324233949\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.2836204152554275e-06\n",
      "  batch 101 loss: 0.004186748611464282\n",
      "  batch 201 loss: 0.0010776719288696768\n",
      "LOSS train 0.0025349280440922894 valid 0.00047459499910473824\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.9345248583704235e-05\n",
      "  batch 101 loss: 0.004976888598830556\n",
      "  batch 201 loss: 0.0011278958078946744\n",
      "LOSS train 0.0030785367480531444 valid 0.0006742461700923741\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0010996484756469727\n",
      "  batch 101 loss: 0.08920414714491925\n",
      "  batch 201 loss: 0.001930457941489294\n",
      "LOSS train 0.034178950638346535 valid 0.000423078570747748\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3165429700165986e-05\n",
      "  batch 101 loss: 0.0008859874997870066\n",
      "  batch 201 loss: 0.000433969469886506\n",
      "LOSS train 0.0005658077700637134 valid 0.00017517752712592483\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.0578211115207525e-06\n",
      "  batch 101 loss: 0.00021388184308307245\n",
      "  batch 201 loss: 7.832176606825669e-05\n",
      "LOSS train 0.00012192924728319318 valid 4.8226225771941245e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.840750524541364e-07\n",
      "  batch 101 loss: 3.0164395047904692e-05\n",
      "  batch 201 loss: 1.971753465340953e-05\n",
      "LOSS train 2.848540508895541e-05 valid 0.00011574129166547209\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.2880486610811204e-06\n",
      "  batch 101 loss: 2.550704664145087e-05\n",
      "  batch 201 loss: 2.9885489188927748e-05\n",
      "LOSS train 2.885571171602697e-05 valid 2.7189040338271298e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.201161623816006e-07\n",
      "  batch 101 loss: 4.547107245798543e-05\n",
      "  batch 201 loss: 0.002564171081464792\n",
      "LOSS train 0.0015836467277608375 valid 0.0013789235381409526\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.5562898311764e-06\n",
      "  batch 101 loss: 0.002291274451526988\n",
      "  batch 201 loss: 0.0025645194231401548\n",
      "LOSS train 0.0034383675254756225 valid 0.007989083416759968\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.813001491129398e-05\n",
      "  batch 101 loss: 0.0007742123578645988\n",
      "  batch 201 loss: 0.0006094651971216081\n",
      "LOSS train 0.0051726137653298416 valid 0.001073199906386435\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.5659820530563592e-05\n",
      "  batch 101 loss: 0.001477054358474561\n",
      "  batch 201 loss: 0.00030495608230921787\n",
      "LOSS train 0.0006935496649320767 valid 2.9056538551230915e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 9.31723989197053e-07\n",
      "  batch 101 loss: 0.0002098943610462811\n",
      "  batch 201 loss: 0.0026098456427098428\n",
      "LOSS train 0.0014574307746419762 valid 0.0003170671116095036\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.283439680468291e-06\n",
      "  batch 101 loss: 0.004755447851493955\n",
      "  batch 201 loss: 0.00037814568011526714\n",
      "LOSS train 0.003517445133530557 valid 0.0001711561344563961\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.4083428434096276e-06\n",
      "  batch 101 loss: 0.0013936327631017776\n",
      "  batch 201 loss: 0.002556398370797979\n",
      "LOSS train 0.0020916460092942147 valid 0.00019699407857842743\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006025906279683113\n",
      "  batch 101 loss: 0.09904406587593258\n",
      "  batch 201 loss: 0.0025538705359213053\n",
      "LOSS train 0.03778199420115252 valid 0.00025732003268785775\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1312965070828796e-05\n",
      "  batch 101 loss: 0.0005582569894613699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.0001641921765258303\n",
      "LOSS train 0.0002872589309032471 valid 1.2608229553734418e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.059956193785183e-06\n",
      "  batch 101 loss: 6.837968558102148e-05\n",
      "  batch 201 loss: 1.7365543790219818e-05\n",
      "LOSS train 3.70675466218104e-05 valid 2.0204755855957046e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.285057315835729e-07\n",
      "  batch 101 loss: 2.0508279112618767e-05\n",
      "  batch 201 loss: 1.1949356837703817e-05\n",
      "LOSS train 1.6248227668936354e-05 valid 7.924699275463354e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.33636682323413e-08\n",
      "  batch 101 loss: 2.8242251946721808e-05\n",
      "  batch 201 loss: 2.588942372312886e-05\n",
      "LOSS train 2.8631279117409857e-05 valid 6.045687314326642e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.6676995073794387e-07\n",
      "  batch 101 loss: 6.240863221592008e-05\n",
      "  batch 201 loss: 0.0006917945806162606\n",
      "LOSS train 0.0026346005723168605 valid 0.0029878150671720505\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.997991792857647e-05\n",
      "  batch 101 loss: 0.001663526270276634\n",
      "  batch 201 loss: 0.00021245552045002114\n",
      "LOSS train 0.0010106548779698068 valid 0.002369337948039174\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.663834650069475e-05\n",
      "  batch 101 loss: 0.004525095653661992\n",
      "  batch 201 loss: 0.0013056980584951817\n",
      "LOSS train 0.002545844025194245 valid 0.0008047986775636673\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 8.147159824147821e-06\n",
      "  batch 101 loss: 0.003302565753692761\n",
      "  batch 201 loss: 0.0016333519046747825\n",
      "LOSS train 0.0033864442632012726 valid 0.007920168340206146\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.5326777510344985e-05\n",
      "  batch 101 loss: 0.0029878224159620003\n",
      "  batch 201 loss: 0.0008939165266201598\n",
      "LOSS train 0.0029737266516319354 valid 0.002829230623319745\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.7821329422295093e-05\n",
      "  batch 101 loss: 0.0008979722532239976\n",
      "  batch 201 loss: 0.0013875782812283433\n",
      "LOSS train 0.002463486464093143 valid 0.0001501845836173743\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.517553024925292e-06\n",
      "  batch 101 loss: 0.002591299471059756\n",
      "  batch 201 loss: 0.0009201965268948697\n",
      "LOSS train 0.0024086303670335526 valid 0.00017220179142896086\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003491087630391121\n",
      "  batch 101 loss: 0.11404245221056045\n",
      "  batch 201 loss: 0.002513863800559193\n",
      "LOSS train 0.04298483302739778 valid 9.636773029342294e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.34688253235072e-06\n",
      "  batch 101 loss: 0.00019781946710281773\n",
      "  batch 201 loss: 3.1094276428120795e-05\n",
      "LOSS train 9.312305049509935e-05 valid 4.054314558743499e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3297457189764826e-06\n",
      "  batch 101 loss: 3.136306137321299e-05\n",
      "  batch 201 loss: 2.1213584475390234e-05\n",
      "LOSS train 2.4998789100016026e-05 valid 1.4601575458073057e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.582503141951747e-08\n",
      "  batch 101 loss: 1.446125878374005e-05\n",
      "  batch 201 loss: 1.691494411261374e-05\n",
      "LOSS train 1.585014275579375e-05 valid 2.137425690307282e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.561894330545329e-08\n",
      "  batch 101 loss: 5.746265721882082e-05\n",
      "  batch 201 loss: 2.367545095694368e-05\n",
      "LOSS train 4.319522889294097e-05 valid 5.746117494709324e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.17109139461536e-08\n",
      "  batch 101 loss: 5.465677360007248e-05\n",
      "  batch 201 loss: 9.197538733133115e-05\n",
      "LOSS train 9.121974145962888e-05 valid 2.3504144337493926e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.0939768950920554e-07\n",
      "  batch 101 loss: 0.002628994771903308\n",
      "  batch 201 loss: 0.001245260175128351\n",
      "LOSS train 0.005634372774500249 valid 0.0003939966845791787\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.466857036575675e-05\n",
      "  batch 101 loss: 0.0008239742404475692\n",
      "  batch 201 loss: 0.0001965369969730091\n",
      "LOSS train 0.0004028015748103609 valid 4.822139089810662e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.557762779062614e-07\n",
      "  batch 101 loss: 0.0020789097343640608\n",
      "  batch 201 loss: 0.002302140646497719\n",
      "LOSS train 0.004017806940955712 valid 0.000613297161180526\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.385735347867012e-05\n",
      "  batch 101 loss: 0.00124351624501287\n",
      "  batch 201 loss: 0.0004074420215329155\n",
      "LOSS train 0.0023491097666846522 valid 0.004546178504824638\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.85194132104516e-05\n",
      "  batch 101 loss: 0.0025182518435758537\n",
      "  batch 201 loss: 0.0005108313723758329\n",
      "LOSS train 0.0024330834392578132 valid 0.00019782852905336767\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.469610819593072e-06\n",
      "  batch 101 loss: 0.0031705267335928513\n",
      "  batch 201 loss: 0.0029266781633486972\n",
      "LOSS train 0.0026013213082145465 valid 5.067830716143362e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00028319038450717925\n",
      "  batch 101 loss: 0.1417655686545186\n",
      "  batch 201 loss: 0.0011258878029184417\n",
      "LOSS train 0.052466361056662005 valid 5.839993536937982e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.652708837762475e-06\n",
      "  batch 101 loss: 8.031122705688176e-05\n",
      "  batch 201 loss: 2.2330251058519936e-05\n",
      "LOSS train 4.6009494058242315e-05 valid 2.4267186745419167e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.27196857042145e-08\n",
      "  batch 101 loss: 2.5636114196458946e-05\n",
      "  batch 201 loss: 3.433528300774924e-05\n",
      "LOSS train 3.431118749999552e-05 valid 2.5068860850296915e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.7142783690360374e-07\n",
      "  batch 101 loss: 3.164595122598257e-05\n",
      "  batch 201 loss: 3.724974279066373e-05\n",
      "LOSS train 3.714243667596521e-05 valid 5.6077766203088686e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.7159478375106118e-07\n",
      "  batch 101 loss: 3.75623422451099e-05\n",
      "  batch 201 loss: 5.648814116284484e-05\n",
      "LOSS train 5.200785023053192e-05 valid 4.8557139962213114e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.6568934370297937e-07\n",
      "  batch 101 loss: 0.00015530357684838238\n",
      "  batch 201 loss: 0.00024543291045119986\n",
      "LOSS train 0.0002657581018213069 valid 1.6537938790861517e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.4340330380946398e-06\n",
      "  batch 101 loss: 0.0010816848312242655\n",
      "  batch 201 loss: 0.0007023749159998261\n",
      "LOSS train 0.0019387281384933553 valid 0.00025217345682904124\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.9980883225798608e-05\n",
      "  batch 101 loss: 0.006922538509825244\n",
      "  batch 201 loss: 0.0024892783268296624\n",
      "LOSS train 0.0035131367229894505 valid 9.66326188063249e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 8.754243026487529e-07\n",
      "  batch 101 loss: 0.0034695796152846015\n",
      "  batch 201 loss: 0.0030805877028615212\n",
      "LOSS train 0.0031352170390830545 valid 0.0008895214414224029\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.75925821531564e-05\n",
      "  batch 101 loss: 0.002582005599979311\n",
      "  batch 201 loss: 0.0077547902829246595\n",
      "LOSS train 0.004941960177537831 valid 0.0003338170936331153\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.5695511829108e-05\n",
      "  batch 101 loss: 0.0010472996503085596\n",
      "  batch 201 loss: 0.0014626333962951322\n",
      "LOSS train 0.0026549203144635874 valid 0.004974727518856525\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.0887311808764934e-05\n",
      "  batch 101 loss: 0.008006134741590358\n",
      "  batch 201 loss: 0.0017154393736564088\n",
      "LOSS train 0.0037572207778720818 valid 0.00022548623383045197\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00014633474871516227\n",
      "  batch 101 loss: 0.026016918511154473\n",
      "  batch 201 loss: 0.0005798182416901909\n",
      "LOSS train 0.00981338083294672 valid 5.649748709402047e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.801134127774276e-07\n",
      "  batch 101 loss: 7.191232755303645e-05\n",
      "  batch 201 loss: 7.714920865055319e-05\n",
      "LOSS train 7.618827629356173e-05 valid 6.687542190775275e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.297736738109961e-07\n",
      "  batch 101 loss: 8.6828701421382e-05\n",
      "  batch 201 loss: 9.26440689431729e-05\n",
      "LOSS train 9.216213806088917e-05 valid 8.078954851953313e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0004692012444139e-06\n",
      "  batch 101 loss: 0.00010373322424698017\n",
      "  batch 201 loss: 0.00010927366408111538\n",
      "LOSS train 0.00010949848822225923 valid 8.969313057605177e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.157631486421451e-06\n",
      "  batch 101 loss: 0.00011975436777788672\n",
      "  batch 201 loss: 0.00012255306972178915\n",
      "LOSS train 0.00012354657528124838 valid 7.995963096618652e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.85329897957854e-07\n",
      "  batch 101 loss: 0.00012783666949417238\n",
      "  batch 201 loss: 0.00012518177811557507\n",
      "LOSS train 0.00012666000999417566 valid 5.772625809186138e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.14467028551735e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00012201778159692366\n",
      "  batch 201 loss: 0.00011438778475167055\n",
      "LOSS train 0.00011590195358097005 valid 5.210454037296586e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.2533730114228093e-07\n",
      "  batch 101 loss: 0.0001053786260445122\n",
      "  batch 201 loss: 9.646073979865832e-05\n",
      "LOSS train 9.759290702150616e-05 valid 7.020466728135943e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1731995073205326e-08\n",
      "  batch 101 loss: 8.681092887741215e-05\n",
      "  batch 201 loss: 7.9576249549973e-05\n",
      "LOSS train 8.01327331042964e-05 valid 9.62938938755542e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 6.288506483542733e-08\n",
      "  batch 101 loss: 7.220244026029832e-05\n",
      "  batch 201 loss: 6.745025922555214e-05\n",
      "LOSS train 6.748431652813585e-05 valid 0.0001201373670483008\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.5960984455887229e-07\n",
      "  batch 101 loss: 6.2872843373043e-05\n",
      "  batch 201 loss: 6.032004665257773e-05\n",
      "LOSS train 5.9961333523300866e-05 valid 0.0001411088596796617\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.6398876798339186e-07\n",
      "  batch 101 loss: 5.818950363732256e-05\n",
      "  batch 201 loss: 5.741173732360494e-05\n",
      "LOSS train 5.6756495695566086e-05 valid 0.00016229152970481664\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00022839592769742013\n",
      "  batch 101 loss: 0.03254502173702349\n",
      "  batch 201 loss: 6.635894542341702e-05\n",
      "LOSS train 0.012044498158555697 valid 8.408437133766711e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.0596773790894077e-06\n",
      "  batch 101 loss: 7.327331103624601e-05\n",
      "  batch 201 loss: 7.392905219148815e-05\n",
      "LOSS train 7.46007434620782e-05 valid 6.352108175633475e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.564804789377377e-07\n",
      "  batch 101 loss: 8.218215784381755e-05\n",
      "  batch 201 loss: 8.728773367238319e-05\n",
      "LOSS train 8.668317286886259e-05 valid 7.554030162282288e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.029449574882164e-07\n",
      "  batch 101 loss: 9.701538345098015e-05\n",
      "  batch 201 loss: 0.0001024083931434916\n",
      "LOSS train 0.00010237593936162806 valid 8.731685375096276e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1165274190716444e-06\n",
      "  batch 101 loss: 0.00011286243673367835\n",
      "  batch 201 loss: 0.00011702799181875889\n",
      "LOSS train 0.00011773672970548016 valid 8.774395973887295e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.123955807997845e-06\n",
      "  batch 101 loss: 0.00012516520676115306\n",
      "  batch 201 loss: 0.00012548583519730983\n",
      "LOSS train 0.00012682080911927587 valid 6.993504939600825e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.931163418106735e-07\n",
      "  batch 101 loss: 0.0001270537829583418\n",
      "  batch 201 loss: 0.0001220140062511632\n",
      "LOSS train 0.0001235896507050786 valid 5.2127274102531374e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.241044032620266e-07\n",
      "  batch 101 loss: 0.00011608423306824989\n",
      "  batch 201 loss: 0.00010762400330804667\n",
      "LOSS train 0.00010901440757340387 valid 5.696453445125371e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.206592959439149e-08\n",
      "  batch 101 loss: 9.81208463045391e-05\n",
      "  batch 201 loss: 8.97584134651197e-05\n",
      "LOSS train 9.065750638763684e-05 valid 7.951915904413909e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.9334236185386543e-08\n",
      "  batch 101 loss: 8.096409914060132e-05\n",
      "  batch 201 loss: 7.469315212574657e-05\n",
      "LOSS train 7.503206494627089e-05 valid 0.00010496107279323041\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 9.450586730963551e-08\n",
      "  batch 101 loss: 6.8412829598401e-05\n",
      "  batch 201 loss: 6.450494220871405e-05\n",
      "LOSS train 6.438094630086044e-05 valid 0.00012733135372400284\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.9381632228032685e-07\n",
      "  batch 101 loss: 6.084567181233069e-05\n",
      "  batch 201 loss: 5.893695860322623e-05\n",
      "LOSS train 5.846763743517137e-05 valid 0.00014778868353459984\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004765244573354721\n",
      "  batch 101 loss: 0.04386261823553468\n",
      "  batch 201 loss: 6.520576619323037e-05\n",
      "LOSS train 0.01634740195956657 valid 7.75899097789079e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.415452950634062e-07\n",
      "  batch 101 loss: 6.885835629873327e-05\n",
      "  batch 201 loss: 6.981756444019993e-05\n",
      "LOSS train 7.00116312935399e-05 valid 5.958418842055835e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.629313818644732e-07\n",
      "  batch 101 loss: 7.622061857091466e-05\n",
      "  batch 201 loss: 8.030545529891242e-05\n",
      "LOSS train 7.957379780370066e-05 valid 6.833489169366658e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.603468839079142e-07\n",
      "  batch 101 loss: 8.795297825145098e-05\n",
      "  batch 201 loss: 9.261938751251364e-05\n",
      "LOSS train 9.226527731032001e-05 valid 7.967044075485319e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.800309635465964e-07\n",
      "  batch 101 loss: 0.00010167385759359605\n",
      "  batch 201 loss: 0.00010641107246726733\n",
      "LOSS train 0.00010663706616227893 valid 8.892310870578513e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.144371199188754e-06\n",
      "  batch 101 loss: 0.00011586986496638474\n",
      "  batch 201 loss: 0.00011917318871439874\n",
      "LOSS train 0.00012009520624694846 valid 8.625538612250239e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0979836224578321e-06\n",
      "  batch 101 loss: 0.00012615756191991067\n",
      "  batch 201 loss: 0.0001257458661984856\n",
      "LOSS train 0.00012720136335473892 valid 6.796256639063358e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.526126137236133e-07\n",
      "  batch 101 loss: 0.00012662480740516458\n",
      "  batch 201 loss: 0.00012136379841706457\n",
      "LOSS train 0.00012296573806248995 valid 5.180659718462266e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.0705581593792886e-07\n",
      "  batch 101 loss: 0.00011549766276857553\n",
      "  batch 201 loss: 0.00010720239406396104\n",
      "LOSS train 0.0001085655143400793 valid 5.709473407478072e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.1017118494200987e-08\n",
      "  batch 101 loss: 9.805290746356832e-05\n",
      "  batch 201 loss: 8.986496784928022e-05\n",
      "LOSS train 9.073645594557403e-05 valid 7.903826190158725e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.8564379615781946e-08\n",
      "  batch 101 loss: 8.12908623106523e-05\n",
      "  batch 201 loss: 7.506567043492395e-05\n",
      "LOSS train 7.539628018302154e-05 valid 0.00010402668704045936\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 9.087350917980075e-08\n",
      "  batch 101 loss: 6.882285535766641e-05\n",
      "  batch 201 loss: 6.48711155042747e-05\n",
      "LOSS train 6.475234416749307e-05 valid 0.0001262037840206176\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.418765358626843e-05\n",
      "  batch 101 loss: 0.03237658545724116\n",
      "  batch 201 loss: 0.00020875817637715954\n",
      "LOSS train 0.011977573245004574 valid 5.4917945817578584e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.320157677284442e-07\n",
      "  batch 101 loss: 7.024097723842715e-05\n",
      "  batch 201 loss: 7.512124104323447e-05\n",
      "LOSS train 7.410474403673856e-05 valid 6.472369568655267e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.833039515186101e-07\n",
      "  batch 101 loss: 8.388175514255636e-05\n",
      "  batch 201 loss: 8.925794704282452e-05\n",
      "LOSS train 8.86962904392671e-05 valid 7.752957753837109e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.404188313055783e-07\n",
      "  batch 101 loss: 9.951814528449177e-05\n",
      "  batch 201 loss: 0.0001050134592901486\n",
      "LOSS train 0.00010507626379589116 valid 8.860716479830444e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1389146675355732e-06\n",
      "  batch 101 loss: 0.00011559783563768632\n",
      "  batch 201 loss: 0.00011935218589030683\n",
      "LOSS train 0.00012017602136362446 valid 8.543606963939965e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0835887951543554e-06\n",
      "  batch 101 loss: 0.00012660102187311395\n",
      "  batch 201 loss: 0.00012585347203980746\n",
      "LOSS train 0.00012725503334128264 valid 6.497439608210698e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 6.888146162964404e-07\n",
      "  batch 101 loss: 0.000125645735533908\n",
      "  batch 201 loss: 0.00011951452029279608\n",
      "LOSS train 0.00012107852139057027 valid 5.095703454571776e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.365446380281355e-07\n",
      "  batch 101 loss: 0.00011220821138749671\n",
      "  batch 201 loss: 0.0001034171103628978\n",
      "LOSS train 0.00010471836202628805 valid 6.140418554423377e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.6851691927731737e-08\n",
      "  batch 101 loss: 9.367555772087144e-05\n",
      "  batch 201 loss: 8.567352198497246e-05\n",
      "LOSS train 8.644195844891119e-05 valid 8.596659608883783e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.261958681832766e-08\n",
      "  batch 101 loss: 7.735966932386873e-05\n",
      "  batch 201 loss: 7.166904081032044e-05\n",
      "LOSS train 7.188604245579431e-05 valid 0.00011094840010628104\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1889645975315943e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 6.604289132837949e-05\n",
      "  batch 201 loss: 6.267248478138754e-05\n",
      "LOSS train 6.245365828266379e-05 valid 0.00013265911547932774\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.202822724939324e-07\n",
      "  batch 101 loss: 5.9615603020120035e-05\n",
      "  batch 201 loss: 5.815492571628056e-05\n",
      "LOSS train 5.761170974361222e-05 valid 0.0001532068126834929\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.819536883383989e-05\n",
      "  batch 101 loss: 0.018569187594505366\n",
      "  batch 201 loss: 6.775959380320273e-05\n",
      "LOSS train 0.0068599511070853636 valid 6.150374247226864e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.098044104874134e-07\n",
      "  batch 101 loss: 8.096810804772759e-05\n",
      "  batch 201 loss: 8.877091710019158e-05\n",
      "LOSS train 8.790968369907698e-05 valid 7.948128040879965e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.765591676114126e-07\n",
      "  batch 101 loss: 0.0001032310640664491\n",
      "  batch 201 loss: 0.00011033362941390124\n",
      "LOSS train 0.00011032882340118504 valid 8.934780635172501e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1516916129039601e-06\n",
      "  batch 101 loss: 0.000122456830581541\n",
      "  batch 201 loss: 0.00012469186232010542\n",
      "LOSS train 0.00012557537009146366 valid 7.164583803387359e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.273894491139799e-07\n",
      "  batch 101 loss: 0.00012725582346831743\n",
      "  batch 201 loss: 0.0001218352143246193\n",
      "LOSS train 0.00012328108757624632 valid 5.1426919526420534e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.832097015925683e-07\n",
      "  batch 101 loss: 0.00011401854941595956\n",
      "  batch 201 loss: 0.00010450722295445303\n",
      "LOSS train 0.00010591983905647968 valid 6.134298018878326e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.708562305997475e-08\n",
      "  batch 101 loss: 9.346681377337519e-05\n",
      "  batch 201 loss: 8.493095143876417e-05\n",
      "LOSS train 8.57892171206047e-05 valid 8.826572593534365e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.851404471788555e-08\n",
      "  batch 101 loss: 7.602585066706524e-05\n",
      "  batch 201 loss: 7.029484020677047e-05\n",
      "LOSS train 7.0525336077114e-05 valid 0.00011449962039478123\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.3419572496786714e-07\n",
      "  batch 101 loss: 6.469783039847243e-05\n",
      "  batch 201 loss: 6.155071842727011e-05\n",
      "LOSS train 6.130342121159362e-05 valid 0.00013681907148566097\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.415492417640053e-07\n",
      "  batch 101 loss: 5.881449318167142e-05\n",
      "  batch 201 loss: 5.767847530023573e-05\n",
      "LOSS train 5.708880499011914e-05 valid 0.00015833295765332878\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.586177990655415e-07\n",
      "  batch 101 loss: 5.721954357056802e-05\n",
      "  batch 201 loss: 5.7702371021832734e-05\n",
      "LOSS train 5.6841673923179354e-05 valid 0.00018280430231243372\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.030897591495887e-07\n",
      "  batch 101 loss: 5.90651101487083e-05\n",
      "  batch 201 loss: 6.090176313705342e-05\n",
      "LOSS train 5.9811256096217665e-05 valid 0.0002120531426044181\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00032734781503677366\n",
      "  batch 101 loss: 0.0010974958705617156\n",
      "  batch 201 loss: 0.00012396376793333275\n",
      "LOSS train 0.0005985847646019676 valid 5.324378071236424e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.80963886831887e-08\n",
      "  batch 101 loss: 9.573018510252496e-05\n",
      "  batch 201 loss: 7.56722590449499e-05\n",
      "LOSS train 7.960442633851853e-05 valid 0.0001213613577419892\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.6529596905456856e-07\n",
      "  batch 101 loss: 6.168138382690813e-05\n",
      "  batch 201 loss: 5.817982105327246e-05\n",
      "LOSS train 5.827964970346859e-05 valid 0.00016145719564519823\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.764673965633847e-07\n",
      "  batch 101 loss: 5.731563314157029e-05\n",
      "  batch 201 loss: 5.8692666839306186e-05\n",
      "LOSS train 5.778858514078667e-05 valid 0.00020182441221550107\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.216728070285171e-07\n",
      "  batch 101 loss: 6.209188226932838e-05\n",
      "  batch 201 loss: 6.550000549339074e-05\n",
      "LOSS train 6.418929089247515e-05 valid 0.00024431999190710485\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.014141687657684e-07\n",
      "  batch 101 loss: 6.963282843088337e-05\n",
      "  batch 201 loss: 7.324205635484305e-05\n",
      "LOSS train 7.194743772208809e-05 valid 0.00027596173458732665\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1198673746548593e-06\n",
      "  batch 101 loss: 7.58271444442471e-05\n",
      "  batch 201 loss: 7.866985567034135e-05\n",
      "LOSS train 7.767836794529027e-05 valid 0.00029191444627940655\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.2326202704571188e-06\n",
      "  batch 101 loss: 7.948887677741823e-05\n",
      "  batch 201 loss: 8.159597530493556e-05\n",
      "LOSS train 8.0914931271099e-05 valid 0.00029782415367662907\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.2747841537930071e-06\n",
      "  batch 101 loss: 8.137402307397678e-05\n",
      "  batch 201 loss: 8.302825293640125e-05\n",
      "LOSS train 8.256465137104223e-05 valid 0.0002993171801790595\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.2854687520302833e-06\n",
      "  batch 101 loss: 8.2327398815778e-05\n",
      "  batch 201 loss: 8.372716663302527e-05\n",
      "LOSS train 8.340361168331796e-05 valid 0.0002992090885527432\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2846953177358955e-06\n",
      "  batch 101 loss: 8.282599030962956e-05\n",
      "  batch 201 loss: 8.40797078990363e-05\n",
      "LOSS train 8.384689911487104e-05 valid 0.0002986313193105161\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.2805583537556231e-06\n",
      "  batch 101 loss: 8.309960204996969e-05\n",
      "  batch 201 loss: 8.426531785630686e-05\n",
      "LOSS train 8.409280417254195e-05 valid 0.0002979967975988984\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0011662741005420685\n",
      "  batch 101 loss: 0.010865140596870333\n",
      "  batch 201 loss: 0.0013699777037254534\n",
      "LOSS train 0.005060614137752528 valid 0.00013258446415420622\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.717456420417875e-06\n",
      "  batch 101 loss: 0.0002040915911857155\n",
      "  batch 201 loss: 0.00012544426281237974\n",
      "LOSS train 0.00015471804059356205 valid 5.4065407312009484e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.125113264308311e-07\n",
      "  batch 101 loss: 0.0001189797753795574\n",
      "  batch 201 loss: 9.744658520958183e-05\n",
      "LOSS train 0.00010184234647751023 valid 8.193577377824113e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.347089194809087e-08\n",
      "  batch 101 loss: 7.918786333902971e-05\n",
      "  batch 201 loss: 7.126931160655658e-05\n",
      "LOSS train 7.838941067701197e-05 valid 6.464772013714537e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.772623932083661e-08\n",
      "  batch 101 loss: 8.997439750714875e-05\n",
      "  batch 201 loss: 8.132511444614466e-05\n",
      "LOSS train 8.211480583846397e-05 valid 9.607252286514267e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.214964741957373e-08\n",
      "  batch 101 loss: 7.198120863222357e-05\n",
      "  batch 201 loss: 6.659224503209771e-05\n",
      "LOSS train 6.678052218975919e-05 valid 0.00012411779607646167\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.7830099750426597e-07\n",
      "  batch 101 loss: 6.158238169291508e-05\n",
      "  batch 201 loss: 5.91994465537482e-05\n",
      "LOSS train 5.884387843188494e-05 valid 0.00014771507994737476\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.99474413623102e-07\n",
      "  batch 101 loss: 5.749942296972677e-05\n",
      "  batch 201 loss: 5.725148767936617e-05\n",
      "LOSS train 5.6528067315367905e-05 valid 0.00017212741659022868\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.388019442558289e-07\n",
      "  batch 101 loss: 5.7944315962572545e-05\n",
      "  batch 201 loss: 5.93406327698176e-05\n",
      "LOSS train 5.833416102799734e-05 valid 0.0002010432508541271\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 6.16710603935644e-07\n",
      "  batch 101 loss: 6.171653946353217e-05\n",
      "  batch 201 loss: 6.432459838038085e-05\n",
      "LOSS train 6.311258310865973e-05 valid 0.00023358056205324829\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 8.2907106843777e-07\n",
      "  batch 101 loss: 6.73963107669806e-05\n",
      "  batch 201 loss: 7.053375267787487e-05\n",
      "LOSS train 6.927286244884408e-05 valid 0.0002632157120388001\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.030984421959147e-06\n",
      "  batch 101 loss: 7.308075877233477e-05\n",
      "  batch 201 loss: 7.601750827518572e-05\n",
      "LOSS train 7.490662176848504e-05 valid 0.00028346985345706344\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.0190865769982335e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.0016012609326025995\n",
      "  batch 201 loss: 0.00012236034063164424\n",
      "LOSS train 0.0006625721044611139 valid 6.124791252659634e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.7453606890048833e-08\n",
      "  batch 101 loss: 8.713301879765822e-05\n",
      "  batch 201 loss: 6.974223573934068e-05\n",
      "LOSS train 7.321106880388157e-05 valid 0.0001318884751526639\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.1639860278810374e-07\n",
      "  batch 101 loss: 5.920973296156262e-05\n",
      "  batch 201 loss: 5.730012347328284e-05\n",
      "LOSS train 5.7104034089116886e-05 valid 0.00017306467634625733\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.443725265446119e-07\n",
      "  batch 101 loss: 5.8182500013685966e-05\n",
      "  batch 201 loss: 6.053524127651144e-05\n",
      "LOSS train 5.945334501949376e-05 valid 0.00021728524006903172\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.213325443444774e-07\n",
      "  batch 101 loss: 6.476422264597658e-05\n",
      "  batch 201 loss: 6.85547846967438e-05\n",
      "LOSS train 6.718302818642223e-05 valid 0.0002587763301562518\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0002972703659907e-06\n",
      "  batch 101 loss: 7.241923891342595e-05\n",
      "  batch 201 loss: 7.583138982681703e-05\n",
      "LOSS train 7.463161041568505e-05 valid 0.0002844707923941314\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1798094783443957e-06\n",
      "  batch 101 loss: 7.769210788865167e-05\n",
      "  batch 201 loss: 8.020950693889972e-05\n",
      "LOSS train 7.935864637364007e-05 valid 0.00029541816911660135\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.257594849448651e-06\n",
      "  batch 101 loss: 8.05081382679873e-05\n",
      "  batch 201 loss: 8.238625057629179e-05\n",
      "LOSS train 8.181539496720459e-05 valid 0.00029884709510952234\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.2821030395571142e-06\n",
      "  batch 101 loss: 8.190437831444797e-05\n",
      "  batch 201 loss: 8.342313414345881e-05\n",
      "LOSS train 8.303379839507326e-05 valid 0.00029936828650534153\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.285835460294038e-06\n",
      "  batch 101 loss: 8.260872515052142e-05\n",
      "  batch 201 loss: 8.392886919068587e-05\n",
      "LOSS train 8.365453912064877e-05 valid 0.0002989451459143311\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2828053149860353e-06\n",
      "  batch 101 loss: 8.298151775647965e-05\n",
      "  batch 201 loss: 8.418659875815137e-05\n",
      "LOSS train 8.398695075771724e-05 valid 0.0002983064332511276\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.2782338308170437e-06\n",
      "  batch 101 loss: 8.318950910279454e-05\n",
      "  batch 201 loss: 8.432426743695487e-05\n",
      "LOSS train 8.417451033500293e-05 valid 0.00029769964748993516\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00045332323759794235\n",
      "  batch 101 loss: 0.01388412071915809\n",
      "  batch 201 loss: 0.0007619389935280196\n",
      "LOSS train 0.005613504678120533 valid 0.00010737177217379212\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.702168421819806e-06\n",
      "  batch 101 loss: 0.00018208674136985792\n",
      "  batch 201 loss: 0.00013874040594600957\n",
      "LOSS train 0.00015273369601991927 valid 9.01560706552118e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2620871711988002e-06\n",
      "  batch 101 loss: 0.00012360429509499226\n",
      "  batch 201 loss: 0.00012570588821290586\n",
      "LOSS train 0.00012681203315212223 valid 7.454056321876124e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.739747136132792e-07\n",
      "  batch 101 loss: 0.00012760277510892593\n",
      "  batch 201 loss: 0.0001231686508248231\n",
      "LOSS train 0.00012417197677322268 valid 5.159723514225334e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.010591899510473e-07\n",
      "  batch 101 loss: 0.00011430015134919813\n",
      "  batch 201 loss: 0.00010405279338556284\n",
      "LOSS train 0.0001055728374049334 valid 6.252920138649642e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.3508180220233045e-08\n",
      "  batch 101 loss: 9.220709094506674e-05\n",
      "  batch 201 loss: 8.331841170729604e-05\n",
      "LOSS train 8.427361710209714e-05 valid 9.173727448796853e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.912579242954962e-08\n",
      "  batch 101 loss: 7.424318667972329e-05\n",
      "  batch 201 loss: 6.86793228010174e-05\n",
      "LOSS train 6.888522719423352e-05 valid 0.00011853173782583326\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.5249213902279735e-07\n",
      "  batch 101 loss: 6.333978926477357e-05\n",
      "  batch 201 loss: 6.047903407079502e-05\n",
      "LOSS train 6.019834912228858e-05 valid 0.00014116836246103048\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.644927371875383e-07\n",
      "  batch 101 loss: 5.816360650214847e-05\n",
      "  batch 201 loss: 5.736348576590444e-05\n",
      "LOSS train 5.6729458775939064e-05 valid 0.0001637033565202728\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.8939600926823914e-07\n",
      "  batch 101 loss: 5.737639753419899e-05\n",
      "  batch 201 loss: 5.822465082246708e-05\n",
      "LOSS train 5.730519737239658e-05 valid 0.0001898493355838582\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.46543305972591e-07\n",
      "  batch 101 loss: 6.000874751180163e-05\n",
      "  batch 201 loss: 6.217466684688589e-05\n",
      "LOSS train 6.1030705436122186e-05 valid 0.00022062727657612413\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.432542042806745e-07\n",
      "  batch 101 loss: 6.50240583570394e-05\n",
      "  batch 201 loss: 6.799770004477068e-05\n",
      "LOSS train 6.673753098153617e-05 valid 0.00025175968767143786\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0014907367527484893\n",
      "  batch 101 loss: 0.0596684128139168\n",
      "  batch 201 loss: 0.000965829061169643\n",
      "LOSS train 0.022807818071755935 valid 0.00014641853340435773\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.607753989053891e-07\n",
      "  batch 101 loss: 9.546100957777526e-05\n",
      "  batch 201 loss: 7.60409548138341e-05\n",
      "LOSS train 8.366059060064313e-05 valid 6.376127566909418e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.618926272494719e-07\n",
      "  batch 101 loss: 8.260138753712453e-05\n",
      "  batch 201 loss: 8.778070119660697e-05\n",
      "LOSS train 8.718427109057308e-05 valid 7.604254642501473e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.124712232733145e-07\n",
      "  batch 101 loss: 9.764455607523815e-05\n",
      "  batch 201 loss: 0.00010306800271507655\n",
      "LOSS train 0.00010305936576896251 valid 8.768210682319477e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.122881003539078e-06\n",
      "  batch 101 loss: 0.00011356706702741803\n",
      "  batch 201 loss: 0.00011764006086991685\n",
      "LOSS train 0.00011837868905321983 valid 8.723820792511106e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1151575745316222e-06\n",
      "  batch 101 loss: 0.00012557461907931612\n",
      "  batch 201 loss: 0.00012563345810463034\n",
      "LOSS train 0.00012698685277727845 valid 6.866381590953097e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.671437924727798e-07\n",
      "  batch 101 loss: 0.00012675822348057864\n",
      "  batch 201 loss: 0.00012143164185943078\n",
      "LOSS train 0.00012300572221637604 valid 5.169502037460916e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.0056849936954677e-07\n",
      "  batch 101 loss: 0.00011513047914604613\n",
      "  batch 201 loss: 0.00010656688464337094\n",
      "LOSS train 0.00010793580656351274 valid 5.800390135846101e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.433697540662251e-08\n",
      "  batch 101 loss: 9.697917996561501e-05\n",
      "  batch 201 loss: 8.869811150930218e-05\n",
      "LOSS train 8.956412914120856e-05 valid 8.115661330521107e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.220413534814725e-08\n",
      "  batch 101 loss: 8.00164885436061e-05\n",
      "  batch 201 loss: 7.389239951180571e-05\n",
      "LOSS train 7.419965281636432e-05 valid 0.00010650940384948626\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.0063259651360568e-07\n",
      "  batch 101 loss: 6.777828327130919e-05\n",
      "  batch 201 loss: 6.400957453593036e-05\n",
      "LOSS train 6.386076213669222e-05 valid 0.00012870048522017896\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.0053055777680128e-07\n",
      "  batch 101 loss: 6.050589492815561e-05\n",
      "  batch 201 loss: 5.8713389046261e-05\n",
      "LOSS train 5.82248463572233e-05 valid 0.0001491588045610115\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.83944274391979e-06\n",
      "  batch 101 loss: 0.01564380826024262\n",
      "  batch 201 loss: 2.5263986934760396e-05\n",
      "LOSS train 0.005748682159053585 valid 2.6337802410125732e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.2754016956459964e-08\n",
      "  batch 101 loss: 1.545897432038146e-05\n",
      "  batch 201 loss: 5.9558139213322646e-06\n",
      "LOSS train 8.489212433460125e-06 valid 3.689862069222727e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2999579439565422e-08\n",
      "  batch 101 loss: 1.5555210339357473e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 6.938945990953016e-07\n",
      "LOSS train 1.1250268102315573e-06 valid 9.023357847581792e-07\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.820629442292557e-09\n",
      "  batch 101 loss: 7.689045563097352e-07\n",
      "  batch 201 loss: 1.3030220256382563e-06\n",
      "LOSS train 1.0198498394049402e-06 valid 1.5146647456276696e-06\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.840858369130729e-09\n",
      "  batch 101 loss: 2.0344513099246343e-06\n",
      "  batch 201 loss: 9.324324116732897e-07\n",
      "LOSS train 1.2785797570581512e-06 valid 1.3588291949417908e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.2227225688075123e-09\n",
      "  batch 101 loss: 1.0953392862234068e-06\n",
      "  batch 201 loss: 7.636382575526568e-07\n",
      "LOSS train 9.066725147532359e-07 valid 1.1550617955435882e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.5767274653153437e-09\n",
      "  batch 101 loss: 8.604336257889145e-07\n",
      "  batch 201 loss: 8.469770796182274e-07\n",
      "LOSS train 1.1955111781187889e-06 valid 6.7892970037064515e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.668042725417763e-08\n",
      "  batch 101 loss: 1.5321851672922547e-06\n",
      "  batch 201 loss: 6.87780687158579e-07\n",
      "LOSS train 9.97177010457306e-07 valid 5.020957587476005e-07\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.516373089316403e-09\n",
      "  batch 101 loss: 1.036078287270925e-06\n",
      "  batch 201 loss: 7.91072328354403e-07\n",
      "LOSS train 8.374248031622961e-07 valid 3.2553145956626395e-07\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.9639369952528796e-09\n",
      "  batch 101 loss: 8.933119428178316e-07\n",
      "  batch 201 loss: 9.638860273497586e-07\n",
      "LOSS train 9.106906083392154e-07 valid 3.1981616643861344e-07\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1249893816511757e-09\n",
      "  batch 101 loss: 9.674760863020993e-07\n",
      "  batch 201 loss: 1.131493744210843e-06\n",
      "LOSS train 9.873900550419022e-07 valid 6.838909030193463e-07\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.6363517829631747e-09\n",
      "  batch 101 loss: 1.1760938799199038e-06\n",
      "  batch 201 loss: 1.0780038088142874e-06\n",
      "LOSS train 1.127163745073904e-06 valid 7.912186106295849e-07\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.94825212424621e-06\n",
      "  batch 101 loss: 0.025815414641983808\n",
      "  batch 201 loss: 0.00011265332046605181\n",
      "LOSS train 0.009519978424091462 valid 5.639447408611886e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.6994788388255984e-07\n",
      "  batch 101 loss: 5.9430953006085476e-05\n",
      "  batch 201 loss: 3.57894305670925e-05\n",
      "LOSS train 4.1160007562138536e-05 valid 1.0648918760125525e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.356408483843552e-07\n",
      "  batch 101 loss: 1.7232808713742996e-05\n",
      "  batch 201 loss: 1.3261601866361161e-05\n",
      "LOSS train 1.3907878179958768e-05 valid 9.758479791344143e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.229102382349083e-08\n",
      "  batch 101 loss: 9.785875466832294e-06\n",
      "  batch 201 loss: 6.916451683878222e-06\n",
      "LOSS train 7.824007391530394e-06 valid 1.443343444407219e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.8274812393647153e-08\n",
      "  batch 101 loss: 6.051437580936181e-06\n",
      "  batch 201 loss: 1.0423057024127047e-05\n",
      "LOSS train 1.1576012005518798e-05 valid 5.2238076023058966e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.332286375254626e-08\n",
      "  batch 101 loss: 7.70429501903891e-05\n",
      "  batch 201 loss: 0.00011726933617353552\n",
      "LOSS train 0.00010296907327232469 valid 5.150479410076514e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.8891463443869725e-07\n",
      "  batch 101 loss: 0.00011446067355336709\n",
      "  batch 201 loss: 0.00010544243318918234\n",
      "LOSS train 0.00010681950633027092 valid 5.954405787633732e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.51739640791493e-08\n",
      "  batch 101 loss: 9.528848244372057e-05\n",
      "  batch 201 loss: 8.696682735262584e-05\n",
      "LOSS train 8.777868403253889e-05 valid 8.447517757304013e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.9089528652548326e-08\n",
      "  batch 101 loss: 7.817857047484722e-05\n",
      "  batch 201 loss: 7.21302562078563e-05\n",
      "LOSS train 7.245722727703575e-05 valid 0.00011020175588782877\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1575557437026874e-07\n",
      "  batch 101 loss: 6.63671138522659e-05\n",
      "  batch 201 loss: 6.28342014010741e-05\n",
      "LOSS train 6.264221888692264e-05 valid 0.0001322300377069041\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.1811943952343425e-07\n",
      "  batch 101 loss: 5.97193240650995e-05\n",
      "  batch 201 loss: 5.815576070688166e-05\n",
      "LOSS train 5.76458342721631e-05 valid 0.00015347878797911108\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.356814704602584e-07\n",
      "  batch 101 loss: 5.730290475611355e-05\n",
      "  batch 201 loss: 5.739804999706166e-05\n",
      "LOSS train 5.66150988303086e-05 valid 0.00017655259580351412\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.423535920679569e-05\n",
      "  batch 101 loss: 0.01470886584444088\n",
      "  batch 201 loss: 0.00020143297188042198\n",
      "LOSS train 0.005506563121666942 valid 0.00010175941133638844\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.9230153813841753e-07\n",
      "  batch 101 loss: 7.027010537967726e-05\n",
      "  batch 201 loss: 0.00011274298065472977\n",
      "LOSS train 9.944608045887621e-05 valid 8.707532833795995e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1704084317898377e-06\n",
      "  batch 101 loss: 0.00012404140667285902\n",
      "  batch 201 loss: 0.00012719038099248792\n",
      "LOSS train 0.00012748231778702938 valid 7.108516729203984e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.439099474344403e-07\n",
      "  batch 101 loss: 0.00012846584520389114\n",
      "  batch 201 loss: 0.00012296779565758697\n",
      "LOSS train 0.00012430458926224847 valid 5.107387187308632e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.750563362496905e-07\n",
      "  batch 101 loss: 0.00011847051214999737\n",
      "  batch 201 loss: 0.0001103674779415087\n",
      "LOSS train 0.00011146755396994828 valid 5.5899825383676216e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.750186457793462e-08\n",
      "  batch 101 loss: 9.913697145123024e-05\n",
      "  batch 201 loss: 8.952896851837977e-05\n",
      "LOSS train 9.06715387514141e-05 valid 8.279331814264879e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.3983163828233957e-08\n",
      "  batch 101 loss: 7.935883336358529e-05\n",
      "  batch 201 loss: 7.273803103316823e-05\n",
      "LOSS train 7.314594369492271e-05 valid 0.00010969543654937297\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1254851415287703e-07\n",
      "  batch 101 loss: 6.665651101229741e-05\n",
      "  batch 201 loss: 6.408946727333387e-05\n",
      "LOSS train 6.346133575467793e-05 valid 0.0001293138338951394\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.041365223703906e-07\n",
      "  batch 101 loss: 6.0332780260523575e-05\n",
      "  batch 201 loss: 5.851917512870841e-05\n",
      "LOSS train 5.80480715795632e-05 valid 0.0001508651621406898\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.1751911592436956e-07\n",
      "  batch 101 loss: 5.734093209184721e-05\n",
      "  batch 201 loss: 5.73137517426403e-05\n",
      "LOSS train 5.65496439510223e-05 valid 0.00017445272533223033\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.532722959993407e-07\n",
      "  batch 101 loss: 5.8147367724359356e-05\n",
      "  batch 201 loss: 5.9603128067919894e-05\n",
      "LOSS train 5.857815049306064e-05 valid 0.00020238329307176173\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.265797856030986e-07\n",
      "  batch 101 loss: 6.193691776559262e-05\n",
      "  batch 201 loss: 6.450161577106428e-05\n",
      "LOSS train 6.32924812512451e-05 valid 0.00023392800358124077\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.5002658367156984e-05\n",
      "  batch 101 loss: 0.026865944116798345\n",
      "  batch 201 loss: 0.0001008294536768517\n",
      "LOSS train 0.009905640392726093 valid 6.201704673003405e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.704837531084195e-07\n",
      "  batch 101 loss: 7.536897328009218e-05\n",
      "  batch 201 loss: 7.937782412682281e-05\n",
      "LOSS train 7.887416652240743e-05 valid 6.85139384586364e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.640497642569244e-07\n",
      "  batch 101 loss: 8.900503932409265e-05\n",
      "  batch 201 loss: 9.509359876801682e-05\n",
      "LOSS train 9.458432335592518e-05 valid 8.293859718833119e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0392426338512451e-06\n",
      "  batch 101 loss: 0.00010636616013357525\n",
      "  batch 201 loss: 0.00011189761046381363\n",
      "LOSS train 0.00011211427386417162 valid 8.955274824984372e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1552180512808263e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00012192951917597839\n",
      "  batch 201 loss: 0.00012398343947666034\n",
      "LOSS train 0.00012506399962057245 valid 7.603159610880539e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.122641495196149e-07\n",
      "  batch 101 loss: 0.0001274953017775715\n",
      "  batch 201 loss: 0.00012405588825401993\n",
      "LOSS train 0.00012547106087100514 valid 5.4498494137078524e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.1821553168119865e-07\n",
      "  batch 101 loss: 0.00011930666222951913\n",
      "  batch 201 loss: 0.0001110093200816209\n",
      "LOSS train 0.00011247880406791166 valid 5.438948574010283e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.945665856823326e-08\n",
      "  batch 101 loss: 0.00010131955715252161\n",
      "  batch 201 loss: 9.25094903726631e-05\n",
      "LOSS train 9.354673412388735e-05 valid 7.578819349873811e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.4318021612780284e-08\n",
      "  batch 101 loss: 8.30979145098354e-05\n",
      "  batch 201 loss: 7.6561408507132e-05\n",
      "LOSS train 7.689467975527499e-05 valid 0.00010203977581113577\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 8.331871867994777e-08\n",
      "  batch 101 loss: 6.983080483905723e-05\n",
      "  batch 201 loss: 6.537861864785554e-05\n",
      "LOSS train 6.540223105125884e-05 valid 0.00012518659059423953\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.8342512703384273e-07\n",
      "  batch 101 loss: 6.148768471803123e-05\n",
      "  batch 201 loss: 5.932410220111706e-05\n",
      "LOSS train 5.8907635831342584e-05 valid 0.00014594873937312514\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.9088412702549247e-07\n",
      "  batch 101 loss: 5.768790838374116e-05\n",
      "  batch 201 loss: 5.7295962556622725e-05\n",
      "LOSS train 5.656591835426857e-05 valid 0.00016766486805863678\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 9.260830469429493e-05\n",
      "  batch 101 loss: 0.00961574400353129\n",
      "  batch 201 loss: 0.0001379119749981328\n",
      "LOSS train 0.0036386323341759683 valid 5.526746826944873e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.959712482057512e-07\n",
      "  batch 101 loss: 0.00011546509308345776\n",
      "  batch 201 loss: 0.00012104289587966833\n",
      "LOSS train 0.00012144257162753336 valid 7.488729897886515e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.907908340916038e-07\n",
      "  batch 101 loss: 0.00012765437968596417\n",
      "  batch 201 loss: 0.000121203763220592\n",
      "LOSS train 0.0001222156873449581 valid 5.10292848048266e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.8286542399437167e-07\n",
      "  batch 101 loss: 0.00010785910198137572\n",
      "  batch 201 loss: 9.582423303299947e-05\n",
      "LOSS train 9.748568638565886e-05 valid 7.652782369405031e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.5254321397151215e-08\n",
      "  batch 101 loss: 8.218166251708681e-05\n",
      "  batch 201 loss: 7.42007111489329e-05\n",
      "LOSS train 7.486504597763264e-05 valid 0.00010961770021822304\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1310582522128243e-07\n",
      "  batch 101 loss: 6.631645468132774e-05\n",
      "  batch 201 loss: 6.228102346085507e-05\n",
      "LOSS train 6.224737814054839e-05 valid 0.0001362808543490246\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.431460779916961e-07\n",
      "  batch 101 loss: 5.887206632905872e-05\n",
      "  batch 201 loss: 5.769821901765226e-05\n",
      "LOSS train 5.710100819191538e-05 valid 0.00015983986668288708\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.6691941204480825e-07\n",
      "  batch 101 loss: 5.724519327031885e-05\n",
      "  batch 201 loss: 5.800060294177456e-05\n",
      "LOSS train 5.7074630085430773e-05 valid 0.00018696486949920654\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.277096715872176e-07\n",
      "  batch 101 loss: 5.958500042765991e-05\n",
      "  batch 201 loss: 6.184289172438184e-05\n",
      "LOSS train 6.0640913917824694e-05 valid 0.0002191257372032851\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 7.330901280511171e-07\n",
      "  batch 101 loss: 6.473728756589025e-05\n",
      "  batch 201 loss: 6.77915632843451e-05\n",
      "LOSS train 6.650254138443975e-05 valid 0.00025119102792814374\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 9.479097207076848e-07\n",
      "  batch 101 loss: 7.066324597531093e-05\n",
      "  batch 201 loss: 7.379428364799878e-05\n",
      "LOSS train 7.259268338286794e-05 valid 0.0002762721269391477\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1214541154913605e-06\n",
      "  batch 101 loss: 7.577833727282269e-05\n",
      "  batch 201 loss: 7.840253934318753e-05\n",
      "LOSS train 7.743834253620502e-05 valid 0.0002907708694692701\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0014736285805702209\n",
      "  batch 101 loss: 1.9054210079435143\n",
      "  batch 201 loss: 0.0004112086759869271\n",
      "LOSS train 0.6987082117247249 valid 0.0033363208640366793\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00013730566948652267\n",
      "  batch 101 loss: 0.002263492075148861\n",
      "  batch 201 loss: 0.00016333276656041562\n",
      "LOSS train 0.0009670878424031922 valid 0.00283937924541533\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.00012357997708022594\n",
      "  batch 101 loss: 0.003464377282427904\n",
      "  batch 201 loss: 0.00015934405233451797\n",
      "LOSS train 0.0014186719360923768 valid 0.002063924679532647\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.625650942325592e-05\n",
      "  batch 101 loss: 0.0038027710391179428\n",
      "  batch 201 loss: 0.00021843298843577942\n",
      "LOSS train 0.0015698693507510387 valid 0.0028329435735940933\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.00012063261121511459\n",
      "  batch 101 loss: 0.004690485535329572\n",
      "  batch 201 loss: 0.0001486526432699975\n",
      "LOSS train 0.001923476429020901 valid 0.002905162749812007\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.00013555433601140975\n",
      "  batch 101 loss: 0.013135825927020051\n",
      "  batch 201 loss: 0.0005297148803674645\n",
      "LOSS train 0.005149464731982664 valid 0.002580550964921713\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.698782116174698e-05\n",
      "  batch 101 loss: 0.01189084706507856\n",
      "  batch 201 loss: 0.004876178033082396\n",
      "LOSS train 0.07102836582451166 valid 0.06727871298789978\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0009575308859348297\n",
      "  batch 101 loss: 0.03336302250223525\n",
      "  batch 201 loss: 0.0026568649270848257\n",
      "LOSS train 0.0271019691417711 valid 0.02644403465092182\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.0007595525681972504\n",
      "  batch 101 loss: 0.07004782034724485\n",
      "  batch 201 loss: 0.0013012508578412962\n",
      "LOSS train 0.04823406395650266 valid 0.041341137140989304\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.0017073173820972443\n",
      "  batch 101 loss: 0.11278684743447229\n",
      "  batch 201 loss: 0.0024737701568483318\n",
      "LOSS train 0.0603309380889113 valid 0.07537420094013214\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 0.0024002839624881742\n",
      "  batch 101 loss: 0.10151127879133127\n",
      "  batch 201 loss: 0.0025238349152368754\n",
      "LOSS train 0.0636848899293043 valid 0.200090691447258\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 0.0045310047268867495\n",
      "  batch 101 loss: 0.11317080537624861\n",
      "  batch 201 loss: 0.002844432180336298\n",
      "LOSS train 0.07572773372687532 valid 0.5911915898323059\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ") 0.05 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.5801452361047266e-05\n",
      "  batch 101 loss: 2.1289787233551034\n",
      "  batch 201 loss: 0.0019465816498268397\n",
      "LOSS train 0.7810007729723234 valid 0.0005255942232906818\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4825889375060797e-05\n",
      "  batch 101 loss: 0.0011827222624560818\n",
      "  batch 201 loss: 0.0006664528418332339\n",
      "LOSS train 0.0007725421674767059 valid 0.00029006728436797857\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.632496132515371e-05\n",
      "  batch 101 loss: 0.00034199636756966357\n",
      "  batch 201 loss: 0.00012276906123588561\n",
      "LOSS train 0.00019720644312599443 valid 8.455732313450426e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.4799290006048977e-06\n",
      "  batch 101 loss: 0.00015915477622911568\n",
      "  batch 201 loss: 2.511915566174139e-05\n",
      "LOSS train 7.459402020905834e-05 valid 3.5318455047672614e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.603285491000861e-06\n",
      "  batch 101 loss: 0.0001210124720546446\n",
      "  batch 201 loss: 1.4293448052740133e-05\n",
      "LOSS train 5.347060835867104e-05 valid 7.027682295301929e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.0799550586380064e-06\n",
      "  batch 101 loss: 6.162265135571943e-05\n",
      "  batch 201 loss: 1.660027046000323e-05\n",
      "LOSS train 3.339131070381985e-05 valid 9.842493454925716e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.751922071794979e-07\n",
      "  batch 101 loss: 4.375621337430857e-05\n",
      "  batch 201 loss: 0.002353801149879473\n",
      "LOSS train 0.09146069455446679 valid 0.07447019964456558\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0008029448240995407\n",
      "  batch 101 loss: 0.016206569686182774\n",
      "  batch 201 loss: 0.002901048342464492\n",
      "LOSS train 0.008274111980759972 valid 0.001632757019251585\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 7.889357395470143e-05\n",
      "  batch 101 loss: 0.007376906715653604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.002462494191713631\n",
      "LOSS train 0.02700626746287199 valid 0.16029709577560425\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.0014485502243041992\n",
      "  batch 101 loss: 0.03518465428147465\n",
      "  batch 201 loss: 0.016810430136101787\n",
      "LOSS train 0.03602549479090977 valid 0.00797231774777174\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.25376496464014e-05\n",
      "  batch 101 loss: 0.09048612594138832\n",
      "  batch 201 loss: 0.017004152970621363\n",
      "LOSS train 0.041297626989508125 valid 0.0056846062652766705\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.5331139117479327e-05\n",
      "  batch 101 loss: 0.052793078889662864\n",
      "  batch 201 loss: 0.02010809832980158\n",
      "LOSS train 0.038271676549208676 valid 0.003444946836680174\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001602761447429657\n",
      "  batch 101 loss: 2.1138652527634987\n",
      "  batch 201 loss: 0.0035363548214081674\n",
      "LOSS train 0.7761543074457722 valid 0.0009932422544807196\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.0141119174659255e-05\n",
      "  batch 101 loss: 0.0013110872905235738\n",
      "  batch 201 loss: 0.00028733653409290127\n",
      "LOSS train 0.0006489816756391106 valid 0.00015551544493064284\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.081753522157669e-05\n",
      "  batch 101 loss: 0.00020267886680812807\n",
      "  batch 201 loss: 2.9663642153536783e-05\n",
      "LOSS train 9.617902162309348e-05 valid 3.2893720344873145e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5324003470595926e-06\n",
      "  batch 101 loss: 5.4764734591117305e-05\n",
      "  batch 201 loss: 1.3912357178469393e-05\n",
      "LOSS train 2.9523723364596102e-05 valid 1.4889019439578988e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.768808139488101e-07\n",
      "  batch 101 loss: 3.0037555370654444e-05\n",
      "  batch 201 loss: 1.845891478296835e-05\n",
      "LOSS train 2.2050393244381456e-05 valid 2.2288326363195665e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.4894440937496255e-07\n",
      "  batch 101 loss: 4.310378341415344e-05\n",
      "  batch 201 loss: 3.2957646885733995e-05\n",
      "LOSS train 3.371828844111129e-05 valid 9.648469131207094e-06\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.552346687589306e-08\n",
      "  batch 101 loss: 8.851995129930402e-05\n",
      "  batch 201 loss: 0.0023602964427027473\n",
      "LOSS train 0.08819181197139266 valid 0.10653087496757507\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0014642052352428435\n",
      "  batch 101 loss: 0.028445847848197446\n",
      "  batch 201 loss: 0.001672112059459323\n",
      "LOSS train 0.01172283289346084 valid 0.00027816896908916533\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.3609981872141363e-05\n",
      "  batch 101 loss: 0.0020539593505236554\n",
      "  batch 201 loss: 0.0005470011685247301\n",
      "LOSS train 0.04069525538372026 valid 0.332589328289032\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.002613019645214081\n",
      "  batch 101 loss: 0.031546239654999225\n",
      "  batch 201 loss: 0.011193025832762942\n",
      "LOSS train 0.024207168511279617 valid 0.004130709916353226\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.9322624430060385e-05\n",
      "  batch 101 loss: 0.07057441900135018\n",
      "  batch 201 loss: 0.015098097453301308\n",
      "LOSS train 0.0461904360989924 valid 0.01284389104694128\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 0.00016965493559837342\n",
      "  batch 101 loss: 0.07610480416798965\n",
      "  batch 201 loss: 0.014879860961227677\n",
      "LOSS train 0.03473945523318178 valid 0.008993701077997684\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005116283148527145\n",
      "  batch 101 loss: 2.050879755988717\n",
      "  batch 201 loss: 0.004865363457938656\n",
      "LOSS train 0.7535726342462395 valid 0.0018363974522799253\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00012571495957672596\n",
      "  batch 101 loss: 0.0015631856617255835\n",
      "  batch 201 loss: 0.00010049097079900093\n",
      "LOSS train 0.0006693905302482886 valid 0.00017694900452625006\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.5349907334893943e-05\n",
      "  batch 101 loss: 0.0001598770612235967\n",
      "  batch 201 loss: 2.776568925128231e-05\n",
      "LOSS train 8.190208376078402e-05 valid 2.4638846298330463e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.211980197695084e-06\n",
      "  batch 101 loss: 2.3333881429152826e-05\n",
      "  batch 201 loss: 2.14027550737228e-05\n",
      "LOSS train 2.1249320326328897e-05 valid 1.5462706869584508e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.265319603291573e-08\n",
      "  batch 101 loss: 1.5209504390440997e-05\n",
      "  batch 201 loss: 2.0750287994815153e-05\n",
      "LOSS train 1.9459562839577406e-05 valid 1.0597562322800513e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.371164767595473e-08\n",
      "  batch 101 loss: 4.991351589069381e-05\n",
      "  batch 201 loss: 6.823967442869617e-05\n",
      "LOSS train 6.414204181088853e-05 valid 9.910785593092442e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2144287757109851e-06\n",
      "  batch 101 loss: 0.00030994841484243806\n",
      "  batch 201 loss: 0.08367737393633433\n",
      "LOSS train 0.05229778004196062 valid 0.013720381073653698\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00015493400394916534\n",
      "  batch 101 loss: 0.004363641474337782\n",
      "  batch 201 loss: 0.0015889280798000983\n",
      "LOSS train 0.028741270198478004 valid 0.0025885559152811766\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 6.703581660985947e-05\n",
      "  batch 101 loss: 0.016161385653540493\n",
      "  batch 201 loss: 0.054133361210115256\n",
      "LOSS train 0.04491464216466788 valid 0.08209232240915298\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.0005300753936171532\n",
      "  batch 101 loss: 0.02738015195413027\n",
      "  batch 201 loss: 0.009164069782709703\n",
      "LOSS train 0.043899355751535626 valid 0.02500384859740734\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 0.00013146540150046348\n",
      "  batch 101 loss: 0.015611826334497892\n",
      "  batch 201 loss: 0.06102274680277333\n",
      "LOSS train 0.04224359603226014 valid 0.0034010987728834152\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.997955195605755e-05\n",
      "  batch 101 loss: 0.009318938698270359\n",
      "  batch 201 loss: 0.055332369769457726\n",
      "LOSS train 0.03091091568084543 valid 0.014487424865365028\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005783882364630699\n",
      "  batch 101 loss: 2.120911703519523\n",
      "  batch 201 loss: 0.004232407612435054\n",
      "LOSS train 0.778723236242393 valid 7.196776277851313e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.751463468186557e-06\n",
      "  batch 101 loss: 0.00012847225661971606\n",
      "  batch 201 loss: 2.2962581851970754e-05\n",
      "LOSS train 6.374518995934665e-05 valid 1.7638834833633155e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.9838009393424727e-07\n",
      "  batch 101 loss: 3.0455477831310417e-05\n",
      "  batch 201 loss: 3.572592784166773e-05\n",
      "LOSS train 3.9861361340663544e-05 valid 2.7617437808657996e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.0852239433443176e-07\n",
      "  batch 101 loss: 3.389246101505705e-05\n",
      "  batch 201 loss: 4.18768854569862e-05\n",
      "LOSS train 4.1546681969744367e-05 valid 4.8171314119827e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.3532933735405094e-07\n",
      "  batch 101 loss: 3.655054978935368e-05\n",
      "  batch 201 loss: 5.1954409777863474e-05\n",
      "LOSS train 4.353577089751282e-05 valid 3.095371357630938e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1104807526862714e-07\n",
      "  batch 101 loss: 0.0002078341984179133\n",
      "  batch 201 loss: 9.212457654030004e-05\n",
      "LOSS train 0.00020959924830880907 valid 0.00018023268785327673\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.315503756515681e-06\n",
      "  batch 101 loss: 0.0005877333043827094\n",
      "  batch 201 loss: 0.05646116974763572\n",
      "LOSS train 0.03811679269523126 valid 0.0006452919915318489\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.8106170296669e-05\n",
      "  batch 101 loss: 0.014423170711379498\n",
      "  batch 201 loss: 0.04828152869828045\n",
      "LOSS train 0.07485813311055549 valid 0.1623266488313675\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.0020861980319023133\n",
      "  batch 101 loss: 0.0893769259005785\n",
      "  batch 201 loss: 0.010184439412842038\n",
      "LOSS train 0.03735230422943536 valid 3.0345159757416695e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.7132573197595777e-07\n",
      "  batch 101 loss: 0.0011638262522319564\n",
      "  batch 201 loss: 0.07026576819538605\n",
      "LOSS train 0.06853721784043443 valid 0.012339482083916664\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 0.0004076926410198212\n",
      "  batch 101 loss: 0.08397623684257269\n",
      "  batch 201 loss: 0.023559997086413206\n",
      "LOSS train 0.03999646370559922 valid 0.00019744597375392914\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.6265441556461154e-06\n",
      "  batch 101 loss: 0.0013027668058202835\n",
      "  batch 201 loss: 0.05272502000327222\n",
      "LOSS train 0.07034623696082958 valid 0.004171107430011034\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.935731153935194e-05\n",
      "  batch 101 loss: 1.8163150576243061\n",
      "  batch 201 loss: 9.337510502518853e-05\n",
      "LOSS train 0.6653729685393099 valid 5.195782068767585e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.1535404559690505e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 5.97449651286297e-05\n",
      "  batch 201 loss: 6.157961312055704e-05\n",
      "LOSS train 6.06644872001171e-05 valid 5.3644165745936334e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.8820169720565903e-07\n",
      "  batch 101 loss: 6.460380555836309e-05\n",
      "  batch 201 loss: 6.660597252448496e-05\n",
      "LOSS train 6.576229452548432e-05 valid 5.627463178825565e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.7363162593683226e-07\n",
      "  batch 101 loss: 7.005595180089585e-05\n",
      "  batch 201 loss: 7.24106350207876e-05\n",
      "LOSS train 7.165101304540075e-05 valid 6.0304624639684334e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.808504283777439e-07\n",
      "  batch 101 loss: 7.661003045541293e-05\n",
      "  batch 201 loss: 7.944813194171729e-05\n",
      "LOSS train 7.882557707862594e-05 valid 6.62640159134753e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.167500007199123e-07\n",
      "  batch 101 loss: 8.471640510151701e-05\n",
      "  batch 201 loss: 8.811979691699889e-05\n",
      "LOSS train 8.773073255431569e-05 valid 7.444252696586773e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.819591312203556e-07\n",
      "  batch 101 loss: 9.473809999690275e-05\n",
      "  batch 201 loss: 9.8630412754801e-05\n",
      "LOSS train 9.86223126988196e-05 valid 8.382281521335244e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0550266597419978e-06\n",
      "  batch 101 loss: 0.00010659230323710745\n",
      "  batch 201 loss: 0.00011045786975699912\n",
      "LOSS train 0.00011099754357694307 valid 8.985566819319502e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.160423271358013e-06\n",
      "  batch 101 loss: 0.00011880927071672431\n",
      "  batch 201 loss: 0.00012124439196355752\n",
      "LOSS train 0.00012237958207884187 valid 8.376659388886765e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0540251969359815e-06\n",
      "  batch 101 loss: 0.00012713335054854725\n",
      "  batch 201 loss: 0.00012581754580537563\n",
      "LOSS train 0.00012731687554072704 valid 6.36085678706877e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.584549555554986e-07\n",
      "  batch 101 loss: 0.00012512667474084082\n",
      "  batch 201 loss: 0.00011869612889768177\n",
      "LOSS train 0.00012021367069209168 valid 5.088706166134216e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.0887786376988517e-07\n",
      "  batch 101 loss: 0.0001106000715776645\n",
      "  batch 201 loss: 0.00010132124855090296\n",
      "LOSS train 0.0001025907232092439 valid 6.478110299212858e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.05 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00021869098767638207\n",
      "  batch 101 loss: 0.5970863733482747\n",
      "  batch 201 loss: 7.038700231532857e-05\n",
      "LOSS train 0.2188353799334626 valid 5.468668678076938e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.2447216401342304e-07\n",
      "  batch 101 loss: 6.794272638671828e-05\n",
      "  batch 201 loss: 7.204646783065983e-05\n",
      "LOSS train 7.107411025845401e-05 valid 6.167333049234003e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.138199387351051e-07\n",
      "  batch 101 loss: 7.950027638798929e-05\n",
      "  batch 201 loss: 8.422421218256205e-05\n",
      "LOSS train 8.356124894467379e-05 valid 7.248306064866483e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.439043449470773e-07\n",
      "  batch 101 loss: 9.326995929995973e-05\n",
      "  batch 201 loss: 9.857286343958549e-05\n",
      "LOSS train 9.840635878856032e-05 valid 8.490676555084065e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0742502490757032e-06\n",
      "  batch 101 loss: 0.00010902837346350224\n",
      "  batch 201 loss: 0.00011381662207355702\n",
      "LOSS train 0.00011434467680676676 valid 8.920982509152964e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1493156489450484e-06\n",
      "  batch 101 loss: 0.00012321052526544917\n",
      "  batch 201 loss: 0.00012469969653750468\n",
      "LOSS train 0.00012584882875315973 valid 7.300842844415456e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.541863644495606e-07\n",
      "  batch 101 loss: 0.00012751438570091978\n",
      "  batch 201 loss: 0.00012269970396658892\n",
      "LOSS train 0.00012413033267896423 valid 5.2096424042247236e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.225472755730152e-07\n",
      "  batch 101 loss: 0.00011558574759192197\n",
      "  batch 201 loss: 0.00010598820820632682\n",
      "LOSS train 0.00010739884482273528 valid 6.031408702256158e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.140487251585e-08\n",
      "  batch 101 loss: 9.418041946446465e-05\n",
      "  batch 201 loss: 8.504830187575862e-05\n",
      "LOSS train 8.599555760169689e-05 valid 8.942307613324374e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.1680277718114664e-08\n",
      "  batch 101 loss: 7.524317187971974e-05\n",
      "  batch 201 loss: 6.921543094222215e-05\n",
      "LOSS train 6.95047012876928e-05 valid 0.00011827371054096147\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.510644597146893e-07\n",
      "  batch 101 loss: 6.33048552344917e-05\n",
      "  batch 201 loss: 6.0272167381754116e-05\n",
      "LOSS train 6.0029947279865765e-05 valid 0.00014344934606924653\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.764364762697369e-07\n",
      "  batch 101 loss: 5.784384242758733e-05\n",
      "  batch 201 loss: 5.7249858398336075e-05\n",
      "LOSS train 5.661475334038133e-05 valid 0.00017075506912078708\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 9.247397072613239e-05\n",
      "  batch 101 loss: 0.9791327780595748\n",
      "  batch 201 loss: 0.01909393617608657\n",
      "LOSS train 0.3657532015510477 valid 5.261192563921213e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.468168870313093e-07\n",
      "  batch 101 loss: 6.316350550150673e-05\n",
      "  batch 201 loss: 6.616214253881481e-05\n",
      "LOSS train 6.512606347687557e-05 valid 5.65847112738993e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.826258373213932e-07\n",
      "  batch 101 loss: 7.100477969288477e-05\n",
      "  batch 201 loss: 7.417016577619506e-05\n",
      "LOSS train 7.336475308852058e-05 valid 6.23868327238597e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.305221904767677e-07\n",
      "  batch 101 loss: 7.995446721224653e-05\n",
      "  batch 201 loss: 8.371585342956678e-05\n",
      "LOSS train 8.313498369216677e-05 valid 7.0958434662316e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.137062104651704e-07\n",
      "  batch 101 loss: 9.089758644904577e-05\n",
      "  batch 201 loss: 9.525466949071415e-05\n",
      "LOSS train 9.505178053463596e-05 valid 8.159071876434609e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0149937588721513e-06\n",
      "  batch 101 loss: 0.00010393839887342438\n",
      "  batch 201 loss: 0.00010838759319085511\n",
      "LOSS train 0.00010875543221609672 valid 8.94927215995267e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1541864660102874e-06\n",
      "  batch 101 loss: 0.00011758539867400941\n",
      "  batch 201 loss: 0.00012056320186417225\n",
      "LOSS train 0.00012157660144526367 valid 8.425636769970879e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0627322626532987e-06\n",
      "  batch 101 loss: 0.00012701576606531263\n",
      "  batch 201 loss: 0.00012582818112036876\n",
      "LOSS train 0.00012725348534402926 valid 6.305378337856382e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 6.458698044298217e-07\n",
      "  batch 101 loss: 0.00012482355662882583\n",
      "  batch 201 loss: 0.00011800213519336467\n",
      "LOSS train 0.00011949505521930978 valid 5.098952169646509e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.8418375475448556e-07\n",
      "  batch 101 loss: 0.00010906853556662099\n",
      "  batch 201 loss: 9.947639259394236e-05\n",
      "LOSS train 0.0001007422488607314 valid 6.757443043170497e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.3190864365242306e-08\n",
      "  batch 101 loss: 8.83789164981863e-05\n",
      "  batch 201 loss: 8.025497360449663e-05\n",
      "LOSS train 8.097177762187257e-05 valid 9.684599353931844e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.475031568697887e-08\n",
      "  batch 101 loss: 7.174004389980836e-05\n",
      "  batch 201 loss: 6.659949385948494e-05\n",
      "LOSS train 6.671736929049421e-05 valid 0.00012384245928842574\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00012093880213797093\n",
      "  batch 101 loss: 0.9646806882922101\n",
      "  batch 201 loss: 6.132292541224161e-05\n",
      "LOSS train 0.35917493436748277 valid 0.0012431696522980928\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.044122416526079e-06\n",
      "  batch 101 loss: 0.00012224827236423152\n",
      "  batch 201 loss: 6.649125370131515e-05\n",
      "LOSS train 9.020337296493421e-05 valid 5.6871413107728586e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.908036862616427e-07\n",
      "  batch 101 loss: 7.154447554057697e-05\n",
      "  batch 201 loss: 7.480987884719071e-05\n",
      "LOSS train 7.401051689673992e-05 valid 6.298001972027123e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.441836012527346e-07\n",
      "  batch 101 loss: 8.080101093582926e-05\n",
      "  batch 201 loss: 8.467739895877458e-05\n",
      "LOSS train 8.41176907626851e-05 valid 7.193302735686302e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.330728451255709e-07\n",
      "  batch 101 loss: 9.210941140736395e-05\n",
      "  batch 201 loss: 9.656459287043617e-05\n",
      "LOSS train 9.640659892040822e-05 valid 8.272421109722927e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0354010737501085e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00010547161528279503\n",
      "  batch 201 loss: 0.0001099023129171428\n",
      "LOSS train 0.00011033827082289526 valid 8.977686957223341e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1590700160013511e-06\n",
      "  batch 101 loss: 0.00011906608420133579\n",
      "  batch 201 loss: 0.00012172294825575136\n",
      "LOSS train 0.0001227974989294605 valid 8.225703641073778e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.027010439429432e-06\n",
      "  batch 101 loss: 0.0001275183263345525\n",
      "  batch 201 loss: 0.00012562854438670002\n",
      "LOSS train 0.00012707290804262597 valid 6.020973887643777e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.785144458059221e-07\n",
      "  batch 101 loss: 0.00012344196234380432\n",
      "  batch 201 loss: 0.00011598346732398568\n",
      "LOSS train 0.00011746434140213384 valid 5.1632439863169566e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.4208958418748807e-07\n",
      "  batch 101 loss: 0.0001063231535988507\n",
      "  batch 201 loss: 9.670100966786776e-05\n",
      "LOSS train 9.791152031238575e-05 valid 7.134079351089895e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1690181054291315e-08\n",
      "  batch 101 loss: 8.573849820891156e-05\n",
      "  batch 201 loss: 7.798400493015834e-05\n",
      "LOSS train 7.861729268503514e-05 valid 0.00010086280963150784\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.895681847003289e-08\n",
      "  batch 101 loss: 6.994465903289892e-05\n",
      "  batch 201 loss: 6.520586800775164e-05\n",
      "LOSS train 6.525172250307343e-05 valid 0.00012733488983940333\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.8496055640280244e-05\n",
      "  batch 101 loss: 0.2928734255241318\n",
      "  batch 201 loss: 6.563168306456647e-05\n",
      "LOSS train 0.10733705292758232 valid 6.157976167742163e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.116069562267512e-07\n",
      "  batch 101 loss: 8.114465569633467e-05\n",
      "  batch 201 loss: 8.913303702684061e-05\n",
      "LOSS train 8.828908514157271e-05 valid 8.005258132470772e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.870297071756794e-07\n",
      "  batch 101 loss: 0.00010418508487873623\n",
      "  batch 201 loss: 0.00011160450827247814\n",
      "LOSS train 0.00011160552747788816 valid 8.870113379089162e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.140538661275059e-06\n",
      "  batch 101 loss: 0.00012404344800700072\n",
      "  batch 201 loss: 0.0001255551749289907\n",
      "LOSS train 0.00012630568474106862 valid 6.49213106953539e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.876494444441051e-07\n",
      "  batch 101 loss: 0.00012510174736917178\n",
      "  batch 201 loss: 0.00011691163539580885\n",
      "LOSS train 0.00011828165472732028 valid 5.2223254897398874e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.218242323375307e-07\n",
      "  batch 101 loss: 0.00010407468465984948\n",
      "  batch 201 loss: 9.29481143623434e-05\n",
      "LOSS train 9.433928388256018e-05 valid 7.948745042085648e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.928240635606926e-08\n",
      "  batch 101 loss: 8.029685691326449e-05\n",
      "  batch 201 loss: 7.265817510642591e-05\n",
      "LOSS train 7.328001429197597e-05 valid 0.00011266782530583441\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.262314344785409e-07\n",
      "  batch 101 loss: 6.510914702630544e-05\n",
      "  batch 201 loss: 6.131793791269046e-05\n",
      "LOSS train 6.123060435144437e-05 valid 0.0001402565831085667\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.594912075437605e-07\n",
      "  batch 101 loss: 5.81955517645838e-05\n",
      "  batch 201 loss: 5.730279741612776e-05\n",
      "LOSS train 5.673234958256936e-05 valid 0.0001685876486590132\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.1789815441006795e-07\n",
      "  batch 101 loss: 5.772040866645512e-05\n",
      "  batch 201 loss: 5.935882727044373e-05\n",
      "LOSS train 5.841116713047366e-05 valid 0.00020748726092278957\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.578628381248563e-07\n",
      "  batch 101 loss: 6.318129393719119e-05\n",
      "  batch 201 loss: 6.743811010494483e-05\n",
      "LOSS train 6.61863430583093e-05 valid 0.00026251733652316034\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.0261462011840194e-06\n",
      "  batch 101 loss: 7.408472990050541e-05\n",
      "  batch 201 loss: 7.947254925284142e-05\n",
      "LOSS train 7.83183906760614e-05 valid 0.0002974734816234559\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000274862889200449\n",
      "  batch 101 loss: 0.17854669904625553\n",
      "  batch 201 loss: 5.86217780505649e-05\n",
      "LOSS train 0.06552772697499587 valid 1.3157208741176873e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3661410775966942e-08\n",
      "  batch 101 loss: 5.5537193554755504e-06\n",
      "  batch 201 loss: 3.5311410422877997e-06\n",
      "LOSS train 3.876113643626999e-06 valid 4.921767867926974e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.5168925528996624e-08\n",
      "  batch 101 loss: 2.5542121565536035e-06\n",
      "  batch 201 loss: 4.0858291353629285e-06\n",
      "LOSS train 3.0218021590814044e-06 valid 5.842168775416212e-06\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.6996460746886442e-08\n",
      "  batch 101 loss: 6.253720950866182e-06\n",
      "  batch 201 loss: 4.777061331679988e-06\n",
      "LOSS train 5.356388496676741e-06 valid 2.0101098925806582e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.4520955776097254e-07\n",
      "  batch 101 loss: 7.853277849392271e-06\n",
      "  batch 201 loss: 1.3455157348403191e-05\n",
      "LOSS train 1.2900367951693798e-05 valid 5.423084985523019e-06\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.3683427318464964e-08\n",
      "  batch 101 loss: 1.635662337548638e-05\n",
      "  batch 201 loss: 9.889369247204627e-06\n",
      "LOSS train 1.6529834952759524e-05 valid 4.9044916522689164e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.367993435356766e-07\n",
      "  batch 101 loss: 1.030048619355739e-05\n",
      "  batch 201 loss: 5.46528100628052e-06\n",
      "LOSS train 1.0211011761127785e-05 valid 6.221525836735964e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.9811342250905e-08\n",
      "  batch 101 loss: 5.355725720761484e-06\n",
      "  batch 201 loss: 5.432791884345533e-06\n",
      "LOSS train 1.150499322977294e-05 valid 8.78206265042536e-06\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.8003270169137974e-08\n",
      "  batch 101 loss: 5.1515135220370215e-06\n",
      "  batch 201 loss: 2.4175450553798327e-06\n",
      "LOSS train 1.7566953751916268e-05 valid 0.0001743625762173906\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.4387224402744325e-06\n",
      "  batch 101 loss: 0.00039614514940637945\n",
      "  batch 201 loss: 3.0616855086122995e-05\n",
      "LOSS train 0.00016489684536271862 valid 7.816815923433751e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.7260234699278954e-08\n",
      "  batch 101 loss: 3.1752468069612404e-05\n",
      "  batch 201 loss: 3.1423468936395696e-05\n",
      "LOSS train 3.100829225654157e-05 valid 8.526918827556074e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.0941762361180735e-08\n",
      "  batch 101 loss: 3.1766631369123385e-05\n",
      "  batch 201 loss: 3.1737223173422537e-05\n",
      "LOSS train 3.149316953988504e-05 valid 7.662679126951844e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.05 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005391949787735939\n",
      "  batch 101 loss: 0.1932814388803672\n",
      "  batch 201 loss: 0.0014408005190489348\n",
      "LOSS train 0.07155375660503967 valid 2.6891651941696182e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4584317796106915e-07\n",
      "  batch 101 loss: 1.4660673914193012e-05\n",
      "  batch 201 loss: 1.152766747509304e-05\n",
      "LOSS train 1.1895022995027803e-05 valid 3.160653250233736e-06\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.770303116354626e-08\n",
      "  batch 101 loss: 7.19889452670941e-05\n",
      "  batch 201 loss: 0.00012410539679422072\n",
      "LOSS train 0.00010644811334634222 valid 6.839269190095365e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.615430513396859e-07\n",
      "  batch 101 loss: 0.00012601059529856684\n",
      "  batch 201 loss: 0.00011751277217399548\n",
      "LOSS train 0.00011874032042916098 valid 5.272274574963376e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.090190744434949e-07\n",
      "  batch 101 loss: 0.00010254820840600587\n",
      "  batch 201 loss: 9.051639543770306e-05\n",
      "LOSS train 9.205278402948315e-05 valid 8.490106120007113e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.007769464602461e-08\n",
      "  batch 101 loss: 7.711391486509456e-05\n",
      "  batch 201 loss: 6.972986299842887e-05\n",
      "LOSS train 7.032772957858463e-05 valid 0.00011959367839153856\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.5710280422354116e-07\n",
      "  batch 101 loss: 6.273878633464847e-05\n",
      "  batch 201 loss: 5.9599666619760684e-05\n",
      "LOSS train 5.942150214017628e-05 valid 0.00014815045869909227\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.0185019568307324e-07\n",
      "  batch 101 loss: 5.7420268167334146e-05\n",
      "  batch 201 loss: 5.7312776981888194e-05\n",
      "LOSS train 5.6634866572044334e-05 valid 0.00018009766063187271\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.866249219048768e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 5.892128521054474e-05\n",
      "  batch 201 loss: 6.154978421136547e-05\n",
      "LOSS train 6.048260603113907e-05 valid 0.0002264016366098076\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 7.812904368620366e-07\n",
      "  batch 101 loss: 6.677337329733745e-05\n",
      "  batch 201 loss: 7.197161154067545e-05\n",
      "LOSS train 7.066478575939822e-05 valid 0.000283797417068854\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1750494013540447e-06\n",
      "  batch 101 loss: 7.884229680257704e-05\n",
      "  batch 201 loss: 8.305537828391607e-05\n",
      "LOSS train 8.222954664187199e-05 valid 0.00028204498812556267\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.162673652288504e-06\n",
      "  batch 101 loss: 8.25014817041847e-05\n",
      "  batch 201 loss: 7.801626541549922e-05\n",
      "LOSS train 7.9079615034894e-05 valid 0.00017876170750241727\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0021250288188457487\n",
      "  batch 101 loss: 0.1457405211861942\n",
      "  batch 201 loss: 7.256922897795448e-05\n",
      "LOSS train 0.05421259179640082 valid 7.271080539794639e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.442533726338297e-07\n",
      "  batch 101 loss: 9.739741945281821e-05\n",
      "  batch 201 loss: 0.00010889468900359134\n",
      "LOSS train 0.0001080529216919569 valid 8.770883141551167e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1326952517265455e-06\n",
      "  batch 101 loss: 0.00012570940687510303\n",
      "  batch 201 loss: 0.00012593824292366661\n",
      "LOSS train 0.00012617978018253395 valid 5.5185999372042716e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.381976759759709e-07\n",
      "  batch 101 loss: 0.00011870951484979742\n",
      "  batch 201 loss: 0.00010642364341038047\n",
      "LOSS train 0.00010797001589828022 valid 6.537693843711168e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.965663386727101e-08\n",
      "  batch 101 loss: 8.914460938171941e-05\n",
      "  batch 201 loss: 7.857272847445528e-05\n",
      "LOSS train 7.982807570249448e-05 valid 0.00010449787077959627\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.254576070816256e-08\n",
      "  batch 101 loss: 6.79936214692134e-05\n",
      "  batch 201 loss: 6.305975570398914e-05\n",
      "LOSS train 6.316653478266151e-05 valid 0.00013607849541585892\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.3793947548256256e-07\n",
      "  batch 101 loss: 5.879872560058175e-05\n",
      "  batch 201 loss: 5.7590319235600874e-05\n",
      "LOSS train 5.706338673015345e-05 valid 0.00016590923769399524\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.0528546378482135e-07\n",
      "  batch 101 loss: 5.775354580464409e-05\n",
      "  batch 201 loss: 5.918664550108588e-05\n",
      "LOSS train 5.837596403740303e-05 valid 0.00020753323042299598\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 6.526370998471975e-07\n",
      "  batch 101 loss: 6.315179121543223e-05\n",
      "  batch 201 loss: 6.757830296123757e-05\n",
      "LOSS train 6.635500118376272e-05 valid 0.0002643996267579496\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.045761746354401e-06\n",
      "  batch 101 loss: 7.456405122638899e-05\n",
      "  batch 201 loss: 7.989638194203508e-05\n",
      "LOSS train 7.883914484479577e-05 valid 0.00029633575468324125\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2663641246035696e-06\n",
      "  batch 101 loss: 8.346792970769457e-05\n",
      "  batch 201 loss: 8.240254710017324e-05\n",
      "LOSS train 8.269915711841745e-05 valid 0.0002165656042052433\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.214739889604971e-07\n",
      "  batch 101 loss: 7.326315845148202e-05\n",
      "  batch 201 loss: 6.474018463507037e-05\n",
      "LOSS train 6.675612945669662e-05 valid 0.00012289147707633674\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.269443918019533e-05\n",
      "  batch 101 loss: 0.0035024867136689863\n",
      "  batch 201 loss: 6.351085662799961e-05\n",
      "LOSS train 0.0013432494171279642 valid 0.0002573321107774973\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.903460886562243e-07\n",
      "  batch 101 loss: 7.114330399872415e-05\n",
      "  batch 201 loss: 4.726049801320187e-05\n",
      "LOSS train 5.3896953913230416e-05 valid 7.425647345371544e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2955833881278522e-08\n",
      "  batch 101 loss: 3.56383546034067e-05\n",
      "  batch 201 loss: 3.351965101614951e-05\n",
      "LOSS train 3.404363488513539e-05 valid 5.4227482905844226e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.175583388947417e-08\n",
      "  batch 101 loss: 3.495314205508748e-05\n",
      "  batch 201 loss: 3.365121550928052e-05\n",
      "LOSS train 3.3048165565500376e-05 valid 5.2432791562750936e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1610512956394814e-07\n",
      "  batch 101 loss: 3.022991495072347e-05\n",
      "  batch 201 loss: 2.8988127999127754e-05\n",
      "LOSS train 2.8832300671827284e-05 valid 5.928532118559815e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.654481133708032e-08\n",
      "  batch 101 loss: 2.8793573648044912e-05\n",
      "  batch 201 loss: 2.9186928480839923e-05\n",
      "LOSS train 2.8681748827800415e-05 valid 7.151421596063301e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1711927072610706e-08\n",
      "  batch 101 loss: 3.1066431821500375e-05\n",
      "  batch 201 loss: 3.1328055054018475e-05\n",
      "LOSS train 3.073518240563606e-05 valid 8.617244748165831e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.3124961191788315e-08\n",
      "  batch 101 loss: 3.179800648183573e-05\n",
      "  batch 201 loss: 3.1902220836173e-05\n",
      "LOSS train 3.176541936235624e-05 valid 7.342662138398737e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.2409192322593299e-08\n",
      "  batch 101 loss: 3.4548424851550406e-05\n",
      "  batch 201 loss: 3.687015639059155e-05\n",
      "LOSS train 3.643789518269382e-05 valid 6.035373007762246e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.122402176813921e-08\n",
      "  batch 101 loss: 4.2030967215964664e-05\n",
      "  batch 201 loss: 4.478351939553704e-05\n",
      "LOSS train 4.4271459264914134e-05 valid 5.245463762548752e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1554060620255769e-07\n",
      "  batch 101 loss: 4.883247491079601e-05\n",
      "  batch 201 loss: 4.965790540268244e-05\n",
      "LOSS train 4.9651467042598094e-05 valid 5.099856207380071e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.830443216022104e-07\n",
      "  batch 101 loss: 5.160904030731217e-05\n",
      "  batch 201 loss: 5.126309644197136e-05\n",
      "LOSS train 5.160532189034502e-05 valid 5.088803300168365e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.025516872294246e-06\n",
      "  batch 101 loss: 0.03164615095056092\n",
      "  batch 201 loss: 6.388950911741631e-05\n",
      "LOSS train 0.011632915021042356 valid 0.0002052849595202133\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.437436968553812e-07\n",
      "  batch 101 loss: 6.622692153825937e-05\n",
      "  batch 201 loss: 7.904082936079249e-05\n",
      "LOSS train 7.576705625823483e-05 valid 0.00024298079370055348\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.923393033910542e-07\n",
      "  batch 101 loss: 7.376082191512979e-05\n",
      "  batch 201 loss: 5.705544988472866e-05\n",
      "LOSS train 6.0912967963024407e-05 valid 9.051043161889538e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.476927188079571e-08\n",
      "  batch 101 loss: 4.17254674528067e-05\n",
      "  batch 201 loss: 3.6567628553711985e-05\n",
      "LOSS train 3.7787181664804845e-05 valid 6.800786650273949e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.2807225857613958e-08\n",
      "  batch 101 loss: 3.460719986435379e-05\n",
      "  batch 201 loss: 3.357565075134517e-05\n",
      "LOSS train 3.371753156037006e-05 valid 5.397302084020339e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.556453394703567e-08\n",
      "  batch 101 loss: 3.504541553184026e-05\n",
      "  batch 201 loss: 3.408876845242048e-05\n",
      "LOSS train 3.353826152756866e-05 valid 5.15873653057497e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.4400969121197703e-07\n",
      "  batch 101 loss: 3.148555235725325e-05\n",
      "  batch 201 loss: 2.9863040252848806e-05\n",
      "LOSS train 2.9730024470897525e-05 valid 5.6480621424270794e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.6193239288404586e-08\n",
      "  batch 101 loss: 2.879947928704496e-05\n",
      "  batch 201 loss: 2.8623786404864405e-05\n",
      "LOSS train 2.821338146248062e-05 valid 6.32222872809507e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.0943523395544616e-08\n",
      "  batch 101 loss: 2.9489021154063268e-05\n",
      "  batch 201 loss: 3.0117180037336767e-05\n",
      "LOSS train 2.9518888665456087e-05 valid 7.99238623585552e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.0008433239127045e-08\n",
      "  batch 101 loss: 3.1773456870212156e-05\n",
      "  batch 201 loss: 3.139032894750926e-05\n",
      "LOSS train 3.1048648283093004e-05 valid 8.319244807353243e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.627171170388465e-08\n",
      "  batch 101 loss: 3.195101512574183e-05\n",
      "  batch 201 loss: 3.2547615725206923e-05\n",
      "LOSS train 3.2323618257085287e-05 valid 7.095620821928605e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.1668026900224504e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 3.562702974591048e-05\n",
      "  batch 201 loss: 3.808771968976998e-05\n",
      "LOSS train 3.762362173751298e-05 valid 5.8741810789797455e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.7699245624244216e-05\n",
      "  batch 101 loss: 8.977184116325697\n",
      "  batch 201 loss: 0.0005316907432495555\n",
      "LOSS train 3.288857172939639 valid 7.297995034605265e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.536313544027507e-07\n",
      "  batch 101 loss: 4.398570206888053e-05\n",
      "  batch 201 loss: 3.326243661604167e-05\n",
      "LOSS train 3.7190280048624835e-05 valid 5.202316970098764e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2787882042175625e-07\n",
      "  batch 101 loss: 3.379693359590874e-05\n",
      "  batch 201 loss: 3.175550177004993e-05\n",
      "LOSS train 3.1532500865272504e-05 valid 5.423921174951829e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.158660421031527e-08\n",
      "  batch 101 loss: 2.9301470208906723e-05\n",
      "  batch 201 loss: 2.8591593270448357e-05\n",
      "LOSS train 2.8298411810794523e-05 valid 6.07413167017512e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.9519123927457257e-08\n",
      "  batch 101 loss: 2.8735983447631953e-05\n",
      "  batch 201 loss: 2.9074789738103844e-05\n",
      "LOSS train 2.8554377943824516e-05 valid 7.060517236823216e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1679918543450184e-08\n",
      "  batch 101 loss: 3.053372603460502e-05\n",
      "  batch 201 loss: 3.086349548709677e-05\n",
      "LOSS train 3.0295014492395362e-05 valid 8.548989717382938e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.1467029657505916e-08\n",
      "  batch 101 loss: 3.1823546536315916e-05\n",
      "  batch 201 loss: 3.1299619467404225e-05\n",
      "LOSS train 3.101676761612381e-05 valid 8.461390098091215e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.9414288746920648e-08\n",
      "  batch 101 loss: 3.170788002847757e-05\n",
      "  batch 201 loss: 3.1557105809554284e-05\n",
      "LOSS train 3.133421117500959e-05 valid 7.717245171079412e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.591394152455905e-08\n",
      "  batch 101 loss: 3.265190549427643e-05\n",
      "  batch 201 loss: 3.318729111242646e-05\n",
      "LOSS train 3.2882053958165824e-05 valid 7.073240703903139e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1672012760755024e-08\n",
      "  batch 101 loss: 3.486365362732613e-05\n",
      "  batch 201 loss: 3.580780419497387e-05\n",
      "LOSS train 3.5478314459026846e-05 valid 6.500418385257944e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.6822881434563897e-08\n",
      "  batch 101 loss: 3.78198628516202e-05\n",
      "  batch 201 loss: 3.89739457983751e-05\n",
      "LOSS train 3.869865665074397e-05 valid 5.960317866993137e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.4860627238231246e-08\n",
      "  batch 101 loss: 4.1377694232664906e-05\n",
      "  batch 201 loss: 4.2665366100891335e-05\n",
      "LOSS train 4.250540541490755e-05 valid 5.46949559065979e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.05 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001021340861916542\n",
      "  batch 101 loss: 24.599241032528226\n",
      "  batch 201 loss: 0.0032947002328000963\n",
      "LOSS train 9.012755332890755 valid 0.0006757475784979761\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.3904349654912947e-05\n",
      "  batch 101 loss: 0.002745658126659691\n",
      "  batch 201 loss: 0.002310765892616473\n",
      "LOSS train 0.0024214341239526104 valid 0.00022696952510159463\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.434511436149478e-05\n",
      "  batch 101 loss: 0.0019892865070141852\n",
      "  batch 201 loss: 0.0016432902790256775\n",
      "LOSS train 0.0016785190004050296 valid 0.00047284827451221645\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.631733410060406e-06\n",
      "  batch 101 loss: 0.0011617867730092258\n",
      "  batch 201 loss: 0.0009667508429265581\n",
      "LOSS train 0.000993446953233925 valid 0.00015780470857862383\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0465383529663087e-05\n",
      "  batch 101 loss: 0.0006770703810616396\n",
      "  batch 201 loss: 0.0005367361754179\n",
      "LOSS train 0.0005584530239829269 valid 2.250755460408982e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.8287101779133084e-06\n",
      "  batch 101 loss: 0.000311732799600577\n",
      "  batch 201 loss: 0.00024790034993202423\n",
      "LOSS train 0.00025285858559765897 valid 1.7974442016566172e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.5366713341791183e-06\n",
      "  batch 101 loss: 0.00014470697940851095\n",
      "  batch 201 loss: 0.0001042585440518451\n",
      "LOSS train 0.00011282412340953449 valid 7.276819815160707e-06\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.664750592084601e-07\n",
      "  batch 101 loss: 6.109765136898204e-05\n",
      "  batch 201 loss: 4.0366165585510316e-05\n",
      "LOSS train 4.465690689201291e-05 valid 1.0462477803230286e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.6319938367814757e-07\n",
      "  batch 101 loss: 2.3186937960417707e-05\n",
      "  batch 201 loss: 1.8400867857053528e-05\n",
      "LOSS train 1.9343409022463347e-05 valid 4.779080882144626e-06\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.7697642508428543e-07\n",
      "  batch 101 loss: 2.992856272840072e-05\n",
      "  batch 201 loss: 2.2352334411266384e-05\n",
      "LOSS train 3.600259947213186e-05 valid 5.492052514455281e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.3209922296227887e-07\n",
      "  batch 101 loss: 6.781437179142813e-05\n",
      "  batch 201 loss: 6.914972466347536e-05\n",
      "LOSS train 6.842293371250273e-05 valid 5.723909998778254e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.01105678267777e-07\n",
      "  batch 101 loss: 7.133108315883874e-05\n",
      "  batch 201 loss: 7.294566411019332e-05\n",
      "LOSS train 7.227830294487787e-05 valid 5.998216147418134e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003384313732385635\n",
      "  batch 101 loss: 51.80777800318785\n",
      "  batch 201 loss: 0.006388544631190598\n",
      "LOSS train 18.982063771176048 valid 0.0007850107504054904\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.9919183366000654e-05\n",
      "  batch 101 loss: 0.005994812587741763\n",
      "  batch 201 loss: 0.005023162318393588\n",
      "LOSS train 0.0051176021180044 valid 0.0003429807838983834\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.7306308038532733e-05\n",
      "  batch 101 loss: 0.0033402827801182868\n",
      "  batch 201 loss: 0.0025224513467401264\n",
      "LOSS train 0.0026972453295843394 valid 0.00013523874804377556\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.690894248895347e-05\n",
      "  batch 101 loss: 0.0016082906018709763\n",
      "  batch 201 loss: 0.0011777998338220641\n",
      "LOSS train 0.0012566250204808 valid 5.099122427054681e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.32351210899651e-06\n",
      "  batch 101 loss: 0.0006498723625554704\n",
      "  batch 201 loss: 0.00047155790438409897\n",
      "LOSS train 0.0005027575218144313 valid 5.1673283451236784e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.4579893690533936e-06\n",
      "  batch 101 loss: 0.00026833416457520796\n",
      "  batch 201 loss: 0.00019815112274955028\n",
      "LOSS train 0.00021175400188140275 valid 5.238992162048817e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.900182340061293e-07\n",
      "  batch 101 loss: 0.00012852978317823727\n",
      "  batch 201 loss: 0.00010650182730387314\n",
      "LOSS train 0.00011209697024221916 valid 5.342649092199281e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.397736094892025e-07\n",
      "  batch 101 loss: 8.737729354834301e-05\n",
      "  batch 201 loss: 8.114025611575926e-05\n",
      "LOSS train 8.249070537197144e-05 valid 5.439841697807424e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.548476474359631e-07\n",
      "  batch 101 loss: 7.318356184441654e-05\n",
      "  batch 201 loss: 7.360347048233962e-05\n",
      "LOSS train 7.238005517990795e-05 valid 5.5261440138565376e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.840399560634979e-07\n",
      "  batch 101 loss: 7.011165611402248e-05\n",
      "  batch 201 loss: 6.945472104234796e-05\n",
      "LOSS train 6.969243569263919e-05 valid 5.5730517487972975e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.847444506594912e-07\n",
      "  batch 101 loss: 7.020492043920967e-05\n",
      "  batch 201 loss: 6.976447603847191e-05\n",
      "LOSS train 6.935940886943994e-05 valid 5.630912710330449e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.465584788704291e-07\n",
      "  batch 101 loss: 7.066786517043511e-05\n",
      "  batch 201 loss: 7.090726921433089e-05\n",
      "LOSS train 7.024212375624331e-05 valid 5.7306726375827566e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00023901620879769326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 18.654851467907427\n",
      "  batch 201 loss: 0.011866285437718034\n",
      "LOSS train 6.839340326047909 valid 0.002683232305571437\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.7521892227232453e-05\n",
      "  batch 101 loss: 0.0033824505738448353\n",
      "  batch 201 loss: 0.0013175218482501805\n",
      "LOSS train 0.0018948695607246293 valid 0.00020959244284313172\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.8702413914725185e-06\n",
      "  batch 101 loss: 0.00025097807207203005\n",
      "  batch 201 loss: 0.00012574728985782714\n",
      "LOSS train 0.00016087770701156615 valid 6.321914406726137e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.631629755953327e-07\n",
      "  batch 101 loss: 6.762736487871735e-05\n",
      "  batch 201 loss: 6.310342363576638e-05\n",
      "LOSS train 6.3614625295296e-05 valid 5.344205055735074e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.5951088648289444e-07\n",
      "  batch 101 loss: 6.0984025167272194e-05\n",
      "  batch 201 loss: 6.0867223392051526e-05\n",
      "LOSS train 6.033008594719195e-05 valid 5.2985942602390423e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.582498538889922e-07\n",
      "  batch 101 loss: 6.154466896077793e-05\n",
      "  batch 201 loss: 6.212378939380869e-05\n",
      "LOSS train 6.130357530806385e-05 valid 5.3391657274914905e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.6467481550062076e-07\n",
      "  batch 101 loss: 6.266273380788334e-05\n",
      "  batch 201 loss: 6.354663260026428e-05\n",
      "LOSS train 6.271302918188193e-05 valid 5.5604403314646333e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.299913052818738e-07\n",
      "  batch 101 loss: 6.472293654042005e-05\n",
      "  batch 201 loss: 6.497788863271125e-05\n",
      "LOSS train 6.459542635559127e-05 valid 5.529691043193452e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.3630701838992537e-07\n",
      "  batch 101 loss: 6.649067029684374e-05\n",
      "  batch 201 loss: 6.736827093845931e-05\n",
      "LOSS train 6.672718482716582e-05 valid 5.6768840295262635e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.731857916340232e-07\n",
      "  batch 101 loss: 6.875042820865929e-05\n",
      "  batch 201 loss: 6.963690816064628e-05\n",
      "LOSS train 6.915173761103604e-05 valid 5.7549688790459186e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.047834929428063e-07\n",
      "  batch 101 loss: 7.158636617532466e-05\n",
      "  batch 201 loss: 7.19321083261093e-05\n",
      "LOSS train 7.18265544262297e-05 valid 5.9600177337415516e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.772488657385111e-07\n",
      "  batch 101 loss: 7.405702242067491e-05\n",
      "  batch 201 loss: 7.622870053864972e-05\n",
      "LOSS train 7.51761834409004e-05 valid 6.299835513345897e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.0601225551217794e-05\n",
      "  batch 101 loss: 2.765321310376021\n",
      "  batch 201 loss: 0.0006826626069232588\n",
      "LOSS train 1.0132302131064117 valid 5.133371814736165e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.8341553843347355e-07\n",
      "  batch 101 loss: 5.897296674447716e-05\n",
      "  batch 201 loss: 6.0518454338307494e-05\n",
      "LOSS train 5.964333967722768e-05 valid 5.30994548171293e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.672690218081698e-07\n",
      "  batch 101 loss: 6.318804898910457e-05\n",
      "  batch 201 loss: 6.494104189187056e-05\n",
      "LOSS train 6.408987563343997e-05 valid 5.5162083299364895e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.412846465129405e-07\n",
      "  batch 101 loss: 6.792307575778978e-05\n",
      "  batch 201 loss: 6.994740225763962e-05\n",
      "LOSS train 6.917329438449634e-05 valid 5.834389230585657e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.315463931765407e-07\n",
      "  batch 101 loss: 7.351582002229406e-05\n",
      "  batch 201 loss: 7.598554240757949e-05\n",
      "LOSS train 7.52975100033007e-05 valid 6.305788701865822e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.459627911681309e-07\n",
      "  batch 101 loss: 8.043719224588131e-05\n",
      "  batch 201 loss: 8.342437766259536e-05\n",
      "LOSS train 8.290721364777204e-05 valid 6.98049261700362e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.904785888968036e-07\n",
      "  batch 101 loss: 8.905775004905081e-05\n",
      "  batch 201 loss: 9.258751283823585e-05\n",
      "LOSS train 9.235777379850307e-05 valid 7.850233669159934e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.5850569778122e-07\n",
      "  batch 101 loss: 9.960988120383263e-05\n",
      "  batch 201 loss: 0.00010347274323578404\n",
      "LOSS train 0.00010369519299817575 valid 8.711355621926486e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1129858467029407e-06\n",
      "  batch 101 loss: 0.00011161489249047918\n",
      "  batch 201 loss: 0.00011507420152298664\n",
      "LOSS train 0.0001158600013747678 valid 8.943497232394293e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.153193079517223e-06\n",
      "  batch 101 loss: 0.00012280208613901777\n",
      "  batch 201 loss: 0.00012404832879326478\n",
      "LOSS train 0.00012538494576161418 valid 7.73240317357704e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 9.364985453430564e-07\n",
      "  batch 101 loss: 0.0001278582285669927\n",
      "  batch 201 loss: 0.00012470624268530627\n",
      "LOSS train 0.00012626256524682727 valid 5.658384907292202e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.816138607566245e-07\n",
      "  batch 101 loss: 0.00012116890641891587\n",
      "  batch 201 loss: 0.00011192225084869279\n",
      "LOSS train 0.0001142640304399823 valid 5.284738654154353e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.0025/4*4**i for i in range(4)]\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "nbs_e = [4,8,12]#,4,8]\n",
    "i=0\n",
    "nbs_hidden = [0,1,2,3]\n",
    "dors = [0,0.05,0.1,0.2,0.4]\n",
    "results = pd.DataFrame()\n",
    "folder_to_save = \"RTS24_AC_12w_split_by_exec_nl\"\n",
    "for nb_e in nbs_e:\n",
    "    for lr in learning_rates:\n",
    "        for nb_hidden in nbs_hidden: \n",
    "            for dor in dors:\n",
    "                m = NN_classes.create_model(nb_hidden,d_ft_in['train'].shape[1],dropout_ratio= dor)\n",
    "                m_name = f\"OE_{nb_hidden}h_{nb_e}e_{lr}lr_{dor}dor\"\n",
    "                optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "                train_loss = training_methods.train_multiple_epochs(nb_e,m,training_loader,validation_loader,loss_fn,optimizer,m_name,folder_to_save)\n",
    "\n",
    "                saved_models = dict()\n",
    "\n",
    "                for mt in [\"min_val\",\"all_epochs\"]:\n",
    "                    path = f\"trained_models/{folder_to_save}/{mt}/model_{m_name}.pth\"\n",
    "\n",
    "\n",
    "                    model = m\n",
    "                    m.load_state_dict(torch.load(path))\n",
    "                    m.eval()\n",
    "\n",
    "                    test_predictions = m(d_ft_in[\"test\"].float())\n",
    "                    test_loss = loss_fn(test_predictions.squeeze(),d_ft_out[\"test\"])\n",
    "\n",
    "                    train_predictions = m(d_ft_in[\"train\"].float())\n",
    "                    train_loss = loss_fn(train_predictions.squeeze(),d_ft_out[\"train\"])\n",
    "\n",
    "                    validation_prediction = m(d_ft_in[\"val\"].float())\n",
    "                    validation_loss = loss_fn(validation_prediction.squeeze(),d_ft_out[\"val\"])\n",
    "\n",
    "                    if mt == \"min_val\": \n",
    "                        min_val = True\n",
    "                    else: \n",
    "                        min_val = False\n",
    "\n",
    "                    r = pd.DataFrame({\"Model_type\": nb_hidden,\n",
    "                                      \"Min_val\":min_val,\n",
    "                                      \"Epochs\": nb_e,\n",
    "                                      \"Lr\":lr,\n",
    "                                      \"Dor\": dor,\n",
    "                                      \"Tr_l\":train_loss.item(),\n",
    "                                      \"Te_l\":test_loss.item(),\n",
    "                                      \"V_l\": validation_loss.item()}\n",
    "                                     ,index = [i]\n",
    "                    )\n",
    "                    i+=1\n",
    "                    results = pd.concat([results,r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe247f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"Loss_results_csv/20Exec_split_by_exec_new_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea933f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (results.Epochs == 12)  & (results.Model_type != 0) \n",
    "sns.boxplot(y = \"Te_l\",x=\"Dor\",data = results[f],hue = \"Min_val\")\n",
    "plt.savefig(\"Figures/Split_by_exec/Min_val_effect_Testloss_fDor.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a759efd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f =  (results.Model_type == 0) & (results.Min_val == True)\n",
    "sns.boxplot(y = \"V_l\",x=\"Epochs\",data = results[f],hue = \"Lr\")\n",
    "plt.savefig(\"Figures/Split_by_exec/Lr_effect_Testloss_fEpochs.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
