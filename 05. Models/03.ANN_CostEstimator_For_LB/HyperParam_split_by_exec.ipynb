{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cb899fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataLoading\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import NN_classes\n",
    "import training_methods\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "061f4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "folder = \"../Data/RTS24_AC_12w\"\n",
    "all_executions = DataLoading.list_executions(folder=\"../Data/RTS24_AC_12w\",per = period,sc=sc)\n",
    "executions = all_executions[1:20]\n",
    "te_s = 0.3\n",
    "val_s = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aa0d046",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_f_sc01_Network_Line_In_N_101_N_102_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_101_N_103_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_101_N_105_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_102_N_104_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_102_N_106_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_103_N_109_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_103_N_124_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_104_N_109_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_105_N_110_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_106_N_108_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_106_N_110_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_107_N_108_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_108_N_109_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_108_N_110_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_109_N_111_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_109_N_112_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_110_N_111_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_110_N_112_cac1_2030.csv\n",
      "1227\n",
      "input_f_sc01_Network_Line_In_N_111_N_113_cac1_2030.csv\n",
      "1227\n"
     ]
    }
   ],
   "source": [
    "dfs_in,dfs_out = DataLoading.load_data(folder,executions,period,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6671c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in,ts_out =  DataLoading.split_tr_val_te_by_exec(dfs_in,dfs_out,executions,te_s,val_s,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93163ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ft_in, d_ft_out = DataLoading.concat_and_normalize_split_by_exec(ts_in,ts_out,executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f72c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(d_ft_in['train'].float(), d_ft_out['train'].float())\n",
    "validation = TensorDataset(d_ft_in['val'].float(), d_ft_out['val'].float())\n",
    "\n",
    "training_loader = DataLoader(train,batch_size=64)\n",
    "validation_loader = DataLoader(train,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d94194d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.2201406061649322e-05\n",
      "  batch 101 loss: 0.1204996619992744\n",
      "  batch 201 loss: 0.000164767281494278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.044235667404096846 valid 0.0006014840328134596\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.681292630266398e-06\n",
      "  batch 101 loss: 0.00027236131966674294\n",
      "  batch 201 loss: 5.8436349319208604e-05\n",
      "LOSS train 0.00015514195799257586 valid 0.0004910084535367787\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.016830353066325e-06\n",
      "  batch 101 loss: 0.0003662908967976364\n",
      "  batch 201 loss: 8.31776264385553e-05\n",
      "LOSS train 0.0002038881896868798 valid 0.000458039139630273\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.595936286728829e-06\n",
      "  batch 101 loss: 0.00039822076774726156\n",
      "  batch 201 loss: 6.36935441548303e-05\n",
      "LOSS train 0.00021898659113981595 valid 0.0004524539690464735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([13104])) that is different to the input size (torch.Size([13104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([17472])) that is different to the input size (torch.Size([17472, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([10920])) that is different to the input size (torch.Size([10920, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.842912338674069e-05\n",
      "  batch 101 loss: 0.13347931323805823\n",
      "  batch 201 loss: 0.002807125097606331\n",
      "LOSS train 0.05038690856477116 valid 0.00041876404429785907\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.8133392333984375e-05\n",
      "  batch 101 loss: 0.0008269710635067895\n",
      "  batch 201 loss: 0.00022606664686463773\n",
      "LOSS train 0.0004243751014995384 valid 0.00012009174679405987\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.5960688991472126e-06\n",
      "  batch 101 loss: 0.00010940661964923492\n",
      "  batch 201 loss: 2.719192711992946e-05\n",
      "LOSS train 6.075725839151353e-05 valid 5.878495721844956e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.139530988642946e-06\n",
      "  batch 101 loss: 5.7172719693880935e-05\n",
      "  batch 201 loss: 1.177490160898742e-05\n",
      "LOSS train 2.941249779110883e-05 valid 4.8474139475729316e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00021132118999958038\n",
      "  batch 101 loss: 0.12281605010153726\n",
      "  batch 201 loss: 0.0024041859491262586\n",
      "LOSS train 0.04610893017692993 valid 5.767903712694533e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.107744993641972e-06\n",
      "  batch 101 loss: 0.00021317482201993698\n",
      "  batch 201 loss: 3.165776637615636e-05\n",
      "LOSS train 9.704114034940466e-05 valid 6.019377178745344e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0995633056154474e-06\n",
      "  batch 101 loss: 2.615330568232821e-05\n",
      "  batch 201 loss: 2.9221105767192056e-05\n",
      "LOSS train 2.8376381838565328e-05 valid 4.762804746860638e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.399226104898844e-07\n",
      "  batch 101 loss: 1.6409299173574255e-05\n",
      "  batch 201 loss: 2.1262053255668434e-05\n",
      "LOSS train 1.7710673806245074e-05 valid 3.767469752347097e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005694927647709846\n",
      "  batch 101 loss: 0.11674428256461397\n",
      "  batch 201 loss: 0.001074377542754519\n",
      "LOSS train 0.04338519808827299 valid 4.539738074527122e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.699344082036986e-07\n",
      "  batch 101 loss: 4.1515618740959325e-05\n",
      "  batch 201 loss: 2.5087330984661095e-05\n",
      "LOSS train 3.2841405957267374e-05 valid 9.73974892986007e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.3706408430589363e-07\n",
      "  batch 101 loss: 3.162173138662183e-05\n",
      "  batch 201 loss: 4.6246214287748445e-05\n",
      "LOSS train 4.017932709984129e-05 valid 4.703203376266174e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.6664638173533605e-07\n",
      "  batch 101 loss: 3.2594616500318806e-05\n",
      "  batch 201 loss: 2.752985032657307e-05\n",
      "LOSS train 2.871700503636107e-05 valid 3.759422179427929e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.4298338210210203e-05\n",
      "  batch 101 loss: 0.05435704511600306\n",
      "  batch 201 loss: 0.0036871860510154873\n",
      "LOSS train 0.021272172078496184 valid 4.470661224331707e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.972717311422457e-08\n",
      "  batch 101 loss: 1.687234599103249e-05\n",
      "  batch 201 loss: 8.54286685950001e-06\n",
      "LOSS train 1.1108537575038621e-05 valid 3.9394264604197815e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.3385971871903167e-07\n",
      "  batch 101 loss: 6.301787404936476e-06\n",
      "  batch 201 loss: 4.843818752817697e-06\n",
      "LOSS train 5.109803215414903e-06 valid 4.264781819074415e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.625729030114599e-07\n",
      "  batch 101 loss: 3.8806713587291595e-06\n",
      "  batch 201 loss: 2.3555768774485842e-06\n",
      "LOSS train 2.9903229991465868e-06 valid 4.423868813319132e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0009146004170179367\n",
      "  batch 101 loss: 0.010039192564145196\n",
      "  batch 201 loss: 0.0012969904128476628\n",
      "LOSS train 0.0045152805432602215 valid 6.864013994345441e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.666554301977158e-07\n",
      "  batch 101 loss: 9.093197525771756e-05\n",
      "  batch 201 loss: 0.00010073051958613633\n",
      "LOSS train 0.00010006320455857302 valid 8.82947861100547e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.13351023173891e-06\n",
      "  batch 101 loss: 0.00011766534877949653\n",
      "  batch 201 loss: 0.00012269802142213847\n",
      "LOSS train 0.00012299149909077 valid 7.52347768866457e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.971268835011869e-07\n",
      "  batch 101 loss: 0.00012768091637838097\n",
      "  batch 201 loss: 0.00012251137409094781\n",
      "LOSS train 0.00012377440874051517 valid 5.136526669957675e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.16364274173975e-05\n",
      "  batch 101 loss: 0.03963006535464046\n",
      "  batch 201 loss: 6.081381900912675e-05\n",
      "LOSS train 0.0145777958060658 valid 5.451550896395929e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.18785675719846e-07\n",
      "  batch 101 loss: 6.75266467851543e-05\n",
      "  batch 201 loss: 7.148678844714595e-05\n",
      "LOSS train 7.051265816738992e-05 valid 6.11039504292421e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.00263083470054e-07\n",
      "  batch 101 loss: 7.860980855639354e-05\n",
      "  batch 201 loss: 8.311446684729162e-05\n",
      "LOSS train 8.24289127427992e-05 valid 7.122827810235322e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.190915832528844e-07\n",
      "  batch 101 loss: 9.162581902728561e-05\n",
      "  batch 201 loss: 9.664451207981984e-05\n",
      "LOSS train 9.641478703624438e-05 valid 8.322844951180741e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004337000846862793\n",
      "  batch 101 loss: 0.01734026889046618\n",
      "  batch 201 loss: 6.816860201070085e-05\n",
      "LOSS train 0.006667355785497414 valid 5.0966496928595006e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.873575456556864e-07\n",
      "  batch 101 loss: 7.779612639751576e-05\n",
      "  batch 201 loss: 8.916082393625402e-05\n",
      "LOSS train 8.688492011020612e-05 valid 7.990713493200019e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.843691805144773e-07\n",
      "  batch 101 loss: 0.00010380093722801575\n",
      "  batch 201 loss: 0.00011089717032149338\n",
      "LOSS train 0.00011090733967212695 valid 8.922522829379886e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1495812941575423e-06\n",
      "  batch 101 loss: 0.00012290882139609494\n",
      "  batch 201 loss: 0.00012491954503161652\n",
      "LOSS train 0.00012581825998180508 valid 7.059790368657559e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.6695672683417797e-05\n",
      "  batch 101 loss: 0.007614352297085816\n",
      "  batch 201 loss: 3.262661152234614e-05\n",
      "LOSS train 0.002898178271994606 valid 0.00010659347753971815\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3990855222800745e-07\n",
      "  batch 101 loss: 6.584289240095131e-05\n",
      "  batch 201 loss: 5.9610316267821875e-05\n",
      "LOSS train 6.0456961581215286e-05 valid 0.000155573696247302\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.4301585401408373e-07\n",
      "  batch 101 loss: 5.7776033560799075e-05\n",
      "  batch 201 loss: 5.9324469270904955e-05\n",
      "LOSS train 5.840160037329315e-05 valid 0.00020202697487547994\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.229607970453799e-07\n",
      "  batch 101 loss: 6.319911140337809e-05\n",
      "  batch 201 loss: 6.654758143071149e-05\n",
      "LOSS train 6.514456654816561e-05 valid 0.0002427845320198685\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0022720348834991454\n",
      "  batch 101 loss: 0.015850791151751763\n",
      "  batch 201 loss: 0.0010565516710630619\n",
      "LOSS train 0.007130849334959712 valid 0.00018509139772504568\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.642280590720475e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00019000596203113673\n",
      "  batch 201 loss: 0.00013505661194358255\n",
      "LOSS train 0.00015400555913325435 valid 7.367978105321527e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1021287355106325e-06\n",
      "  batch 101 loss: 0.00012213259427767297\n",
      "  batch 201 loss: 0.00012192503999926885\n",
      "LOSS train 0.0001236395805707093 valid 8.334748417837545e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.086812699213624e-06\n",
      "  batch 101 loss: 0.0001261923332779702\n",
      "  batch 201 loss: 0.00012584170262016413\n",
      "LOSS train 0.0001270724631205455 valid 6.312463665381074e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0018054090440273284\n",
      "  batch 101 loss: 0.007987159964686725\n",
      "  batch 201 loss: 0.00011507962760333612\n",
      "LOSS train 0.003650819112151975 valid 6.357369420584291e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.847621989436448e-07\n",
      "  batch 101 loss: 0.00012535801642911791\n",
      "  batch 201 loss: 0.00012003419652558023\n",
      "LOSS train 0.00011899631026454322 valid 5.521496132132597e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.568504199502058e-08\n",
      "  batch 101 loss: 9.760043121787021e-05\n",
      "  batch 201 loss: 8.340400349879929e-05\n",
      "LOSS train 8.554959808012366e-05 valid 0.00010053557343780994\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.745413313386962e-08\n",
      "  batch 101 loss: 6.97823175528356e-05\n",
      "  batch 201 loss: 6.406518042467724e-05\n",
      "LOSS train 6.439495271540878e-05 valid 0.00013304827734827995\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006705530732870102\n",
      "  batch 101 loss: 0.015986039265990258\n",
      "  batch 201 loss: 0.00030646707280538975\n",
      "LOSS train 0.006240198431055516 valid 7.497824844904244e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.964752487372607e-07\n",
      "  batch 101 loss: 9.425920175544889e-05\n",
      "  batch 201 loss: 0.00010194458000796658\n",
      "LOSS train 0.00010216864675618499 valid 8.868242730386555e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1402153904782609e-06\n",
      "  batch 101 loss: 0.0001189066116091908\n",
      "  batch 201 loss: 0.0001234882370374635\n",
      "LOSS train 0.0001238021826445416 valid 7.293591625057161e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.52770681376569e-07\n",
      "  batch 101 loss: 0.00012734573166653718\n",
      "  batch 201 loss: 0.00012141612830305349\n",
      "LOSS train 0.0001227197792488515 valid 5.096012682770379e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00037052951753139494\n",
      "  batch 101 loss: 0.004305155434881271\n",
      "  batch 201 loss: 2.583829391028303e-05\n",
      "LOSS train 0.001726574261614389 valid 3.6925684980815277e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.314867848937865e-08\n",
      "  batch 101 loss: 1.0392786076636185e-05\n",
      "  batch 201 loss: 5.098360138049429e-06\n",
      "LOSS train 6.679464289653806e-06 valid 3.983940041507594e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.37375126441475e-08\n",
      "  batch 101 loss: 2.3454846071047085e-06\n",
      "  batch 201 loss: 2.204597589354762e-06\n",
      "LOSS train 2.1848308432148495e-06 valid 4.171625187154859e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.553415813759784e-08\n",
      "  batch 101 loss: 2.357290625951691e-06\n",
      "  batch 201 loss: 2.1730604322556244e-06\n",
      "LOSS train 2.2171976345815968e-06 valid 4.018311301479116e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 9.023200254887342e-07\n",
      "  batch 101 loss: 0.02209528682516975\n",
      "  batch 201 loss: 8.103999207378365e-05\n",
      "LOSS train 0.008142195774250996 valid 7.102819654392079e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.678044832777232e-07\n",
      "  batch 101 loss: 8.24599489897082e-05\n",
      "  batch 201 loss: 8.243275961376639e-05\n",
      "LOSS train 8.39965550634115e-05 valid 7.273077062563971e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.487598097417504e-07\n",
      "  batch 101 loss: 9.451638578639177e-05\n",
      "  batch 201 loss: 0.00010119943890742888\n",
      "LOSS train 0.00010096061353245007 valid 8.732968854019418e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1167519551236183e-06\n",
      "  batch 101 loss: 0.0001136853267468041\n",
      "  batch 201 loss: 0.00011845403814163547\n",
      "LOSS train 0.00011904152655217877 valid 8.549515769118443e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002768580988049507\n",
      "  batch 101 loss: 0.006015914373201667\n",
      "  batch 201 loss: 7.862350155846799e-05\n",
      "LOSS train 0.002365089827955152 valid 5.1335864554857835e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.222082523279823e-07\n",
      "  batch 101 loss: 8.761841621890198e-05\n",
      "  batch 201 loss: 0.0001251070495800377\n",
      "LOSS train 0.00011167326162262809 valid 5.2335220971144736e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.263730104663409e-07\n",
      "  batch 101 loss: 0.00011489021469287763\n",
      "  batch 201 loss: 9.975645968324898e-05\n",
      "LOSS train 0.0001021197519945324 valid 7.457630999851972e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5840213336559826e-08\n",
      "  batch 101 loss: 8.276591336425554e-05\n",
      "  batch 201 loss: 7.381930390465641e-05\n",
      "LOSS train 7.511885734895372e-05 valid 0.00010818660666700453\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00014848017133772373\n",
      "  batch 101 loss: 0.025098254172626185\n",
      "  batch 201 loss: 0.00016382108187826817\n",
      "LOSS train 0.009333986009324613 valid 5.4684864153387025e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.885284528834746e-07\n",
      "  batch 101 loss: 9.42007782850851e-05\n",
      "  batch 201 loss: 9.46957115411351e-05\n",
      "LOSS train 9.592206028017099e-05 valid 7.234901568153873e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.242429223377257e-07\n",
      "  batch 101 loss: 0.00010479347185537335\n",
      "  batch 201 loss: 0.0001109175520826966\n",
      "LOSS train 0.00011077085206927103 valid 8.614319813204929e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.2070171942468732e-06\n",
      "  batch 101 loss: 0.0001207122339462785\n",
      "  batch 201 loss: 0.0001239256716348791\n",
      "LOSS train 0.0001245900327847553 valid 7.440722401952371e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00029213953763246536\n",
      "  batch 101 loss: 2.0566574790125016\n",
      "  batch 201 loss: 0.0007330506037214945\n",
      "LOSS train 0.7538201867756993 valid 0.0035696469713002443\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00021258044987916945\n",
      "  batch 101 loss: 0.003054721076778151\n",
      "  batch 201 loss: 0.00028147072260026107\n",
      "LOSS train 0.0013666471362091712 valid 0.0037152536679059267\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.00021713675931096078\n",
      "  batch 101 loss: 0.0035687835427870595\n",
      "  batch 201 loss: 0.0002723132737014566\n",
      "LOSS train 0.0015190781444498782 valid 0.003108022268861532\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.00017612550407648087\n",
      "  batch 101 loss: 0.004936899319109216\n",
      "  batch 201 loss: 0.000339260031178128\n",
      "LOSS train 0.002101957457293443 valid 0.0028486819937825203\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00027222143486142157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 2.068170643961057\n",
      "  batch 201 loss: 0.0034442438988480715\n",
      "LOSS train 0.7593842358488313 valid 0.0006835560780018568\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.964441828429699e-05\n",
      "  batch 101 loss: 0.0014922003669198603\n",
      "  batch 201 loss: 0.00028178602704429065\n",
      "LOSS train 0.0006966298963664989 valid 0.000156109977979213\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.04960897564888e-06\n",
      "  batch 101 loss: 0.0002035056574277405\n",
      "  batch 201 loss: 3.3468968094894084e-05\n",
      "LOSS train 9.620181785126928e-05 valid 6.190537533257157e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.1522796305362135e-06\n",
      "  batch 101 loss: 5.427309221886389e-05\n",
      "  batch 201 loss: 1.0212623108145635e-05\n",
      "LOSS train 2.780900790756464e-05 valid 4.944560714648105e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001669972576200962\n",
      "  batch 101 loss: 2.1592801195615903\n",
      "  batch 201 loss: 0.005864059365121648\n",
      "LOSS train 0.7935116582551388 valid 0.0001622240961296484\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.5503584872931242e-05\n",
      "  batch 101 loss: 0.00042843556264415383\n",
      "  batch 201 loss: 7.760907505144132e-05\n",
      "LOSS train 0.00019928018489389658 valid 5.029418753110804e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.596900740172714e-06\n",
      "  batch 101 loss: 5.643819035867636e-05\n",
      "  batch 201 loss: 2.127903171185608e-05\n",
      "LOSS train 3.754191742194256e-05 valid 3.3731259463820606e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.4032953155692667e-07\n",
      "  batch 101 loss: 1.5218974260733375e-05\n",
      "  batch 201 loss: 2.066141338673333e-05\n",
      "LOSS train 1.9256340795939754e-05 valid 5.616742782876827e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004510105401277542\n",
      "  batch 101 loss: 2.1739376329630615\n",
      "  batch 201 loss: 0.0038739919365616514\n",
      "LOSS train 0.7979838078571957 valid 0.00022982587688602507\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.4673943407833576e-05\n",
      "  batch 101 loss: 0.0002529843979573343\n",
      "  batch 201 loss: 2.7949793538937227e-05\n",
      "LOSS train 0.00011959331643929911 valid 3.498844671412371e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.7451613277662545e-07\n",
      "  batch 101 loss: 3.0113177786006418e-05\n",
      "  batch 201 loss: 4.0143715959857215e-05\n",
      "LOSS train 4.343640323932316e-05 valid 3.661773007479496e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.271755849709734e-07\n",
      "  batch 101 loss: 2.7519613663571363e-05\n",
      "  batch 201 loss: 3.644766846718994e-05\n",
      "LOSS train 3.9415255038971944e-05 valid 8.80404986673966e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002537563815712929\n",
      "  batch 101 loss: 0.7907967903916415\n",
      "  batch 201 loss: 6.15139551791799e-05\n",
      "LOSS train 0.29826575511924225 valid 5.923297430854291e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.683104296214879e-08\n",
      "  batch 101 loss: 6.365270180594962e-05\n",
      "  batch 201 loss: 6.806470454648661e-05\n",
      "LOSS train 6.653250655010477e-05 valid 5.808345667901449e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.240731479716487e-07\n",
      "  batch 101 loss: 7.372330815996975e-05\n",
      "  batch 201 loss: 7.73929560500619e-05\n",
      "LOSS train 7.662234386874436e-05 valid 6.546593067469075e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.995396688580513e-07\n",
      "  batch 101 loss: 8.422618000395233e-05\n",
      "  batch 201 loss: 8.855069483615808e-05\n",
      "LOSS train 8.808489476425645e-05 valid 7.584818376926705e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.343007389456034e-05\n",
      "  batch 101 loss: 0.5554880143964874\n",
      "  batch 201 loss: 6.073828217267874e-05\n",
      "LOSS train 0.2035340079230628 valid 5.511012932402082e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.3817082769237457e-07\n",
      "  batch 101 loss: 6.894612238738773e-05\n",
      "  batch 201 loss: 7.334590788104833e-05\n",
      "LOSS train 7.237478314561816e-05 valid 6.295683851931244e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.436530384235084e-07\n",
      "  batch 101 loss: 8.140165558870649e-05\n",
      "  batch 201 loss: 8.645920431945343e-05\n",
      "LOSS train 8.584046203072548e-05 valid 7.481445209123194e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.890948083717376e-07\n",
      "  batch 101 loss: 9.619694497928322e-05\n",
      "  batch 201 loss: 0.0001017238854393554\n",
      "LOSS train 0.00010166444581308006 valid 8.704583160579205e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0008656354248523712\n",
      "  batch 101 loss: 0.22619976371857775\n",
      "  batch 201 loss: 0.00550196027244283\n",
      "LOSS train 0.08520852219085816 valid 6.423153536161408e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.724084232700989e-07\n",
      "  batch 101 loss: 8.449171060874505e-05\n",
      "  batch 201 loss: 9.333360358823484e-05\n",
      "LOSS train 9.25544188270405e-05 valid 8.393618918489665e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0570432641543449e-06\n",
      "  batch 101 loss: 0.00010975646250557247\n",
      "  batch 201 loss: 0.00011685795819005307\n",
      "LOSS train 0.00011694817486334817 valid 8.459004311589524e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0686476161936298e-06\n",
      "  batch 101 loss: 0.0001271050599311252\n",
      "  batch 201 loss: 0.00012548265300779348\n",
      "LOSS train 0.00012632011459671517 valid 5.5370495829265565e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00024108491837978362\n",
      "  batch 101 loss: 0.7220779986535308\n",
      "  batch 201 loss: 6.148826256776375e-05\n",
      "LOSS train 0.2646245161974295 valid 5.4177373385755345e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.072672891197726e-07\n",
      "  batch 101 loss: 6.668899622127356e-05\n",
      "  batch 201 loss: 7.042696709959273e-05\n",
      "LOSS train 6.945544939279009e-05 valid 6.014672908349894e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.76958445890341e-07\n",
      "  batch 101 loss: 7.71409366188891e-05\n",
      "  batch 201 loss: 8.143978639964189e-05\n",
      "LOSS train 8.072768147004077e-05 valid 6.957693403819576e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.8584547736682e-07\n",
      "  batch 101 loss: 8.959453790112093e-05\n",
      "  batch 201 loss: 9.454448734913968e-05\n",
      "LOSS train 9.424906383400488e-05 valid 8.15751773188822e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0015714706480503082\n",
      "  batch 101 loss: 0.18037761523894005\n",
      "  batch 201 loss: 7.679827776428283e-05\n",
      "LOSS train 0.06669708733626323 valid 6.68633365421556e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.295185059774667e-07\n",
      "  batch 101 loss: 8.928914172201985e-05\n",
      "  batch 201 loss: 9.931418785754432e-05\n",
      "LOSS train 9.856673667685848e-05 valid 8.78315549925901e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1254775745328515e-06\n",
      "  batch 101 loss: 0.00011690479233152474\n",
      "  batch 201 loss: 0.00012254060724956162\n",
      "LOSS train 0.00012266320114342086 valid 7.39011011319235e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.715237345313653e-07\n",
      "  batch 101 loss: 0.00012736779225519968\n",
      "  batch 201 loss: 0.0001208560715610929\n",
      "LOSS train 0.00012193113366515468 valid 5.0996019126614556e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0008589541167020797\n",
      "  batch 101 loss: 0.20601079135783948\n",
      "  batch 201 loss: 0.001699957247110433\n",
      "LOSS train 0.07643607816494845 valid 6.849297642474994e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1625579645624384e-06\n",
      "  batch 101 loss: 0.0001356918642159144\n",
      "  batch 201 loss: 0.00013513527173927286\n",
      "LOSS train 0.00013720504211094174 valid 9.136634616879746e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3686306192539633e-06\n",
      "  batch 101 loss: 0.0001389133291104372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.00013759143761490122\n",
      "LOSS train 0.00013936785842735925 valid 6.617492181248963e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.660519284196198e-07\n",
      "  batch 101 loss: 0.00013007119352550944\n",
      "  batch 201 loss: 0.00011858509716603294\n",
      "LOSS train 0.00012077170364359901 valid 5.4972959333099425e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002482319995760918\n",
      "  batch 101 loss: 0.006259977708518249\n",
      "  batch 201 loss: 5.872825686310534e-05\n",
      "LOSS train 0.0024221436691105225 valid 0.00026192437508143485\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.022042488330044e-06\n",
      "  batch 101 loss: 7.86624223758281e-05\n",
      "  batch 201 loss: 7.96614667956419e-05\n",
      "LOSS train 7.595197100368957e-05 valid 0.00012197132309665903\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.681508911133278e-07\n",
      "  batch 101 loss: 5.0513009730082106e-05\n",
      "  batch 201 loss: 4.022769626317313e-05\n",
      "LOSS train 4.2883844542568226e-05 valid 7.231758354464546e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1905026440217625e-08\n",
      "  batch 101 loss: 3.519651157375847e-05\n",
      "  batch 201 loss: 3.35955514788111e-05\n",
      "LOSS train 3.3916657362511124e-05 valid 5.5512533435830846e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0019605731964111328\n",
      "  batch 101 loss: 0.4762547750913984\n",
      "  batch 201 loss: 6.258789182084001e-05\n",
      "LOSS train 0.17521154090533295 valid 5.8461020671529695e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.340674397302791e-07\n",
      "  batch 101 loss: 7.574719559215737e-05\n",
      "  batch 201 loss: 8.217524981319002e-05\n",
      "LOSS train 8.125651094395344e-05 valid 7.254119555000216e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.450452878605574e-07\n",
      "  batch 101 loss: 9.434026010922025e-05\n",
      "  batch 201 loss: 0.00010125229160564685\n",
      "LOSS train 0.00010099850675739214 valid 8.74900579219684e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1195421393495054e-06\n",
      "  batch 101 loss: 0.00011428472837110348\n",
      "  batch 201 loss: 0.00011927200705429186\n",
      "LOSS train 0.00011982541559914336 valid 8.361596701433882e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005689123645424843\n",
      "  batch 101 loss: 2.7742112151259772\n",
      "  batch 201 loss: 9.38067827880218e-05\n",
      "LOSS train 1.0164404144297963 valid 4.175499634584412e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.1447284123278223e-07\n",
      "  batch 101 loss: 5.16509089294459e-06\n",
      "  batch 201 loss: 1.5178221421763282e-05\n",
      "LOSS train 1.122392415664353e-05 valid 4.120687299291603e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.4703530268889153e-08\n",
      "  batch 101 loss: 1.564498814360604e-05\n",
      "  batch 201 loss: 2.1310116858046512e-05\n",
      "LOSS train 2.1517338742606814e-05 valid 6.792562635382637e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1085168807767332e-07\n",
      "  batch 101 loss: 6.124132697209461e-05\n",
      "  batch 201 loss: 3.3572565889699036e-05\n",
      "LOSS train 3.740127325977337e-05 valid 4.3259697122266516e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.5189748955890536e-05\n",
      "  batch 101 loss: 11.473624747210415\n",
      "  batch 201 loss: 0.0021142391744069754\n",
      "LOSS train 4.203987521963107 valid 9.713954204926267e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.6609227750450372e-05\n",
      "  batch 101 loss: 0.0013204708672128619\n",
      "  batch 201 loss: 0.0010584098915569484\n",
      "LOSS train 0.001108300915429703 valid 0.00010266003664582968\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.113564690575004e-06\n",
      "  batch 101 loss: 0.0007239989619120024\n",
      "  batch 201 loss: 0.0005255094579479191\n",
      "LOSS train 0.0005722595336646586 valid 0.00012008275371044874\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.6881683152168988e-06\n",
      "  batch 101 loss: 0.00031198270080494693\n",
      "  batch 201 loss: 0.00023586581446579657\n",
      "LOSS train 0.0002508211649904 valid 0.00017147498147096485\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017945995554327965\n",
      "  batch 101 loss: 4.687381835160777\n",
      "  batch 201 loss: 0.003715090212645009\n",
      "LOSS train 1.7187099372227157 valid 0.0003038207069039345\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.481870564632118e-06\n",
      "  batch 101 loss: 0.0003063819892850006\n",
      "  batch 201 loss: 0.0001069326222204836\n",
      "LOSS train 0.0001696516730603118 valid 5.3342020692070946e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.576589369913563e-07\n",
      "  batch 101 loss: 6.007925613630505e-05\n",
      "  batch 201 loss: 5.9998254237143555e-05\n",
      "LOSS train 5.973142565497442e-05 valid 5.224947017268278e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.7643407267751173e-07\n",
      "  batch 101 loss: 6.158245959341002e-05\n",
      "  batch 201 loss: 6.344955474105518e-05\n",
      "LOSS train 6.309193346475692e-05 valid 5.7779867347562686e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.45191715657711e-05\n",
      "  batch 101 loss: 8.427180767210666\n",
      "  batch 201 loss: 0.0019988842454040424\n",
      "LOSS train 3.0877564332883756 valid 0.00016973736637737602\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.5822831483092159e-06\n",
      "  batch 101 loss: 0.00015658751521868908\n",
      "  batch 201 loss: 6.72839428352745e-05\n",
      "LOSS train 9.859103266408788e-05 valid 5.147945921635255e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.868586489057634e-07\n",
      "  batch 101 loss: 5.721021492718137e-05\n",
      "  batch 201 loss: 6.016289467879687e-05\n",
      "LOSS train 5.79814710936295e-05 valid 5.194260666030459e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.1454146665055305e-07\n",
      "  batch 101 loss: 5.9607730918287416e-05\n",
      "  batch 201 loss: 6.0076248955738266e-05\n",
      "LOSS train 5.9421095465283904e-05 valid 5.261230035102926e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.706443287432194e-06\n",
      "  batch 101 loss: 0.13208687825206653\n",
      "  batch 201 loss: 0.00013638084911917758\n",
      "LOSS train 0.048474967707525074 valid 0.000473855558084324\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.322336412267759e-07\n",
      "  batch 101 loss: 6.380967316090392e-05\n",
      "  batch 201 loss: 0.0001135913102223185\n",
      "LOSS train 0.0001283445127538994 valid 0.00044044057722203434\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.5950164349051195e-07\n",
      "  batch 101 loss: 7.391567911895436e-05\n",
      "  batch 201 loss: 0.00010866132742421542\n",
      "LOSS train 0.00010816012662298785 valid 0.0006493583787232637\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.9740323477890343e-06\n",
      "  batch 101 loss: 9.965312950271254e-05\n",
      "  batch 201 loss: 0.00010516417403778178\n",
      "LOSS train 0.00018414282212672047 valid 0.0006464084144681692\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.828209060477093e-06\n",
      "  batch 101 loss: 0.00010001501579267824\n",
      "  batch 201 loss: 0.00012794177438081534\n",
      "LOSS train 0.0001729310547959721 valid 0.00029928330332040787\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0625856702972669e-07\n",
      "  batch 101 loss: 9.40431741616976e-05\n",
      "  batch 201 loss: 0.0001308277701730276\n",
      "LOSS train 0.0001735913694970711 valid 0.0006343181594274938\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.8358319357503206e-06\n",
      "  batch 101 loss: 0.00033269586587266533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 0.0004220076109686488\n",
      "LOSS train 0.0007383210025535189 valid 0.0076264250092208385\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.126614287495613e-05\n",
      "  batch 101 loss: 0.005813717785276822\n",
      "  batch 201 loss: 0.002739353307551937\n",
      "LOSS train 0.003493415190783481 valid 0.0007842782069928944\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00020502842962741852\n",
      "  batch 101 loss: 0.1221977606555447\n",
      "  batch 201 loss: 0.0021654399612452834\n",
      "LOSS train 0.04592895457024717 valid 0.00036676801391877234\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.4269525893032552e-05\n",
      "  batch 101 loss: 0.0005868093221215532\n",
      "  batch 201 loss: 0.0001904364452639129\n",
      "LOSS train 0.00031476114366878156 valid 6.278957880567759e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.3001130213961006e-06\n",
      "  batch 101 loss: 8.136010092130164e-05\n",
      "  batch 201 loss: 3.073086875701847e-05\n",
      "LOSS train 4.766137141444603e-05 valid 4.8118847189471126e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5210240962915122e-06\n",
      "  batch 101 loss: 3.102691283402237e-05\n",
      "  batch 201 loss: 1.52816392233035e-05\n",
      "LOSS train 2.0688105381843957e-05 valid 3.705385097418912e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.7522661437396892e-07\n",
      "  batch 101 loss: 2.0409563076100314e-05\n",
      "  batch 201 loss: 1.6402822745931188e-05\n",
      "LOSS train 1.734103629409246e-05 valid 4.469701525522396e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.7431673263199625e-07\n",
      "  batch 101 loss: 4.0395936218828864e-05\n",
      "  batch 201 loss: 2.800380522103296e-05\n",
      "LOSS train 5.64581011511129e-05 valid 6.89696244080551e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.2247495255433025e-07\n",
      "  batch 101 loss: 0.00024938521968351777\n",
      "  batch 201 loss: 0.004256951354473131\n",
      "LOSS train 0.0025896086320772688 valid 0.0010746974730864167\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0152788599953055e-05\n",
      "  batch 101 loss: 0.0012856369329529117\n",
      "  batch 201 loss: 0.0035094850444511395\n",
      "LOSS train 0.00269726365163162 valid 0.00016761684673838317\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0013258010149002075\n",
      "  batch 101 loss: 0.08265078285941854\n",
      "  batch 201 loss: 0.0018190364647307433\n",
      "LOSS train 0.03150182081240501 valid 6.301822577370331e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.006440380588174e-06\n",
      "  batch 101 loss: 0.00011719154035745305\n",
      "  batch 201 loss: 2.3631034655409166e-05\n",
      "LOSS train 6.267940735487283e-05 valid 3.79404955310747e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.644724635407328e-07\n",
      "  batch 101 loss: 1.9329560270762158e-05\n",
      "  batch 201 loss: 1.9312048780193437e-05\n",
      "LOSS train 1.774308260635588e-05 valid 3.437678242335096e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.201433047361207e-08\n",
      "  batch 101 loss: 2.1382350039402808e-05\n",
      "  batch 201 loss: 2.0792377295038023e-05\n",
      "LOSS train 2.1875964922657706e-05 valid 3.483708496787585e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.953591658500954e-08\n",
      "  batch 101 loss: 3.721411495689608e-05\n",
      "  batch 201 loss: 6.639373055350006e-05\n",
      "LOSS train 7.58284164807691e-05 valid 3.503869811538607e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1975338566116988e-07\n",
      "  batch 101 loss: 0.0025124335426335164\n",
      "  batch 201 loss: 0.003995879533176776\n",
      "LOSS train 0.0036137612501462397 valid 0.0034463198389858007\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.1812912784516814e-05\n",
      "  batch 101 loss: 0.0017692471119516995\n",
      "  batch 201 loss: 0.0014248413559835172\n",
      "LOSS train 0.001850905315422806 valid 0.00014057163207326084\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.4617058807052674e-06\n",
      "  batch 101 loss: 0.004142151183841634\n",
      "  batch 201 loss: 0.0015163237539672992\n",
      "LOSS train 0.003314394301157799 valid 0.006196444854140282\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00022621968761086465\n",
      "  batch 101 loss: 0.13812850903952495\n",
      "  batch 201 loss: 0.0009311014074046398\n",
      "LOSS train 0.05103749771174929 valid 4.101487502339296e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.802935190033167e-07\n",
      "  batch 101 loss: 3.5317215333634523e-05\n",
      "  batch 201 loss: 2.3888017303761443e-05\n",
      "LOSS train 2.7741717409572054e-05 valid 3.69348272215575e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.500202289316803e-08\n",
      "  batch 101 loss: 2.628331350933877e-05\n",
      "  batch 201 loss: 4.479564462599228e-05\n",
      "LOSS train 4.0536645795264486e-05 valid 3.852681038551964e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.9707367502851414e-07\n",
      "  batch 101 loss: 2.57053514224026e-05\n",
      "  batch 201 loss: 4.526238578819175e-05\n",
      "LOSS train 3.663857766393145e-05 valid 4.9113212298834696e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.26251488836715e-07\n",
      "  batch 101 loss: 5.859358147972671e-05\n",
      "  batch 201 loss: 5.575778046477353e-05\n",
      "LOSS train 5.8636861954072204e-05 valid 6.184145604493096e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.621864976186771e-07\n",
      "  batch 101 loss: 0.00014885520274219744\n",
      "  batch 201 loss: 0.0001201427933119703\n",
      "LOSS train 0.0002477099480342869 valid 0.0018823854625225067\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.735779456794262e-05\n",
      "  batch 101 loss: 0.0009917410425987327\n",
      "  batch 201 loss: 0.002064049472101033\n",
      "LOSS train 0.0029914410853975506 valid 0.029162229970097542\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00024332856759428978\n",
      "  batch 101 loss: 0.008006907393573784\n",
      "  batch 201 loss: 0.0005538876953323779\n",
      "LOSS train 0.003355779753608645 valid 0.0005732736317440867\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.032317290082574e-05\n",
      "  batch 101 loss: 0.03916165097586827\n",
      "  batch 201 loss: 2.9556873985825405e-05\n",
      "LOSS train 0.015541103249356496 valid 0.00012767393491230905\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.7641950398683548e-06\n",
      "  batch 101 loss: 0.0001132808423727738\n",
      "  batch 201 loss: 6.981446370446065e-05\n",
      "LOSS train 8.663112998062519e-05 valid 5.970666097709909e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.660079114022665e-07\n",
      "  batch 101 loss: 7.64182619195708e-05\n",
      "  batch 201 loss: 8.053820903114684e-05\n",
      "LOSS train 7.981010080484438e-05 valid 6.85725171933882e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.652603380847722e-07\n",
      "  batch 101 loss: 8.825817582646777e-05\n",
      "  batch 201 loss: 9.295638442608833e-05\n",
      "LOSS train 9.261220878418902e-05 valid 7.998385262908414e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.857732948148623e-07\n",
      "  batch 101 loss: 0.00010207696251427479\n",
      "  batch 201 loss: 0.00010681660696263861\n",
      "LOSS train 0.00010705981616966533 valid 8.907097071642056e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1469222226878629e-06\n",
      "  batch 101 loss: 0.00011627893295894865\n",
      "  batch 201 loss: 0.00011951171555040219\n",
      "LOSS train 0.00012045239555738053 valid 8.58632629388012e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0911037679761648e-06\n",
      "  batch 101 loss: 0.0001263608834187835\n",
      "  batch 201 loss: 0.00012579210183389478\n",
      "LOSS train 0.00012725735361291234 valid 6.720249075442553e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.366862701019272e-07\n",
      "  batch 101 loss: 0.000126416514946186\n",
      "  batch 201 loss: 0.00012099517966191797\n",
      "LOSS train 0.00012259396755601404 valid 5.1576302212197334e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00010723995976150036\n",
      "  batch 101 loss: 0.022575494023046757\n",
      "  batch 201 loss: 0.0011478065866867837\n",
      "LOSS train 0.008753553080447797 valid 5.852052345289849e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.356284236768261e-07\n",
      "  batch 101 loss: 7.389507694369967e-05\n",
      "  batch 201 loss: 7.946619675294642e-05\n",
      "LOSS train 7.85993476932699e-05 valid 6.940551975276321e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.823527994332835e-07\n",
      "  batch 101 loss: 9.018238232556541e-05\n",
      "  batch 201 loss: 9.644040792409215e-05\n",
      "LOSS train 9.6055287017307e-05 valid 8.406760025536641e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0593798651825636e-06\n",
      "  batch 101 loss: 0.00010829133749240327\n",
      "  batch 201 loss: 0.00011365978646239227\n",
      "LOSS train 0.00011405745536339365 valid 8.906768925953656e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.146865834016353e-06\n",
      "  batch 101 loss: 0.0001234918372665561\n",
      "  batch 201 loss: 0.00012488283321829385\n",
      "LOSS train 0.0001260253097869351 valid 7.24582641851157e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.434169285465032e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00012747332387618826\n",
      "  batch 201 loss: 0.00012274335186049257\n",
      "LOSS train 0.00012426508941210479 valid 5.252940172795206e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.43146275554318e-07\n",
      "  batch 101 loss: 0.00011667837732602493\n",
      "  batch 201 loss: 0.00010796486740446199\n",
      "LOSS train 0.0001093865891352551 valid 5.702579801436514e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.156923634785926e-08\n",
      "  batch 101 loss: 9.79391593224932e-05\n",
      "  batch 201 loss: 8.935127851998459e-05\n",
      "LOSS train 9.028198898036886e-05 valid 8.058959065238014e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00024804677814245225\n",
      "  batch 101 loss: 0.03833682917786064\n",
      "  batch 201 loss: 6.589913213247201e-05\n",
      "LOSS train 0.014174272413837015 valid 5.464059722726233e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.2294996092095973e-07\n",
      "  batch 101 loss: 6.784840260024793e-05\n",
      "  batch 201 loss: 7.190281726707326e-05\n",
      "LOSS train 7.092802643988835e-05 valid 6.149982800707221e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.097113873693161e-07\n",
      "  batch 101 loss: 7.92118789718188e-05\n",
      "  batch 201 loss: 8.382036578950647e-05\n",
      "LOSS train 8.314750625986263e-05 valid 7.196052320068702e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.336160681210459e-07\n",
      "  batch 101 loss: 9.25441570757357e-05\n",
      "  batch 201 loss: 9.763971160168694e-05\n",
      "LOSS train 9.744253990890847e-05 valid 8.40328648337163e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0587625001790001e-06\n",
      "  batch 101 loss: 0.00010756244095318835\n",
      "  batch 201 loss: 0.00011218240554370595\n",
      "LOSS train 0.00011266282856994814 valid 8.977961260825396e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1591172369662671e-06\n",
      "  batch 101 loss: 0.00012134602293599528\n",
      "  batch 201 loss: 0.0001233493767949767\n",
      "LOSS train 0.00012451681233903897 valid 7.885988452471793e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.651156869949772e-07\n",
      "  batch 101 loss: 0.00012789166441621092\n",
      "  batch 201 loss: 0.0001250723660746189\n",
      "LOSS train 0.00012662708616312308 valid 5.7879351516021416e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.186023554415442e-07\n",
      "  batch 101 loss: 0.00012222580551792816\n",
      "  batch 201 loss: 0.00011493259175495041\n",
      "LOSS train 0.00011645373718949532 valid 5.1676823204616085e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.5101205576211214e-05\n",
      "  batch 101 loss: 0.049383315007344206\n",
      "  batch 201 loss: 5.975676800971996e-05\n",
      "LOSS train 0.018139945492682035 valid 5.384356700233184e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.954745625378564e-07\n",
      "  batch 101 loss: 6.58136840820589e-05\n",
      "  batch 201 loss: 6.928402644462039e-05\n",
      "LOSS train 6.831377346988963e-05 valid 5.9102720115333796e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.507064997800625e-07\n",
      "  batch 101 loss: 7.5433850565787e-05\n",
      "  batch 201 loss: 7.937824532291415e-05\n",
      "LOSS train 7.863297339562593e-05 valid 6.7393877543509e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.407147495541721e-07\n",
      "  batch 101 loss: 8.673594649962979e-05\n",
      "  batch 201 loss: 9.12715986942203e-05\n",
      "LOSS train 9.087863093008553e-05 valid 7.839455065550283e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.565093932906165e-07\n",
      "  batch 101 loss: 0.00010005216941408435\n",
      "  batch 201 loss: 0.00010476619221208238\n",
      "LOSS train 0.00010492339510999574 valid 8.821118535706773e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.132062025135383e-06\n",
      "  batch 101 loss: 0.0001141793344186226\n",
      "  batch 201 loss: 0.00011773976340464288\n",
      "LOSS train 0.00011858419249092016 valid 8.764136873651296e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1221737076994032e-06\n",
      "  batch 101 loss: 0.00012521847012749275\n",
      "  batch 201 loss: 0.00012542146045291247\n",
      "LOSS train 0.00012683299848979818 valid 7.105831173248589e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.157017873600125e-07\n",
      "  batch 101 loss: 0.00012731180836851762\n",
      "  batch 201 loss: 0.0001227218367534988\n",
      "LOSS train 0.00012433247983281134 valid 5.307022001943551e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000846221148967743\n",
      "  batch 101 loss: 0.0011977782351436871\n",
      "  batch 201 loss: 2.6017425295776774e-05\n",
      "LOSS train 0.0007619457656974624 valid 3.5244851460447535e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.4722712649017922e-08\n",
      "  batch 101 loss: 5.3021330705860235e-06\n",
      "  batch 201 loss: 2.9922198885401487e-06\n",
      "LOSS train 3.515007525966345e-06 valid 4.173684283159673e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.72537589455169e-09\n",
      "  batch 101 loss: 2.1583036323136184e-06\n",
      "  batch 201 loss: 2.3898568927904762e-06\n",
      "LOSS train 2.246230402748375e-06 valid 4.324385372456163e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0363571618654533e-08\n",
      "  batch 101 loss: 2.450449879347616e-06\n",
      "  batch 201 loss: 2.615563250003561e-06\n",
      "LOSS train 2.4412209299749193e-06 valid 4.13513662351761e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.308280262601329e-09\n",
      "  batch 101 loss: 3.3651903531506376e-06\n",
      "  batch 201 loss: 4.539612438918539e-06\n",
      "LOSS train 4.145331015610492e-06 valid 3.953651321353391e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.412819983670488e-08\n",
      "  batch 101 loss: 4.429213834384882e-06\n",
      "  batch 201 loss: 6.282026673360974e-06\n",
      "LOSS train 5.2235649675831635e-06 valid 4.7229194024112076e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 8.07048400019994e-08\n",
      "  batch 101 loss: 6.133661406124702e-06\n",
      "  batch 201 loss: 7.868143438543029e-06\n",
      "LOSS train 6.479508642361254e-06 valid 4.516725675784983e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.769305971625727e-08\n",
      "  batch 101 loss: 6.158425595401695e-06\n",
      "  batch 201 loss: 7.4177605154090995e-06\n",
      "LOSS train 6.362477757946034e-06 valid 4.2894283978966996e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 1.1239269224461168e-06\n",
      "  batch 101 loss: 0.0007147347448665187\n",
      "  batch 201 loss: 8.544147221755339e-05\n",
      "LOSS train 0.0003089372041026414 valid 0.00014379982894752175\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.7831236366182565e-07\n",
      "  batch 101 loss: 5.737997456236599e-05\n",
      "  batch 201 loss: 5.8942657759644134e-05\n",
      "LOSS train 5.824144338049876e-05 valid 0.00021525242482312024\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.080799696268514e-07\n",
      "  batch 101 loss: 6.502835798528394e-05\n",
      "  batch 201 loss: 7.029073647572659e-05\n",
      "LOSS train 6.867459763274077e-05 valid 0.00027190151740796864\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0914324957411736e-06\n",
      "  batch 101 loss: 7.533703076887832e-05\n",
      "  batch 201 loss: 7.88349864672e-05\n",
      "LOSS train 7.770434375986405e-05 valid 0.0002930941409431398\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.2410205090418458e-06\n",
      "  batch 101 loss: 8.078444700458931e-05\n",
      "  batch 201 loss: 8.225658197147823e-05\n",
      "LOSS train 8.184484760387112e-05 valid 0.0002987959887832403\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2817363312933594e-06\n",
      "  batch 101 loss: 8.187285146277646e-05\n",
      "  batch 201 loss: 8.347849999609026e-05\n",
      "LOSS train 8.307479465998274e-05 valid 0.0002993171219713986\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.285468169953674e-06\n",
      "  batch 101 loss: 8.269881969681592e-05\n",
      "  batch 201 loss: 8.400358039239109e-05\n",
      "LOSS train 8.380024948170043e-05 valid 0.0002985767787322402\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.280168944504112e-06\n",
      "  batch 101 loss: 8.308941587756636e-05\n",
      "  batch 201 loss: 8.424138661894176e-05\n",
      "LOSS train 8.407197075178377e-05 valid 0.0002980671706609428\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0013655197620391845\n",
      "  batch 101 loss: 0.019695869778297494\n",
      "  batch 201 loss: 0.00010402084022189229\n",
      "LOSS train 0.00777205800220841 valid 5.918721581110731e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.710910045308992e-07\n",
      "  batch 101 loss: 7.774300217079144e-05\n",
      "  batch 201 loss: 8.465226950193028e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 8.351734803186562e-05 valid 7.282599835889414e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.661238098284229e-07\n",
      "  batch 101 loss: 9.587495406549352e-05\n",
      "  batch 201 loss: 0.00010203541521264014\n",
      "LOSS train 0.00010191190146697708 valid 8.732950664125383e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1182294110767543e-06\n",
      "  batch 101 loss: 0.00011412436910774205\n",
      "  batch 201 loss: 0.00011885908896260843\n",
      "LOSS train 0.00011947741331040738 valid 8.455332863377407e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0754338291008025e-06\n",
      "  batch 101 loss: 0.0001267965970481555\n",
      "  batch 201 loss: 0.0001258317705242007\n",
      "LOSS train 0.0001271514010804472 valid 6.208179547684267e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.332184420898557e-07\n",
      "  batch 101 loss: 0.0001244379297645537\n",
      "  batch 201 loss: 0.00011731095075901976\n",
      "LOSS train 0.000118773010656666 valid 5.108189725433476e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.7241687601199372e-07\n",
      "  batch 101 loss: 0.0001080851615802203\n",
      "  batch 201 loss: 9.905441777391388e-05\n",
      "LOSS train 0.00010018543083298518 valid 6.722091347910464e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.3560754723584978e-08\n",
      "  batch 101 loss: 8.872693017110578e-05\n",
      "  batch 201 loss: 8.104181141447952e-05\n",
      "LOSS train 8.166546274424036e-05 valid 9.398108522873372e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.617438513785601e-05\n",
      "  batch 101 loss: 0.0011078078701802952\n",
      "  batch 201 loss: 9.095981127757113e-05\n",
      "LOSS train 0.0004789557827433326 valid 0.00014216142881195992\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.654351919773035e-07\n",
      "  batch 101 loss: 5.75381121097962e-05\n",
      "  batch 201 loss: 5.8225004103178435e-05\n",
      "LOSS train 5.787691376122567e-05 valid 0.0002121964207617566\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.882377783767879e-07\n",
      "  batch 101 loss: 6.44690422285521e-05\n",
      "  batch 201 loss: 6.968635395878663e-05\n",
      "LOSS train 6.808142238292803e-05 valid 0.0002696776937227696\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0759053111542015e-06\n",
      "  batch 101 loss: 7.489104299111204e-05\n",
      "  batch 201 loss: 7.846789986274417e-05\n",
      "LOSS train 7.73190669337048e-05 valid 0.00029296515276655555\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.2401011190377177e-06\n",
      "  batch 101 loss: 7.990125692288075e-05\n",
      "  batch 201 loss: 8.207068275737583e-05\n",
      "LOSS train 8.141936742706573e-05 valid 0.00029867427656427026\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.2808668543584645e-06\n",
      "  batch 101 loss: 8.185054665204916e-05\n",
      "  batch 201 loss: 8.342399171738179e-05\n",
      "LOSS train 8.302877873806736e-05 valid 0.000299336010357365\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2856039393227547e-06\n",
      "  batch 101 loss: 8.266183757768886e-05\n",
      "  batch 201 loss: 8.397822899041784e-05\n",
      "LOSS train 8.371676004978222e-05 valid 0.0002988076885230839\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.2818210234399886e-06\n",
      "  batch 101 loss: 8.304033876243011e-05\n",
      "  batch 201 loss: 8.423002048857598e-05\n",
      "LOSS train 8.404578727216812e-05 valid 0.00029811004060320556\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00011144179850816727\n",
      "  batch 101 loss: 0.004661811111529915\n",
      "  batch 201 loss: 2.0304575912177825e-05\n",
      "LOSS train 0.0017609067129066612 valid 6.458533607656136e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.291896862516296e-08\n",
      "  batch 101 loss: 1.998263188738747e-05\n",
      "  batch 201 loss: 1.697136029633839e-05\n",
      "LOSS train 1.7057622171588988e-05 valid 4.931582952849567e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2032818403895362e-08\n",
      "  batch 101 loss: 1.0572871361773651e-05\n",
      "  batch 201 loss: 6.487360640505813e-06\n",
      "LOSS train 7.121427769530057e-06 valid 3.64952466043178e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.8025576764557626e-08\n",
      "  batch 101 loss: 2.3337031032610866e-06\n",
      "  batch 201 loss: 2.1968033620112236e-06\n",
      "LOSS train 2.1843831236001094e-06 valid 4.0440369048155844e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.292628083632735e-09\n",
      "  batch 101 loss: 1.9892068196014635e-06\n",
      "  batch 201 loss: 1.9059370889351613e-06\n",
      "LOSS train 1.8188849360912266e-06 valid 4.117769276490435e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.3549157529268995e-08\n",
      "  batch 101 loss: 2.0671389442838974e-06\n",
      "  batch 201 loss: 1.724814141113029e-06\n",
      "LOSS train 1.765914848587332e-06 valid 4.200715193292126e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.5974874258972706e-08\n",
      "  batch 101 loss: 1.9319864620115367e-06\n",
      "  batch 201 loss: 1.5676683808152348e-06\n",
      "LOSS train 1.632698186817159e-06 valid 4.125208579353057e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.148279466178792e-08\n",
      "  batch 101 loss: 1.6244315084179561e-06\n",
      "  batch 201 loss: 2.3879032949025715e-06\n",
      "LOSS train 2.068899764174606e-06 valid 4.2324238165747374e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00037735011428594587\n",
      "  batch 101 loss: 0.006747319422429427\n",
      "  batch 201 loss: 0.00019300443476822694\n",
      "LOSS train 0.002708890932298855 valid 0.0001000034244498238\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.81492276978679e-07\n",
      "  batch 101 loss: 7.876880230469397e-05\n",
      "  batch 201 loss: 8.246338295975875e-05\n",
      "LOSS train 9.246787851971488e-05 valid 6.130598194431514e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.850909656146541e-07\n",
      "  batch 101 loss: 0.00012194863943932433\n",
      "  batch 201 loss: 0.00011032442182454361\n",
      "LOSS train 0.00011177277806815428 valid 6.084956112317741e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.8413028303475586e-08\n",
      "  batch 101 loss: 9.230249301708682e-05\n",
      "  batch 201 loss: 8.173769026825539e-05\n",
      "LOSS train 8.296411989922423e-05 valid 9.79048345470801e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.044928679533768e-08\n",
      "  batch 101 loss: 7.088112255132728e-05\n",
      "  batch 201 loss: 6.522289829604233e-05\n",
      "LOSS train 6.553124549824773e-05 valid 0.00012958260776940733\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.1067018678877503e-07\n",
      "  batch 101 loss: 6.041793519216299e-05\n",
      "  batch 201 loss: 5.834484043248267e-05\n",
      "LOSS train 5.7976680205773755e-05 valid 0.0001539194636279717\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.3373777114320546e-07\n",
      "  batch 101 loss: 5.722782070250787e-05\n",
      "  batch 201 loss: 5.7453662590489786e-05\n",
      "LOSS train 5.667777957855849e-05 valid 0.00018065827316604555\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.916822581435554e-07\n",
      "  batch 101 loss: 5.892763147585356e-05\n",
      "  batch 201 loss: 6.0963304659935604e-05\n",
      "LOSS train 5.981039511726978e-05 valid 0.00021332943288143724\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00018105052411556243\n",
      "  batch 101 loss: 0.04546717295539565\n",
      "  batch 201 loss: 0.0008737056411337107\n",
      "LOSS train 0.01714794712026873 valid 0.00014251968241296709\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.8639714582823216e-06\n",
      "  batch 101 loss: 0.0002462000827654265\n",
      "  batch 201 loss: 0.0001376491768678534\n",
      "LOSS train 0.000168327982997726 valid 8.336656173923984e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.960630627057981e-07\n",
      "  batch 101 loss: 8.710496897037956e-05\n",
      "  batch 201 loss: 0.00010910062549555732\n",
      "LOSS train 0.0001023021344129423 valid 8.032597543206066e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.071146471076645e-06\n",
      "  batch 101 loss: 0.00010898335405272519\n",
      "  batch 201 loss: 0.00011012703253754808\n",
      "LOSS train 0.00011190101533776171 valid 8.452961628790945e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1531525524333118e-06\n",
      "  batch 101 loss: 0.00011678847745770326\n",
      "  batch 201 loss: 0.00011748740932034708\n",
      "LOSS train 0.00011895744514914864 valid 8.756868191994727e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1721636838046835e-06\n",
      "  batch 101 loss: 0.000121054335380677\n",
      "  batch 201 loss: 0.000121967477398357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0001235260692485995 valid 8.253420674009249e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0373212717240677e-06\n",
      "  batch 101 loss: 0.00012751277901429603\n",
      "  batch 201 loss: 0.00012597205497968388\n",
      "LOSS train 0.0001274965553681459 valid 6.306612340267748e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.520455644931645e-07\n",
      "  batch 101 loss: 0.0001255284621674946\n",
      "  batch 201 loss: 0.00011879177147875453\n",
      "LOSS train 0.00012069139230141032 valid 5.0908718549180776e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.945577777922154e-05\n",
      "  batch 101 loss: 0.03160964928742033\n",
      "  batch 201 loss: 0.00015487190370549797\n",
      "LOSS train 0.011688517035102554 valid 5.334504021448083e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.453992343973369e-07\n",
      "  batch 101 loss: 7.701047726186516e-05\n",
      "  batch 201 loss: 8.0927634235195e-05\n",
      "LOSS train 8.049489044937311e-05 valid 6.840544665465131e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.275357686216011e-07\n",
      "  batch 101 loss: 9.146503085503354e-05\n",
      "  batch 201 loss: 9.683117100394157e-05\n",
      "LOSS train 9.662634917544776e-05 valid 8.292838174384087e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0493658919585869e-06\n",
      "  batch 101 loss: 0.0001082430881081109\n",
      "  batch 201 loss: 0.00011353777450182179\n",
      "LOSS train 0.00011396470909617065 valid 8.908269956009462e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1446281132521107e-06\n",
      "  batch 101 loss: 0.00012339986300389684\n",
      "  batch 201 loss: 0.00012472197076704105\n",
      "LOSS train 0.00012596595376173966 valid 7.298978744074702e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.547683682991192e-07\n",
      "  batch 101 loss: 0.00012733165920280953\n",
      "  batch 201 loss: 0.00012306651319306637\n",
      "LOSS train 0.00012450795140325898 valid 5.2796731324633583e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.535346331773326e-07\n",
      "  batch 101 loss: 0.00011724685804438195\n",
      "  batch 201 loss: 0.00010861856524115864\n",
      "LOSS train 0.00011006825439209347 valid 5.650871025864035e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.579615390161052e-08\n",
      "  batch 101 loss: 9.866676241756522e-05\n",
      "  batch 201 loss: 9.008245520419677e-05\n",
      "LOSS train 9.098946273234472e-05 valid 7.954663306009024e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00048607848584651946\n",
      "  batch 101 loss: 2.0146559192428684\n",
      "  batch 201 loss: 0.000244186271338549\n",
      "LOSS train 0.738279879128977 valid 0.0018415984231978655\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.140715442597865e-05\n",
      "  batch 101 loss: 0.0017660914940825024\n",
      "  batch 201 loss: 0.00014432430909664618\n",
      "LOSS train 0.0007467848196152346 valid 0.0018592553678900003\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.607263185083866e-05\n",
      "  batch 101 loss: 0.0023699996984123573\n",
      "  batch 201 loss: 0.0002132482330671337\n",
      "LOSS train 0.000983430668743628 valid 0.0016889841062948108\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.034488461911678e-05\n",
      "  batch 101 loss: 0.0029814174787316005\n",
      "  batch 201 loss: 0.00012273753033468894\n",
      "LOSS train 0.0011748284849868753 valid 0.0016556887421756983\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.007453426718712e-05\n",
      "  batch 101 loss: 0.00483013801249399\n",
      "  batch 201 loss: 0.0004005776462963695\n",
      "LOSS train 0.0019969739260891433 valid 0.002464761957526207\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.692071652039885e-05\n",
      "  batch 101 loss: 0.006787792793438711\n",
      "  batch 201 loss: 0.0005533595891574805\n",
      "LOSS train 0.0027410877154348257 valid 0.0023418040946125984\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.509067188948392e-05\n",
      "  batch 101 loss: 0.008612327718296911\n",
      "  batch 201 loss: 0.0006523342663376752\n",
      "LOSS train 0.0752198822674839 valid 0.04137362539768219\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0005157272890210151\n",
      "  batch 101 loss: 0.016697693000605796\n",
      "  batch 201 loss: 0.005095759265277593\n",
      "LOSS train 0.008638656221312256 valid 0.00625829491764307\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0031259292364120483\n",
      "  batch 101 loss: 1.7793072544201278\n",
      "  batch 201 loss: 0.0032397858600597827\n",
      "LOSS train 0.6545164147703209 valid 0.001399750355631113\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.390109658241272e-05\n",
      "  batch 101 loss: 0.0017574271268676967\n",
      "  batch 201 loss: 0.00027905391674721614\n",
      "LOSS train 0.0008037596240956524 valid 0.000360634847311303\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.346927300095558e-05\n",
      "  batch 101 loss: 0.000581026775726059\n",
      "  batch 201 loss: 3.3652946467555014e-05\n",
      "LOSS train 0.00023909781663990413 valid 0.00012694440374616534\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.513329037465155e-06\n",
      "  batch 101 loss: 0.000138280587079862\n",
      "  batch 201 loss: 1.605525651257267e-05\n",
      "LOSS train 6.214222951332356e-05 valid 4.811456528841518e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.3858899183105678e-06\n",
      "  batch 101 loss: 3.399841345981258e-05\n",
      "  batch 201 loss: 1.9454829227925075e-05\n",
      "LOSS train 2.3531947731282256e-05 valid 3.913289765478112e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.8583242460153994e-08\n",
      "  batch 101 loss: 4.420505322059398e-05\n",
      "  batch 201 loss: 4.502200715251092e-05\n",
      "LOSS train 5.607403058602758e-05 valid 5.7066266890615225e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.026488073170185e-07\n",
      "  batch 101 loss: 0.039843492279751445\n",
      "  batch 201 loss: 0.06678135695168748\n",
      "LOSS train 0.045985586274302756 valid 0.002364867366850376\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.9546623807400465e-05\n",
      "  batch 101 loss: 0.01009307157539297\n",
      "  batch 201 loss: 0.08459415068704403\n",
      "LOSS train 0.044384998872030984 valid 0.0033494445960968733\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002650073915719986\n",
      "  batch 101 loss: 2.104738626037724\n",
      "  batch 201 loss: 0.0048558013828005646\n",
      "LOSS train 0.7731515182891772 valid 0.000607611087616533\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.5807890817523e-05\n",
      "  batch 101 loss: 0.0007354894584568683\n",
      "  batch 201 loss: 7.180057415098417e-05\n",
      "LOSS train 0.0003166810304123212 valid 9.329490421805531e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.876691043842584e-06\n",
      "  batch 101 loss: 5.444314196665801e-05\n",
      "  batch 201 loss: 2.7690355900631402e-05\n",
      "LOSS train 3.921626466429825e-05 valid 3.4887892979895696e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1559593986021355e-07\n",
      "  batch 101 loss: 2.0791188740076903e-05\n",
      "  batch 201 loss: 3.301900923815992e-05\n",
      "LOSS train 2.7747494661505717e-05 valid 5.197006248636171e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.8991442630067467e-07\n",
      "  batch 101 loss: 1.7539886603117338e-05\n",
      "  batch 201 loss: 2.8496693639681327e-05\n",
      "LOSS train 2.3125693307799967e-05 valid 3.176996688125655e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.650551535538398e-08\n",
      "  batch 101 loss: 4.785221912698034e-05\n",
      "  batch 201 loss: 6.438230851017579e-05\n",
      "LOSS train 5.731255202753789e-05 valid 0.00014392034790944308\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.042952062562108e-06\n",
      "  batch 101 loss: 0.0001636782351852162\n",
      "  batch 201 loss: 0.027414188803450087\n",
      "LOSS train 0.0456852846882445 valid 0.025673726573586464\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00027833983302116394\n",
      "  batch 101 loss: 0.012809650486451574\n",
      "  batch 201 loss: 0.008141962297959254\n",
      "LOSS train 0.040852454757691455 valid 0.04976634308695793\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004518852382898331\n",
      "  batch 101 loss: 2.076126766349189\n",
      "  batch 201 loss: 0.004150725759973284\n",
      "LOSS train 0.762246631652891 valid 0.000402027100790292\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.4385609216988085e-05\n",
      "  batch 101 loss: 0.00039780363938916706\n",
      "  batch 201 loss: 2.725528789596865e-05\n",
      "LOSS train 0.00017879749673858775 valid 3.511031172820367e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.3001524823484943e-07\n",
      "  batch 101 loss: 2.9068931155507016e-05\n",
      "  batch 201 loss: 3.621269263476279e-05\n",
      "LOSS train 3.8730779218421826e-05 valid 3.8046244299039245e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.520613972796127e-07\n",
      "  batch 101 loss: 3.0765494011575355e-05\n",
      "  batch 201 loss: 4.763274000652018e-05\n",
      "LOSS train 3.932031247728153e-05 valid 6.972415576456115e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.590379724802915e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 3.083325987518038e-05\n",
      "  batch 201 loss: 7.535587589700298e-05\n",
      "LOSS train 6.404100419882731e-05 valid 7.09845990058966e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.3261551177711225e-07\n",
      "  batch 101 loss: 0.0002074639517468313\n",
      "  batch 201 loss: 0.00010262495570714236\n",
      "LOSS train 0.00016891150865846143 valid 0.0003463896573521197\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.812049446627498e-06\n",
      "  batch 101 loss: 0.0009300298967355047\n",
      "  batch 201 loss: 0.029301492460654117\n",
      "LOSS train 0.04322436464093159 valid 0.004470854997634888\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0002052071690559387\n",
      "  batch 101 loss: 0.03237874728627503\n",
      "  batch 201 loss: 0.050294546234654264\n",
      "LOSS train 0.06282293359235598 valid 0.021980617195367813\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.754414644092322e-06\n",
      "  batch 101 loss: 0.36940280455665175\n",
      "  batch 201 loss: 6.25023199518182e-05\n",
      "LOSS train 0.1511536211181509 valid 0.00010217600356554613\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.3658966054208576e-06\n",
      "  batch 101 loss: 0.0001483283494724219\n",
      "  batch 201 loss: 7.752250461180665e-05\n",
      "LOSS train 0.00010476162216468182 valid 6.727341678924859e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.381813338724896e-07\n",
      "  batch 101 loss: 8.742098136281129e-05\n",
      "  batch 201 loss: 9.345306360728501e-05\n",
      "LOSS train 9.299532603141988e-05 valid 8.1700760347303e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0169827146455646e-06\n",
      "  batch 101 loss: 0.00010511333096189901\n",
      "  batch 201 loss: 0.00011089355180331495\n",
      "LOSS train 0.00011116136166549287 valid 8.956850069807842e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1554885713849218e-06\n",
      "  batch 101 loss: 0.00012174805454549186\n",
      "  batch 201 loss: 0.00012410783995562725\n",
      "LOSS train 0.00012507502925604685 valid 7.424175419146195e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 8.780963980825617e-07\n",
      "  batch 101 loss: 0.0001276377962483366\n",
      "  batch 201 loss: 0.00012284835759970747\n",
      "LOSS train 0.0001242015299247742 valid 5.193037577555515e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.138850297546014e-07\n",
      "  batch 101 loss: 0.00011506223976311957\n",
      "  batch 201 loss: 0.00010499812542093423\n",
      "LOSS train 0.0001064339019619213 valid 6.203347584232688e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.4586981908214512e-08\n",
      "  batch 101 loss: 9.250310724155497e-05\n",
      "  batch 201 loss: 8.328930342713648e-05\n",
      "LOSS train 8.42389091060432e-05 valid 9.286266868002713e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.82547872606665e-06\n",
      "  batch 101 loss: 1.1703901883625076\n",
      "  batch 201 loss: 7.945547545205046e-05\n",
      "LOSS train 0.42876200147869287 valid 5.266062362352386e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.4895198041340337e-07\n",
      "  batch 101 loss: 6.230320736904105e-05\n",
      "  batch 201 loss: 6.480764437583275e-05\n",
      "LOSS train 6.386247847104565e-05 valid 5.561501893680543e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.539037763606757e-07\n",
      "  batch 101 loss: 6.909297265337955e-05\n",
      "  batch 201 loss: 7.19053722332319e-05\n",
      "LOSS train 7.108206851699456e-05 valid 6.037136699887924e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.824889740324579e-07\n",
      "  batch 101 loss: 7.696624144955422e-05\n",
      "  batch 201 loss: 8.031175370888377e-05\n",
      "LOSS train 7.966324857402752e-05 valid 6.755072536179796e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.440072658937425e-07\n",
      "  batch 101 loss: 8.65934977764482e-05\n",
      "  batch 201 loss: 9.055318135551715e-05\n",
      "LOSS train 9.020094486144304e-05 valid 7.720449502812698e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.343411511508748e-07\n",
      "  batch 101 loss: 9.83284472727064e-05\n",
      "  batch 201 loss: 0.00010268281870537521\n",
      "LOSS train 0.0001028056318181697 valid 8.693259587744251e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1098281538579613e-06\n",
      "  batch 101 loss: 0.00011161485021432327\n",
      "  batch 201 loss: 0.00011541123236071372\n",
      "LOSS train 0.00011616165165789356 valid 8.906424045562744e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1468060984043404e-06\n",
      "  batch 101 loss: 0.00012354035210250912\n",
      "  batch 201 loss: 0.00012463596331713234\n",
      "LOSS train 0.00012593553010080603 valid 7.453189755324274e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00014854778535664082\n",
      "  batch 101 loss: 0.4646188261050861\n",
      "  batch 201 loss: 0.01747183768656214\n",
      "LOSS train 0.1766652083828444 valid 5.60283224331215e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.663642539526336e-07\n",
      "  batch 101 loss: 7.071796430864196e-05\n",
      "  batch 201 loss: 7.574516321255942e-05\n",
      "LOSS train 7.475386670717027e-05 valid 6.544253847096115e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.990313704591244e-07\n",
      "  batch 101 loss: 8.49248720282958e-05\n",
      "  batch 201 loss: 9.05708596428667e-05\n",
      "LOSS train 9.004312987716007e-05 valid 7.897940668044612e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 9.673211752669885e-07\n",
      "  batch 101 loss: 0.00010149495861924151\n",
      "  batch 201 loss: 0.00010726351568052906\n",
      "LOSS train 0.00010740068411065301 valid 8.937990060076118e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1522442946443334e-06\n",
      "  batch 101 loss: 0.00011837799937495674\n",
      "  batch 201 loss: 0.00012181541140023456\n",
      "LOSS train 0.00012268295325035342 valid 8.055262151174247e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.96156595647335e-07\n",
      "  batch 101 loss: 0.00012778877131722766\n",
      "  batch 201 loss: 0.00012505772424105998\n",
      "LOSS train 0.0001263663000976448 valid 5.597564086201601e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.647953392122872e-07\n",
      "  batch 101 loss: 0.00012030906068275726\n",
      "  batch 201 loss: 0.00011124855791422306\n",
      "LOSS train 0.00011270811665363266 valid 5.5414926464436576e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.676458269794239e-08\n",
      "  batch 101 loss: 9.934859218304836e-05\n",
      "  batch 201 loss: 8.949132042971541e-05\n",
      "LOSS train 9.06197219116509e-05 valid 8.288213575724512e-05\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 7.836416363716126e-05\n",
      "  batch 101 loss: 0.2902577984713525\n",
      "  batch 201 loss: 6.870386420814611e-05\n",
      "LOSS train 0.10639451541024529 valid 6.114618008723482e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.012756057316438e-07\n",
      "  batch 101 loss: 8.042844365036217e-05\n",
      "  batch 201 loss: 8.821660323064862e-05\n",
      "LOSS train 8.736201595635372e-05 valid 7.911947614047676e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.699034853838383e-07\n",
      "  batch 101 loss: 0.00010292482918998758\n",
      "  batch 201 loss: 0.0001103450147707008\n",
      "LOSS train 0.00011031905918714536 valid 8.912000339478254e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.147767179645598e-06\n",
      "  batch 101 loss: 0.00012307275601244782\n",
      "  batch 201 loss: 0.00012518409074118608\n",
      "LOSS train 0.00012591760477040898 valid 6.745501741534099e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.419993926305324e-07\n",
      "  batch 101 loss: 0.0001260132992047147\n",
      "  batch 201 loss: 0.00011855751325583697\n",
      "LOSS train 0.00011988999910296622 valid 5.137469997862354e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.5426878235302866e-07\n",
      "  batch 101 loss: 0.00010644522705547388\n",
      "  batch 201 loss: 9.527702845730347e-05\n",
      "LOSS train 9.670188764518834e-05 valid 7.604569691466168e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.4589575130230514e-08\n",
      "  batch 101 loss: 8.233181046989558e-05\n",
      "  batch 201 loss: 7.43081148152669e-05\n",
      "LOSS train 7.500435546364062e-05 valid 0.00010948848648695275\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.1277980775048491e-07\n",
      "  batch 101 loss: 6.62796811343469e-05\n",
      "  batch 201 loss: 6.214625800907924e-05\n",
      "LOSS train 6.211733154700079e-05 valid 0.00013737211702391505\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00011580653488636017\n",
      "  batch 101 loss: 0.07285404982213549\n",
      "  batch 201 loss: 0.00013573963070939499\n",
      "LOSS train 0.02678221073513389 valid 4.27920458605513e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.794500455318484e-08\n",
      "  batch 101 loss: 1.308495989178482e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 1.2949302217748481e-05\n",
      "LOSS train 1.2296886260238743e-05 valid 3.715752609423362e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.781999556755182e-08\n",
      "  batch 101 loss: 9.931604835173857e-06\n",
      "  batch 201 loss: 8.751768283445927e-06\n",
      "LOSS train 9.016155252958504e-06 valid 4.5295826566871256e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.75420312240749e-09\n",
      "  batch 101 loss: 9.661372308755744e-06\n",
      "  batch 201 loss: 8.243928097613208e-06\n",
      "LOSS train 8.274050744619958e-06 valid 4.458242983673699e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.78544131712988e-09\n",
      "  batch 101 loss: 6.599591160920681e-06\n",
      "  batch 201 loss: 5.444953927167262e-06\n",
      "LOSS train 5.782667765146764e-06 valid 3.562312849680893e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.1942774967319564e-08\n",
      "  batch 101 loss: 5.465732712082172e-06\n",
      "  batch 201 loss: 4.311632754507855e-06\n",
      "LOSS train 4.4199243593984585e-06 valid 3.588771869544871e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.7165054891374897e-08\n",
      "  batch 101 loss: 3.299787882866667e-06\n",
      "  batch 201 loss: 2.493220315216149e-06\n",
      "LOSS train 2.6785171571133844e-06 valid 3.942092371289618e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 8.596750262768183e-09\n",
      "  batch 101 loss: 2.8531922103525177e-06\n",
      "  batch 201 loss: 2.4285857097794406e-06\n",
      "LOSS train 2.401214105793395e-06 valid 3.888955689035356e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0012332437932491302\n",
      "  batch 101 loss: 0.04560559541570797\n",
      "  batch 201 loss: 0.00010891209495270004\n",
      "LOSS train 0.01723116686045563 valid 6.742405093973503e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.979039946803823e-07\n",
      "  batch 101 loss: 0.00012385579197371043\n",
      "  batch 201 loss: 0.00010244426400447537\n",
      "LOSS train 0.00010547336777568862 valid 9.086117643164471e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 4.5788419811287896e-08\n",
      "  batch 101 loss: 7.402215221645747e-05\n",
      "  batch 201 loss: 6.427148486636724e-05\n",
      "LOSS train 6.579874804384208e-05 valid 0.00014014705084264278\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.5759229174582285e-07\n",
      "  batch 101 loss: 5.810001727525105e-05\n",
      "  batch 201 loss: 5.760297394857616e-05\n",
      "LOSS train 5.713319030390736e-05 valid 0.0001879506162367761\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.288124521030113e-07\n",
      "  batch 101 loss: 6.015371727073671e-05\n",
      "  batch 201 loss: 6.41417932641275e-05\n",
      "LOSS train 6.302446692581938e-05 valid 0.0002523690345697105\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.562676859786733e-07\n",
      "  batch 101 loss: 7.215315649375498e-05\n",
      "  batch 201 loss: 7.873567601109244e-05\n",
      "LOSS train 7.732503974303212e-05 valid 0.0002977017138618976\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2739085650537163e-06\n",
      "  batch 101 loss: 8.342586157368715e-05\n",
      "  batch 201 loss: 8.186131527850194e-05\n",
      "LOSS train 8.213669534706285e-05 valid 0.00020346904057078063\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.321431283140555e-07\n",
      "  batch 101 loss: 7.061259120405339e-05\n",
      "  batch 201 loss: 6.096357470141811e-05\n",
      "LOSS train 6.323266560411533e-05 valid 0.00011159070709254593\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0007720733433961868\n",
      "  batch 101 loss: 0.05539427374189245\n",
      "  batch 201 loss: 0.00011157194658920843\n",
      "LOSS train 0.020648885184840746 valid 6.167402170831338e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.138369644759223e-07\n",
      "  batch 101 loss: 0.00011819406505424013\n",
      "  batch 201 loss: 9.42284691967643e-05\n",
      "LOSS train 9.804235386662938e-05 valid 9.955192945199087e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 7.420202564389911e-08\n",
      "  batch 101 loss: 6.877915979885075e-05\n",
      "  batch 201 loss: 6.123377931771756e-05\n",
      "LOSS train 6.224058240654763e-05 valid 0.00014974626537878066\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.105959694948979e-07\n",
      "  batch 101 loss: 5.7241327414772055e-05\n",
      "  batch 201 loss: 5.7824222905082935e-05\n",
      "LOSS train 5.72221310855952e-05 valid 0.0001994659542106092\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 6.067130743758753e-07\n",
      "  batch 101 loss: 6.219304899843792e-05\n",
      "  batch 201 loss: 6.746700460894317e-05\n",
      "LOSS train 6.618797730222898e-05 valid 0.0002708591055124998\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0841491894097998e-06\n",
      "  batch 101 loss: 7.639565139243132e-05\n",
      "  batch 201 loss: 8.203103460687089e-05\n",
      "LOSS train 8.08460585823503e-05 valid 0.00028360774740576744\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.173707569250837e-06\n",
      "  batch 101 loss: 8.245280176197412e-05\n",
      "  batch 201 loss: 7.697735051124255e-05\n",
      "LOSS train 7.807385893082048e-05 valid 0.00016530888387933373\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.987319360021502e-07\n",
      "  batch 101 loss: 6.327569578161274e-05\n",
      "  batch 201 loss: 5.408830106375717e-05\n",
      "LOSS train 5.6271221673060134e-05 valid 9.759777458384633e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0016642329096794128\n",
      "  batch 101 loss: 0.24110954438277987\n",
      "  batch 201 loss: 0.0004522662087401841\n",
      "LOSS train 0.08916090480624417 valid 6.871391087770462e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.9108637934550643e-06\n",
      "  batch 101 loss: 0.00016388364801969146\n",
      "  batch 201 loss: 0.0001309631869662553\n",
      "LOSS train 0.00014185419671769225 valid 8.988635818241164e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1139280104544014e-06\n",
      "  batch 101 loss: 0.00012420621154888068\n",
      "  batch 201 loss: 0.00012633912437308935\n",
      "LOSS train 0.00012675204007940013 valid 6.56574047752656e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.163020200096071e-07\n",
      "  batch 101 loss: 0.00012593024302191225\n",
      "  batch 201 loss: 0.00011905590523838328\n",
      "LOSS train 0.00011991277385765561 valid 5.1697224989766255e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.3945127648185006e-07\n",
      "  batch 101 loss: 0.00010493063669400726\n",
      "  batch 201 loss: 9.280565985818612e-05\n",
      "LOSS train 9.437111331351597e-05 valid 8.140972931869328e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.2680583242618012e-08\n",
      "  batch 101 loss: 7.900127246102784e-05\n",
      "  batch 201 loss: 7.120175229147208e-05\n",
      "LOSS train 7.187663240217724e-05 valid 0.00011655785056063905\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.4332081264001317e-07\n",
      "  batch 101 loss: 6.370560421828486e-05\n",
      "  batch 201 loss: 6.022843442337944e-05\n",
      "LOSS train 6.0106925324388886e-05 valid 0.00014521277626045048\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.859064807125833e-07\n",
      "  batch 101 loss: 5.7636841807209296e-05\n",
      "  batch 201 loss: 5.7240160208493764e-05\n",
      "LOSS train 5.660584045856576e-05 valid 0.00017612420197110623\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00010921474546194077\n",
      "  batch 101 loss: 11.573190016395511\n",
      "  batch 201 loss: 0.0005335994171991842\n",
      "LOSS train 4.239502922861222 valid 4.6123623178573325e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.41172547248425e-07\n",
      "  batch 101 loss: 1.3292934899595821e-05\n",
      "  batch 201 loss: 5.0711572792749846e-06\n",
      "LOSS train 7.4902992768960054e-06 valid 4.649108450394124e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.617226553207729e-07\n",
      "  batch 101 loss: 1.3319865300047695e-05\n",
      "  batch 201 loss: 9.85330831582587e-06\n",
      "LOSS train 1.250176424173291e-05 valid 4.2608568037394434e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.1929164833854884e-07\n",
      "  batch 101 loss: 3.107846657712798e-05\n",
      "  batch 201 loss: 1.2775727406051373e-05\n",
      "LOSS train 1.8625198611511683e-05 valid 4.655156590160914e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.3427379094064234e-07\n",
      "  batch 101 loss: 3.598143805561449e-05\n",
      "  batch 201 loss: 1.721488075702382e-05\n",
      "LOSS train 3.120903792642278e-05 valid 0.00013655591465067118\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.9536009606090373e-07\n",
      "  batch 101 loss: 7.618398478200562e-05\n",
      "  batch 201 loss: 2.446748462375581e-05\n",
      "LOSS train 4.349475786837555e-05 valid 7.847900269553065e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0043265774584142e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 6.175273862822906e-05\n",
      "  batch 201 loss: 1.7019835735254673e-05\n",
      "LOSS train 3.623223654195056e-05 valid 5.4236490541370586e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.4300478142104113e-07\n",
      "  batch 101 loss: 6.22360089130325e-05\n",
      "  batch 201 loss: 1.5488677152575293e-05\n",
      "LOSS train 3.587745462859707e-05 valid 6.618660700041801e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 5.148256896063686e-06\n",
      "  batch 101 loss: 10.358172689634376\n",
      "  batch 201 loss: 0.0019099908822681755\n",
      "LOSS train 3.795230326992515 valid 0.000266718037892133\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.162774563767016e-06\n",
      "  batch 101 loss: 0.0007448823406593874\n",
      "  batch 201 loss: 0.0003909871872747317\n",
      "LOSS train 0.0004787332305141841 valid 0.00019589638395700604\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.3058126205578446e-06\n",
      "  batch 101 loss: 0.00010766504001367139\n",
      "  batch 201 loss: 5.561882861456979e-05\n",
      "LOSS train 7.565843235722371e-05 valid 5.093009531265125e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.9109753338852897e-07\n",
      "  batch 101 loss: 5.911955996452889e-05\n",
      "  batch 201 loss: 0.0010104367351050315\n",
      "LOSS train 0.0013477874618086426 valid 5.181735104997642e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.076631764997728e-07\n",
      "  batch 101 loss: 0.007951624644247203\n",
      "  batch 201 loss: 6.059556440959568e-05\n",
      "LOSS train 0.002951277623078534 valid 5.266965672490187e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.493451004032977e-07\n",
      "  batch 101 loss: 6.198931052495027e-05\n",
      "  batch 201 loss: 0.0007154133490712411\n",
      "LOSS train 0.0029668259879697925 valid 7.011199340922758e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.7116175517439844e-05\n",
      "  batch 101 loss: 7.618409677888849e-05\n",
      "  batch 201 loss: 0.0010729578765858606\n",
      "LOSS train 0.0004516244078984481 valid 5.518800753634423e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.406378502608277e-07\n",
      "  batch 101 loss: 6.757931166703201e-05\n",
      "  batch 201 loss: 6.898460147112928e-05\n",
      "LOSS train 7.310506514128172e-05 valid 5.701508780475706e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.89903474226594e-05\n",
      "  batch 101 loss: 123.19492953189649\n",
      "  batch 201 loss: 0.038338647186756135\n",
      "LOSS train 45.14424010369783 valid 0.008640316314995289\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.440185502171517e-05\n",
      "  batch 101 loss: 0.00447284116060473\n",
      "  batch 201 loss: 0.0008919150175643153\n",
      "LOSS train 0.0020537004923396156 valid 0.00011359933705534786\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.547929859953001e-06\n",
      "  batch 101 loss: 7.699679057623144e-05\n",
      "  batch 201 loss: 5.572672664129641e-05\n",
      "LOSS train 6.274864920872864e-05 valid 5.1095790695399046e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.550700446590781e-07\n",
      "  batch 101 loss: 5.334459289770166e-05\n",
      "  batch 201 loss: 5.3511016058109815e-05\n",
      "LOSS train 5.276431309559464e-05 valid 5.0985061534447595e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.4114200641633943e-07\n",
      "  batch 101 loss: 5.3724567542303704e-05\n",
      "  batch 201 loss: 5.394207609242585e-05\n",
      "LOSS train 5.317770660190285e-05 valid 5.103141302242875e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.475619294273201e-07\n",
      "  batch 101 loss: 5.4198315419853314e-05\n",
      "  batch 201 loss: 5.443640829071228e-05\n",
      "LOSS train 5.367180312779112e-05 valid 5.1094102673232555e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.54885308095254e-07\n",
      "  batch 101 loss: 5.472940200888843e-05\n",
      "  batch 201 loss: 5.499462932675669e-05\n",
      "LOSS train 5.422943582084122e-05 valid 5.11772304889746e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.6318986783735455e-07\n",
      "  batch 101 loss: 5.533356697014824e-05\n",
      "  batch 201 loss: 5.56336375848332e-05\n",
      "LOSS train 5.486745113481221e-05 valid 5.1288003305671737e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00017414355650544167\n",
      "  batch 101 loss: 85.07641475327313\n",
      "  batch 201 loss: 0.028158374689519407\n",
      "LOSS train 31.178891058523384 valid 0.005248236935585737\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00019140880554914476\n",
      "  batch 101 loss: 0.012579385275021195\n",
      "  batch 201 loss: 0.007073387517593801\n",
      "LOSS train 0.00831201884660174 valid 0.002002378925681114\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.9862327501177788e-05\n",
      "  batch 101 loss: 0.002099752262001857\n",
      "  batch 201 loss: 0.0009887064521899448\n",
      "LOSS train 0.0012568414803264293 valid 0.00020504974236246198\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.0742636115755886e-06\n",
      "  batch 101 loss: 0.0002276314128539525\n",
      "  batch 201 loss: 0.00011073524394305422\n",
      "LOSS train 0.00014157396699474603 valid 6.618539919145405e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.8658340195543132e-07\n",
      "  batch 101 loss: 4.768871239548389e-05\n",
      "  batch 201 loss: 4.148507969603088e-05\n",
      "LOSS train 4.250066609819152e-05 valid 5.7445879065198824e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 9.750950084708166e-08\n",
      "  batch 101 loss: 3.940312728900608e-05\n",
      "  batch 201 loss: 4.0885416192395494e-05\n",
      "LOSS train 3.9364421222954985e-05 valid 5.142076770425774e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.5603320207446814e-07\n",
      "  batch 101 loss: 4.0062877351374484e-05\n",
      "  batch 201 loss: 4.405820306601527e-05\n",
      "LOSS train 4.21316697331629e-05 valid 6.085475251893513e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.4203549653757363e-07\n",
      "  batch 101 loss: 5.126331531755568e-05\n",
      "  batch 201 loss: 6.008866098454746e-05\n",
      "LOSS train 5.7265150371343864e-05 valid 5.1952833018731326e-05\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0001959213614463806\n",
      "  batch 101 loss: 0.1118841287021587\n",
      "  batch 201 loss: 0.00017593530545582326\n",
      "LOSS train 0.041135736743972334 valid 0.0008582250447943807\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.598061088472605e-05\n",
      "  batch 101 loss: 0.0004309113523470387\n",
      "  batch 201 loss: 0.00016975558111766986\n",
      "LOSS train 0.00025066815347760655 valid 0.0012178386095911264\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.908970255404711e-05\n",
      "  batch 101 loss: 0.0007746685412143961\n",
      "  batch 201 loss: 0.00016698749531144586\n",
      "LOSS train 0.00039028280630228626 valid 0.0006371743511408567\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.518151352182031e-05\n",
      "  batch 101 loss: 0.0008154691677555092\n",
      "  batch 201 loss: 0.0001780578917157527\n",
      "LOSS train 0.0004309092723086649 valid 0.0007927656406536698\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.659799858927727e-05\n",
      "  batch 101 loss: 0.0012852920201089546\n",
      "  batch 201 loss: 0.00023590562610706912\n",
      "LOSS train 0.0005861584497646145 valid 0.0008857101202011108\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.340668372809887e-05\n",
      "  batch 101 loss: 0.0024490730991965394\n",
      "  batch 201 loss: 0.00018179178870923352\n",
      "LOSS train 0.0010093267174209396 valid 0.0006710660527460277\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.1245408356189726e-05\n",
      "  batch 101 loss: 0.0024766378695767343\n",
      "  batch 201 loss: 0.00017332746448118998\n",
      "LOSS train 0.0013363302839725427 valid 0.002992108464241028\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00011057998053729535\n",
      "  batch 101 loss: 0.0057454981518094425\n",
      "  batch 201 loss: 0.002471735826766235\n",
      "LOSS train 0.0032672730791797728 valid 0.0006447246414609253\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.457501064985991e-05\n",
      "  batch 101 loss: 0.004187757180116023\n",
      "  batch 201 loss: 0.002152976754659903\n",
      "LOSS train 0.0026741344018364043 valid 0.0010069571435451508\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 6.0537215322256085e-05\n",
      "  batch 101 loss: 0.006865734088933095\n",
      "  batch 201 loss: 0.0002997689451967744\n",
      "LOSS train 0.0027304504342165995 valid 0.0011381404474377632\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.557025644928218e-05\n",
      "  batch 101 loss: 0.00773747798819386\n",
      "  batch 201 loss: 0.0003447494728595757\n",
      "LOSS train 0.003128569873221863 valid 0.0019384288461878896\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 0.0001334539707750082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.007695616839855575\n",
      "  batch 201 loss: 0.0004670085366933563\n",
      "LOSS train 0.0033610089520905457 valid 0.0023009609431028366\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0010063230991363525\n",
      "  batch 101 loss: 0.08987513329600916\n",
      "  batch 201 loss: 0.002150022409041412\n",
      "LOSS train 0.034404536443310464 valid 0.00035498623037710786\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.615075541660189e-06\n",
      "  batch 101 loss: 0.00043769797674030996\n",
      "  batch 201 loss: 0.00014206510222720682\n",
      "LOSS train 0.00022997154376956536 valid 4.606762377079576e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0921589273493736e-06\n",
      "  batch 101 loss: 5.523698167962721e-05\n",
      "  batch 201 loss: 2.221172930603643e-05\n",
      "LOSS train 3.3264780697355645e-05 valid 3.479792212601751e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.386148793855682e-07\n",
      "  batch 101 loss: 2.9084424784286967e-05\n",
      "  batch 201 loss: 1.418862354285011e-05\n",
      "LOSS train 2.01962076535116e-05 valid 3.7456695281434804e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.049432962143328e-07\n",
      "  batch 101 loss: 1.875311781077471e-05\n",
      "  batch 201 loss: 3.139789200531595e-05\n",
      "LOSS train 3.908180803338484e-05 valid 7.649280451005325e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.829177876468748e-07\n",
      "  batch 101 loss: 9.457841409584944e-05\n",
      "  batch 201 loss: 0.0019648509798753364\n",
      "LOSS train 0.0031227910319782727 valid 0.000520796631462872\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.845597479492426e-06\n",
      "  batch 101 loss: 0.0004006633614335442\n",
      "  batch 201 loss: 0.0002802793646606006\n",
      "LOSS train 0.0025291488862774964 valid 0.0024578950833529234\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.6426084116101264e-05\n",
      "  batch 101 loss: 0.003534565084555652\n",
      "  batch 201 loss: 0.00019509535536599287\n",
      "LOSS train 0.0015143678635397989 valid 0.0008476285729557276\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.306487713009119e-05\n",
      "  batch 101 loss: 0.006217110429315653\n",
      "  batch 201 loss: 0.0019426221447065473\n",
      "LOSS train 0.003076008944425177 valid 7.081037620082498e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.5355221694335341e-06\n",
      "  batch 101 loss: 0.002407743980329542\n",
      "  batch 201 loss: 0.0012344701776601141\n",
      "LOSS train 0.003986540241471846 valid 0.011667315848171711\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.190322503447533e-05\n",
      "  batch 101 loss: 0.0019513666857528733\n",
      "  batch 201 loss: 0.00022317119315630408\n",
      "LOSS train 0.001381917123114526 valid 0.0009978656889870763\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.8837450770661235e-05\n",
      "  batch 101 loss: 0.0031873936088959456\n",
      "  batch 201 loss: 0.0026539137630607\n",
      "LOSS train 0.002760117033935935 valid 0.00020733621204271913\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0008784236758947372\n",
      "  batch 101 loss: 0.09943151364568621\n",
      "  batch 201 loss: 0.0018923081032698975\n",
      "LOSS train 0.03754786094003519 valid 5.0665781600400805e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.660028160084039e-06\n",
      "  batch 101 loss: 0.00014555795551132177\n",
      "  batch 201 loss: 2.7873071858266484e-05\n",
      "LOSS train 7.054844341577596e-05 valid 7.663630822207779e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.6334335416322576e-07\n",
      "  batch 101 loss: 3.625357795954187e-05\n",
      "  batch 201 loss: 2.34844507372145e-05\n",
      "LOSS train 3.1807634961076694e-05 valid 3.4286174923181534e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.737703420687467e-08\n",
      "  batch 101 loss: 1.5587856760248543e-05\n",
      "  batch 201 loss: 1.7759213917543094e-05\n",
      "LOSS train 1.670472492927256e-05 valid 4.0702092519495636e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.780412266176427e-08\n",
      "  batch 101 loss: 3.915625088438901e-05\n",
      "  batch 201 loss: 3.6110306250520804e-05\n",
      "LOSS train 4.034000428810398e-05 valid 6.046165435691364e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.791749259107746e-07\n",
      "  batch 101 loss: 7.609385789692169e-05\n",
      "  batch 201 loss: 0.00028511312237242234\n",
      "LOSS train 0.004382350255092695 valid 0.0010690460912883282\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.900278846733272e-05\n",
      "  batch 101 loss: 0.0010503817257631453\n",
      "  batch 201 loss: 0.00010080664673296269\n",
      "LOSS train 0.0004848845396320143 valid 6.316060171229765e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.6332731320289895e-07\n",
      "  batch 101 loss: 0.002537546479661614\n",
      "  batch 201 loss: 0.0026103427533234937\n",
      "LOSS train 0.00294312024077074 valid 0.0001370234094792977\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.553269827738404e-06\n",
      "  batch 101 loss: 0.0012426451842475217\n",
      "  batch 201 loss: 0.0034050170347472886\n",
      "LOSS train 0.0027019070186505125 valid 0.0013059687335044146\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 9.638736955821514e-06\n",
      "  batch 101 loss: 0.0018521079140919028\n",
      "  batch 201 loss: 0.0028211213673785098\n",
      "LOSS train 0.002597327228050701 valid 0.0003411221841815859\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.3582537434995175e-06\n",
      "  batch 101 loss: 0.002631231025297893\n",
      "  batch 201 loss: 0.0026173346251744077\n",
      "LOSS train 0.00317055744983255 valid 0.00026321844779886305\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.98000895883888e-06\n",
      "  batch 101 loss: 0.001630043978075264\n",
      "  batch 201 loss: 0.002679934352345299\n",
      "LOSS train 0.002593443812616937 valid 0.003565483260899782\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0004419459030032158\n",
      "  batch 101 loss: 0.13844406032701953\n",
      "  batch 201 loss: 0.0008635593159124255\n",
      "LOSS train 0.05120973060966274 valid 4.187599188298918e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.2377347340807318e-06\n",
      "  batch 101 loss: 4.884412984665687e-05\n",
      "  batch 201 loss: 2.244262717795209e-05\n",
      "LOSS train 3.3352518790047476e-05 valid 4.310297663323581e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.3086482694197913e-08\n",
      "  batch 101 loss: 2.6087084233950008e-05\n",
      "  batch 201 loss: 3.165551824167778e-05\n",
      "LOSS train 3.44794122058321e-05 valid 3.492250107228756e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.0443338144104928e-07\n",
      "  batch 101 loss: 2.5550932091391586e-05\n",
      "  batch 201 loss: 3.953555795760622e-05\n",
      "LOSS train 3.9530736164820674e-05 valid 9.59030439844355e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.824619489023462e-07\n",
      "  batch 101 loss: 3.4102231356882836e-05\n",
      "  batch 201 loss: 5.2583997180590814e-05\n",
      "LOSS train 4.4646764875060965e-05 valid 3.439985812292434e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.816344931488857e-07\n",
      "  batch 101 loss: 0.00012920246914291056\n",
      "  batch 201 loss: 0.00012977238764506183\n",
      "LOSS train 0.00020632994996308947 valid 0.000263136433204636\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.484217741061002e-06\n",
      "  batch 101 loss: 0.0010485064596286976\n",
      "  batch 201 loss: 0.0027972745688748545\n",
      "LOSS train 0.004453176726444689 valid 0.002304881578311324\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.825038999319076e-05\n",
      "  batch 101 loss: 0.0033032751409336923\n",
      "  batch 201 loss: 0.0011056470769108273\n",
      "LOSS train 0.0017065595886192452 valid 3.8782185583841056e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 6.880793807795272e-07\n",
      "  batch 101 loss: 0.0030714183180680266\n",
      "  batch 201 loss: 0.006448477544472553\n",
      "LOSS train 0.004397509725294894 valid 0.0017176283290609717\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.315211109817028e-05\n",
      "  batch 101 loss: 0.002566089983010897\n",
      "  batch 201 loss: 0.0010828697589749935\n",
      "LOSS train 0.0020232212518882554 valid 0.0006243615061976016\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2188364053145051e-05\n",
      "  batch 101 loss: 0.006410485745873302\n",
      "  batch 201 loss: 0.002896141662931768\n",
      "LOSS train 0.004091856468787874 valid 0.00017335882876068354\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 4.73366177175194e-06\n",
      "  batch 101 loss: 0.0030108094739262014\n",
      "  batch 201 loss: 0.004136949083767831\n",
      "LOSS train 0.0033315790097754546 valid 0.0004897591425105929\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.641440072096884e-06\n",
      "  batch 101 loss: 0.02015430444607773\n",
      "  batch 201 loss: 6.60624844385893e-05\n",
      "LOSS train 0.007428161516431845 valid 5.8782588894246146e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.424573464551941e-07\n",
      "  batch 101 loss: 7.631281525391387e-05\n",
      "  batch 201 loss: 8.28264000801937e-05\n",
      "LOSS train 8.190547309273465e-05 valid 7.312918751267716e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.565417374484241e-07\n",
      "  batch 101 loss: 9.499514340404857e-05\n",
      "  batch 201 loss: 0.00010175265817963464\n",
      "LOSS train 0.00010151166870526393 valid 8.762227662373334e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1218417785130442e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00011426729264968572\n",
      "  batch 201 loss: 0.00011894064445357344\n",
      "LOSS train 0.0001195532805525923 valid 8.490047184750438e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0741391452029347e-06\n",
      "  batch 101 loss: 0.00012687785948003238\n",
      "  batch 201 loss: 0.00012584431600885183\n",
      "LOSS train 0.00012713588240399992 valid 6.189411215018481e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.190208659972996e-07\n",
      "  batch 101 loss: 0.00012426215155755926\n",
      "  batch 201 loss: 0.00011706447790629681\n",
      "LOSS train 0.00011859227230484349 valid 5.119460911373608e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.653146136959549e-07\n",
      "  batch 101 loss: 0.00010802532163097567\n",
      "  batch 201 loss: 9.874639254462635e-05\n",
      "LOSS train 9.998659568665285e-05 valid 6.77059288136661e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.3068075759292696e-08\n",
      "  batch 101 loss: 8.849224851360304e-05\n",
      "  batch 201 loss: 8.083556611381936e-05\n",
      "LOSS train 8.148462830788395e-05 valid 9.453186794416979e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.708317075914238e-08\n",
      "  batch 101 loss: 7.298811974123964e-05\n",
      "  batch 201 loss: 6.798311683041903e-05\n",
      "LOSS train 6.806888906474661e-05 valid 0.00011918239033548161\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.5521363820880653e-07\n",
      "  batch 101 loss: 6.315563455018491e-05\n",
      "  batch 201 loss: 6.04851460707323e-05\n",
      "LOSS train 6.015057877884695e-05 valid 0.0001406054216204211\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.613295328046661e-07\n",
      "  batch 101 loss: 5.82500179143608e-05\n",
      "  batch 201 loss: 5.742928369954825e-05\n",
      "LOSS train 5.6783887063476617e-05 valid 0.00016205110296141356\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.798824764089659e-07\n",
      "  batch 101 loss: 5.7305013385757774e-05\n",
      "  batch 201 loss: 5.8015260080424014e-05\n",
      "LOSS train 5.711410657199233e-05 valid 0.00018695206381380558\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 4.86712483689189e-05\n",
      "  batch 101 loss: 0.039853118763185195\n",
      "  batch 201 loss: 6.0318619098325144e-05\n",
      "LOSS train 0.014654509215411936 valid 5.440592940431088e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.150961467530578e-07\n",
      "  batch 101 loss: 6.72576063334418e-05\n",
      "  batch 201 loss: 7.114023218036891e-05\n",
      "LOSS train 7.016638269489218e-05 valid 6.0778351326007396e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.924106881138868e-07\n",
      "  batch 101 loss: 7.810871406036313e-05\n",
      "  batch 201 loss: 8.252627543242852e-05\n",
      "LOSS train 8.183048751831578e-05 valid 7.061895303195342e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.069064642768354e-07\n",
      "  batch 101 loss: 9.085900972195304e-05\n",
      "  batch 201 loss: 9.580988885090846e-05\n",
      "LOSS train 9.555339097510064e-05 valid 8.252804400399327e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0318810382159426e-06\n",
      "  batch 101 loss: 0.00010544724600265454\n",
      "  batch 201 loss: 0.00011014945206142102\n",
      "LOSS train 0.00011053804236096503 valid 8.981090650195256e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1596555123105645e-06\n",
      "  batch 101 loss: 0.00011950958308659665\n",
      "  batch 201 loss: 0.00012204727867924703\n",
      "LOSS train 0.00012313351456067566 valid 8.190015068976209e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0205814760411158e-06\n",
      "  batch 101 loss: 0.00012757926191852675\n",
      "  batch 201 loss: 0.00012564628056679794\n",
      "LOSS train 0.0001271754786077988 valid 6.118087912909687e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.02106265432667e-07\n",
      "  batch 101 loss: 0.00012412665594865757\n",
      "  batch 201 loss: 0.00011748172938041534\n",
      "LOSS train 0.00011904008660260447 valid 5.094095831736922e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.9150495063513519e-07\n",
      "  batch 101 loss: 0.00010989447868269053\n",
      "  batch 201 loss: 0.00010124778361387144\n",
      "LOSS train 0.00010246907794890621 valid 6.361163832480088e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.9914346012228634e-08\n",
      "  batch 101 loss: 9.185128123931463e-05\n",
      "  batch 201 loss: 8.41888970285254e-05\n",
      "LOSS train 8.487478764674874e-05 valid 8.808004349702969e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.801813818427036e-08\n",
      "  batch 101 loss: 7.628448829336775e-05\n",
      "  batch 201 loss: 7.086157150069994e-05\n",
      "LOSS train 7.10234960462626e-05 valid 0.00011240777530474588\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.2511342902143953e-07\n",
      "  batch 101 loss: 6.551656998908584e-05\n",
      "  batch 201 loss: 6.230843954085685e-05\n",
      "LOSS train 6.205848232669239e-05 valid 0.0001336805580649525\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.32265955209732e-05\n",
      "  batch 101 loss: 0.045639593832893295\n",
      "  batch 201 loss: 8.371141961106332e-05\n",
      "LOSS train 0.01705645188480841 valid 5.136177787790075e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.784691605484113e-07\n",
      "  batch 101 loss: 6.560758371051633e-05\n",
      "  batch 201 loss: 6.953507036996598e-05\n",
      "LOSS train 6.837285074266303e-05 valid 5.932150088483468e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.562875594478101e-07\n",
      "  batch 101 loss: 7.579335755508509e-05\n",
      "  batch 201 loss: 7.980203227361926e-05\n",
      "LOSS train 7.906289103810015e-05 valid 6.782283162465319e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.496993930544704e-07\n",
      "  batch 101 loss: 8.729244779942747e-05\n",
      "  batch 201 loss: 9.188868452838505e-05\n",
      "LOSS train 9.151332046513035e-05 valid 7.89828845881857e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 9.673858585301787e-07\n",
      "  batch 101 loss: 0.00010079648227247162\n",
      "  batch 201 loss: 0.00010552378240390681\n",
      "LOSS train 0.00010571244413309088 valid 8.856068598106503e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1381114745745436e-06\n",
      "  batch 101 loss: 0.00011496396486109006\n",
      "  batch 201 loss: 0.00011841165363307482\n",
      "LOSS train 0.00011929218140303686 valid 8.704389620106667e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1117697431473062e-06\n",
      "  batch 101 loss: 0.00012567340873943068\n",
      "  batch 201 loss: 0.00012559788736211887\n",
      "LOSS train 0.00012703057408487193 valid 6.963241321500391e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 7.869738328736275e-07\n",
      "  batch 101 loss: 0.00012702700801014543\n",
      "  batch 201 loss: 0.00012212409643126422\n",
      "LOSS train 0.0001237315636396593 valid 5.242331826593727e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.3832049666671083e-07\n",
      "  batch 101 loss: 0.00011672850463583018\n",
      "  batch 201 loss: 0.00010857294055767852\n",
      "LOSS train 0.00010996628690956754 valid 5.582869562203996e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 6.239121830731164e-08\n",
      "  batch 101 loss: 9.955205582883763e-05\n",
      "  batch 201 loss: 9.127091289542477e-05\n",
      "LOSS train 9.218607888783481e-05 valid 7.691342034377158e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.5590292150591268e-08\n",
      "  batch 101 loss: 8.256807220959673e-05\n",
      "  batch 201 loss: 7.615614760197786e-05\n",
      "LOSS train 7.652866364655509e-05 valid 0.00010196727089351043\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 8.304760740429628e-08\n",
      "  batch 101 loss: 6.97023821453513e-05\n",
      "  batch 201 loss: 6.556752730261905e-05\n",
      "LOSS train 6.548193716303553e-05 valid 0.0001243880979018286\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00045595765113830565\n",
      "  batch 101 loss: 0.042934712239075454\n",
      "  batch 201 loss: 0.0001297380702862938\n",
      "LOSS train 0.016377755193237437 valid 7.554733019787818e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.030778164742515e-07\n",
      "  batch 101 loss: 7.019448655682936e-05\n",
      "  batch 201 loss: 7.129932547741192e-05\n",
      "LOSS train 7.15409117139723e-05 valid 6.094610580476001e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.964651791146025e-07\n",
      "  batch 101 loss: 7.836756903998321e-05\n",
      "  batch 201 loss: 8.283021220449882e-05\n",
      "LOSS train 8.213967113002355e-05 valid 7.093368185451254e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.132120274240151e-07\n",
      "  batch 101 loss: 9.12554161141088e-05\n",
      "  batch 201 loss: 9.624176787156103e-05\n",
      "LOSS train 9.599905720628718e-05 valid 8.289323886856437e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0384297638665886e-06\n",
      "  batch 101 loss: 0.00010594999522822946\n",
      "  batch 201 loss: 0.00011063708008350659\n",
      "LOSS train 0.0001110474785588979 valid 8.984012674773112e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1601569713093341e-06\n",
      "  batch 101 loss: 0.00011996029985311907\n",
      "  batch 201 loss: 0.0001223779178354789\n",
      "LOSS train 0.00012348418256838807 valid 8.121257269522175e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.0081484651891514e-06\n",
      "  batch 101 loss: 0.00012768568964190762\n",
      "  batch 201 loss: 0.00012554341919440048\n",
      "LOSS train 0.00012707965212407395 valid 6.035546903149225e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.820992009830661e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.00012370574376973308\n",
      "  batch 201 loss: 0.00011689790777836606\n",
      "LOSS train 0.00011844820476190619 valid 5.103911098558456e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.7845615730038844e-07\n",
      "  batch 101 loss: 0.00010911946917531168\n",
      "  batch 201 loss: 0.00010045422936627802\n",
      "LOSS train 0.0001016553440296522 valid 6.458539428422228e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.7660734101809793e-08\n",
      "  batch 101 loss: 9.105795039317855e-05\n",
      "  batch 201 loss: 8.347775013135106e-05\n",
      "LOSS train 8.413930422256815e-05 valid 8.926468581194058e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.123934559174813e-08\n",
      "  batch 101 loss: 7.56733596608683e-05\n",
      "  batch 201 loss: 7.035622553758003e-05\n",
      "LOSS train 7.049700803481056e-05 valid 0.00011347328108968213\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.2971477190149016e-07\n",
      "  batch 101 loss: 6.512896463618745e-05\n",
      "  batch 201 loss: 6.201495214895658e-05\n",
      "LOSS train 6.174875222860221e-05 valid 0.0001346473436569795\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.003912627100944519\n",
      "  batch 101 loss: 0.006202241310625141\n",
      "  batch 201 loss: 7.087652332415928e-06\n",
      "LOSS train 0.0037089941262983747 valid 4.0076320146908984e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.545272405375727e-08\n",
      "  batch 101 loss: 7.473666696000692e-06\n",
      "  batch 201 loss: 5.519549050916339e-06\n",
      "LOSS train 5.715920726884794e-06 valid 4.3491116230143234e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.536839813023107e-08\n",
      "  batch 101 loss: 5.931477809895114e-06\n",
      "  batch 201 loss: 3.465583888910828e-06\n",
      "LOSS train 4.0834904826881075e-06 valid 4.1910090658348054e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.393439202336594e-08\n",
      "  batch 101 loss: 4.48453966953366e-06\n",
      "  batch 201 loss: 2.5398335602488943e-06\n",
      "LOSS train 3.0834224276077293e-06 valid 4.3811884097522125e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.9797259887564e-08\n",
      "  batch 101 loss: 3.655468465098011e-06\n",
      "  batch 201 loss: 2.828194207893375e-06\n",
      "LOSS train 2.8408413042107552e-06 valid 4.330055526224896e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.875219696667045e-08\n",
      "  batch 101 loss: 5.3735086032702385e-06\n",
      "  batch 201 loss: 3.184435463765567e-06\n",
      "LOSS train 3.691828350595696e-06 valid 4.38368042523507e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.269931302289479e-08\n",
      "  batch 101 loss: 5.020715711481216e-06\n",
      "  batch 201 loss: 2.7730073917098252e-06\n",
      "LOSS train 3.371187486250048e-06 valid 4.428517786436714e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.088870355190011e-08\n",
      "  batch 101 loss: 4.20112719041299e-06\n",
      "  batch 201 loss: 3.059092655917084e-06\n",
      "LOSS train 3.2026879265025682e-06 valid 4.3467647628858685e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.0798648872878402e-07\n",
      "  batch 101 loss: 6.132624536547837e-06\n",
      "  batch 201 loss: 3.6338525455903436e-06\n",
      "LOSS train 4.246527447455245e-06 valid 4.374387935968116e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.1386126971046905e-07\n",
      "  batch 101 loss: 8.350508566365988e-06\n",
      "  batch 201 loss: 4.496290216238208e-06\n",
      "LOSS train 5.799842486084013e-06 valid 4.5722936192760244e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.6298806713166415e-08\n",
      "  batch 101 loss: 7.757869769022818e-06\n",
      "  batch 201 loss: 6.3990196190388815e-06\n",
      "LOSS train 7.166838266037623e-06 valid 4.6388100599870086e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.7272964871372095e-07\n",
      "  batch 101 loss: 1.123435443616927e-05\n",
      "  batch 201 loss: 1.3964197381426401e-05\n",
      "LOSS train 1.271177295414738e-05 valid 6.250434671528637e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0011153796315193176\n",
      "  batch 101 loss: 0.005915211804676801\n",
      "  batch 201 loss: 0.00011343456010308728\n",
      "LOSS train 0.002651178469921728 valid 7.232023926917464e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 8.287634409498424e-07\n",
      "  batch 101 loss: 0.00012516604092979833\n",
      "  batch 201 loss: 0.00010902410629114457\n",
      "LOSS train 0.00011075793893252634 valid 7.058033952489495e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1681939895424875e-08\n",
      "  batch 101 loss: 8.404390383248028e-05\n",
      "  batch 201 loss: 7.253238855355449e-05\n",
      "LOSS train 7.417952724317262e-05 valid 0.00011829040886368603\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.5114032066776418e-07\n",
      "  batch 101 loss: 6.290279951599586e-05\n",
      "  batch 201 loss: 5.953435920901029e-05\n",
      "LOSS train 5.9374748035048343e-05 valid 0.000150501771713607\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.1481049518333747e-07\n",
      "  batch 101 loss: 5.743310847094563e-05\n",
      "  batch 201 loss: 5.761288062899439e-05\n",
      "LOSS train 5.684884978702876e-05 valid 0.0001819732424337417\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.980229641660117e-07\n",
      "  batch 101 loss: 5.913860064254095e-05\n",
      "  batch 201 loss: 6.173943423505079e-05\n",
      "LOSS train 6.04002832562564e-05 valid 0.00021888199262320995\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.317750714719295e-07\n",
      "  batch 101 loss: 6.465691106598115e-05\n",
      "  batch 201 loss: 6.802574079301848e-05\n",
      "LOSS train 6.673586962226461e-05 valid 0.00025426101638004184\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.692360617918894e-07\n",
      "  batch 101 loss: 7.129955014931965e-05\n",
      "  batch 201 loss: 7.487437094710004e-05\n",
      "LOSS train 7.350206721332223e-05 valid 0.0002792924933601171\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.1432755854912103e-06\n",
      "  batch 101 loss: 7.662494196438275e-05\n",
      "  batch 201 loss: 7.918303020801432e-05\n",
      "LOSS train 7.834197905413354e-05 valid 0.00029360511689446867\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.2446615437511355e-06\n",
      "  batch 101 loss: 7.973720204063284e-05\n",
      "  batch 201 loss: 8.164361958620247e-05\n",
      "LOSS train 8.110219283728742e-05 valid 0.000298239232506603\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2777544907294213e-06\n",
      "  batch 101 loss: 8.142438665686313e-05\n",
      "  batch 201 loss: 8.2905445774486e-05\n",
      "LOSS train 8.255273140938308e-05 valid 0.00029846487450413406\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.279367716051638e-06\n",
      "  batch 101 loss: 8.211409253249258e-05\n",
      "  batch 201 loss: 8.365135997678407e-05\n",
      "LOSS train 8.323703757627293e-05 valid 0.0002991469227708876\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0014442116022109984\n",
      "  batch 101 loss: 0.012896576952480246\n",
      "  batch 201 loss: 0.0004135141914593987\n",
      "LOSS train 0.005454148981775006 valid 0.00010545545956119895\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.49129758332856e-07\n",
      "  batch 101 loss: 0.0001223412862236728\n",
      "  batch 201 loss: 0.00011620965866995903\n",
      "LOSS train 0.0001173943623715896 valid 5.2760089602088556e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.5312074032844974e-07\n",
      "  batch 101 loss: 0.00011533481747846963\n",
      "  batch 201 loss: 0.00010174841806247059\n",
      "LOSS train 0.00010353456788139978 valid 7.185350114014e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1775083521570195e-08\n",
      "  batch 101 loss: 8.437613517571663e-05\n",
      "  batch 201 loss: 7.486939807677118e-05\n",
      "LOSS train 7.593044421148892e-05 valid 0.00011029839515686035\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1616018127824646e-07\n",
      "  batch 101 loss: 6.588065589767211e-05\n",
      "  batch 201 loss: 6.170784337427903e-05\n",
      "LOSS train 6.171768891304871e-05 valid 0.00013897987082600594\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.5278972316300496e-07\n",
      "  batch 101 loss: 5.8381423244782126e-05\n",
      "  batch 201 loss: 5.7377742643893724e-05\n",
      "LOSS train 5.680946400424056e-05 valid 0.00016505061648786068\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.972300328314304e-07\n",
      "  batch 101 loss: 5.7450849213864784e-05\n",
      "  batch 201 loss: 5.853809479617667e-05\n",
      "LOSS train 5.760029796170124e-05 valid 0.0001948780845850706\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.778114427812398e-07\n",
      "  batch 101 loss: 6.079780409095292e-05\n",
      "  batch 201 loss: 6.334489625146488e-05\n",
      "LOSS train 6.214968439882043e-05 valid 0.00022896425798535347\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 7.982907118275762e-07\n",
      "  batch 101 loss: 6.659071159106134e-05\n",
      "  batch 201 loss: 6.980661759826035e-05\n",
      "LOSS train 6.8526457651957e-05 valid 0.0002606788766570389\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0134297917829827e-06\n",
      "  batch 101 loss: 7.260608939532175e-05\n",
      "  batch 201 loss: 7.56420047548545e-05\n",
      "LOSS train 7.450290634459044e-05 valid 0.0002824981929734349\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.1658720177365468e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 7.715112943060376e-05\n",
      "  batch 201 loss: 7.961713856161624e-05\n",
      "LOSS train 7.874041442881626e-05 valid 0.0002937106182798743\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.2454135867301374e-06\n",
      "  batch 101 loss: 7.994523454158298e-05\n",
      "  batch 201 loss: 8.189391531800539e-05\n",
      "LOSS train 8.12638192494291e-05 valid 0.00029815506422892213\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002766587398946285\n",
      "  batch 101 loss: 0.011868406652829434\n",
      "  batch 201 loss: 9.470570023040637e-05\n",
      "LOSS train 0.00450702856525969 valid 7.747139898128808e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.119478636421263e-07\n",
      "  batch 101 loss: 9.913743332845115e-05\n",
      "  batch 201 loss: 0.00010877453375570667\n",
      "LOSS train 0.00010849970087990966 valid 8.829414582578465e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1334990995237603e-06\n",
      "  batch 101 loss: 0.0001245891877374561\n",
      "  batch 201 loss: 0.0001258601600534348\n",
      "LOSS train 0.00012630535119096615 valid 6.0314305301290005e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.810880975332111e-07\n",
      "  batch 101 loss: 0.0001228253802025847\n",
      "  batch 201 loss: 0.00011329150198434946\n",
      "LOSS train 0.00011481066487679097 valid 5.474321369547397e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 7.474001449736534e-08\n",
      "  batch 101 loss: 9.998052282298886e-05\n",
      "  batch 201 loss: 8.959938626389884e-05\n",
      "LOSS train 9.08591614340563e-05 valid 8.320099004777148e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.6289831112080718e-08\n",
      "  batch 101 loss: 7.844381622362562e-05\n",
      "  batch 201 loss: 7.168208694338318e-05\n",
      "LOSS train 7.213337885115747e-05 valid 0.00011303559585940093\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2781850273313466e-07\n",
      "  batch 101 loss: 6.511765424875193e-05\n",
      "  batch 201 loss: 6.164620189110792e-05\n",
      "LOSS train 6.147674376474502e-05 valid 0.0001373414124827832\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.442545155645348e-07\n",
      "  batch 101 loss: 5.869567462013947e-05\n",
      "  batch 201 loss: 5.7577058032620696e-05\n",
      "LOSS train 5.6998049354126206e-05 valid 0.00016029544349294156\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.698076034197584e-07\n",
      "  batch 101 loss: 5.725373798156852e-05\n",
      "  batch 201 loss: 5.791175443960128e-05\n",
      "LOSS train 5.7029969757247905e-05 valid 0.00018643596558831632\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.253513882053084e-07\n",
      "  batch 101 loss: 5.9549327809236274e-05\n",
      "  batch 201 loss: 6.161485236361842e-05\n",
      "LOSS train 6.049099890488223e-05 valid 0.00021735747577622533\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 7.218045357149094e-07\n",
      "  batch 101 loss: 6.445824473189532e-05\n",
      "  batch 201 loss: 6.741285681698628e-05\n",
      "LOSS train 6.615352749918618e-05 valid 0.00024918740382418036\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 9.345226135337725e-07\n",
      "  batch 101 loss: 7.032999562142094e-05\n",
      "  batch 201 loss: 7.34268733913268e-05\n",
      "LOSS train 7.222072166960211e-05 valid 0.0002744938828982413\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002853601239621639\n",
      "  batch 101 loss: 0.025047395180429248\n",
      "  batch 201 loss: 2.6581531956253456e-05\n",
      "LOSS train 0.009308435704586464 valid 8.290616096928716e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.563786882907153e-08\n",
      "  batch 101 loss: 3.124157917000048e-05\n",
      "  batch 201 loss: 2.9764329730710416e-05\n",
      "LOSS train 2.8611904133142507e-05 valid 8.175084803951904e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.2679918654612265e-07\n",
      "  batch 101 loss: 1.4990411765154477e-05\n",
      "  batch 201 loss: 8.752874184949633e-06\n",
      "LOSS train 9.72641008971157e-06 valid 3.8683603634126484e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.302134013618343e-08\n",
      "  batch 101 loss: 2.3260457190588114e-06\n",
      "  batch 201 loss: 1.9420704653327903e-06\n",
      "LOSS train 2.3697260994453537e-06 valid 4.807407094631344e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.2636120345632663e-08\n",
      "  batch 101 loss: 6.41012840020494e-06\n",
      "  batch 201 loss: 2.541630523182903e-06\n",
      "LOSS train 4.091746771325813e-06 valid 4.114843613933772e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.797839665116044e-08\n",
      "  batch 101 loss: 4.362056748732357e-06\n",
      "  batch 201 loss: 3.9382530110287915e-06\n",
      "LOSS train 4.024359886311136e-06 valid 3.9965489122550935e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1740891750378069e-07\n",
      "  batch 101 loss: 7.359482041806586e-06\n",
      "  batch 201 loss: 4.429198005766466e-06\n",
      "LOSS train 4.91966146336216e-06 valid 4.0708484448259696e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 6.213196229509777e-08\n",
      "  batch 101 loss: 5.292995730599159e-06\n",
      "  batch 201 loss: 2.8881705729588702e-06\n",
      "LOSS train 3.566573456015705e-06 valid 3.868428393616341e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 7.693027328059543e-08\n",
      "  batch 101 loss: 5.933160898905498e-06\n",
      "  batch 201 loss: 2.1004731283369438e-06\n",
      "LOSS train 3.5095803306935873e-06 valid 3.881956945406273e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 6.857586413389072e-08\n",
      "  batch 101 loss: 6.202305723093105e-06\n",
      "  batch 201 loss: 2.811434309535343e-06\n",
      "LOSS train 3.7985534637253116e-06 valid 4.0119786717696115e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.2123987188679166e-08\n",
      "  batch 101 loss: 4.698632222357446e-06\n",
      "  batch 201 loss: 2.0302169157560003e-06\n",
      "LOSS train 3.0094672637849413e-06 valid 3.9233713323483244e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.9280782807036306e-08\n",
      "  batch 101 loss: 6.178945332635521e-06\n",
      "  batch 201 loss: 2.8123227147602847e-06\n",
      "LOSS train 3.950689878019607e-06 valid 4.036452082800679e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0005488152801990509\n",
      "  batch 101 loss: 0.013779921588720753\n",
      "  batch 201 loss: 0.0008430132034118287\n",
      "LOSS train 0.005660588025947395 valid 0.0004279501154087484\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.9548066484276206e-06\n",
      "  batch 101 loss: 0.00019129760585201439\n",
      "  batch 201 loss: 9.234970417310251e-05\n",
      "LOSS train 0.00012204878240838245 valid 0.0001366486685583368\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.2017393095884474e-07\n",
      "  batch 101 loss: 6.248125083402556e-05\n",
      "  batch 201 loss: 7.690965941719696e-05\n",
      "LOSS train 7.856188844076254e-05 valid 6.19913189439103e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 6.523555930471048e-07\n",
      "  batch 101 loss: 0.00012587380027298423\n",
      "  batch 201 loss: 0.0001214149722932234\n",
      "LOSS train 0.00012220240991498295 valid 5.096878157928586e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.480350303812884e-07\n",
      "  batch 101 loss: 0.00011190048668368036\n",
      "  batch 201 loss: 0.00010160966421608464\n",
      "LOSS train 0.00010304908728324672 valid 6.604781810892746e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.5806364217496593e-08\n",
      "  batch 101 loss: 8.95039856106905e-05\n",
      "  batch 201 loss: 8.103872082756424e-05\n",
      "LOSS train 8.18150466294845e-05 valid 9.62396661634557e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 6.129837856860831e-08\n",
      "  batch 101 loss: 7.224075796102625e-05\n",
      "  batch 201 loss: 6.70476981417778e-05\n",
      "LOSS train 6.717699432309872e-05 valid 0.00012262251402717084\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.6932324797380716e-07\n",
      "  batch 101 loss: 6.212769782678152e-05\n",
      "  batch 201 loss: 5.9659095728648023e-05\n",
      "LOSS train 5.9300652724348954e-05 valid 0.0001448664697818458\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.816458436427638e-07\n",
      "  batch 101 loss: 5.769765861828091e-05\n",
      "  batch 201 loss: 5.724105382967082e-05\n",
      "LOSS train 5.6529249974450496e-05 valid 0.0001676740066614002\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.1215909732272846e-07\n",
      "  batch 101 loss: 5.7525370438042954e-05\n",
      "  batch 201 loss: 5.864865885769177e-05\n",
      "LOSS train 5.769455401855089e-05 valid 0.00019594852346926928\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.831518865306862e-07\n",
      "  batch 101 loss: 6.072216325719637e-05\n",
      "  batch 201 loss: 6.306757693891996e-05\n",
      "LOSS train 6.188456205645474e-05 valid 0.00022698981047142297\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.812695548636838e-07\n",
      "  batch 101 loss: 6.603365757086977e-05\n",
      "  batch 201 loss: 6.906729002707834e-05\n",
      "LOSS train 6.782616607917603e-05 valid 0.00025727940374054015\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.7943173083476722e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.01143297815022379\n",
      "  batch 201 loss: 7.744907601590967e-05\n",
      "LOSS train 0.004241265774207799 valid 6.889502401463687e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 7.719018321949989e-07\n",
      "  batch 101 loss: 9.153170809213407e-05\n",
      "  batch 201 loss: 0.0001017242881613356\n",
      "LOSS train 0.00010090133705472621 valid 8.873915066942573e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.141195825766772e-06\n",
      "  batch 101 loss: 0.00011893616281952291\n",
      "  batch 201 loss: 0.00012322632041275483\n",
      "LOSS train 0.0001236383845701848 valid 7.383197225863114e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.701873593963683e-07\n",
      "  batch 101 loss: 0.00012760800517639837\n",
      "  batch 201 loss: 0.0001218610117098251\n",
      "LOSS train 0.0001231901006154398 valid 5.107840115670115e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.5316010578535495e-07\n",
      "  batch 101 loss: 0.00011230387306795819\n",
      "  batch 201 loss: 0.00010188903402649885\n",
      "LOSS train 0.000103340044128488 valid 6.587195093743503e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.5318846635636874e-08\n",
      "  batch 101 loss: 8.952655581992986e-05\n",
      "  batch 201 loss: 8.112306940120107e-05\n",
      "LOSS train 8.186978151022627e-05 valid 9.579997276887298e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 6.123518232925562e-08\n",
      "  batch 101 loss: 7.225650315149323e-05\n",
      "  batch 201 loss: 6.708318661821977e-05\n",
      "LOSS train 6.722430776080528e-05 valid 0.0001222675055032596\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.6954203601926565e-07\n",
      "  batch 101 loss: 6.216412713683895e-05\n",
      "  batch 201 loss: 5.966488499325351e-05\n",
      "LOSS train 5.932210186885587e-05 valid 0.0001448580005671829\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.8399495931807906e-07\n",
      "  batch 101 loss: 5.774896206162339e-05\n",
      "  batch 201 loss: 5.728959745653128e-05\n",
      "LOSS train 5.65772852010405e-05 valid 0.00016786980268079787\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.1368537495145575e-07\n",
      "  batch 101 loss: 5.762773504329744e-05\n",
      "  batch 201 loss: 5.873509000252852e-05\n",
      "LOSS train 5.7766447087357976e-05 valid 0.0001950419828062877\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.788391717942432e-07\n",
      "  batch 101 loss: 6.0786811457091974e-05\n",
      "  batch 201 loss: 6.391497118215738e-05\n",
      "LOSS train 6.224412741658975e-05 valid 0.0002265693328808993\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.824006024748087e-07\n",
      "  batch 101 loss: 6.616525280946916e-05\n",
      "  batch 201 loss: 6.913758911196055e-05\n",
      "LOSS train 6.793595796710882e-05 valid 0.000258227635640651\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0003171057254076004\n",
      "  batch 101 loss: 0.030104230873112103\n",
      "  batch 201 loss: 0.00015063563059811714\n",
      "LOSS train 0.011218045512393204 valid 6.102357656345703e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.66517555853352e-07\n",
      "  batch 101 loss: 7.709973252531199e-05\n",
      "  batch 201 loss: 8.261292825864074e-05\n",
      "LOSS train 8.210434051238652e-05 valid 7.30929896235466e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.356344187632203e-07\n",
      "  batch 101 loss: 9.42976240662574e-05\n",
      "  batch 201 loss: 0.000100673308977548\n",
      "LOSS train 0.00010053597234160313 valid 8.706367952981964e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1113277287222445e-06\n",
      "  batch 101 loss: 0.00011284406377228607\n",
      "  batch 201 loss: 0.00011750853487797031\n",
      "LOSS train 0.00011825241216414917 valid 8.604276808910072e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0911727440543474e-06\n",
      "  batch 101 loss: 0.00012615798987383186\n",
      "  batch 201 loss: 0.00012575908153053205\n",
      "LOSS train 0.00012700182718881746 valid 6.433667294913903e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.724894046783448e-07\n",
      "  batch 101 loss: 0.0001251158176273748\n",
      "  batch 201 loss: 0.00011871853373122576\n",
      "LOSS train 0.00012014208957455364 valid 5.089371188660152e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 2.0426334231160582e-07\n",
      "  batch 101 loss: 0.00011025259628922867\n",
      "  batch 201 loss: 0.00010104936942298081\n",
      "LOSS train 0.00010231383776577859 valid 6.47418200969696e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.731801830828772e-08\n",
      "  batch 101 loss: 9.074101695546233e-05\n",
      "  batch 201 loss: 8.276693693460402e-05\n",
      "LOSS train 8.352233957657352e-05 valid 9.12028262973763e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.680430720327422e-08\n",
      "  batch 101 loss: 7.471811871937462e-05\n",
      "  batch 201 loss: 6.934751277640317e-05\n",
      "LOSS train 6.951174072587942e-05 valid 0.0001161703112302348\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.41599120979663e-07\n",
      "  batch 101 loss: 6.413104197235952e-05\n",
      "  batch 201 loss: 6.119586822251222e-05\n",
      "LOSS train 6.090931157611119e-05 valid 0.00013789413787890226\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 2.4715287509025076e-07\n",
      "  batch 101 loss: 5.8679629354401186e-05\n",
      "  batch 201 loss: 5.760349239039897e-05\n",
      "LOSS train 5.700810186788778e-05 valid 0.00015879393322393298\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.7128131225472316e-07\n",
      "  batch 101 loss: 5.724391552689667e-05\n",
      "  batch 201 loss: 5.7760371092854256e-05\n",
      "LOSS train 5.690127542907365e-05 valid 0.00018332741456106305\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ") 0 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00033795442432165145\n",
      "  batch 101 loss: 2.0419477938958153\n",
      "  batch 201 loss: 0.0003754871679120697\n",
      "LOSS train 0.7482580475016329 valid 0.0017198820132762194\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.177151247859001e-05\n",
      "  batch 101 loss: 0.0010764626518425758\n",
      "  batch 201 loss: 6.393847135768738e-05\n",
      "LOSS train 0.0004360433642876663 valid 0.0014628758653998375\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.420050954446197e-05\n",
      "  batch 101 loss: 0.0012934461951681442\n",
      "  batch 201 loss: 9.992243176611738e-05\n",
      "LOSS train 0.0005248410572985216 valid 0.0011703853961080313\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.718291711062193e-05\n",
      "  batch 101 loss: 0.0016205580943460518\n",
      "  batch 201 loss: 0.0001221209705659021\n",
      "LOSS train 0.000655888262648686 valid 0.0012645144015550613\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.736302325502038e-05\n",
      "  batch 101 loss: 0.002367601150726841\n",
      "  batch 201 loss: 0.00015362013173728429\n",
      "LOSS train 0.000940840188894483 valid 0.0015248768031597137\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.167736111208797e-05\n",
      "  batch 101 loss: 0.004079080093879384\n",
      "  batch 201 loss: 0.0004140320824092214\n",
      "LOSS train 0.001670218355204333 valid 0.0018278275383636355\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.5073305480182174e-05\n",
      "  batch 101 loss: 0.004939930945110973\n",
      "  batch 201 loss: 0.0007476889623103489\n",
      "LOSS train 0.04786174756927954 valid 0.03047802671790123\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0003118810430169105\n",
      "  batch 101 loss: 0.02020469357164984\n",
      "  batch 201 loss: 0.002587821465640445\n",
      "LOSS train 0.02841062436773727 valid 0.11651363968849182\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.001290009021759033\n",
      "  batch 101 loss: 0.03811952008109074\n",
      "  batch 201 loss: 0.023856026722933167\n",
      "LOSS train 0.0443810639204031 valid 0.09611809253692627\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.0008471183478832245\n",
      "  batch 101 loss: 0.02658252168330364\n",
      "  batch 201 loss: 0.025743941398322933\n",
      "LOSS train 0.04519915857254558 valid 0.04855808988213539\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 0.00016402719542384146\n",
      "  batch 101 loss: 0.011511177790671354\n",
      "  batch 201 loss: 0.03225319047967787\n",
      "LOSS train 0.046183415565016296 valid 0.020489918068051338\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 3.100727684795856e-05\n",
      "  batch 101 loss: 0.007973365496145562\n",
      "  batch 201 loss: 0.018546630601776998\n",
      "LOSS train 0.046937838204057065 valid 0.033389538526535034\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") 0.1 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 8.446495980024338e-05\n",
      "  batch 101 loss: 1.3306496569514275\n",
      "  batch 201 loss: 0.00830388333182782\n",
      "LOSS train 0.49133332311124595 valid 0.0004930983996018767\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.916102832183242e-05\n",
      "  batch 101 loss: 0.0016256169124972074\n",
      "  batch 201 loss: 0.00045431530772475524\n",
      "LOSS train 0.0008136328858429576 valid 0.00010310781362932175\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.3062172587960957e-06\n",
      "  batch 101 loss: 0.00013596100823633605\n",
      "  batch 201 loss: 4.695182900832151e-05\n",
      "LOSS train 7.525954825413775e-05 valid 3.950930477003567e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.6913955884519967e-07\n",
      "  batch 101 loss: 2.1498535274986353e-05\n",
      "  batch 201 loss: 2.1104982297401876e-05\n",
      "LOSS train 2.2078009281428352e-05 valid 4.361132960184477e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 4.997450378141366e-07\n",
      "  batch 101 loss: 1.889930611469026e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 201 loss: 1.6018755757158943e-05\n",
      "LOSS train 2.5429186625876018e-05 valid 0.000109668260847684\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 4.221195194986649e-07\n",
      "  batch 101 loss: 0.00015001977616975636\n",
      "  batch 201 loss: 0.08579301306478555\n",
      "LOSS train 0.03745153220310612 valid 0.009497628547251225\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.00014410888776183127\n",
      "  batch 101 loss: 0.04058735890605021\n",
      "  batch 201 loss: 0.03529457074240781\n",
      "LOSS train 0.05329498363447277 valid 0.03009737841784954\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0001309318281710148\n",
      "  batch 101 loss: 0.013485376791504678\n",
      "  batch 201 loss: 0.04894211988925235\n",
      "LOSS train 0.032512990987668626 valid 0.010824299417436123\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.00010677406564354896\n",
      "  batch 101 loss: 0.019682666161097585\n",
      "  batch 201 loss: 0.06495142323314212\n",
      "LOSS train 0.04218061956459308 valid 0.0024594382848590612\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.8111338140442966e-05\n",
      "  batch 101 loss: 0.01735317029757425\n",
      "  batch 201 loss: 0.07661161647411063\n",
      "LOSS train 0.044020070907601835 valid 0.0005470275646075606\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.6348520293831825e-05\n",
      "  batch 101 loss: 0.0152269474210334\n",
      "  batch 201 loss: 0.0553503696876578\n",
      "LOSS train 0.033297981310489964 valid 0.0009351595654152334\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.5381963457912206e-05\n",
      "  batch 101 loss: 0.1055155791802099\n",
      "  batch 201 loss: 0.003337734142114641\n",
      "LOSS train 0.04087978860026698 valid 0.0026704384945333004\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") 0.2 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00032159067690372466\n",
      "  batch 101 loss: 2.066055229441263\n",
      "  batch 201 loss: 0.005543215627549216\n",
      "LOSS train 0.7592776433747874 valid 0.0004643347056116909\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.589315503835678e-05\n",
      "  batch 101 loss: 0.0007031247297709342\n",
      "  batch 201 loss: 8.018587843253044e-05\n",
      "LOSS train 0.0003119951646382745 valid 7.130669109756127e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.593772416934371e-06\n",
      "  batch 101 loss: 7.84434943989254e-05\n",
      "  batch 201 loss: 1.993687112189946e-05\n",
      "LOSS train 4.455962510828379e-05 valid 4.058979175169952e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.218585571739823e-07\n",
      "  batch 101 loss: 1.6599788007169992e-05\n",
      "  batch 201 loss: 2.3154093230459694e-05\n",
      "LOSS train 1.9117568383627016e-05 valid 3.320967880426906e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.209037226450164e-08\n",
      "  batch 101 loss: 1.630458351883135e-05\n",
      "  batch 201 loss: 1.941864009722849e-05\n",
      "LOSS train 2.7362546215821095e-05 valid 3.620602728915401e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.988276719406713e-07\n",
      "  batch 101 loss: 7.282460653186718e-05\n",
      "  batch 201 loss: 8.70621330841459e-05\n",
      "LOSS train 7.508250323703428e-05 valid 3.531199763529003e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 7.479205123672727e-08\n",
      "  batch 101 loss: 0.00010982527106989437\n",
      "  batch 201 loss: 0.057413367163280785\n",
      "LOSS train 0.03313989495152935 valid 0.012003875337541103\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00011645534075796604\n",
      "  batch 101 loss: 0.0050999979831976815\n",
      "  batch 201 loss: 0.05584733970463276\n",
      "LOSS train 0.05636049135423508 valid 0.0029019161593168974\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.0001975390501320362\n",
      "  batch 101 loss: 0.01684496022993699\n",
      "  batch 201 loss: 0.005565422200015746\n",
      "LOSS train 0.021113799362965337 valid 0.0043263863772153854\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.5986631885170934e-05\n",
      "  batch 101 loss: 0.0804026219341904\n",
      "  batch 201 loss: 0.030051426886348053\n",
      "LOSS train 0.05247019230999605 valid 0.03212488070130348\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 0.00025702396407723427\n",
      "  batch 101 loss: 0.03317195052746683\n",
      "  batch 201 loss: 0.06723779087653384\n",
      "LOSS train 0.04795221289391237 valid 0.012796765193343163\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 0.00018284399062395095\n",
      "  batch 101 loss: 0.007715360381407663\n",
      "  batch 201 loss: 0.047239996250718834\n",
      "LOSS train 0.07741390565075935 valid 0.1363883912563324\n",
      "ObjectiveEstimator_ANN_Single_layer(\n",
      "  (output_layer): Linear(in_features=1227, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ") 0.4 0\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.000546850860118866\n",
      "  batch 101 loss: 2.048445764509961\n",
      "  batch 201 loss: 0.0036733767684199847\n",
      "LOSS train 0.751961557308394 valid 0.00017730407125782222\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 1.2391651980578899e-05\n",
      "  batch 101 loss: 0.00021730352118538577\n",
      "  batch 201 loss: 2.749728316302935e-05\n",
      "LOSS train 0.00010104954547956707 valid 3.7439345760503784e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0001676855608821e-07\n",
      "  batch 101 loss: 2.637602123286342e-05\n",
      "  batch 201 loss: 4.160663873790327e-05\n",
      "LOSS train 3.7885631804000875e-05 valid 3.635280882008374e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.2209562303032726e-07\n",
      "  batch 101 loss: 2.7313954365126848e-05\n",
      "  batch 201 loss: 5.056758135197015e-05\n",
      "LOSS train 3.6937846898881314e-05 valid 6.83939506416209e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.1864954760530964e-07\n",
      "  batch 101 loss: 4.329435163981543e-05\n",
      "  batch 201 loss: 5.260451376216224e-05\n",
      "LOSS train 9.677030814870434e-05 valid 3.3869349863380194e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.1488860258832573e-07\n",
      "  batch 101 loss: 0.00016576029998759622\n",
      "  batch 201 loss: 0.0001662439133724547\n",
      "LOSS train 0.00021218978886631352 valid 0.00020905188284814358\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.2456754706799983e-06\n",
      "  batch 101 loss: 0.0004433268203865737\n",
      "  batch 201 loss: 0.08795809551382262\n",
      "LOSS train 0.06708752138725325 valid 0.0016527455300092697\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.00013905031606554986\n",
      "  batch 101 loss: 0.005811887540912722\n",
      "  batch 201 loss: 0.002563085042493185\n",
      "LOSS train 0.013890381064148699 valid 0.039865680038928986\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.00042012419551610945\n",
      "  batch 101 loss: 0.06582944833673537\n",
      "  batch 201 loss: 0.04671900733374059\n",
      "LOSS train 0.08715102066296143 valid 0.016796596348285675\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.0004429074004292488\n",
      "  batch 101 loss: 0.016576175591908396\n",
      "  batch 201 loss: 0.002799178533896338\n",
      "LOSS train 0.010558801594522061 valid 0.008470848202705383\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 9.838009253144265e-05\n",
      "  batch 101 loss: 0.18879087522625923\n",
      "  batch 201 loss: 0.00620617339911405\n",
      "LOSS train 0.07196636602918757 valid 0.0014052673941478133\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.5082580503076315e-05\n",
      "  batch 101 loss: 0.08334708186943317\n",
      "  batch 201 loss: 0.0729301376035437\n",
      "LOSS train 0.05862988687033813 valid 0.0020384083036333323\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00041193384677171705\n",
      "  batch 101 loss: 0.6632823584007475\n",
      "  batch 201 loss: 1.730783818970849e-05\n",
      "LOSS train 0.24985972762871098 valid 8.362002699868754e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.7191761091671652e-08\n",
      "  batch 101 loss: 6.38713848769612e-05\n",
      "  batch 201 loss: 7.019121098437608e-05\n",
      "LOSS train 6.809521348168512e-05 valid 5.987577969790436e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.702353519154713e-07\n",
      "  batch 101 loss: 7.670893275189883e-05\n",
      "  batch 201 loss: 8.092892033801036e-05\n",
      "LOSS train 8.020856322408501e-05 valid 6.904796464368701e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 7.750406803097576e-07\n",
      "  batch 101 loss: 8.89178837178406e-05\n",
      "  batch 201 loss: 9.379543169188765e-05\n",
      "LOSS train 9.347721943296888e-05 valid 8.089939365163445e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0024655784945936e-06\n",
      "  batch 101 loss: 0.00010338958861439096\n",
      "  batch 201 loss: 0.00010833941769533339\n",
      "LOSS train 0.0001086361529649986 valid 8.953527139965445e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1549173359526322e-06\n",
      "  batch 101 loss: 0.00011826673524183207\n",
      "  batch 201 loss: 0.00012135321050351423\n",
      "LOSS train 0.00012232946203168498 valid 8.238336158683524e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.029281847877428e-06\n",
      "  batch 101 loss: 0.00012751362594485728\n",
      "  batch 201 loss: 0.00012558901732745653\n",
      "LOSS train 0.00012697299530539704 valid 5.935368608334102e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.571049405261874e-07\n",
      "  batch 101 loss: 0.00012287368870715908\n",
      "  batch 201 loss: 0.00011497604373971625\n",
      "LOSS train 0.00011644471822359724 valid 5.229003363638185e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.199388862005435e-07\n",
      "  batch 101 loss: 0.00010455825559063214\n",
      "  batch 201 loss: 9.475076365447421e-05\n",
      "LOSS train 9.595155322048723e-05 valid 7.447068492183462e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.3119387176629971e-08\n",
      "  batch 101 loss: 8.364410673948441e-05\n",
      "  batch 201 loss: 7.609125240605863e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 7.668031002508325e-05 valid 0.0001045828394126147\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 9.302949365519452e-08\n",
      "  batch 101 loss: 6.834545452875317e-05\n",
      "  batch 201 loss: 6.393455745069331e-05\n",
      "LOSS train 6.392678109404564e-05 valid 0.00013094954192638397\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.1169218598515726e-07\n",
      "  batch 101 loss: 5.987150969076538e-05\n",
      "  batch 201 loss: 5.810333234990139e-05\n",
      "LOSS train 5.765125604930024e-05 valid 0.00015604372310917825\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.1 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 3.975206986069679e-05\n",
      "  batch 101 loss: 0.6276981451077154\n",
      "  batch 201 loss: 0.0014881703379796818\n",
      "LOSS train 0.23058246802474136 valid 5.738278923672624e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.540033478406258e-07\n",
      "  batch 101 loss: 9.004825910778891e-05\n",
      "  batch 201 loss: 5.358379016001891e-05\n",
      "LOSS train 7.25771916100152e-05 valid 6.129142275312915e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 6.047500573913567e-07\n",
      "  batch 101 loss: 7.874134512348973e-05\n",
      "  batch 201 loss: 8.330737392725496e-05\n",
      "LOSS train 8.263552085769906e-05 valid 7.152366015361622e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.249660459114239e-07\n",
      "  batch 101 loss: 9.206248897726254e-05\n",
      "  batch 201 loss: 9.725747601578405e-05\n",
      "LOSS train 9.704777975775703e-05 valid 8.388236165046692e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.0560861846897751e-06\n",
      "  batch 101 loss: 0.00010750246655959473\n",
      "  batch 201 loss: 0.00011237053593220025\n",
      "LOSS train 0.00011283702507536053 valid 8.961075218394399e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1562154395505787e-06\n",
      "  batch 101 loss: 0.0001219989329740656\n",
      "  batch 201 loss: 0.00012398731872679037\n",
      "LOSS train 0.0001250966724117231 valid 7.578360236948356e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.075651905732229e-07\n",
      "  batch 101 loss: 0.00012781819028191422\n",
      "  batch 201 loss: 0.00012379033490162784\n",
      "LOSS train 0.00012521122462032754 valid 5.3467061661649495e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.81577956432011e-07\n",
      "  batch 101 loss: 0.00011779489477248717\n",
      "  batch 201 loss: 0.00010854194458829624\n",
      "LOSS train 0.00010997461628692144 valid 5.757183680543676e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.737748440675205e-08\n",
      "  batch 101 loss: 9.693689194648414e-05\n",
      "  batch 201 loss: 8.75457570089111e-05\n",
      "LOSS train 8.856701821695168e-05 valid 8.539904956705868e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.125013790850062e-08\n",
      "  batch 101 loss: 7.732775480462806e-05\n",
      "  batch 201 loss: 7.088764634090694e-05\n",
      "LOSS train 7.12549153673542e-05 valid 0.0001147280927398242\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.351994797005318e-07\n",
      "  batch 101 loss: 6.448999419944812e-05\n",
      "  batch 201 loss: 6.110202530635434e-05\n",
      "LOSS train 6.0919124173582424e-05 valid 0.00014009918959345669\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.5866262149065733e-07\n",
      "  batch 101 loss: 5.824686574669613e-05\n",
      "  batch 201 loss: 5.7343799771274465e-05\n",
      "LOSS train 5.6756143806902174e-05 valid 0.00016660404799040407\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.2 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00024980565533041957\n",
      "  batch 101 loss: 0.6420540113621053\n",
      "  batch 201 loss: 6.236536845591445e-05\n",
      "LOSS train 0.23531536440602543 valid 5.446562499855645e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 4.171108594164252e-07\n",
      "  batch 101 loss: 6.74147491235999e-05\n",
      "  batch 201 loss: 7.136411338706238e-05\n",
      "LOSS train 7.039166001169968e-05 valid 6.1019702116027474e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.982374932500533e-07\n",
      "  batch 101 loss: 7.850460885492793e-05\n",
      "  batch 201 loss: 8.305041769062882e-05\n",
      "LOSS train 8.236590833270311e-05 valid 7.12550972821191e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 8.196257840609178e-07\n",
      "  batch 101 loss: 9.17236526834131e-05\n",
      "  batch 201 loss: 9.688687327980006e-05\n",
      "LOSS train 9.666518806936885e-05 valid 8.358172635780647e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.050732025760226e-06\n",
      "  batch 101 loss: 0.00010706854777140507\n",
      "  batch 201 loss: 0.00011195403155369377\n",
      "LOSS train 0.00011240282767636807 valid 8.968013571575284e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.1574079690035433e-06\n",
      "  batch 101 loss: 0.00012163606033539055\n",
      "  batch 201 loss: 0.00012375717519944374\n",
      "LOSS train 0.00012485428816545532 valid 7.6546952186618e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 9.219930507242679e-07\n",
      "  batch 101 loss: 0.00012786268794229727\n",
      "  batch 201 loss: 0.000124059231851561\n",
      "LOSS train 0.0001254770511614536 valid 5.394394611357711e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.9906910387799143e-07\n",
      "  batch 101 loss: 0.00011839383671258475\n",
      "  batch 201 loss: 0.00010925469934818466\n",
      "LOSS train 0.00011069269765186032 valid 5.686082658939995e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 5.291967681841925e-08\n",
      "  batch 101 loss: 9.77295951648216e-05\n",
      "  batch 201 loss: 8.827376182807712e-05\n",
      "LOSS train 8.931542981670916e-05 valid 8.424868428846821e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.8584156552824424e-08\n",
      "  batch 101 loss: 7.794496991209599e-05\n",
      "  batch 201 loss: 7.138714975326366e-05\n",
      "LOSS train 7.177703655659757e-05 valid 0.00011370139691280201\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.3070672139292583e-07\n",
      "  batch 101 loss: 6.484958604005442e-05\n",
      "  batch 201 loss: 6.135846121537724e-05\n",
      "LOSS train 6.119292424205764e-05 valid 0.0001391467230860144\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 2.5366343834321017e-07\n",
      "  batch 101 loss: 5.838022582224767e-05\n",
      "  batch 201 loss: 5.7388482006786034e-05\n",
      "LOSS train 5.6814535812480534e-05 valid 0.00016545182734262198\n",
      "ObjectiveEstimator_ANN_1hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=35, out_features=1, bias=True)\n",
      ") 0.4 1\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00044267944991588593\n",
      "  batch 101 loss: 0.3911678674114063\n",
      "  batch 201 loss: 0.020625906419734292\n",
      "LOSS train 0.15102534291201222 valid 5.889923340873793e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.454749043565243e-07\n",
      "  batch 101 loss: 7.445987460869219e-05\n",
      "  batch 201 loss: 8.036330850700324e-05\n",
      "LOSS train 7.948046779860399e-05 valid 7.051066495478153e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 8.047311712289229e-07\n",
      "  batch 101 loss: 9.170360952566625e-05\n",
      "  batch 201 loss: 9.831891366047784e-05\n",
      "LOSS train 9.79870596547665e-05 valid 8.565570169594139e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.0874551662709565e-06\n",
      "  batch 101 loss: 0.00011096449570430878\n",
      "  batch 201 loss: 0.0001164068228092674\n",
      "LOSS train 0.00011686701257424216 valid 8.693857671460137e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.1099324910901486e-06\n",
      "  batch 101 loss: 0.00012588300906429595\n",
      "  batch 201 loss: 0.0001258448511816823\n",
      "LOSS train 0.00012692279450789517 valid 6.305280840024352e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 6.458469579229131e-07\n",
      "  batch 101 loss: 0.0001245297015179858\n",
      "  batch 201 loss: 0.00011664626664014576\n",
      "LOSS train 0.00011807443134175328 valid 5.1896931836381555e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.3206985386204905e-07\n",
      "  batch 101 loss: 0.0001051614235177567\n",
      "  batch 201 loss: 9.463160227824119e-05\n",
      "LOSS train 9.594474351945461e-05 valid 7.589842425659299e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.4432785064855124e-08\n",
      "  batch 101 loss: 8.25735918783721e-05\n",
      "  batch 201 loss: 7.481860984171363e-05\n",
      "LOSS train 7.545321720113036e-05 valid 0.00010782092431327328\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 1.059235364664346e-07\n",
      "  batch 101 loss: 6.697509125388024e-05\n",
      "  batch 201 loss: 6.276342977457717e-05\n",
      "LOSS train 6.273547140590247e-05 valid 0.00013495943858288229\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 2.3197953851195053e-07\n",
      "  batch 101 loss: 5.904396038886262e-05\n",
      "  batch 201 loss: 5.7640334304664975e-05\n",
      "LOSS train 5.714107745872266e-05 valid 0.00016146886628121138\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 3.765348810702562e-07\n",
      "  batch 101 loss: 5.7303446458263354e-05\n",
      "  batch 201 loss: 5.831077941365948e-05\n",
      "LOSS train 5.7444195718767915e-05 valid 0.00019601677195169032\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.849602166563273e-07\n",
      "  batch 101 loss: 6.119604342870844e-05\n",
      "  batch 201 loss: 6.47228369123809e-05\n",
      "LOSS train 6.35366765805799e-05 valid 0.00024648348335176706\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0002214113622903824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 0.13973410888762372\n",
      "  batch 201 loss: 8.837426318223152e-05\n",
      "LOSS train 0.05131885459041559 valid 0.00026260490994900465\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.623418736737222e-07\n",
      "  batch 101 loss: 8.751079408739315e-05\n",
      "  batch 201 loss: 9.578612236964546e-05\n",
      "LOSS train 9.334003153199797e-05 valid 0.0003506291832309216\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.6286569007206708e-06\n",
      "  batch 101 loss: 9.714218056046775e-05\n",
      "  batch 201 loss: 9.549067665716393e-05\n",
      "LOSS train 9.457637007961658e-05 valid 0.00030963061726652086\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.3607642904389649e-06\n",
      "  batch 101 loss: 8.362075108948374e-05\n",
      "  batch 201 loss: 7.85936366213491e-05\n",
      "LOSS train 7.860290869213727e-05 valid 0.0002356536715524271\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.580177382100373e-07\n",
      "  batch 101 loss: 6.898847722595747e-05\n",
      "  batch 201 loss: 6.572047134454806e-05\n",
      "LOSS train 6.552115164537006e-05 valid 0.00018898191046901047\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 5.592594243353233e-07\n",
      "  batch 101 loss: 6.0861633219246866e-05\n",
      "  batch 201 loss: 5.939904035358268e-05\n",
      "LOSS train 5.8903626291467866e-05 valid 0.00017052776820492\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.454086592886597e-07\n",
      "  batch 101 loss: 5.77161093082168e-05\n",
      "  batch 201 loss: 5.7628050348057515e-05\n",
      "LOSS train 5.690018975433754e-05 valid 0.00017886293062474579\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.915518729831092e-07\n",
      "  batch 101 loss: 5.816075590416858e-05\n",
      "  batch 201 loss: 5.987963152733755e-05\n",
      "LOSS train 5.8940225807253844e-05 valid 0.00021218828624114394\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 6.978491001063957e-07\n",
      "  batch 101 loss: 6.359404644683764e-05\n",
      "  batch 201 loss: 6.790457593524479e-05\n",
      "LOSS train 6.671153992522208e-05 valid 0.0002661037433426827\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.0592597391223534e-06\n",
      "  batch 101 loss: 7.470863910157277e-05\n",
      "  batch 201 loss: 8.001886769079647e-05\n",
      "LOSS train 7.892585943570935e-05 valid 0.0002946809399873018\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.2587134551722557e-06\n",
      "  batch 101 loss: 8.312255755527076e-05\n",
      "  batch 201 loss: 8.181568137729301e-05\n",
      "LOSS train 8.217798623162051e-05 valid 0.0002127476327586919\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.954243872314691e-07\n",
      "  batch 101 loss: 7.248931285971593e-05\n",
      "  batch 201 loss: 6.37821176894704e-05\n",
      "LOSS train 6.585323237211944e-05 valid 0.00012057591084158048\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.1 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.2803538013249635e-05\n",
      "  batch 101 loss: 0.05014415988412452\n",
      "  batch 201 loss: 0.0001110545747269498\n",
      "LOSS train 0.018451020463601878 valid 6.536579894600436e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 6.973629933781922e-07\n",
      "  batch 101 loss: 0.00012073056071017163\n",
      "  batch 201 loss: 9.809155935840862e-05\n",
      "LOSS train 0.0001013195275867301 valid 9.388839680468664e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 5.5023683671606705e-08\n",
      "  batch 101 loss: 7.113881861641857e-05\n",
      "  batch 201 loss: 6.259345484181722e-05\n",
      "LOSS train 6.379107881435803e-05 valid 0.00014507623563986272\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.8517028113128616e-07\n",
      "  batch 101 loss: 5.749672443698728e-05\n",
      "  batch 201 loss: 5.743500616944175e-05\n",
      "LOSS train 5.692886519748574e-05 valid 0.00019184757547918707\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 5.588692874880508e-07\n",
      "  batch 101 loss: 6.08862104400032e-05\n",
      "  batch 201 loss: 6.55568993892075e-05\n",
      "LOSS train 6.434383365307766e-05 valid 0.0002603703469503671\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0112988820765166e-06\n",
      "  batch 101 loss: 7.414103733708543e-05\n",
      "  batch 201 loss: 8.035089116333439e-05\n",
      "LOSS train 7.905981750569721e-05 valid 0.000292712589725852\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.2383025023154914e-06\n",
      "  batch 101 loss: 8.330488451292695e-05\n",
      "  batch 201 loss: 7.988975310126988e-05\n",
      "LOSS train 8.05172466112082e-05 valid 0.00018483131134416908\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 5.154921382199973e-07\n",
      "  batch 101 loss: 6.720317649751451e-05\n",
      "  batch 201 loss: 5.7640869647457295e-05\n",
      "LOSS train 5.9904366309468226e-05 valid 0.00010430227848701179\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 9.193972800858319e-08\n",
      "  batch 101 loss: 4.74512043734876e-05\n",
      "  batch 201 loss: 4.1800597994097185e-05\n",
      "LOSS train 4.309242236386526e-05 valid 7.888268737588078e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 1.8322757568967062e-08\n",
      "  batch 101 loss: 3.780403835207835e-05\n",
      "  batch 201 loss: 3.5123941089523213e-05\n",
      "LOSS train 3.5680116493053584e-05 valid 6.694789772154763e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.3855051292921417e-08\n",
      "  batch 101 loss: 3.458487435750612e-05\n",
      "  batch 201 loss: 3.3565931594239374e-05\n",
      "LOSS train 3.370015645302937e-05 valid 5.590068394667469e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.166722869238584e-08\n",
      "  batch 101 loss: 3.497593151223555e-05\n",
      "  batch 201 loss: 3.445320961191101e-05\n",
      "LOSS train 3.404333084592888e-05 valid 5.124522795085795e-05\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.2 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 6.815242115408182e-05\n",
      "  batch 101 loss: 0.36195390126327764\n",
      "  batch 201 loss: 6.877881107811846e-05\n",
      "LOSS train 0.1326529240518889 valid 6.061354361008853e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.884088386665098e-07\n",
      "  batch 101 loss: 7.953699168638196e-05\n",
      "  batch 201 loss: 8.707229947049199e-05\n",
      "LOSS train 8.620463128677213e-05 valid 7.79222245910205e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 9.477374987909571e-07\n",
      "  batch 101 loss: 0.00010133275633847916\n",
      "  batch 201 loss: 0.00010872248612685098\n",
      "LOSS train 0.00010865946640613305 valid 8.939138933783397e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.1524414730956778e-06\n",
      "  batch 101 loss: 0.00012171692244351107\n",
      "  batch 201 loss: 0.000124522746230582\n",
      "LOSS train 0.00012523321177051192 valid 7.071412255754694e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 8.088158938335255e-07\n",
      "  batch 101 loss: 0.0001269158099410106\n",
      "  batch 201 loss: 0.00012044728194496201\n",
      "LOSS train 0.0001217342196747974 valid 5.089776459499262e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.023228444159031e-07\n",
      "  batch 101 loss: 0.00010941687401782473\n",
      "  batch 201 loss: 9.829397272028473e-05\n",
      "LOSS train 9.975127472927899e-05 valid 7.173738413257524e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1750490784834256e-08\n",
      "  batch 101 loss: 8.506068739279727e-05\n",
      "  batch 201 loss: 7.65568704287034e-05\n",
      "LOSS train 7.734820793351095e-05 valid 0.00010531411680858582\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.589125511411112e-08\n",
      "  batch 101 loss: 6.791377234094398e-05\n",
      "  batch 201 loss: 6.333009086915808e-05\n",
      "LOSS train 6.337894337992198e-05 valid 0.0001336719433311373\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 2.2541327780345454e-07\n",
      "  batch 101 loss: 5.926782432652544e-05\n",
      "  batch 201 loss: 5.772204561651506e-05\n",
      "LOSS train 5.725374243875261e-05 valid 0.00016072737344074994\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 3.722809560713358e-07\n",
      "  batch 101 loss: 5.727883346651197e-05\n",
      "  batch 201 loss: 5.8254825088397414e-05\n",
      "LOSS train 5.7398647773311914e-05 valid 0.00019571355369407684\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 5.830544614582323e-07\n",
      "  batch 101 loss: 6.116158163081309e-05\n",
      "  batch 201 loss: 6.472558696742681e-05\n",
      "LOSS train 6.353893050573712e-05 valid 0.00024687181576155126\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 9.187471005134284e-07\n",
      "  batch 101 loss: 7.0815730770164e-05\n",
      "  batch 201 loss: 7.630254973832962e-05\n",
      "LOSS train 7.504155100391155e-05 valid 0.0002955697709694505\n",
      "ObjectiveEstimator_ANN_2hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=35, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=35, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ") 0.4 2\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0019860127568244934\n",
      "  batch 101 loss: 0.08356272476209597\n",
      "  batch 201 loss: 9.639816236358457e-05\n",
      "LOSS train 0.0314047401408 valid 7.955190085340291e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 9.7785668913275e-07\n",
      "  batch 101 loss: 0.00012680039433291768\n",
      "  batch 201 loss: 0.0001132287992561487\n",
      "LOSS train 0.00011360604123209113 valid 6.99738520779647e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.1781127113863476e-08\n",
      "  batch 101 loss: 8.356660130289129e-05\n",
      "  batch 201 loss: 7.065956513770289e-05\n",
      "LOSS train 7.268050177240667e-05 valid 0.00012587236415129155\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 1.8673068552743643e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 6.0608400631281256e-05\n",
      "  batch 201 loss: 5.781710102269244e-05\n",
      "LOSS train 5.774978187665367e-05 valid 0.00016550417058169842\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.99868113163393e-07\n",
      "  batch 101 loss: 5.75780289557315e-05\n",
      "  batch 201 loss: 5.9682957545419416e-05\n",
      "LOSS train 5.8783374944198176e-05 valid 0.0002173544926336035\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 7.217855454655364e-07\n",
      "  batch 101 loss: 6.535071500252343e-05\n",
      "  batch 201 loss: 7.112877873623802e-05\n",
      "LOSS train 6.978019612708502e-05 valid 0.00028447527438402176\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.1798417835962027e-06\n",
      "  batch 101 loss: 7.928371625894215e-05\n",
      "  batch 201 loss: 8.34526031542282e-05\n",
      "LOSS train 8.257586709313038e-05 valid 0.000269810640020296\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 1.0768328502308577e-06\n",
      "  batch 101 loss: 8.088320460046816e-05\n",
      "  batch 201 loss: 7.408763060993806e-05\n",
      "LOSS train 7.557291895291168e-05 valid 0.0001529936125734821\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 3.285710045020096e-07\n",
      "  batch 101 loss: 6.072115439337722e-05\n",
      "  batch 201 loss: 5.216368359185708e-05\n",
      "LOSS train 5.4201116133687483e-05 valid 9.480347216594964e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.7962147366197314e-08\n",
      "  batch 101 loss: 4.4128047509843785e-05\n",
      "  batch 201 loss: 3.948286479385388e-05\n",
      "LOSS train 4.051960664939489e-05 valid 7.557107164757326e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 1.4098252449912251e-08\n",
      "  batch 101 loss: 3.658035708895113e-05\n",
      "  batch 201 loss: 3.4389911292009856e-05\n",
      "LOSS train 3.4830663472517605e-05 valid 6.444344762712717e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 1.7962061065190936e-08\n",
      "  batch 101 loss: 3.446054447493907e-05\n",
      "  batch 201 loss: 3.3703550407722105e-05\n",
      "LOSS train 3.373131443276006e-05 valid 5.398212670115754e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00022155819460749625\n",
      "  batch 101 loss: 10.411263636776512\n",
      "  batch 201 loss: 0.0005121243462235725\n",
      "LOSS train 3.814006215937537 valid 5.3935211326461285e-05\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 5.5810046433180103e-08\n",
      "  batch 101 loss: 2.5746864187112804e-05\n",
      "  batch 201 loss: 1.739310223342727e-05\n",
      "LOSS train 1.890024717218134e-05 valid 3.879343785229139e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 2.64699838226079e-08\n",
      "  batch 101 loss: 8.49587439915922e-06\n",
      "  batch 201 loss: 4.215828560347745e-06\n",
      "LOSS train 5.229738567776698e-06 valid 3.857854244415648e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 2.8991719318582908e-08\n",
      "  batch 101 loss: 2.2191508949731543e-06\n",
      "  batch 201 loss: 2.2432389260984565e-06\n",
      "LOSS train 2.1692527511319626e-06 valid 4.058900231029838e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 2.277559360663872e-08\n",
      "  batch 101 loss: 2.169736575723391e-06\n",
      "  batch 201 loss: 2.0870695861674447e-06\n",
      "LOSS train 2.0849515742144995e-06 valid 4.157820512773469e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 2.8093072614865377e-08\n",
      "  batch 101 loss: 2.5375409687455887e-06\n",
      "  batch 201 loss: 2.31041376359542e-06\n",
      "LOSS train 2.229547340165367e-06 valid 4.163084668107331e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 1.8086042246068247e-08\n",
      "  batch 101 loss: 2.3438200400960342e-06\n",
      "  batch 201 loss: 2.1778816233108957e-06\n",
      "LOSS train 2.240067307629876e-06 valid 4.1166691516991705e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 9.169025361188688e-09\n",
      "  batch 101 loss: 2.7331964059840176e-06\n",
      "  batch 201 loss: 2.210451761186505e-06\n",
      "LOSS train 2.3921439715786784e-06 valid 4.338092549005523e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 8.915156968214433e-09\n",
      "  batch 101 loss: 3.017405421132935e-06\n",
      "  batch 201 loss: 2.9583102212882295e-06\n",
      "LOSS train 2.7748496463256757e-06 valid 4.202176569378935e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 9.132511991083448e-09\n",
      "  batch 101 loss: 4.59732667593471e-06\n",
      "  batch 201 loss: 3.4588656512823945e-06\n",
      "LOSS train 3.6007566138161878e-06 valid 4.2150713852606714e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 8.42307827042532e-09\n",
      "  batch 101 loss: 5.0832678877554824e-06\n",
      "  batch 201 loss: 4.06184347941263e-06\n",
      "LOSS train 5.062978046240171e-06 valid 4.1958010115195066e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 8.504226798322634e-09\n",
      "  batch 101 loss: 5.288568000594296e-06\n",
      "  batch 201 loss: 3.998907581248545e-06\n",
      "LOSS train 3.998387731500925e-06 valid 4.298455678508617e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.1 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 2.2650172468274832e-05\n",
      "  batch 101 loss: 15.725252418901073\n",
      "  batch 201 loss: 0.0031427209899993615\n",
      "LOSS train 5.761838798912672 valid 0.00015268963761627674\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 3.0556644778698685e-05\n",
      "  batch 101 loss: 0.0017324992490466685\n",
      "  batch 201 loss: 0.0013450158591149376\n",
      "LOSS train 0.001426388909562658 valid 0.0006442258600145578\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.534856273792684e-05\n",
      "  batch 101 loss: 0.0009396768151782453\n",
      "  batch 201 loss: 0.0008004552641068585\n",
      "LOSS train 0.00081062683187026 valid 0.0001640268455957994\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 5.317128379829228e-06\n",
      "  batch 101 loss: 0.0004445384338032454\n",
      "  batch 201 loss: 0.00035882574462448247\n",
      "LOSS train 0.00037139110805423277 valid 8.604560571257025e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 1.88647914910689e-06\n",
      "  batch 101 loss: 0.0002467211886687437\n",
      "  batch 201 loss: 0.00018454364697390702\n",
      "LOSS train 0.00019476724636471052 valid 5.66945927857887e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 1.0695624951040371e-06\n",
      "  batch 101 loss: 0.00012674121484451461\n",
      "  batch 201 loss: 0.00010142045268366928\n",
      "LOSS train 0.00010678477161364577 valid 0.0001248224580194801\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 5.749014599132351e-07\n",
      "  batch 101 loss: 0.00010677159146325721\n",
      "  batch 201 loss: 0.00010901408565587189\n",
      "LOSS train 9.920724001498816e-05 valid 6.328078598016873e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 2.2137503037811258e-07\n",
      "  batch 101 loss: 7.810381107901776e-05\n",
      "  batch 201 loss: 7.240636532515054e-05\n",
      "LOSS train 7.358792741870807e-05 valid 5.4833533795317635e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.293639722163789e-07\n",
      "  batch 101 loss: 7.092386457770772e-05\n",
      "  batch 201 loss: 6.984786373323004e-05\n",
      "LOSS train 7.002671077732771e-05 valid 5.665768185281195e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.847197124036029e-07\n",
      "  batch 101 loss: 7.295121900824597e-05\n",
      "  batch 201 loss: 7.473002583992639e-05\n",
      "LOSS train 7.382488658030135e-05 valid 5.948856778559275e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 9.083575423574076e-07\n",
      "  batch 101 loss: 7.567232941710245e-05\n",
      "  batch 201 loss: 7.718126847066741e-05\n",
      "LOSS train 7.660172056749773e-05 valid 6.204019155120477e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 6.207521801115945e-07\n",
      "  batch 101 loss: 7.96504171057677e-05\n",
      "  batch 201 loss: 8.276785237740114e-05\n",
      "LOSS train 8.200667831917245e-05 valid 6.743785343132913e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.2 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00015685534104704858\n",
      "  batch 101 loss: 20.66936787690036\n",
      "  batch 201 loss: 0.010501126125454903\n",
      "LOSS train 7.576530982862183 valid 0.0031502852216362953\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.142727607861161e-05\n",
      "  batch 101 loss: 0.0029169540078146385\n",
      "  batch 201 loss: 0.0012045418031630107\n",
      "LOSS train 0.001671091831760863 valid 0.00019842757319565862\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 3.446313494350761e-06\n",
      "  batch 101 loss: 0.00028308209992246704\n",
      "  batch 201 loss: 0.00013586538067102084\n",
      "LOSS train 0.0001779782060944627 valid 5.367081757867709e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 4.367517976788804e-07\n",
      "  batch 101 loss: 7.165415006056719e-05\n",
      "  batch 201 loss: 6.548987674250384e-05\n",
      "LOSS train 6.619782175637625e-05 valid 5.033328488934785e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.289252344984561e-07\n",
      "  batch 101 loss: 5.963533811154775e-05\n",
      "  batch 201 loss: 6.0200226253073195e-05\n",
      "LOSS train 5.930007408582968e-05 valid 5.077705282019451e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.251733141951263e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 5.9481837361090584e-05\n",
      "  batch 201 loss: 5.972065642708912e-05\n",
      "LOSS train 5.903922021135815e-05 valid 5.121896538184956e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 3.548643144313246e-07\n",
      "  batch 101 loss: 6.012015606756904e-05\n",
      "  batch 201 loss: 6.740633729805267e-05\n",
      "LOSS train 6.332520027441845e-05 valid 5.2249786676838994e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 3.8674421375617386e-07\n",
      "  batch 101 loss: 6.384558218996972e-05\n",
      "  batch 201 loss: 6.38876283483114e-05\n",
      "LOSS train 6.330566292233879e-05 valid 5.310184133122675e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.0759710827842356e-07\n",
      "  batch 101 loss: 6.468939818660147e-05\n",
      "  batch 201 loss: 6.539474267810874e-05\n",
      "LOSS train 6.472953306674687e-05 valid 5.375801629270427e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 4.415856528794393e-07\n",
      "  batch 101 loss: 6.67111423535971e-05\n",
      "  batch 201 loss: 6.772647379875707e-05\n",
      "LOSS train 6.697509877914934e-05 valid 5.483796849148348e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 4.852208803640679e-07\n",
      "  batch 101 loss: 6.898730760894978e-05\n",
      "  batch 201 loss: 7.017021547198964e-05\n",
      "LOSS train 6.945222302030223e-05 valid 5.5408898333553225e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 5.351840445655398e-07\n",
      "  batch 101 loss: 7.101387477177923e-05\n",
      "  batch 201 loss: 7.161405359056517e-05\n",
      "LOSS train 7.118554513232457e-05 valid 5.358822818379849e-05\n",
      "ObjectiveEstimator_ANN_3hidden_layer(\n",
      "  (hidden_layer1): Linear(in_features=1227, out_features=306, bias=True)\n",
      "  (hidden_layer2): Linear(in_features=306, out_features=76, bias=True)\n",
      "  (hidden_layer3): Linear(in_features=76, out_features=19, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (output_layer): Linear(in_features=19, out_features=1, bias=True)\n",
      ") 0.4 3\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.0006091529503464699\n",
      "  batch 101 loss: 13.996231927517801\n",
      "  batch 201 loss: 0.017180146165192128\n",
      "LOSS train 5.13517297417925 valid 0.0009689031867310405\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 2.7081521693617105e-05\n",
      "  batch 101 loss: 0.0013698917982401327\n",
      "  batch 201 loss: 0.0003665258029650431\n",
      "LOSS train 0.0006813447791714164 valid 6.28341076662764e-05\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 1.0758895223261789e-06\n",
      "  batch 101 loss: 8.75297390302876e-05\n",
      "  batch 201 loss: 7.129698842618381e-05\n",
      "LOSS train 7.561694228270725e-05 valid 5.237639197730459e-05\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 3.0912520742276684e-07\n",
      "  batch 101 loss: 6.25162071082741e-05\n",
      "  batch 201 loss: 6.20320114921924e-05\n",
      "LOSS train 6.122832146768852e-05 valid 5.2548657549778e-05\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 3.654426109278575e-07\n",
      "  batch 101 loss: 6.112203173870512e-05\n",
      "  batch 201 loss: 6.185004479448253e-05\n",
      "LOSS train 6.11121278560169e-05 valid 5.303963189362548e-05\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 3.646127515821718e-07\n",
      "  batch 101 loss: 6.261242262553424e-05\n",
      "  batch 201 loss: 6.378321253578179e-05\n",
      "LOSS train 6.280038865326201e-05 valid 5.4022988479118794e-05\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 4.229139449307695e-07\n",
      "  batch 101 loss: 6.513755705782387e-05\n",
      "  batch 201 loss: 6.620776464842493e-05\n",
      "LOSS train 6.54070687589357e-05 valid 5.5206688557518646e-05\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 4.4429078116081655e-07\n",
      "  batch 101 loss: 6.775181673674525e-05\n",
      "  batch 201 loss: 6.873662191537732e-05\n",
      "LOSS train 6.81492381742858e-05 valid 5.718721149605699e-05\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 4.96434877277352e-07\n",
      "  batch 101 loss: 7.098816687175713e-05\n",
      "  batch 201 loss: 7.255848426211742e-05\n",
      "LOSS train 7.186204718878205e-05 valid 6.007438059896231e-05\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 5.719262480852195e-07\n",
      "  batch 101 loss: 7.513739371006522e-05\n",
      "  batch 201 loss: 7.701730580720323e-05\n",
      "LOSS train 7.638676094920344e-05 valid 6.371118797687814e-05\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 6.513120024465024e-07\n",
      "  batch 101 loss: 8.043581254014497e-05\n",
      "  batch 201 loss: 8.281319759134931e-05\n",
      "LOSS train 8.239105001445547e-05 valid 6.893237878102809e-05\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 7.611951150465757e-07\n",
      "  batch 101 loss: 8.722045211243313e-05\n",
      "  batch 201 loss: 9.006973637724513e-05\n",
      "LOSS train 8.984424124679248e-05 valid 7.59068934712559e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01*4**i for i in range(2)]\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "nbs_e = [4,8,12]#,4,8]\n",
    "i=0\n",
    "nbs_hidden = [0,1,2,3]\n",
    "dors = [0,0.1,0.2,0.4]\n",
    "results = pd.DataFrame()\n",
    "folder_to_save = \"RTS24_AC_12w_split_by_exec\"\n",
    "for nb_e in nbs_e:\n",
    "    for lr in learning_rates:\n",
    "        for nb_hidden in nbs_hidden: \n",
    "            for dor in dors:\n",
    "                m = NN_classes.create_model(nb_hidden,d_ft_in['train'].shape[1],dropout_ratio= dor)\n",
    "                m_name = f\"OE_{nb_hidden}h_{nb_e}e_{lr}lr_{dor}dor\"\n",
    "                optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "                train_loss = training_methods.train_multiple_epochs(nb_e,m,training_loader,validation_loader,loss_fn,optimizer,m_name,folder_to_save)\n",
    "\n",
    "                saved_models = dict()\n",
    "\n",
    "                for mt in [\"min_val\",\"all_epochs\"]:\n",
    "                    path = f\"trained_models/{folder_to_save}/{mt}/model_{m_name}.pth\"\n",
    "\n",
    "\n",
    "                    model = m\n",
    "                    m.load_state_dict(torch.load(path))\n",
    "                    m.eval()\n",
    "\n",
    "                    test_predictions = m(d_ft_in[\"test\"].float())\n",
    "                    test_loss = loss_fn(test_predictions,d_ft_out[\"test\"])\n",
    "\n",
    "                    train_predictions = m(d_ft_in[\"train\"].float())\n",
    "                    train_loss = loss_fn(train_predictions,d_ft_out[\"train\"])\n",
    "\n",
    "                    validation_prediction = m(d_ft_in[\"val\"].float())\n",
    "                    validation_loss = loss_fn(validation_prediction,d_ft_out[\"val\"])\n",
    "\n",
    "                    if mt == \"min_val\": \n",
    "                        min_val = True\n",
    "                    else: \n",
    "                        min_val = False\n",
    "\n",
    "                    r = pd.DataFrame({\"Model_type\": nb_hidden,\n",
    "                                      \"Min_val\":min_val,\n",
    "                                      \"Epochs\": nb_e,\n",
    "                                      \"Lr\":lr,\n",
    "                                      \"Dor\": dor,\n",
    "                                      \"Tr_l\":train_loss.item(),\n",
    "                                      \"Te_l\":test_loss.item(),\n",
    "                                      \"V_l\": validation_loss.item()}\n",
    "                                     ,index = [i]\n",
    "                    )\n",
    "                    i+=1\n",
    "                    results = pd.concat([results,r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2fe247f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"Loss_results_csv/20Exec_split_by_exec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3ba17c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = (results.Epochs == 12)  & (results.Model_type != 0) \n",
    "sns.boxplot(y = \"Te_l\",x=\"Dor\",data = results[f],hue = \"Min_val\")\n",
    "plt.savefig(\"Figures/Split_by_exec/Min_val_effect_Testloss_fDor.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a759efd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f =  (results.Model_type == 0) & (results.Min_val == True)\n",
    "sns.boxplot(y = \"V_l\",x=\"Epochs\",data = results[f],hue = \"Lr\")\n",
    "plt.savefig(\"Figures/Split_by_exec/Lr_effect_Testloss_fEpochs.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
