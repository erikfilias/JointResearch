{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20856959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split,TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Importing the libraries\n",
    "import torch\n",
    "#from torchviz import make_dot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import NN_classes\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "import training_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ad5d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a606a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "executions = [\"Network_Line_Out_N_101_N_102_cac1\",\"Network_Line_Out_N_102_N_104_cac1\",\"Network_Line_Out_N_101_N_105_cac1\",\"Network_Line_Out_N_102_N_104_cac1\",\"Network_Line_Out_N_102_N_106_cac1\",\"Network_Line_Out_N_103_N_109_cac1\"]\n",
    "#executions = [\"Network_Line_Out_N_101_N_102_cac1\"]\n",
    "\n",
    "#executions = [\"Network_Full_Generation_Full\",\"Network_Line_In_N_101_N_102_cac1\",\"Network_Line_In_N_101_N_103_cac1\",\"Network_Line_In_N_101_N_105_cac1\"]\n",
    "sc = \"sc01\"\n",
    "period = \"2030\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750122b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/input_f_sc01_Network_Line_Out_N_101_N_102_cac1_2030.csv\n",
      "1312\n",
      "Data/input_f_sc01_Network_Line_Out_N_102_N_104_cac1_2030.csv\n",
      "1312\n",
      "Data/input_f_sc01_Network_Line_Out_N_101_N_105_cac1_2030.csv\n",
      "1312\n",
      "Data/input_f_sc01_Network_Line_Out_N_102_N_104_cac1_2030.csv\n",
      "1312\n",
      "Data/input_f_sc01_Network_Line_Out_N_102_N_106_cac1_2030.csv\n",
      "1312\n",
      "Data/input_f_sc01_Network_Line_Out_N_103_N_109_cac1_2030.csv\n",
      "1312\n"
     ]
    }
   ],
   "source": [
    "dfs_in = dict()\n",
    "dfs_out = dict()\n",
    "folder = \"RTS_24\"\n",
    "for execution in executions:\n",
    "    #Read the data from desired execution\n",
    "    df_in_e = pd.read_csv(f\"Data/{folder}/input_f_{sc}_{execution}_{period}.csv\",header=[0,1])\n",
    "    df_out_e = pd.read_csv(f\"Data/{folder}/output_f_{sc}_{execution}_{period}.csv\",header=[0,1])\n",
    "\n",
    "    #Drop the first row(s) because its useless \n",
    "    df_in_e = df_in_e.drop([0])\n",
    "    if folder == \"RTS_24\":\n",
    "        df_out_e = df_out_e.drop([0])\n",
    "    elif folder == \"RTS_24_AC\":\n",
    "        df_out_e = df_out_e.drop([0,1])\n",
    "    print(f\"Data/input_f_{sc}_{execution}_{period}.csv\")\n",
    "    \n",
    "    #Split the real and imaginary part the input data: \n",
    "    df_in_e_r = df_in_e[\"Value_R\"]\n",
    "    df_in_e_i = df_in_e[\"Value_I\"]\n",
    "    \n",
    "    #And order the variables: \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(len(df_in_e_r.columns)+ len(df_in_e_i.columns))\n",
    "    \n",
    "    df_in_e_c = pd.concat([df_in_e_r,df_in_e_i],axis=1)\n",
    "    df_out_e = df_out_e[\"Value\"]\n",
    "    for col in df_out_e.columns: \n",
    "        df_out_e[col] = df_out_e[col].astype(float)\n",
    "    dfs_in[execution] = df_in_e_c\n",
    "    dfs_out[execution] = df_out_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90b43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in  = dict()\n",
    "ts_out = dict()\n",
    "\n",
    "ts_in[\"train\"] = dict()\n",
    "ts_in[\"test\"]  = dict()\n",
    "ts_in[\"val\"]  = dict()\n",
    "\n",
    "ts_out[\"train\"]= dict()\n",
    "ts_out[\"test\"] = dict()\n",
    "ts_out[\"val\"]= dict()\n",
    "\n",
    "\n",
    "#Test size as fraction of full dataset, validation size as fraction of training data set\n",
    "test_size,validation_size = 0.2,0.2\n",
    "\n",
    "for execution in executions: \n",
    "    #Convert input dataframes numpy arrays sum the columns of the output: \n",
    "    np_in = dfs_in[execution].to_numpy()\n",
    "    np_out = dfs_out[execution].to_numpy().sum(axis=1)\n",
    "    \n",
    "    #We don't normalize the separate runs, but will do it afterward, all together\n",
    "\n",
    "    #Convert to torch tensors\n",
    "    t_in = torch.from_numpy(np_in)\n",
    "    t_out = torch.from_numpy(np_out)\n",
    "\n",
    "    #And split into train, validation, and test set:\n",
    "    train_in,ts_in[\"test\"][execution],train_out,ts_out[\"test\"][execution]= train_test_split(t_in,t_out,test_size=test_size,shuffle=False)\n",
    "    ts_in[\"train\"][execution],ts_in[\"val\"][execution],ts_out[\"train\"][execution],ts_out[\"val\"][execution] = train_test_split(train_in,train_out,test_size=validation_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f0e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the training and testing sets to a single tensor, and normalize: \n",
    "first = True\n",
    "for execution in executions:\n",
    "    if first: \n",
    "        tr_in = ts_in[\"train\"][execution]\n",
    "        tr_out = ts_out[\"train\"][execution]\n",
    "        te_in = ts_in[\"test\"][execution]\n",
    "        te_out = ts_out[\"test\"][execution]\n",
    "        val_in = ts_in[\"val\"][execution]\n",
    "        val_out = ts_out[\"val\"][execution]\n",
    "        first = False\n",
    "    else: \n",
    "        tr_in = torch.cat((tr_in,ts_in[\"train\"][execution]))\n",
    "        tr_out= torch.cat((tr_out,ts_out[\"train\"][execution]))\n",
    "        te_in = torch.cat((te_in,ts_in[\"test\"][execution]))\n",
    "        te_out= torch.cat((te_out,ts_out[\"test\"][execution]))\n",
    "        val_in = torch.cat((val_in,ts_in[\"val\"][execution]))\n",
    "        val_out= torch.cat((val_out,ts_out[\"val\"][execution]))\n",
    "        \n",
    "        \n",
    "maxs= torch.cat((tr_in,te_in,val_in)).abs().max(dim = 0).values\n",
    "# maxs_te = te_in.abs().max(dim = 0).values\n",
    "tr_in = torch.nan_to_num(tr_in/maxs)\n",
    "te_in = torch.nan_to_num(te_in/maxs)\n",
    "val_in = torch.nan_to_num(val_in/maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a2c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ts_in  = dict()\n",
    "\n",
    "n_ts_in[\"train\"] = dict()\n",
    "n_ts_in[\"test\"]  = dict()\n",
    "n_ts_in[\"val\"]  = dict()\n",
    "\n",
    "for execution in executions: \n",
    "    n_ts_in[\"train\"][execution] = torch.nan_to_num(ts_in[\"train\"][execution]/maxs)\n",
    "    n_ts_in[\"test\"][execution] = torch.nan_to_num(ts_in[\"test\"][execution]/maxs)\n",
    "    n_ts_in[\"val\"][execution] = torch.nan_to_num(ts_in[\"val\"][execution]/maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebcd4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(tr_in.float(), tr_out.float())\n",
    "validation = TensorDataset(val_in, val_out)\n",
    "\n",
    "training_loader = DataLoader(train,batch_size=32)\n",
    "validation_loader = DataLoader(train,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1acb8fac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1 loss: 0.4808466339111328\n",
      "  batch 101 loss: 3.9140544447302816\n",
      "  batch 201 loss: 1.7130151024460794\n",
      "  batch 301 loss: 0.6783644327521324\n",
      "  batch 401 loss: 0.6253941395878791\n",
      "  batch 501 loss: 0.2895984887331724\n",
      "  batch 601 loss: 0.1671581783797592\n",
      "  batch 701 loss: 0.08890095236711204\n",
      "  batch 801 loss: 0.1477286569075659\n",
      "  batch 901 loss: 0.10265894392970949\n",
      "  batch 1001 loss: 0.019355966607108713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.019355966607108713 valid 3.95135760307312\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.008500305414199829\n",
      "  batch 101 loss: 0.04793586740735918\n",
      "  batch 201 loss: 0.031291165300644935\n",
      "  batch 301 loss: 0.02166490328963846\n",
      "  batch 401 loss: 0.04485066747991368\n",
      "  batch 501 loss: 0.01794984140433371\n",
      "  batch 601 loss: 0.034255422619171444\n",
      "  batch 701 loss: 0.04711033577565104\n",
      "  batch 801 loss: 0.07993934328318573\n",
      "  batch 901 loss: 0.04499069046229124\n",
      "  batch 1001 loss: 0.02603263978147879\n",
      "LOSS train 0.02603263978147879 valid 3.8955087661743164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([10488])) that is different to the input size (torch.Size([10488, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1 loss: 0.5047174072265626\n",
      "  batch 101 loss: 6.5499325665831565\n",
      "  batch 201 loss: 0.4376942977262661\n",
      "  batch 301 loss: 0.033452451386256146\n",
      "  batch 401 loss: 0.1905786937265657\n",
      "  batch 501 loss: 0.03687682198069524\n",
      "  batch 601 loss: 0.050204033288173376\n",
      "  batch 701 loss: 0.06304576861148234\n",
      "  batch 801 loss: 0.6135004765354097\n",
      "  batch 901 loss: 0.2933079294068739\n",
      "  batch 1001 loss: 0.05199463279743213\n",
      "LOSS train 0.05199463279743213 valid 3.7469770908355713\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0013370612263679505\n",
      "  batch 101 loss: 0.03787773148098495\n",
      "  batch 201 loss: 0.10887664567679167\n",
      "  batch 301 loss: 0.038657416318601465\n",
      "  batch 401 loss: 0.3593461203738116\n",
      "  batch 501 loss: 0.05611602072021924\n",
      "  batch 601 loss: 0.0727459300897317\n",
      "  batch 701 loss: 0.08674444074276835\n",
      "  batch 801 loss: 0.5398490991862491\n",
      "  batch 901 loss: 0.08533523302525282\n",
      "  batch 1001 loss: 0.023485966389998794\n",
      "LOSS train 0.023485966389998794 valid 3.6823384761810303\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.46555816650390625\n",
      "  batch 101 loss: 2.330517705976963\n",
      "  batch 201 loss: 0.38562087565660474\n",
      "  batch 301 loss: 0.0246466097002849\n",
      "  batch 401 loss: 0.09539984902832657\n",
      "  batch 501 loss: 0.024277506202924997\n",
      "  batch 601 loss: 0.04148301693843678\n",
      "  batch 701 loss: 0.04444466685410589\n",
      "  batch 801 loss: 0.26729397286195306\n",
      "  batch 901 loss: 0.04726162607315928\n",
      "  batch 1001 loss: 0.08142886005342007\n",
      "LOSS train 0.08142886005342007 valid 4.5257110595703125\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.02125441551208496\n",
      "  batch 101 loss: 0.13939936984330414\n",
      "  batch 201 loss: 0.050609264138620345\n",
      "  batch 301 loss: 0.039854424429358916\n",
      "  batch 401 loss: 0.1554464983008802\n",
      "  batch 501 loss: 0.0693018718296662\n",
      "  batch 601 loss: 0.11342854178277775\n",
      "  batch 701 loss: 0.07402522307820618\n",
      "  batch 801 loss: 0.25996210318000523\n",
      "  batch 901 loss: 0.18702985728625207\n",
      "  batch 1001 loss: 0.05053267307113856\n",
      "LOSS train 0.05053267307113856 valid 3.80141019821167\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.48760238647460935\n",
      "  batch 101 loss: 7.110809044986963\n",
      "  batch 201 loss: 1.2849937292560936\n",
      "  batch 301 loss: 0.20530088035855443\n",
      "  batch 401 loss: 0.4065820401115343\n",
      "  batch 501 loss: 0.0596036111691501\n",
      "  batch 601 loss: 0.052356238688807934\n",
      "  batch 701 loss: 0.03973684174270602\n",
      "  batch 801 loss: 0.5710550663713366\n",
      "  batch 901 loss: 0.2697205288289115\n",
      "  batch 1001 loss: 0.06739426682353951\n",
      "LOSS train 0.06739426682353951 valid 4.163037300109863\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.007631551027297973\n",
      "  batch 101 loss: 0.04951797152665677\n",
      "  batch 201 loss: 0.04616519718198106\n",
      "  batch 301 loss: 0.02448828783177305\n",
      "  batch 401 loss: 0.28206787551069284\n",
      "  batch 501 loss: 0.14130154876736925\n",
      "  batch 601 loss: 0.02524897839030018\n",
      "  batch 701 loss: 0.03996318854973652\n",
      "  batch 801 loss: 0.5475264999410138\n",
      "  batch 901 loss: 0.24022634807042778\n",
      "  batch 1001 loss: 0.07776303727863705\n",
      "LOSS train 0.07776303727863705 valid 4.391965866088867\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.48016571044921874\n",
      "  batch 101 loss: 3.2549496072717012\n",
      "  batch 201 loss: 0.0828803477017209\n",
      "  batch 301 loss: 0.05982004762394354\n",
      "  batch 401 loss: 0.5306531883543357\n",
      "  batch 501 loss: 0.39982772138435396\n",
      "  batch 601 loss: 0.1049915132188471\n",
      "  batch 701 loss: 0.1139048795599956\n",
      "  batch 801 loss: 0.46517881579697135\n",
      "  batch 901 loss: 0.6215872304746881\n",
      "  batch 1001 loss: 0.178349847830832\n",
      "LOSS train 0.178349847830832 valid 4.531747817993164\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.02157966375350952\n",
      "  batch 101 loss: 0.28790216219611464\n",
      "  batch 201 loss: 0.07319497712654993\n",
      "  batch 301 loss: 0.04992185755632818\n",
      "  batch 401 loss: 0.26103839436545967\n",
      "  batch 501 loss: 0.07264409884926863\n",
      "  batch 601 loss: 1.6689823078527115\n",
      "  batch 701 loss: 0.057962177069857714\n",
      "  batch 801 loss: 0.5226919809123501\n",
      "  batch 901 loss: 0.08879862866131588\n",
      "  batch 1001 loss: 0.06277349620126188\n",
      "LOSS train 0.06277349620126188 valid 7.426761627197266\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.470120849609375\n",
      "  batch 101 loss: 16183.212323064805\n",
      "  batch 201 loss: 3.1284316253662108\n",
      "  batch 301 loss: 2.2249884551763532\n",
      "  batch 401 loss: 3.0025329411029817\n",
      "  batch 501 loss: 2.8027310210466383\n",
      "  batch 601 loss: 2.4719521695375444\n",
      "  batch 701 loss: 3.060567528605461\n",
      "  batch 801 loss: 3.1022731465101243\n",
      "  batch 901 loss: 3.925292410850525\n",
      "  batch 1001 loss: 2.542053033709526\n",
      "LOSS train 2.542053033709526 valid 2.9219796657562256\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.026255013942718505\n",
      "  batch 101 loss: 2.5135779201984407\n",
      "  batch 201 loss: 3.294626410007477\n",
      "  batch 301 loss: 2.3092871177196503\n",
      "  batch 401 loss: 2.8786384481191636\n",
      "  batch 501 loss: 2.775112825036049\n",
      "  batch 601 loss: 2.4034868377447127\n",
      "  batch 701 loss: 2.9018803024291993\n",
      "  batch 801 loss: 3.00672345995903\n",
      "  batch 901 loss: 3.745513374209404\n",
      "  batch 1001 loss: 2.5699243170022963\n",
      "LOSS train 2.5699243170022963 valid 3.372559070587158\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.46641132354736325\n",
      "  batch 101 loss: 46.07828995019197\n",
      "  batch 201 loss: 1.569479754632339\n",
      "  batch 301 loss: 3.170069308169186\n",
      "  batch 401 loss: 3.2063645006064325\n",
      "  batch 501 loss: 0.6435858978983015\n",
      "  batch 601 loss: 3.7305673980154097\n",
      "  batch 701 loss: 1.4218103971797973\n",
      "  batch 801 loss: 13.366055365204812\n",
      "  batch 901 loss: 10.558086533211172\n",
      "  batch 1001 loss: 3.6766662796586753\n",
      "LOSS train 3.6766662796586753 valid 22.802478790283203\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.4093305206298828\n",
      "  batch 101 loss: 3.1058238322939724\n",
      "  batch 201 loss: 0.4420868744933978\n",
      "  batch 301 loss: 1.6944047834724187\n",
      "  batch 401 loss: 2.092101758532226\n",
      "  batch 501 loss: 0.11649549862369896\n",
      "  batch 601 loss: 3.0309199310466646\n",
      "  batch 701 loss: 20.428384106531738\n",
      "  batch 801 loss: 7.544705700203776\n",
      "  batch 901 loss: 7.065612006895244\n",
      "  batch 1001 loss: 3.9231068274751304\n",
      "LOSS train 3.9231068274751304 valid 15.32473087310791\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.5228364562988281\n",
      "  batch 101 loss: 23585663.777968712\n",
      "  batch 201 loss: 3.368270345926285\n",
      "  batch 301 loss: 2.43880479156971\n",
      "  batch 401 loss: 3.0342203003168104\n",
      "  batch 501 loss: 2.8146897459030153\n",
      "  batch 601 loss: 2.3517615538835526\n",
      "  batch 701 loss: 2.827311139702797\n",
      "  batch 801 loss: 3.177112307548523\n",
      "  batch 901 loss: 3.575298697948456\n",
      "  batch 1001 loss: 2.502042719721794\n",
      "LOSS train 2.502042719721794 valid 2.9897429943084717\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0300234055519104\n",
      "  batch 101 loss: 2.515944870710373\n",
      "  batch 201 loss: 3.1085414493083956\n",
      "  batch 301 loss: 2.2196064621210096\n",
      "  batch 401 loss: 2.8980513602495193\n",
      "  batch 501 loss: 2.7214972305297853\n",
      "  batch 601 loss: 2.3294373899698257\n",
      "  batch 701 loss: 2.8776938879489897\n",
      "  batch 801 loss: 3.032850387096405\n",
      "  batch 901 loss: 3.7475853252410887\n",
      "  batch 1001 loss: 2.4812682914733886\n",
      "LOSS train 2.4812682914733886 valid 3.1181976795196533\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.49107967376708983\n",
      "  batch 101 loss: 3.908002321124077\n",
      "  batch 201 loss: 1.6561919391155242\n",
      "  batch 301 loss: 0.6508688987791538\n",
      "  batch 401 loss: 0.5961126083135605\n",
      "  batch 501 loss: 0.2796161615103483\n",
      "  batch 601 loss: 0.16158149035647512\n",
      "  batch 701 loss: 0.08213921804446728\n",
      "  batch 801 loss: 0.1473669028840959\n",
      "  batch 901 loss: 0.09839078190270811\n",
      "  batch 1001 loss: 0.018189405030570923\n",
      "LOSS train 0.018189405030570923 valid 3.9183919429779053\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.007913458943367004\n",
      "  batch 101 loss: 0.04586666591698304\n",
      "  batch 201 loss: 0.03229316374054179\n",
      "  batch 301 loss: 0.021885420214384794\n",
      "  batch 401 loss: 0.044434313969686626\n",
      "  batch 501 loss: 0.018032418517395853\n",
      "  batch 601 loss: 0.03407949725165963\n",
      "  batch 701 loss: 0.0458614363335073\n",
      "  batch 801 loss: 0.07859017177135684\n",
      "  batch 901 loss: 0.04501915887463838\n",
      "  batch 1001 loss: 0.026011390620842578\n",
      "LOSS train 0.026011390620842578 valid 3.88503360748291\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.003580067157745361\n",
      "  batch 101 loss: 0.03678950964938849\n",
      "  batch 201 loss: 0.029789468655362725\n",
      "  batch 301 loss: 0.020382466183509678\n",
      "  batch 401 loss: 0.07220694810384884\n",
      "  batch 501 loss: 0.01890806755749509\n",
      "  batch 601 loss: 0.03760099080856889\n",
      "  batch 701 loss: 0.0501873829215765\n",
      "  batch 801 loss: 0.11450600340263918\n",
      "  batch 901 loss: 0.045158933971542865\n",
      "  batch 1001 loss: 0.022581133537460118\n",
      "LOSS train 0.022581133537460118 valid 3.9030721187591553\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.002536244988441467\n",
      "  batch 101 loss: 0.02970487515791319\n",
      "  batch 201 loss: 0.028713830579072237\n",
      "  batch 301 loss: 0.02133653461234644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 401 loss: 0.05378525264095515\n",
      "  batch 501 loss: 0.020172401282470675\n",
      "  batch 601 loss: 0.048108673715032635\n",
      "  batch 701 loss: 0.0467384966998361\n",
      "  batch 801 loss: 0.11066845989087597\n",
      "  batch 901 loss: 0.04537907757330686\n",
      "  batch 1001 loss: 0.021923284311778844\n",
      "LOSS train 0.021923284311778844 valid 3.9744744300842285\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.46873069763183595\n",
      "  batch 101 loss: 4.319261511564255\n",
      "  batch 201 loss: 0.27664346027188\n",
      "  batch 301 loss: 0.03447177627007477\n",
      "  batch 401 loss: 0.16416093832580372\n",
      "  batch 501 loss: 0.043997973166406155\n",
      "  batch 601 loss: 0.042509000197751445\n",
      "  batch 701 loss: 0.07482115617545787\n",
      "  batch 801 loss: 0.7319168318039737\n",
      "  batch 901 loss: 0.10418367812409997\n",
      "  batch 1001 loss: 0.04914840347017162\n",
      "LOSS train 0.04914840347017162 valid 3.974503755569458\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0018115429580211639\n",
      "  batch 101 loss: 0.03674841858141008\n",
      "  batch 201 loss: 0.06444751193688716\n",
      "  batch 301 loss: 0.02946833033056464\n",
      "  batch 401 loss: 0.1781067834456917\n",
      "  batch 501 loss: 0.041977765671908855\n",
      "  batch 601 loss: 0.060962091098626846\n",
      "  batch 701 loss: 0.0390846168412827\n",
      "  batch 801 loss: 0.5167952673323453\n",
      "  batch 901 loss: 0.2693339367862791\n",
      "  batch 1001 loss: 0.05463983018416911\n",
      "LOSS train 0.05463983018416911 valid 3.6057705879211426\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.00040620092302560805\n",
      "  batch 101 loss: 0.05089814098086208\n",
      "  batch 201 loss: 0.07545314439688809\n",
      "  batch 301 loss: 0.02218855368322693\n",
      "  batch 401 loss: 0.1947202080365969\n",
      "  batch 501 loss: 0.04752098985016346\n",
      "  batch 601 loss: 0.03830879603512585\n",
      "  batch 701 loss: 0.053930636749137194\n",
      "  batch 801 loss: 0.27617866334912833\n",
      "  batch 901 loss: 0.0739834241126664\n",
      "  batch 1001 loss: 0.018736419077031316\n",
      "LOSS train 0.018736419077031316 valid 3.6992886066436768\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.003119632601737976\n",
      "  batch 101 loss: 0.0558313011797145\n",
      "  batch 201 loss: 0.04687382477452047\n",
      "  batch 301 loss: 0.014525525913049932\n",
      "  batch 401 loss: 0.0684327880141791\n",
      "  batch 501 loss: 0.022402790232445114\n",
      "  batch 601 loss: 0.032532522809051445\n",
      "  batch 701 loss: 0.03691159088979475\n",
      "  batch 801 loss: 0.1266291921582888\n",
      "  batch 901 loss: 0.0727508410718292\n",
      "  batch 1001 loss: 0.021095113279880024\n",
      "LOSS train 0.021095113279880024 valid 3.6952812671661377\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.48434425354003907\n",
      "  batch 101 loss: 2.431421849131584\n",
      "  batch 201 loss: 0.41338854234665634\n",
      "  batch 301 loss: 0.025848085386678578\n",
      "  batch 401 loss: 0.1018851196905598\n",
      "  batch 501 loss: 0.023699525648262353\n",
      "  batch 601 loss: 0.03823813831200823\n",
      "  batch 701 loss: 0.04434489410603419\n",
      "  batch 801 loss: 0.2642135286855046\n",
      "  batch 901 loss: 0.04855608956888318\n",
      "  batch 1001 loss: 0.07882798228412867\n",
      "LOSS train 0.07882798228412867 valid 4.596536159515381\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.024162695407867432\n",
      "  batch 101 loss: 0.15126843644247856\n",
      "  batch 201 loss: 0.05247494917013682\n",
      "  batch 301 loss: 0.03890607035369612\n",
      "  batch 401 loss: 0.15441167718963697\n",
      "  batch 501 loss: 0.06809283983893692\n",
      "  batch 601 loss: 0.12337324310676195\n",
      "  batch 701 loss: 0.07204987173201516\n",
      "  batch 801 loss: 0.259184437164804\n",
      "  batch 901 loss: 0.1891672662599012\n",
      "  batch 1001 loss: 0.05085221830988303\n",
      "LOSS train 0.05085221830988303 valid 3.8407280445098877\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.004828559160232544\n",
      "  batch 101 loss: 0.07699475904286374\n",
      "  batch 201 loss: 0.07814232190605253\n",
      "  batch 301 loss: 0.04132036383351078\n",
      "  batch 401 loss: 0.16581204349640757\n",
      "  batch 501 loss: 0.06968502681702375\n",
      "  batch 601 loss: 0.049039086806587875\n",
      "  batch 701 loss: 0.08344614533416461\n",
      "  batch 801 loss: 0.36178523116977884\n",
      "  batch 901 loss: 0.07757312600500882\n",
      "  batch 1001 loss: 0.05041393575636903\n",
      "LOSS train 0.05041393575636903 valid 3.6248815059661865\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.0005666865780949592\n",
      "  batch 101 loss: 0.05283158903082949\n",
      "  batch 201 loss: 0.0798130872566253\n",
      "  batch 301 loss: 0.07545176183804869\n",
      "  batch 401 loss: 0.22113336787791923\n",
      "  batch 501 loss: 0.07777702069375664\n",
      "  batch 601 loss: 0.0497011662251316\n",
      "  batch 701 loss: 0.08709601586306234\n",
      "  batch 801 loss: 0.3465239572757855\n",
      "  batch 901 loss: 0.07700690445955843\n",
      "  batch 1001 loss: 0.08539253645052668\n",
      "LOSS train 0.08539253645052668 valid 3.938323497772217\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.4992685317993164\n",
      "  batch 101 loss: 11.220134819746017\n",
      "  batch 201 loss: 0.9502231283928267\n",
      "  batch 301 loss: 0.14842403122689574\n",
      "  batch 401 loss: 0.47130693880841135\n",
      "  batch 501 loss: 0.07982949294499121\n",
      "  batch 601 loss: 0.08488938538939692\n",
      "  batch 701 loss: 0.21541260961035733\n",
      "  batch 801 loss: 0.3920548921066802\n",
      "  batch 901 loss: 0.21509789338568225\n",
      "  batch 1001 loss: 0.05227737470529974\n",
      "LOSS train 0.05227737470529974 valid 3.9095003604888916\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0024928557872772217\n",
      "  batch 101 loss: 0.02922203687208821\n",
      "  batch 201 loss: 0.018545933313143904\n",
      "  batch 301 loss: 0.015682337700563948\n",
      "  batch 401 loss: 0.10265026210690849\n",
      "  batch 501 loss: 0.049358975416980685\n",
      "  batch 601 loss: 0.025862173594068737\n",
      "  batch 701 loss: 0.16931247511180117\n",
      "  batch 801 loss: 0.8140300250891596\n",
      "  batch 901 loss: 0.13290568928001448\n",
      "  batch 1001 loss: 0.04657630079687806\n",
      "LOSS train 0.04657630079687806 valid 3.886085271835327\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.0016401159763336183\n",
      "  batch 101 loss: 0.07029029243858531\n",
      "  batch 201 loss: 0.14737004815484397\n",
      "  batch 301 loss: 0.034546748043212575\n",
      "  batch 401 loss: 0.21283360506989993\n",
      "  batch 501 loss: 0.0887186428293353\n",
      "  batch 601 loss: 0.04685917358729057\n",
      "  batch 701 loss: 0.123148565182928\n",
      "  batch 801 loss: 0.39236534666386436\n",
      "  batch 901 loss: 0.09037686300929636\n",
      "  batch 1001 loss: 0.03452574082271895\n",
      "LOSS train 0.03452574082271895 valid 3.718898296356201\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.007911602258682251\n",
      "  batch 101 loss: 0.10615694716892904\n",
      "  batch 201 loss: 0.1260281883436255\n",
      "  batch 301 loss: 0.025302842872624753\n",
      "  batch 401 loss: 0.09882659142720512\n",
      "  batch 501 loss: 0.0824562637609779\n",
      "  batch 601 loss: 0.03980689663090743\n",
      "  batch 701 loss: 0.10182120905490592\n",
      "  batch 801 loss: 0.3829277994669974\n",
      "  batch 901 loss: 0.07803977674338966\n",
      "  batch 1001 loss: 0.029354984076344407\n",
      "LOSS train 0.029354984076344407 valid 3.7871859073638916\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.47309783935546873\n",
      "  batch 101 loss: 3.2103252749145033\n",
      "  batch 201 loss: 0.09372373835649342\n",
      "  batch 301 loss: 0.039563913391903044\n",
      "  batch 401 loss: 0.6923733470542356\n",
      "  batch 501 loss: 1.122932057827711\n",
      "  batch 601 loss: 0.519820655286312\n",
      "  batch 701 loss: 1.6927336294576525\n",
      "  batch 801 loss: 0.18111585187725723\n",
      "  batch 901 loss: 0.48387209463398906\n",
      "  batch 1001 loss: 0.07252134735463187\n",
      "LOSS train 0.07252134735463187 valid 10.792954444885254\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.04711188793182373\n",
      "  batch 101 loss: 1.2644128028862178\n",
      "  batch 201 loss: 1.25582036068663\n",
      "  batch 301 loss: 3.620458692535758\n",
      "  batch 401 loss: 2.5054366440710147\n",
      "  batch 501 loss: 0.246932584149763\n",
      "  batch 601 loss: 0.7327713627624326\n",
      "  batch 701 loss: 0.6346220030752011\n",
      "  batch 801 loss: 3.4311391798849216\n",
      "  batch 901 loss: 0.21935015531256796\n",
      "  batch 1001 loss: 0.05117281673010439\n",
      "LOSS train 0.05117281673010439 valid 9.577683448791504\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.027960808277130128\n",
      "  batch 101 loss: 0.3733247725851834\n",
      "  batch 201 loss: 1.1369539401098154\n",
      "  batch 301 loss: 0.24153724023140966\n",
      "  batch 401 loss: 0.7444548487849534\n",
      "  batch 501 loss: 0.5457642152905464\n",
      "  batch 601 loss: 0.9366331971902401\n",
      "  batch 701 loss: 1.5703890617378056\n",
      "  batch 801 loss: 3.519064826257527\n",
      "  batch 901 loss: 0.08073516116477548\n",
      "  batch 1001 loss: 0.030875791634898633\n",
      "LOSS train 0.030875791634898633 valid 9.68613052368164\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.010196502208709718\n",
      "  batch 101 loss: 0.4792550282552838\n",
      "  batch 201 loss: 3.6046828709170224\n",
      "  batch 301 loss: 0.3008842325815931\n",
      "  batch 401 loss: 2.7402053000219166\n",
      "  batch 501 loss: 0.3298206136003137\n",
      "  batch 601 loss: 0.7081740082777105\n",
      "  batch 701 loss: 0.34852992216590795\n",
      "  batch 801 loss: 3.8421027638576923\n",
      "  batch 901 loss: 0.2545489471592009\n",
      "  batch 1001 loss: 0.06123970465734601\n",
      "LOSS train 0.06123970465734601 valid 12.949822425842285\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.4858474349975586\n",
      "  batch 101 loss: 18751.44958403051\n",
      "  batch 201 loss: 3.1090972876548766\n",
      "  batch 301 loss: 2.2210240817070006\n",
      "  batch 401 loss: 2.9548357474803923\n",
      "  batch 501 loss: 2.779927397966385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 601 loss: 2.4287029618024825\n",
      "  batch 701 loss: 3.0425941514968873\n",
      "  batch 801 loss: 3.1002687764167787\n",
      "  batch 901 loss: 3.9517746496200563\n",
      "  batch 1001 loss: 2.530954757928848\n",
      "LOSS train 2.530954757928848 valid 3.0499534606933594\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.03181617021560669\n",
      "  batch 101 loss: 2.5447273445129395\n",
      "  batch 201 loss: 3.3554027378559113\n",
      "  batch 301 loss: 2.3059470975399017\n",
      "  batch 401 loss: 2.9716196668148043\n",
      "  batch 501 loss: 2.791324318647385\n",
      "  batch 601 loss: 2.4242157447338104\n",
      "  batch 701 loss: 2.9250802671909333\n",
      "  batch 801 loss: 3.0083009070158004\n",
      "  batch 901 loss: 3.7466279578208925\n",
      "  batch 1001 loss: 2.5609968292713163\n",
      "LOSS train 2.5609968292713163 valid 3.247371196746826\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.022440967559814454\n",
      "  batch 101 loss: 2.482841749191284\n",
      "  batch 201 loss: 3.2424973237514494\n",
      "  batch 301 loss: 2.316059809923172\n",
      "  batch 401 loss: 2.8528396391868593\n",
      "  batch 501 loss: 2.785937284231186\n",
      "  batch 601 loss: 2.4553697085380555\n",
      "  batch 701 loss: 2.93327967107296\n",
      "  batch 801 loss: 3.0550099658966063\n",
      "  batch 901 loss: 3.802508187890053\n",
      "  batch 1001 loss: 2.5938501811027526\n",
      "LOSS train 2.5938501811027526 valid 3.2310283184051514\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.022454912662506103\n",
      "  batch 101 loss: 2.5701682925224305\n",
      "  batch 201 loss: 3.338685104846954\n",
      "  batch 301 loss: 2.3612752103805543\n",
      "  batch 401 loss: 2.9869246852397917\n",
      "  batch 501 loss: 2.865476998090744\n",
      "  batch 601 loss: 2.568605901002884\n",
      "  batch 701 loss: 3.0290630465745925\n",
      "  batch 801 loss: 3.1829138416051865\n",
      "  batch 901 loss: 3.9112665164470672\n",
      "  batch 1001 loss: 2.6794886708259584\n",
      "LOSS train 2.6794886708259584 valid 2.930633306503296\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.4607653427124023\n",
      "  batch 101 loss: 46.26723515190184\n",
      "  batch 201 loss: 1.5956775264581666\n",
      "  batch 301 loss: 3.0809147956222294\n",
      "  batch 401 loss: 3.152426712177694\n",
      "  batch 501 loss: 0.6021649290341884\n",
      "  batch 601 loss: 3.663182056422811\n",
      "  batch 701 loss: 1.4097143539553507\n",
      "  batch 801 loss: 13.425282412171363\n",
      "  batch 901 loss: 10.54130192099139\n",
      "  batch 1001 loss: 3.68229422329925\n",
      "LOSS train 3.68229422329925 valid 22.481021881103516\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.4055084991455078\n",
      "  batch 101 loss: 3.0794603803008793\n",
      "  batch 201 loss: 0.4308492561103776\n",
      "  batch 301 loss: 1.55974251372274\n",
      "  batch 401 loss: 1.872719710841775\n",
      "  batch 501 loss: 0.13513137080706655\n",
      "  batch 601 loss: 19.057086133072154\n",
      "  batch 701 loss: 1.0334195959195496\n",
      "  batch 801 loss: 18.345700983814893\n",
      "  batch 901 loss: 1.815306460224092\n",
      "  batch 1001 loss: 0.9825531497597695\n",
      "LOSS train 0.9825531497597695 valid 29.832815170288086\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.3532537078857422\n",
      "  batch 101 loss: 13.493567258119583\n",
      "  batch 201 loss: 0.6926123740477488\n",
      "  batch 301 loss: 0.5736235673166812\n",
      "  batch 401 loss: 6.042433261498809\n",
      "  batch 501 loss: 1.8582937353104354\n",
      "  batch 601 loss: 16.22737983867526\n",
      "  batch 701 loss: 0.6902563545061275\n",
      "  batch 801 loss: 10.575715026259422\n",
      "  batch 901 loss: 3.48599967231974\n",
      "  batch 1001 loss: 1.9593148764036596\n",
      "LOSS train 1.9593148764036596 valid 22.865867614746094\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.24841314315795898\n",
      "  batch 101 loss: 12.698536374866963\n",
      "  batch 201 loss: 5.241948217600584\n",
      "  batch 301 loss: 0.6591833719983697\n",
      "  batch 401 loss: 1.4245553758740426\n",
      "  batch 501 loss: 0.046848396260757\n",
      "  batch 601 loss: 5.184646954205818\n",
      "  batch 701 loss: 28.111360675990582\n",
      "  batch 801 loss: 3.808696493245661\n",
      "  batch 901 loss: 0.26883028661832215\n",
      "  batch 1001 loss: 0.09301245576702058\n",
      "LOSS train 0.09301245576702058 valid 26.713823318481445\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.44861656188964844\n",
      "  batch 101 loss: 786379613.4895923\n",
      "  batch 201 loss: 154.0198593521118\n",
      "  batch 301 loss: 21.210363538265227\n",
      "  batch 401 loss: 3.4548418164253234\n",
      "  batch 501 loss: 3.0105165386199952\n",
      "  batch 601 loss: 2.556806181669235\n",
      "  batch 701 loss: 2.8728401929140093\n",
      "  batch 801 loss: 3.4155880230665208\n",
      "  batch 901 loss: 3.6408299446105956\n",
      "  batch 1001 loss: 2.8545234811306\n",
      "LOSS train 2.8545234811306 valid 2.9324944019317627\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.02500981330871582\n",
      "  batch 101 loss: 2.7598565846681593\n",
      "  batch 201 loss: 3.1537091553211214\n",
      "  batch 301 loss: 2.5534621155261994\n",
      "  batch 401 loss: 2.9987344348430636\n",
      "  batch 501 loss: 2.976904503107071\n",
      "  batch 601 loss: 2.4460408520698547\n",
      "  batch 701 loss: 2.9377425515651705\n",
      "  batch 801 loss: 3.470007530450821\n",
      "  batch 901 loss: 3.631378091573715\n",
      "  batch 1001 loss: 2.7566459596157076\n",
      "LOSS train 2.7566459596157076 valid 2.9351677894592285\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.027700722217559814\n",
      "  batch 101 loss: 2.766942069530487\n",
      "  batch 201 loss: 3.1220058143138885\n",
      "  batch 301 loss: 2.4369357949495316\n",
      "  batch 401 loss: 3.0443235445022583\n",
      "  batch 501 loss: 2.8738603127002715\n",
      "  batch 601 loss: 2.383303911685944\n",
      "  batch 701 loss: 2.8784043848514558\n",
      "  batch 801 loss: 3.3593972539901733\n",
      "  batch 901 loss: 3.575535223484039\n",
      "  batch 1001 loss: 2.6142640805244444\n",
      "LOSS train 2.6142640805244444 valid 2.9961745738983154\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.03023533821105957\n",
      "  batch 101 loss: 2.6460521805286406\n",
      "  batch 201 loss: 3.0763861536979675\n",
      "  batch 301 loss: 2.3009190356731413\n",
      "  batch 401 loss: 2.9504669189453123\n",
      "  batch 501 loss: 2.7322863203287127\n",
      "  batch 601 loss: 2.329073273539543\n",
      "  batch 701 loss: 2.809503684043884\n",
      "  batch 801 loss: 3.1203363698720934\n",
      "  batch 901 loss: 3.5847221541404726\n",
      "  batch 1001 loss: 2.489021978974342\n",
      "LOSS train 2.489021978974342 valid 2.9886693954467773\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.44598304748535156\n",
      "  batch 101 loss: 3.6357506534457205\n",
      "  batch 201 loss: 1.642408429980278\n",
      "  batch 301 loss: 0.6283625707030296\n",
      "  batch 401 loss: 0.5635569755733013\n",
      "  batch 501 loss: 0.2585723426938057\n",
      "  batch 601 loss: 0.1525103115197271\n",
      "  batch 701 loss: 0.0761444521183148\n",
      "  batch 801 loss: 0.13767408894374966\n",
      "  batch 901 loss: 0.09864187587983907\n",
      "  batch 1001 loss: 0.019418185371905566\n",
      "LOSS train 0.019418185371905566 valid 3.901299238204956\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0069259774684906\n",
      "  batch 101 loss: 0.04262878437759355\n",
      "  batch 201 loss: 0.031208159528905526\n",
      "  batch 301 loss: 0.021679984747897833\n",
      "  batch 401 loss: 0.04602670676773414\n",
      "  batch 501 loss: 0.01805097747826949\n",
      "  batch 601 loss: 0.034922124342992904\n",
      "  batch 701 loss: 0.047452203137800096\n",
      "  batch 801 loss: 0.08099946649046615\n",
      "  batch 901 loss: 0.04336054421961308\n",
      "  batch 1001 loss: 0.025620265523903073\n",
      "LOSS train 0.025620265523903073 valid 3.877915859222412\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.0033165663480758667\n",
      "  batch 101 loss: 0.035592615474015474\n",
      "  batch 201 loss: 0.030274103647097945\n",
      "  batch 301 loss: 0.02053167814621702\n",
      "  batch 401 loss: 0.07496699571609497\n",
      "  batch 501 loss: 0.019219155630562455\n",
      "  batch 601 loss: 0.03974339155480266\n",
      "  batch 701 loss: 0.04945921123959124\n",
      "  batch 801 loss: 0.11438472068170086\n",
      "  batch 901 loss: 0.046070337812416255\n",
      "  batch 1001 loss: 0.022555350984912365\n",
      "LOSS train 0.022555350984912365 valid 3.904029130935669\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.0026537024974822997\n",
      "  batch 101 loss: 0.030072322770720347\n",
      "  batch 201 loss: 0.028797864923253657\n",
      "  batch 301 loss: 0.021240713614970444\n",
      "  batch 401 loss: 0.05456285352120176\n",
      "  batch 501 loss: 0.020174538511782886\n",
      "  batch 601 loss: 0.049293805435299876\n",
      "  batch 701 loss: 0.04637456163065508\n",
      "  batch 801 loss: 0.10933083762181922\n",
      "  batch 901 loss: 0.04514167544897646\n",
      "  batch 1001 loss: 0.02189752530306578\n",
      "LOSS train 0.02189752530306578 valid 3.970102310180664\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.004074451327323913\n",
      "  batch 101 loss: 0.03791709434590303\n",
      "  batch 201 loss: 0.03264639823697507\n",
      "  batch 301 loss: 0.020623429319821297\n",
      "  batch 401 loss: 0.051938195768743756\n",
      "  batch 501 loss: 0.021135413887677715\n",
      "  batch 601 loss: 0.045387565130367874\n",
      "  batch 701 loss: 0.04693284032400698\n",
      "  batch 801 loss: 0.10468348618829623\n",
      "  batch 901 loss: 0.038236470308620485\n",
      "  batch 1001 loss: 0.02373076921561733\n",
      "LOSS train 0.02373076921561733 valid 4.062802791595459\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.0062502151727676395\n",
      "  batch 101 loss: 0.0506941050075693\n",
      "  batch 201 loss: 0.034686076558427884\n",
      "  batch 301 loss: 0.020769965081708506\n",
      "  batch 401 loss: 0.05586354544619098\n",
      "  batch 501 loss: 0.021720378266181797\n",
      "  batch 601 loss: 0.04342364906799048\n",
      "  batch 701 loss: 0.04528171543264761\n",
      "  batch 801 loss: 0.09806088062934577\n",
      "  batch 901 loss: 0.04063363420311362\n",
      "  batch 1001 loss: 0.024669692376628517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.024669692376628517 valid 4.108790874481201\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.006849660873413086\n",
      "  batch 101 loss: 0.05434956596523989\n",
      "  batch 201 loss: 0.03596405640244484\n",
      "  batch 301 loss: 0.020881190734216945\n",
      "  batch 401 loss: 0.05591354054864496\n",
      "  batch 501 loss: 0.021894433656707405\n",
      "  batch 601 loss: 0.04198232606053352\n",
      "  batch 701 loss: 0.042780724633485076\n",
      "  batch 801 loss: 0.09104353792965413\n",
      "  batch 901 loss: 0.04356769630685449\n",
      "  batch 1001 loss: 0.02487525444244966\n",
      "LOSS train 0.02487525444244966 valid 4.06896448135376\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.005806527137756348\n",
      "  batch 101 loss: 0.0504627425695071\n",
      "  batch 201 loss: 0.036787798220757395\n",
      "  batch 301 loss: 0.021051961991470306\n",
      "  batch 401 loss: 0.055970871101599186\n",
      "  batch 501 loss: 0.022103378060273828\n",
      "  batch 601 loss: 0.04008748156484217\n",
      "  batch 701 loss: 0.04131142813013867\n",
      "  batch 801 loss: 0.08695968168554828\n",
      "  batch 901 loss: 0.04417190247215331\n",
      "  batch 1001 loss: 0.024940978598315268\n",
      "LOSS train 0.024940978598315268 valid 3.9861316680908203\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.5137705993652344\n",
      "  batch 101 loss: 4.43735745549202\n",
      "  batch 201 loss: 0.3127046289201826\n",
      "  batch 301 loss: 0.030870654811151324\n",
      "  batch 401 loss: 0.14138152114173863\n",
      "  batch 501 loss: 0.06537781770108268\n",
      "  batch 601 loss: 0.06913476602872834\n",
      "  batch 701 loss: 0.1017410723224748\n",
      "  batch 801 loss: 0.703521135346964\n",
      "  batch 901 loss: 0.13950162773486227\n",
      "  batch 1001 loss: 0.06430586218833924\n",
      "LOSS train 0.06430586218833924 valid 4.028796195983887\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0035979828238487245\n",
      "  batch 101 loss: 0.023860523472249043\n",
      "  batch 201 loss: 0.03995097983279265\n",
      "  batch 301 loss: 0.01684124751307536\n",
      "  batch 401 loss: 0.10841692039277405\n",
      "  batch 501 loss: 0.13040826612268575\n",
      "  batch 601 loss: 0.09548922301095444\n",
      "  batch 701 loss: 0.06405087725492194\n",
      "  batch 801 loss: 0.34928864347282795\n",
      "  batch 901 loss: 0.05739404879743233\n",
      "  batch 1001 loss: 0.03345171871056664\n",
      "LOSS train 0.03345171871056664 valid 4.274729251861572\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.008129480481147765\n",
      "  batch 101 loss: 0.022881265429023186\n",
      "  batch 201 loss: 0.025527256926870905\n",
      "  batch 301 loss: 0.010162742644315586\n",
      "  batch 401 loss: 0.08079424469469813\n",
      "  batch 501 loss: 0.12251746502355672\n",
      "  batch 601 loss: 0.09353971167991404\n",
      "  batch 701 loss: 0.03741136710013961\n",
      "  batch 801 loss: 0.19959510993794538\n",
      "  batch 901 loss: 0.04176790510769934\n",
      "  batch 1001 loss: 0.01709584893193096\n",
      "LOSS train 0.01709584893193096 valid 4.049323081970215\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.0032913345098495484\n",
      "  batch 101 loss: 0.014656715533055831\n",
      "  batch 201 loss: 0.0195863526003086\n",
      "  batch 301 loss: 0.008964810542092892\n",
      "  batch 401 loss: 0.04868524847726803\n",
      "  batch 501 loss: 0.06729974386980757\n",
      "  batch 601 loss: 0.060518444422341416\n",
      "  batch 701 loss: 0.0379970535292523\n",
      "  batch 801 loss: 0.21240517559024738\n",
      "  batch 901 loss: 0.05127509046345949\n",
      "  batch 1001 loss: 0.010041794571297941\n",
      "LOSS train 0.010041794571297941 valid 4.12492036819458\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.0034380629658699036\n",
      "  batch 101 loss: 0.018370031499362085\n",
      "  batch 201 loss: 0.015851535792462526\n",
      "  batch 301 loss: 0.010137371800810797\n",
      "  batch 401 loss: 0.050943029812478925\n",
      "  batch 501 loss: 0.018378137271502056\n",
      "  batch 601 loss: 0.010770615417131922\n",
      "  batch 701 loss: 0.025223462664216642\n",
      "  batch 801 loss: 0.17721811947354582\n",
      "  batch 901 loss: 0.06622231464134529\n",
      "  batch 1001 loss: 0.022213157156511443\n",
      "LOSS train 0.022213157156511443 valid 4.059914588928223\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.002079358249902725\n",
      "  batch 101 loss: 0.015089526702649892\n",
      "  batch 201 loss: 0.06571974574762862\n",
      "  batch 301 loss: 0.015408968245319557\n",
      "  batch 401 loss: 0.0354704929178115\n",
      "  batch 501 loss: 0.022041063485085034\n",
      "  batch 601 loss: 0.02667974013806088\n",
      "  batch 701 loss: 0.048060037187242416\n",
      "  batch 801 loss: 0.2546577439142857\n",
      "  batch 901 loss: 0.031138876543554943\n",
      "  batch 1001 loss: 0.017545181495370342\n",
      "LOSS train 0.017545181495370342 valid 3.6974689960479736\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.00207705557346344\n",
      "  batch 101 loss: 0.034956142406445\n",
      "  batch 201 loss: 0.030948493874748236\n",
      "  batch 301 loss: 0.009272921535302885\n",
      "  batch 401 loss: 0.013069679591571912\n",
      "  batch 501 loss: 0.021869808780320455\n",
      "  batch 601 loss: 0.08705764616606756\n",
      "  batch 701 loss: 0.035588988676900045\n",
      "  batch 801 loss: 0.17866564315976574\n",
      "  batch 901 loss: 0.03593711902271025\n",
      "  batch 1001 loss: 0.00959057731932262\n",
      "LOSS train 0.00959057731932262 valid 3.7922439575195312\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0037731757760047914\n",
      "  batch 101 loss: 0.03900746619969141\n",
      "  batch 201 loss: 0.016289133631507868\n",
      "  batch 301 loss: 0.005954828192334389\n",
      "  batch 401 loss: 0.0139577793047647\n",
      "  batch 501 loss: 0.036564424629032144\n",
      "  batch 601 loss: 0.07735624956199899\n",
      "  batch 701 loss: 0.019216151867294685\n",
      "  batch 801 loss: 0.12640167419682258\n",
      "  batch 901 loss: 0.050596336246235295\n",
      "  batch 1001 loss: 0.010341273557860403\n",
      "LOSS train 0.010341273557860403 valid 3.827697992324829\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.48900680541992186\n",
      "  batch 101 loss: 2.4245892530679702\n",
      "  batch 201 loss: 0.40753868330270054\n",
      "  batch 301 loss: 0.025602334996219726\n",
      "  batch 401 loss: 0.09524137541186065\n",
      "  batch 501 loss: 0.024191836731042714\n",
      "  batch 601 loss: 0.036852612914517524\n",
      "  batch 701 loss: 0.04418576398747973\n",
      "  batch 801 loss: 0.2621915188699495\n",
      "  batch 901 loss: 0.04562277577351779\n",
      "  batch 1001 loss: 0.08158206688589416\n",
      "LOSS train 0.08158206688589416 valid 4.563438415527344\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.02170133113861084\n",
      "  batch 101 loss: 0.13981661439756862\n",
      "  batch 201 loss: 0.050181081106420604\n",
      "  batch 301 loss: 0.03958012197166681\n",
      "  batch 401 loss: 0.15893157684709877\n",
      "  batch 501 loss: 0.06826722524128855\n",
      "  batch 601 loss: 0.12067239166703075\n",
      "  batch 701 loss: 0.07271258723922074\n",
      "  batch 801 loss: 0.2606749215896707\n",
      "  batch 901 loss: 0.19664772777818143\n",
      "  batch 1001 loss: 0.051348607679829\n",
      "LOSS train 0.051348607679829 valid 3.8312160968780518\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.00411141037940979\n",
      "  batch 101 loss: 0.0721615979897615\n",
      "  batch 201 loss: 0.07601641326677054\n",
      "  batch 301 loss: 0.04172222585155396\n",
      "  batch 401 loss: 0.1652541045937687\n",
      "  batch 501 loss: 0.06958726016804576\n",
      "  batch 601 loss: 0.04888753889594227\n",
      "  batch 701 loss: 0.08442264896235428\n",
      "  batch 801 loss: 0.3641016276273876\n",
      "  batch 901 loss: 0.08001987196039409\n",
      "  batch 1001 loss: 0.04837846306880238\n",
      "LOSS train 0.04837846306880238 valid 3.621877431869507\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.0005709905177354813\n",
      "  batch 101 loss: 0.052909567575406984\n",
      "  batch 201 loss: 0.08308507344219834\n",
      "  batch 301 loss: 0.07650478021882008\n",
      "  batch 401 loss: 0.21895509571302682\n",
      "  batch 501 loss: 0.0775678171031177\n",
      "  batch 601 loss: 0.04971461069071666\n",
      "  batch 701 loss: 0.08667565292154905\n",
      "  batch 801 loss: 0.34853775086812677\n",
      "  batch 901 loss: 0.07630757920444012\n",
      "  batch 1001 loss: 0.08449022177432199\n",
      "LOSS train 0.08449022177432199 valid 3.939154863357544\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.005020277500152588\n",
      "  batch 101 loss: 0.07986937886744272\n",
      "  batch 201 loss: 0.08258574928622693\n",
      "  batch 301 loss: 0.0668373362114653\n",
      "  batch 401 loss: 0.19901560834608972\n",
      "  batch 501 loss: 0.07423641260713339\n",
      "  batch 601 loss: 0.050466299187392\n",
      "  batch 701 loss: 0.08877028047165368\n",
      "  batch 801 loss: 0.3279926712717861\n",
      "  batch 901 loss: 0.09997780303005128\n",
      "  batch 1001 loss: 0.08001205515232869\n",
      "LOSS train 0.08001205515232869 valid 4.081973075866699\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.004755748510360718\n",
      "  batch 101 loss: 0.08287025084951892\n",
      "  batch 201 loss: 0.08235091809183359\n",
      "  batch 301 loss: 0.06684953912743367\n",
      "  batch 401 loss: 0.19931972494814545\n",
      "  batch 501 loss: 0.07456964332144707\n",
      "  batch 601 loss: 0.050750827556475996\n",
      "  batch 701 loss: 0.08812407373421592\n",
      "  batch 801 loss: 0.30841800284571946\n",
      "  batch 901 loss: 0.12643747955095022\n",
      "  batch 1001 loss: 0.08922326352214441\n",
      "LOSS train 0.08922326352214441 valid 4.219370365142822\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.004554665386676788\n",
      "  batch 101 loss: 0.07820983993064147\n",
      "  batch 201 loss: 0.08273019566899166\n",
      "  batch 301 loss: 0.06697717463830485\n",
      "  batch 401 loss: 0.1966393958288245\n",
      "  batch 501 loss: 0.07450193766970187\n",
      "  batch 601 loss: 0.05073179145809263\n",
      "  batch 701 loss: 0.08749831608613022\n",
      "  batch 801 loss: 0.2978726161271334\n",
      "  batch 901 loss: 0.15068442008458077\n",
      "  batch 1001 loss: 0.08449962634476833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.08449962634476833 valid 4.34503173828125\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0051615524291992185\n",
      "  batch 101 loss: 0.07646693438640796\n",
      "  batch 201 loss: 0.08229106021812185\n",
      "  batch 301 loss: 0.06568094410467892\n",
      "  batch 401 loss: 0.1953231842396781\n",
      "  batch 501 loss: 0.07440745685016736\n",
      "  batch 601 loss: 0.05078942950349301\n",
      "  batch 701 loss: 0.08750015011319193\n",
      "  batch 801 loss: 0.2907425358449109\n",
      "  batch 901 loss: 0.15639740461483598\n",
      "  batch 1001 loss: 0.08014746369677596\n",
      "LOSS train 0.08014746369677596 valid 4.319479465484619\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.461282958984375\n",
      "  batch 101 loss: 16.34450750157237\n",
      "  batch 201 loss: 0.2144525778386742\n",
      "  batch 301 loss: 0.04063709376845509\n",
      "  batch 401 loss: 0.30678221189882604\n",
      "  batch 501 loss: 0.09405938786105253\n",
      "  batch 601 loss: 0.07230133591074264\n",
      "  batch 701 loss: 0.1472294491302455\n",
      "  batch 801 loss: 0.33352535967016594\n",
      "  batch 901 loss: 0.19279743898659946\n",
      "  batch 1001 loss: 0.05386129686259664\n",
      "LOSS train 0.05386129686259664 valid 3.610919237136841\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.00028975050896406173\n",
      "  batch 101 loss: 0.024578083016967865\n",
      "  batch 201 loss: 0.04425025999895297\n",
      "  batch 301 loss: 0.011449615718447603\n",
      "  batch 401 loss: 0.21212375776609405\n",
      "  batch 501 loss: 0.03609919840004295\n",
      "  batch 601 loss: 0.03691148932266515\n",
      "  batch 701 loss: 0.016694242347730325\n",
      "  batch 801 loss: 0.3884453460853547\n",
      "  batch 901 loss: 0.04774205801775679\n",
      "  batch 1001 loss: 0.02455358936887933\n",
      "LOSS train 0.02455358936887933 valid 3.6648521423339844\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.0009990672767162324\n",
      "  batch 101 loss: 0.06069035373395309\n",
      "  batch 201 loss: 0.06720437755808234\n",
      "  batch 301 loss: 0.03191572296054801\n",
      "  batch 401 loss: 0.1582511300203623\n",
      "  batch 501 loss: 0.032812977312132716\n",
      "  batch 601 loss: 0.018883967302390375\n",
      "  batch 701 loss: 0.030137908242686536\n",
      "  batch 801 loss: 0.4996985806245357\n",
      "  batch 901 loss: 0.17031119617051446\n",
      "  batch 1001 loss: 0.027305831815174316\n",
      "LOSS train 0.027305831815174316 valid 3.835461378097534\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.005524499416351318\n",
      "  batch 101 loss: 0.05438091990654357\n",
      "  batch 201 loss: 0.04230751474853605\n",
      "  batch 301 loss: 0.009852932175272144\n",
      "  batch 401 loss: 0.42055056055716705\n",
      "  batch 501 loss: 0.15538169183768333\n",
      "  batch 601 loss: 0.04172436839900911\n",
      "  batch 701 loss: 0.11222952855372569\n",
      "  batch 801 loss: 0.2703281113621779\n",
      "  batch 901 loss: 0.1419794308487326\n",
      "  batch 1001 loss: 0.042993000308051706\n",
      "LOSS train 0.042993000308051706 valid 4.0844879150390625\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.009222902059555053\n",
      "  batch 101 loss: 0.11010063302892377\n",
      "  batch 201 loss: 0.08624424389796331\n",
      "  batch 301 loss: 0.02434189210209297\n",
      "  batch 401 loss: 0.1125372551975306\n",
      "  batch 501 loss: 0.07094453404148225\n",
      "  batch 601 loss: 0.041804931261576715\n",
      "  batch 701 loss: 0.09018036043678876\n",
      "  batch 801 loss: 0.3705480155721307\n",
      "  batch 901 loss: 0.1085767648066394\n",
      "  batch 1001 loss: 0.027792412503622473\n",
      "LOSS train 0.027792412503622473 valid 3.8441379070281982\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.005947936177253723\n",
      "  batch 101 loss: 0.08267727321333951\n",
      "  batch 201 loss: 0.05733428924228065\n",
      "  batch 301 loss: 0.020744765299023128\n",
      "  batch 401 loss: 0.09243402420164784\n",
      "  batch 501 loss: 0.05420959990238771\n",
      "  batch 601 loss: 0.0406158964545466\n",
      "  batch 701 loss: 0.07628868868094286\n",
      "  batch 801 loss: 0.2972288439236581\n",
      "  batch 901 loss: 0.07598994541796855\n",
      "  batch 1001 loss: 0.02271230789134279\n",
      "LOSS train 0.02271230789134279 valid 3.610290050506592\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.0013990765810012818\n",
      "  batch 101 loss: 0.04316153376857983\n",
      "  batch 201 loss: 0.055621241962653584\n",
      "  batch 301 loss: 0.01996512027166318\n",
      "  batch 401 loss: 0.08618233286833857\n",
      "  batch 501 loss: 0.039886785360140495\n",
      "  batch 601 loss: 0.04341746352263726\n",
      "  batch 701 loss: 0.05899309920263476\n",
      "  batch 801 loss: 0.25689129628939555\n",
      "  batch 901 loss: 0.06321161903906614\n",
      "  batch 1001 loss: 0.023824261144036428\n",
      "LOSS train 0.023824261144036428 valid 3.5504021644592285\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.0006512959301471711\n",
      "  batch 101 loss: 0.03852957459166646\n",
      "  batch 201 loss: 0.05980628039105795\n",
      "  batch 301 loss: 0.02084282217809232\n",
      "  batch 401 loss: 0.08930568754498382\n",
      "  batch 501 loss: 0.04026640967633284\n",
      "  batch 601 loss: 0.0462413064998691\n",
      "  batch 701 loss: 0.05822460182302166\n",
      "  batch 801 loss: 0.25325393928214907\n",
      "  batch 901 loss: 0.05680414812755771\n",
      "  batch 1001 loss: 0.047832760255842\n",
      "LOSS train 0.047832760255842 valid 3.551586389541626\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.48159740447998045\n",
      "  batch 101 loss: 3.253736540656537\n",
      "  batch 201 loss: 0.08660455694887786\n",
      "  batch 301 loss: 0.04961621948517859\n",
      "  batch 401 loss: 0.7290671245008707\n",
      "  batch 501 loss: 1.2631240363791585\n",
      "  batch 601 loss: 0.17988979041576386\n",
      "  batch 701 loss: 0.10916178652085363\n",
      "  batch 801 loss: 0.2401150441612117\n",
      "  batch 901 loss: 0.5381892738305032\n",
      "  batch 1001 loss: 0.11381207057042048\n",
      "LOSS train 0.11381207057042048 valid 4.1639404296875\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.0184479558467865\n",
      "  batch 101 loss: 0.22992304330691696\n",
      "  batch 201 loss: 0.14723665659315885\n",
      "  batch 301 loss: 0.19877615382662042\n",
      "  batch 401 loss: 0.11157756762811914\n",
      "  batch 501 loss: 0.052413411580491814\n",
      "  batch 601 loss: 0.06952704028459265\n",
      "  batch 701 loss: 0.2932721405895427\n",
      "  batch 801 loss: 2.5855186012387277\n",
      "  batch 901 loss: 0.7540862323250621\n",
      "  batch 1001 loss: 0.14163686907850206\n",
      "LOSS train 0.14163686907850206 valid 7.221835136413574\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.002286727428436279\n",
      "  batch 101 loss: 0.06194053460145369\n",
      "  batch 201 loss: 0.6531157729658298\n",
      "  batch 301 loss: 0.19473300011828543\n",
      "  batch 401 loss: 0.17223102196352558\n",
      "  batch 501 loss: 0.22105124540627002\n",
      "  batch 601 loss: 0.0729156642430462\n",
      "  batch 701 loss: 0.531617076061666\n",
      "  batch 801 loss: 3.032619686871767\n",
      "  batch 901 loss: 6.8066887360811235\n",
      "  batch 1001 loss: 1.7682527385558933\n",
      "LOSS train 1.7682527385558933 valid 54.17569351196289\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.7326599884033204\n",
      "  batch 101 loss: 3.417513580862433\n",
      "  batch 201 loss: 0.2635904813930392\n",
      "  batch 301 loss: 0.5037837370252237\n",
      "  batch 401 loss: 1.5558688586205245\n",
      "  batch 501 loss: 0.38490429749712346\n",
      "  batch 601 loss: 0.5723261267901398\n",
      "  batch 701 loss: 0.3245387952029705\n",
      "  batch 801 loss: 0.8773557084612549\n",
      "  batch 901 loss: 3.9373666440322994\n",
      "  batch 1001 loss: 0.7730714508332313\n",
      "LOSS train 0.7730714508332313 valid 9.529199600219727\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.0029333728551864625\n",
      "  batch 101 loss: 0.252189987055026\n",
      "  batch 201 loss: 0.31309980812482535\n",
      "  batch 301 loss: 0.7360926087200642\n",
      "  batch 401 loss: 0.35178169986698776\n",
      "  batch 501 loss: 0.06843507875222712\n",
      "  batch 601 loss: 0.7267640078481054\n",
      "  batch 701 loss: 0.39673743593506516\n",
      "  batch 801 loss: 3.66338216137141\n",
      "  batch 901 loss: 1.42357481604442\n",
      "  batch 1001 loss: 0.5294442440755666\n",
      "LOSS train 0.5294442440755666 valid 6.344390392303467\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.008619963526725768\n",
      "  batch 101 loss: 1.1332737354468554\n",
      "  batch 201 loss: 0.29672115644440056\n",
      "  batch 301 loss: 1.4036945507396013\n",
      "  batch 401 loss: 0.5293013799097389\n",
      "  batch 501 loss: 1.0303783676121383\n",
      "  batch 601 loss: 1.4987658111937343\n",
      "  batch 701 loss: 0.4446247139107436\n",
      "  batch 801 loss: 1.0879138405807316\n",
      "  batch 901 loss: 0.8362010714784265\n",
      "  batch 1001 loss: 0.7091217489074916\n",
      "LOSS train 0.7091217489074916 valid 7.006083965301514\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.09503058433532714\n",
      "  batch 101 loss: 2.049604087732732\n",
      "  batch 201 loss: 1.8459791977703572\n",
      "  batch 301 loss: 0.7461808691453189\n",
      "  batch 401 loss: 0.9486006220337003\n",
      "  batch 501 loss: 0.27311651640571655\n",
      "  batch 601 loss: 0.6383775861514732\n",
      "  batch 701 loss: 0.5255080216657371\n",
      "  batch 801 loss: 0.6740853402810171\n",
      "  batch 901 loss: 0.9247371251625008\n",
      "  batch 1001 loss: 1.689343167860061\n",
      "LOSS train 1.689343167860061 valid 7.563069820404053\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.05151388168334961\n",
      "  batch 101 loss: 0.35767392566427586\n",
      "  batch 201 loss: 0.7046347029833123\n",
      "  batch 301 loss: 3.605729138813913\n",
      "  batch 401 loss: 1.3512084595812484\n",
      "  batch 501 loss: 0.29141153453849256\n",
      "  batch 601 loss: 0.1498233885038644\n",
      "  batch 701 loss: 0.1398014277080074\n",
      "  batch 801 loss: 1.877197231836617\n",
      "  batch 901 loss: 0.7609903519228101\n",
      "  batch 1001 loss: 0.12250949547160417\n",
      "LOSS train 0.12250949547160417 valid 8.295000076293945\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.4570319366455078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 101 loss: 11797.539998268187\n",
      "  batch 201 loss: 3.155270057916641\n",
      "  batch 301 loss: 2.2347846746444704\n",
      "  batch 401 loss: 3.0615558081865313\n",
      "  batch 501 loss: 2.8165529322624208\n",
      "  batch 601 loss: 2.5018982595205306\n",
      "  batch 701 loss: 3.0428545480966567\n",
      "  batch 801 loss: 3.0837019479274748\n",
      "  batch 901 loss: 3.867468537092209\n",
      "  batch 1001 loss: 2.550157918334007\n",
      "LOSS train 2.550157918334007 valid 3.003542184829712\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.023484544754028322\n",
      "  batch 101 loss: 2.4897468596696855\n",
      "  batch 201 loss: 3.25125117123127\n",
      "  batch 301 loss: 2.3117117935419085\n",
      "  batch 401 loss: 2.84400160074234\n",
      "  batch 501 loss: 2.774747458100319\n",
      "  batch 601 loss: 2.4203374713659285\n",
      "  batch 701 loss: 2.913242597579956\n",
      "  batch 801 loss: 3.0277395260334017\n",
      "  batch 901 loss: 3.7772894102334975\n",
      "  batch 1001 loss: 2.581390620470047\n",
      "LOSS train 2.581390620470047 valid 3.316047430038452\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.022427020072937013\n",
      "  batch 101 loss: 2.5467533761262895\n",
      "  batch 201 loss: 3.3229398602247238\n",
      "  batch 301 loss: 2.3490335857868194\n",
      "  batch 401 loss: 2.9671621030569075\n",
      "  batch 501 loss: 2.8528005731105806\n",
      "  batch 601 loss: 2.5591288858652117\n",
      "  batch 701 loss: 3.0166102385520936\n",
      "  batch 801 loss: 3.1724352633953092\n",
      "  batch 901 loss: 3.9012988448143004\n",
      "  batch 1001 loss: 2.672252840399742\n",
      "LOSS train 2.672252840399742 valid 2.9376533031463623\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.024785144329071043\n",
      "  batch 101 loss: 2.6695288395881653\n",
      "  batch 201 loss: 3.41593100130558\n",
      "  batch 301 loss: 2.4374663215875625\n",
      "  batch 401 loss: 3.091661214828491\n",
      "  batch 501 loss: 2.9589002358913423\n",
      "  batch 601 loss: 2.633278402686119\n",
      "  batch 701 loss: 3.1589797323942186\n",
      "  batch 801 loss: 3.2436557006835938\n",
      "  batch 901 loss: 4.037862368822098\n",
      "  batch 1001 loss: 2.740455234646797\n",
      "LOSS train 2.740455234646797 valid 2.9544715881347656\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.028692352771759033\n",
      "  batch 101 loss: 2.721286609172821\n",
      "  batch 201 loss: 3.533677251338959\n",
      "  batch 301 loss: 2.4884959149360655\n",
      "  batch 401 loss: 3.1942392760515212\n",
      "  batch 501 loss: 3.048388190865517\n",
      "  batch 601 loss: 2.7139594888687135\n",
      "  batch 701 loss: 3.3060717940330506\n",
      "  batch 801 loss: 3.269418524503708\n",
      "  batch 901 loss: 4.202992327213288\n",
      "  batch 1001 loss: 2.7791413205862043\n",
      "LOSS train 2.7791413205862043 valid 3.090531826019287\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.03286762475967407\n",
      "  batch 101 loss: 2.750198702812195\n",
      "  batch 201 loss: 3.663228964805603\n",
      "  batch 301 loss: 2.5096333628892897\n",
      "  batch 401 loss: 3.3026440244913102\n",
      "  batch 501 loss: 3.109033328294754\n",
      "  batch 601 loss: 2.7983729135990143\n",
      "  batch 701 loss: 3.4266685461997985\n",
      "  batch 801 loss: 3.292165752053261\n",
      "  batch 901 loss: 4.334016125202179\n",
      "  batch 1001 loss: 2.801272928714752\n",
      "LOSS train 2.801272928714752 valid 3.269556760787964\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.03684614896774292\n",
      "  batch 101 loss: 2.7742790567874906\n",
      "  batch 201 loss: 3.749500725865364\n",
      "  batch 301 loss: 2.5191258919239043\n",
      "  batch 401 loss: 3.373776088356972\n",
      "  batch 501 loss: 3.1375724625587464\n",
      "  batch 601 loss: 2.8483562219142913\n",
      "  batch 701 loss: 3.485354177951813\n",
      "  batch 801 loss: 3.3052857542037963\n",
      "  batch 901 loss: 4.386872088909149\n",
      "  batch 1001 loss: 2.8086351096630096\n",
      "LOSS train 2.8086351096630096 valid 3.344008207321167\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.03832515239715576\n",
      "  batch 101 loss: 2.782509282231331\n",
      "  batch 201 loss: 3.769948430657387\n",
      "  batch 301 loss: 2.520437422990799\n",
      "  batch 401 loss: 3.3836789393424986\n",
      "  batch 501 loss: 3.138929325342178\n",
      "  batch 601 loss: 2.8488393592834473\n",
      "  batch 701 loss: 3.476554526686668\n",
      "  batch 801 loss: 3.3013287234306334\n",
      "  batch 901 loss: 4.364979763031005\n",
      "  batch 1001 loss: 2.802477396726608\n",
      "LOSS train 2.802477396726608 valid 3.2683255672454834\n",
      "EPOCH 1:\n",
      "  batch 1 loss: 0.515582046508789\n",
      "  batch 101 loss: 44.67173801422119\n",
      "  batch 201 loss: 1.594906390691176\n",
      "  batch 301 loss: 3.49387289583683\n",
      "  batch 401 loss: 3.285376684749499\n",
      "  batch 501 loss: 0.5869953097868711\n",
      "  batch 601 loss: 3.894331332333386\n",
      "  batch 701 loss: 1.4917724863393231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-185:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "    self._run()\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 773, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "PermissionError: [Errno 13] Permission denied: b'trained_models/sl_20230613_165450\\\\events.out.tfevents.1686668090.SET-L-ME-T20003.21632.180'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 801 loss: 13.80372010976076\n",
      "  batch 901 loss: 10.262496636509896\n",
      "  batch 1001 loss: 3.6587807289883494\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'trained_models/sl_20230613_165450\\\\events.out.tfevents.1686668090.SET-L-ME-T20003.21632.180'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m m \u001b[38;5;241m=\u001b[39m m_d[m_name]\n\u001b[0;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m---> 17\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_multiple_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m m(te_in\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     20\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m loss_fn(test_predictions,te_out)\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\JointResearch2023_new\\JointResearch\\05. Models\\03.ANN_CostEstimator_For_LB\\training_methods.py:74\u001b[0m, in \u001b[0;36mtrain_multiple_epochs\u001b[1;34m(nb_epochs, model, training_loader, validation_loader, loss_fn, optimizer, model_name, save_trained)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[0;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 74\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m running_vloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# statistics for batch normalization.\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\JointResearch2023_new\\JointResearch\\05. Models\\03.ANN_CostEstimator_For_LB\\training_methods.py:57\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, training_loader, epoch_index, tb_writer, optimizer, loss_fn, f_print)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  batch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, last_loss))\n\u001b[0;32m     56\u001b[0m         tb_x \u001b[38;5;241m=\u001b[39m epoch_index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(training_loader) \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 57\u001b[0m         \u001b[43mtb_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoss/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m         running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_loss\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:391\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[0;32m    386\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[0;32m    388\u001b[0m summary \u001b[38;5;241m=\u001b[39m scalar(\n\u001b[0;32m    389\u001b[0m     tag, scalar_value, new_style\u001b[38;5;241m=\u001b[39mnew_style, double_precision\u001b[38;5;241m=\u001b[39mdouble_precision\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:113\u001b[0m, in \u001b[0;36mFileWriter.add_summary\u001b[1;34m(self, summary, global_step, walltime)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"Adds a `Summary` protocol buffer to the event file.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03mThis method wraps the provided summary in an `Event` protocol buffer\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03mand adds it to the event file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    walltime (from time.time()) seconds after epoch\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m event \u001b[38;5;241m=\u001b[39m event_pb2\u001b[38;5;241m.\u001b[39mEvent(summary\u001b[38;5;241m=\u001b[39msummary)\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:98\u001b[0m, in \u001b[0;36mFileWriter.add_event\u001b[1;34m(self, event, step, walltime)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Make sure step is converted from numpy or other formats\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# since protobuf might not convert depending on version\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     event\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(step)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:117\u001b[0m, in \u001b[0;36mEventFileWriter.add_event\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, event_pb2\u001b[38;5;241m.\u001b[39mEvent):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an event_pb2.Event proto, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(event)\n\u001b[0;32m    116\u001b[0m     )\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:171\u001b[0m, in \u001b[0;36m_AsyncWriter.write\u001b[1;34m(self, bytestring)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"Enqueue the given bytes to be written asychronously.\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Status of the worker should be checked under the lock to avoid\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# multiple threads passing the check and then switching just before\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# blocking on putting to the queue which might result in a deadlock.\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_worker_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriter is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:212\u001b[0m, in \u001b[0;36m_AsyncWriter._check_worker_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker\u001b[38;5;241m.\u001b[39mexception\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\threading.py:1016\u001b[0m, in \u001b[0;36mThread._bootstrap_inner\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     _sys\u001b[38;5;241m.\u001b[39msetprofile(_profile_hook)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1016\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_excepthook(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:244\u001b[0m, in \u001b[0;36m_AsyncWriterThread.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:275\u001b[0m, in \u001b[0;36m_AsyncWriterThread._run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_signal:\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_pending_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py:40\u001b[0m, in \u001b[0;36mRecordWriter.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     38\u001b[0m header_crc \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, masked_crc32c(header))\n\u001b[0;32m     39\u001b[0m footer_crc \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, masked_crc32c(data))\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheader_crc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfooter_crc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:773\u001b[0m, in \u001b[0;36mGFile.write\u001b[1;34m(self, file_content)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m         \u001b[38;5;66;03m# append the later chunks\u001b[39;00m\n\u001b[1;32m--> 773\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;66;03m# add to temp file, but wait for flush to write to final filesystem\u001b[39;00m\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_temp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:167\u001b[0m, in \u001b[0;36mLocalFileSystem.append\u001b[1;34m(self, filename, file_content, binary_mode)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, file_content, binary_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;124;03m\"\"\"Append string file contents to a file.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m        binary_mode: bool, write as binary if True, otherwise text\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mab\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbinary_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:171\u001b[0m, in \u001b[0;36mLocalFileSystem._write\u001b[1;34m(self, filename, file_content, mode)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, file_content, mode):\n\u001b[0;32m    170\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    172\u001b[0m         compatify \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_bytes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;28;01melse\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mas_text\n\u001b[0;32m    173\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(compatify(file_content))\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'trained_models/sl_20230613_165450\\\\events.out.tfevents.1686668090.SET-L-ME-T20003.21632.180'"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01*4**i for i in range(4)]\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "nbs_e = [2,4,8]\n",
    "i=0\n",
    "results = pd.DataFrame()\n",
    "for nb_e in nbs_e:\n",
    "    for lr in learning_rates:\n",
    "        m_d = dict()\n",
    "\n",
    "        m_d[\"sl\"] = NN_classes.ObjectiveEstimator_ANN_Single_layer(input_size=tr_in.shape[1],output_size=1)\n",
    "        m_d[\"3h\"] = NN_classes.ObjectiveEstimator_ANN_3hidden_layer(input_size=tr_in.shape[1],hidden_size1=int(tr_in.shape[1]/4),hidden_size2=int(tr_in.shape[1]/16),hidden_size3=int(tr_in.shape[1]/64),output_size=1)\n",
    "\n",
    "\n",
    "        for m_name in m_d:\n",
    "            m = m_d[m_name]\n",
    "            optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "            train_loss = training_methods.train_multiple_epochs(nb_e,m,training_loader,validation_loader,loss_fn,optimizer,m_name)\n",
    "            \n",
    "            test_predictions = m(te_in.float())\n",
    "            test_loss = loss_fn(test_predictions,te_out)\n",
    "            train_predictions = m(tr_in.float())\n",
    "            train_loss = loss_fn(train_predictions,tr_out)\n",
    "            \n",
    "            r = pd.DataFrame({\"Model\": m_name,\"Epochs\": nb_e,\"Lr\":lr, \"Tr_l\":train_loss.item(),\"Te_l\":test_loss.item()},index = [i]\n",
    "            )\n",
    "            i+=1\n",
    "            results = pd.concat([results,r])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f42359f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>3h</th>\n",
       "      <th>sl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.800205</td>\n",
       "      <td>11.384189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.640344</td>\n",
       "      <td>15.935939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.490673</td>\n",
       "      <td>12.699363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model         3h         sl\n",
       "Epochs                     \n",
       "2       4.800205  11.384189\n",
       "4       5.640344  15.935939\n",
       "8       7.490673  12.699363"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"Model\"\n",
    "val = \"Te_l\"\n",
    "index = \"Epochs\"\n",
    "lr = 0.16\n",
    "lr_filter = results[\"Lr\"]== lr\n",
    "results_p = pd.pivot_table(results[lr_filter],index = index,columns =col,values = val)\n",
    "results_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "96174606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Epochs'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGwCAYAAAAJ/wd3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEYklEQVR4nO3deXxU1f3/8ddkJQlJWEMSSSDsCQJuqCwuFAXDEhTcEBDBWhcUlW9dALVqVcRWpa0VS39WUVSssohQUKSC4gaICJUAYRXZwprJQkKSub8/TjIhEiCByb2T5P18PM4DZu4k+TC1zJtzzj0fl2VZFiIiIiI2CXC6ABEREalbFD5ERETEVgofIiIiYiuFDxEREbGVwoeIiIjYSuFDREREbKXwISIiIrYKcrqAX/N4POzevZvIyEhcLpfT5YiIiEglWJZFdnY28fHxBAScem7D78LH7t27SUhIcLoMEREROQM7d+6kefPmp3yN34WPyMhIwBQfFRXlcDUiIiJSGW63m4SEBO/n+Kn4XfgoXWqJiopS+BAREalhKrNlQhtORURExFYKHyIiImIrhQ8RERGxld/t+RAREfFXxcXFFBYWOl2GY4KDgwkMDDzr76PwISIichqWZbF3716OHDnidCmOa9CgAbGxsWd1FpfCh4iIyGmUBo+YmBjCw8Pr5CGYlmWRl5dHZmYmAHFxcWf8vRQ+RERETqG4uNgbPBo3bux0OY4KCwsDIDMzk5iYmDNegtGGUxERkVMo3eMRHh7ucCX+ofR9OJu9L1UOH1988QUDBw4kPj4el8vF3LlzT3hNeno6aWlpREdHExkZyaWXXsrPP/98xkWKiIg4rS4utVTEF+9DlcNHbm4uXbp04ZVXXqnw+pYtW+jZsycdOnRg6dKl/Pjjjzz++OPUq1fvrIsVERGRmq/Kez5SU1NJTU096fWJEyfSr18/XnjhBe9zrVq1OrPqREREpNbx6Z4Pj8fDggULaNeuHX379iUmJoZLLrmkwqWZUgUFBbjd7nJDRERETm/p0qW4XK4q3QLcsmVLpkyZUm01VYZPw0dmZiY5OTk8//zzXHPNNXz66adcd911DB48mGXLllX4NZMmTSI6Oto7EhISfFmSSPWzLDh6xOkqRMQP3XbbbbhcLu66664Trt1zzz24XC5uu+02+wtzmM9nPgAGDRrEgw8+yHnnncejjz7KgAEDeO211yr8mvHjx5OVleUdO3fu9GVJItWrIAfeuQEmt4BpV8KXL8HBLU5XJSJ+JCEhgZkzZ3L06FHvc/n5+bz33nskJiY6WJlzfBo+mjRpQlBQECkpKeWeT05OPundLqGhoURFRZUbIjVC7kF4Kw02LzaPd/8AS56Cv10Ar3aHpc9DZrqZGRGROuuCCy4gMTGR2bNne5+bPXs2CQkJnH/++d7nCgoKGDt2LDExMdSrV4+ePXuycuXKct/rP//5D+3atSMsLIxevXqxffv2E37e119/zeWXX05YWBgJCQmMHTuW3NzcavvznQmfho+QkBC6du3Kxo0byz2/adMmWrRo4csfJeKsIzvhX31h1/cQ1hCGzYIBL0OrXuAKhMyfYOkkePVSeKUrLHkadq9REBGpo0aNGsUbb7zhffyvf/2L0aNHl3vNww8/zKxZs5g+fTqrV6+mTZs29O3bl0OHDgGwc+dOBg8eTL9+/VizZg2//e1vefTRR8t9j3Xr1tG3b18GDx7M2rVref/991m+fDn33ntv9f8hq6DKd7vk5OSwefNm7+Nt27axZs0aGjVqRGJiIg899BA33XQTl19+Ob169WLRokV8/PHHLF261Jd1izgncwPMGAzuXRB1DoyYA03bm2sXjYa8Q7DxP7B+Hmz9HA5mwJcvmtGgBSQPhJRr4ZwLIUDn/InUBSNGjGD8+PFs374dl8vFV199xcyZM72fjbm5uUydOpU333zTe0fpP//5TxYvXszrr7/OQw89xNSpU2nVqhUvv/wyLpeL9u3bs27dOiZPnuz9OX/605+45ZZbeOCBBwBo27Ytf/3rX7niiiuYOnWq3xx7UeXwsWrVKnr16uV9PG7cOABGjhzJm2++yXXXXcdrr73GpEmTGDt2LO3bt2fWrFn07NnTd1WLOGXnCnj3Rjh6GJq0hxGzIbp5+deEN4Lzh5uR74ZNn0D6R5DxGRzZAd+8YkZkfEkQSYPEbhBw9p0iRcQ/NWnShP79+zN9+nQsy6J///40adLEe33Lli0UFhbSo0cP73PBwcFcfPHFpKenA+YAz0svvbTcIV/dunUr93O+//57Nm/ezDvvvON9zrIsPB4P27ZtIzk5ubr+iFVS5fBx5ZVXYp1m6nj06NEnTCeJ1HgZi+Hft0JhHpxzEQz7wASNU6kXBZ1vMONYLmz+DNZ/ZAJJ9m5Y8Q8zIppCh/6QMghaXgaBwfb8mUTENqNHj/Yuf/z9738vd630c/XXp4daluV97nSfvWBu/LjzzjsZO3bsCdf8aXOrGsuJVMbaf8Pcu8FTBK17w01vQ0hE1b5HSIQJFymDoDDfLMmsnwcbF0Dufvj+TTPqNTBBJDkNWveCoNBq+AOJiN2uueYajh07BkDfvn3LXWvTpg0hISEsX76cW265BTC9U1atWuVdQklJSTnh3Kxvv/223OMLLriAn376iTZt2lTPH8JHFD5ETufbqbCoZFNXpxtg0KsQFHJ23zO4HrRPNaO4ELZ9YWZENiyAvAOw5h0zQiKhXV8TWNpcBSFqbCVSUwUGBnqXUH7dDTYiIoK7776bhx56yLuH8oUXXiAvL4/bb78dgLvuuosXX3yRcePGceedd/L999/z5ptvlvs+jzzyCJdeeiljxozhjjvuICIigvT0dBYvXszf/vY3W/6claHwIXIylgX//aPZKApwyV3Qd5LvN4kGBkOb3mYMeBl2fA3p8yD9Y8jeA//70IzgcBNAUgZB2z5mSUdEapRTHSfx/PPP4/F4GDFiBNnZ2Vx00UV88sknNGzYEDDLJrNmzeLBBx/k1Vdf5eKLL+a5554rt82hc+fOLFu2jIkTJ3LZZZdhWRatW7fmpptuqvY/W1W4rMosItnI7XYTHR1NVlaWzvwQ5xQXwYIHYfVb5vFvHofL/g/s7Grp8cCuVWZGZP08yDrurJzAEGj9GxNE2qea231FpFrk5+ezbds2kpKS/OZuESed7P2oyue3Zj5Efq0wH2bdDhvmgyvAzEZceJv9dQQEQMLFZvR5BvasMSEkfR4c3AybFpkREARJl5s9Ih0GQP2m9tcqIlIFCh8ix8vPgvdugR3LITAUhvw/cyus01wuiD/fjN5PmJNT139kgkjmetjyXzMWjIPE7mZGJHkARMU7XbmIyAkUPkRKZe+DGUNg3zqz0XPoe5B0mdNVncjlgmYpZvQaDwc2m3NE1s8zsyM7lpux8CFofrEJT8lp0FCnDIuIf1D4EAE4tBXevg4ObzdnbgyfBXFdnK6qcpq0MftRLvs/U3/6xyaI/LKibHz6mPnzpAyC5EHma0REHKLwIbJnrZnxyM00x5+PmAONWztd1Zlp2BK632eGezekzzdLMzu+gj0/mrHkaYhJMbMhKWnm93ZupBWROk/hQ+q27cvhvaFQ4IZm55oZj8hYp6vyjah4uOR3ZuTsNxto0+eZM0Uy15ux7Hlo1Lrk8LM0iDtPQUREqp3Ch9Rd6fPhw9FQXGA2aQ59D8IaOF1V9ajfFC4aZUbeIXOXzPp5ZpPqoS2w/CUzGiSaGZHkNGjeVY3vRKRaKHxI3bT6Lfj4frA80L4/XP86BIc5XZU9whvBebeYke+GjE/NnTObP4MjPx/X+C7ONL5LToMW3dX4TkR8Rv+skbrFsuDLl2DefSZ4nD8cbnyr7gSPX6sXBZ2uN71qHtoCN75tjpAPiTSnq66YBtMHwJ/bwbyxJqAUFzpdtYj4QMuWLZkyZYojP1vhQ+oOjwc+mQhLnjKPez4Iaa9AoCYAAdM3JiXNnG3y8BYY+j6cN8w0uss7AKunm425f2oNc+6GjQvNgWwi4pemTp1K586diYqKIioqim7durFw4UKnywK07CJ1RXEhfDQG1r5vHvd5Frrf62xN/iwoFNpfY0ZxIWz/0uwR2TDfdOD98V0zQuqbxnfJadD26qp3+hWRatO8eXOef/55b4fb6dOnM2jQIH744Qc6duzoaG2a+ZDa71iuuaNl7fvgCoTr/qHgURWBwaaPzMAp8H8b4bYFcPGdEBkPx3Lgf7Pgg5HwQmt4fzis/cDsJRERRw0cOJB+/frRrl072rVrx7PPPkv9+vX59ttvva/Jy8tj9OjRREZGkpiYyLRp02ypTTMfUrvlHYJ3bzIHbQWFwY3Tzb/U5cwEBELLnmZc8zzs+r7sdNUjO8wBZ+kfm8Z3rXqZZZz2/cwmV5FawrIsjhYWO/Kzw4IDcZ3B7fDFxcV88MEH5Obm0q1bN+/zL774In/84x+ZMGECH374IXfffTeXX345HTp08GXZJ1D4kNoraxfMGAz7N5h9C7f8GxIvcbqq2iMgABK6mnH1H80BZunzTBA5mAEZn5jhCjSN71JKG9/FOF25yFk5WlhMyhOfOPKz1z/dl/CQyn90r1u3jm7dupGfn0/9+vWZM2cOKSkp3uv9+vXjnnvuAeCRRx7h5ZdfZunSpQofImdk/yZzXLr7F7M8MGI2xCQ7XVXt5XJB/Hlm/OZxE/hKO/Du+x9s/dyM+ePMbbvJaeY23uhznK5cpFZr3749a9as4ciRI8yaNYuRI0eybNkybwDp3Lmz97Uul4vY2FgyMzOrvS6FD6l9fvke3rkejh6Cxm3McekNEp2uqu5wuUzQi0mGKx+Bg1vKOvDu/sEc9b7jK1j0iDnIrPSY94Ytna5cpFLCggNZ/7Qzy7dhwVU7byckJMS74fSiiy5i5cqV/OUvf+Ef//gHAMHBweVe73K58Hg8vin2FBQ+pHbZ8l+YORwKc037+WEfQkQTp6uq2xq3hsvGmXHk57LGdzu/hV9WmrH4cYjtXNKBdxA0bed01SIn5XK5qrT04U8sy6KgoMDpMhQ+pBb53yyYfSd4CqHVlXDTDAiNdLoqOV6DROg2xgz3HnPr7vqPzEzI3rVm/PcZaJpcEkTSoFlH9ZsROQMTJkwgNTWVhIQEsrOzmTlzJkuXLmXRokVOl6bwIbXEin/Cfx4CLOh4nbmdNijU6arkVKLi4OI7zMg9ABsWmKWZrUthfzosS4dlk6FRq7KlmfgLFEREKmnfvn2MGDGCPXv2EB0dTefOnVm0aBFXX32106XhsizLcrqI47ndbqKjo8nKyiIqKsrpcsTfWRYsnWQ+pAC6/hZSX1Afkprs6GHYuMgEkc1LTOO/UtGJZqNqSho0v1iN78QW+fn5bNu2jaSkJOrVq+d0OY472ftRlc9vzXxIzeUphv/8Hlb9yzy+cjxc8Yj+ZVzThTWE84aaUZBd0vhunvk162f49u9m1I+F5AElje966Jh8kRpE/2+VmqmoAGbfYfYL4IL+fzazHlK7hEbCuUPMOJYHW5aYILJpEeTshZX/z4zwxtChv9msmnQ5BIU4XbmInILCh9Q8Bdkw8xbY9gUEBMOQf5p9HlK7hYSbJZfkgSZ8bl1mTlfdsADyDsLqt8yoFw3tUs3STOvf1N2OxSJ+TOFDapac/eYMjz1rTFOzm2ZA615OVyV2CwqFdn3MGDAFti83e0TS50NuJqydaUZIfWjbxwSRNldDaH2nKxcRFD6kJjm8w5xaemiLmWYf9iGcc4HTVYnTAoNNAG3dC/r9GXZ+V3a6qnsX/DTbjKB60OYqs0ek/TVmhkREHKHwITXDvp/g7cFmnT860Zxa2qSN01WJvwkINMe3t+gO10yCXath/VwTRA5vN+eKbJhvluta9zJBpEN/Nb4TsZnCh/i/Hd/AezdBfhbEpMDwWRAV73RV4u9cLmh+oRlXPw1715U1vjuw0dw9k/EpfHy/6dKbkgYdBkJkM6crF6n1FD7Ev21cCB/cBkX5kHAp3DLT3IopUhUuF8R1NuM3j0HmhrIgsm8dbFtmxoLfQ2K3ktNVB0J0c6crF6mVFD7Ef615Fz66F6xiaNsXbnjT3PEgcrZiOphxxcOm8V36xyaM7Poefv7ajEWPwjkXlp2u2qiV01WL1BoKH+KfvvqraTYG0GUopP3NbCwU8bXGraHnA2Yc2VkWRH7+1oSRXd/DZ3+A2E7mHJGUNGja3umqRc7KbbfdxpEjR5g7d64jP1/hQ/yLZcHiJ+Drv5rH3e6Fq/+oY7TFHg0SoNs9ZmTvLWl8N8/cyrt3nRmfPwNN2psQkjIImp2rU3VFqkjhQ/xHcRF8PBbWvGMeX/009Ljf2Zqk7oqMNafmdv0t5B6EjQtMENm61GxY/eJPZjRMKtkjMsjc+q0gInJa+uek+IdjefD+MBM8XIEw6O8KHuI/IhrDBbfC8A/hoc1w3TToMMCcHXJ4G3z1F/h/v4GXz4WFj5o7tDwep6sW4cMPP6RTp06EhYXRuHFjrrrqKnJzc50uSzMf4geOHob3hsLP35i/zK9/Azr0c7oqkYqFNYAuN5lRkGNu102fB5s+Bfcv8N1UM+o3MwElJQ1a9FTju9rEsqAwz5mfHRxe6dm1PXv2MHToUF544QWuu+46srOz+fLLL/GHZvb6f4M4y70HZgyBzJ8gNNrcStuiu9NViVROaH04d7AZhUdhy3/N0szGhZCzD1a9bkZYIxOoU66FpCvU+K6mK8yD5xw6a2jCbgiJqNRL9+zZQ1FREYMHD6ZFixYAdOrUqTqrqzSFD3HOwS3w9rVw5Gfzr8ThsyH2XKerEjkzwWHmtNQO/aHomDk3ZH1J47ujh+CHGWaERpvj3ZPToE1vNb6TatOlSxd69+5Np06d6Nu3L3369OH666+nYUPnz0pS+BBn7F5jZjzyDpjzE0bMgYYtna5KxDeCQqDt1WYMmAI7vippfPexmRFZ+74ZwRHmNSmDTAM8Nb6rGYLDzQyEUz+7kgIDA1m8eDFff/01n376KX/729+YOHEi3333XTUWWDkuyx8Wf47jdruJjo4mKyuLqKgop8uR6rB1GcwcBseyIbazOS69fozTVYlUP4/HNL4rPV3V/UvZtaB60Lq32SPS7hqzt0T8Qn5+Ptu2bSMpKYl69eo5Xc4ZKy4upkWLFowbN461a9ee8TkfJ3s/qvL5rZkPsddPc2H2HVB8DFpeBje/C/UUMqWOCAiAFt3M6Psc7F5tQsj6j8xdMxsXmBEQDK2uMDMi7fubu21Equi7775jyZIl9OnTh5iYGL777jv2799PcnIya9eudbQ2hQ+xz8rXYcH/AZbpmzH4/0Fwzf1XhMhZcbnM8e3nXAhXPQn7/meCSPo82L8BNn9mhusBaNnD7BFJHmjOHxGphKioKL744gumTJmC2+2mRYsWvPjii6SmpvL+++87WpuWXaT6WZY5jOnzZ83jC0dB/xdN+3MROdH+TZD+kZkR2bvuuAsuSLjEzIgkDzQnskq1qy3LLr6iZRfxfx4PLHoEVkwzjy9/GHpN0CmQIqfStB00fQgufwgObSvbI7JrFez81oxPxkP8BSWnq6aZHjUiNYTCh1SfomMw9y743yzzOPUFuOROZ2sSqWkaJZnTfnvcD1m/QPp8MyPy8zdmz8ju1fDZk6bHTMogE0RiOjhdtcgpKXxI9SjIgX+PMIcuBQTBdf+ATtc7XZVIzRbdHC69y4zsfabxXfo82Pal2TOy739mebNJOxNCUtLMHWWaaRQ/o/Ahvpd7EN69wbQiDw6Hm96GNlc5XZVI7RLZDLrebkbeIdj4HzMjsuVzOLAJvvyzGQ1blgSRQWZzq4KI+AGFD/GtIzvh7evgYIY5UnrYB9D8IqerEqndwhvB+cPNyM+CTZ+YILL5Mzi8Hb7+qxlR55iNqslpkHipNn1XkZ/dn+EYX7wPVe5q+8UXXzBw4EDi4+NxuVynPKDkzjvvxOVyMWXKlLMoUWqMzA3weh8TPKKaw+hFCh4idqsXDZ1vhJvfgYe3wg3ToeNgCKkP7l3w3WvwZj94sQPMf9DMlBQXOl21XwsODgYgL8+hZnJ+pvR9KH1fzkSVZz5yc3Pp0qULo0aNYsiQISd93dy5c/nuu++Ij3eo+Y7Ya+cKeOcGyD8CTdrDiNlmfVpEnBMSAR2vNaMw3+zBSp9nlmhyM2HVv8wIa2gOM0tJg1ZXQlCow4X7l8DAQBo0aEBmZiYA4eHhuOrg8pVlWeTl5ZGZmUmDBg0IDDzzmbMqh4/U1FRSU1NP+Zpdu3Zx77338sknn9C/f/9TvragoICCggLvY7fbXdWSxGkZi+Hft5pOj+dcZJZawhs5XZWIHC+4nums26GfuRNt+xdlje/yDsKaGWaERpnj3VPSzHHvIZXvJVKbxcaaw91KA0hd1qBBA+/7caZ8vufD4/EwYsQIHnroITp27Hja10+aNImnnnrK12WIXdb+G+beDZ4i8xfVTW9Xut2ziDgkKMRsAm9zFfR/GX7+uuR01Y8hZy+s+7cZweGm8V1yGrTrC6GRTlfuGJfLRVxcHDExMRQW1t1lquDg4LOa8Sjl8/AxefJkgoKCGDt2bKVeP378eMaNG+d97Ha7SUjQqX01wjevmoOOADrdAINeNX+piUjNERgESZebkfoC/LLSzIikz4Osneb36z+CwFBo09sEkfbXmKWaOigwMNAnH751nU/Dx/fff89f/vIXVq9eXen1sNDQUEJDtb5Yo1gWLHkalr9kHl9yt2mSFVDl/csi4k8CAiDxEjP6Pgu7fyg7XfXQFrNXZON/zNk9SVeYpZkOAyCiidOVSw1zVr1dXC4Xc+bM4dprrwVgypQpjBs3joDjPoSKi4sJCAggISGB7du3n/Z7qreLnysugvkPwA9vm8e9n4Ce43R2gEhtZlmQub5kFmQe7E8vu+YKgBY9zDkiHQZAVJxzdYqjqvL57dPwcfDgQfbs2VPuNX379mXEiBGMGjWK9u3b+7R4sVlhPsy63Zyq6AqAAVPgwpFOVyUidjuQUbY0s+fH4y64IOHistNVGyQ6VqLYr1oby+Xk5LB582bv423btrFmzRoaNWpEYmIijRs3Lvf64OBgYmNjKxU8xI/lZ8F7t8CO5Wbt9/rXzWFFIlL3NGkLl//ejMPbzUbV9fPglxWw8zszPp0I8eeXna6qxndynCqHj1WrVtGrVy/v49LNoiNHjuTNN9/0WWHiR7L3wYwhsG8dhETC0Pcg6TKnqxIRf9CwJXS/z4ysXWZmdP08cwfN7h/MWPIUxHQ0syEpg6BpBy3V1nFntexSHbTs4mcObTXHpR/eDhFNYfgsiOvidFUi4u9y9h/X+O4Lczt+qcZtTRBJTjN/nyiI1Aq27fmoDgoffmTPWjPjkZtp/nUzfLamTkWk6vIOwcaFJohs+S8UHyu71qCFWcJNudY0vtNdczWWwoecve3L4b2hUOCGZp1g+IcQeXYn2omIkO+GjE/NhtWMxVB0tOxaZHxJEEmDxG5qfFfDKHzI2UmfDx+OhuICcwvdze9CWAOnqxKR2uZYrum8u36e6cR7LLvsWkRT6NDf7BFpeRkEnnkTM7GHwoecudVvwcf3g+Uxjaaufx2Cw5yuSkRqu8J82LrULM1sWGCaVJaq18AEkeQ0aN1Lje/8lMKHVJ1lwfKXza50gPOHw4C/mKOXRUTsVFxoNqmmzzMzsXkHyq6FRJo+MymDTG8aNb7zGwofUjUeD3z6GHz7d/O454PQ+w/agS4izvMUw8/flDS+mwfZxx1kGRxuAkjKIGjbB+rpM8NJCh9SecWF8NEYWPu+edznWeh+r7M1iYhUxOOBXavKTlc98nPZtcAQaP0bE0Tap9bZxndOUviQyjmWC/8eCZsXm0ZRg/4OXW52uioRkdOzLHO0e/o8E0YOlp28bRrfXW72iHQYAPWbOldnHaLwIaeXdwjevdG0zw4KgxvfgnZ9nK5KRKTqLAsy08s68Gb+VHbNFQCJ3c2MSPIAiIp3rs5aTuFDTi1rF8wYDPs3mF3kwz4wzaBERGqDA5vLZkT2rCl/rfnFZaerNmzhSHm1lcKHnNz+Tea4dPcv5kCfEbMhJtnpqkREqsfhHabxXfo80/DueHFdSmZEBkGTNs7UV4sofEjFfvke3rkejh6Cxm1gxBy1vBaRusO9p6Tx3Uew4ytznlGpmJSSDrxp5ve626/KFD7kRJuXwPsjoDDXtLke9iFENHG6KhERZ+Tsh40LzB6RbcvKN75r1NrMiKSkQdx5CiKVpPAh5a37EObcBZ5CaHUl3DQDQiOdrkpExD8cPQwbF5kZkS3/Na0lSjVINDMiyWnQvKsa352CwoeU+W4aLHwYsKDjYLjuNR1NLCJyMgXZps9M+jzT+K4wr+xaZJxpfJecBi26q/Hdryh8iLn1bOkkWDbZPO56B6RO1v9ZREQq61gebFliZkQ2Lirf+C68SUnjuzRIukKN71D4EE8x/Of3sOpf5vGVE+CKh7VuKSJypooKTOO79fPMXpGjh8uu1Ys2jThT0qBVLwiu51iZTlL4qMuKCmD2HSap44L+f4auv3W6KhGR2qO4ELYvN3/PbpgPufvLroXUN43vktOg7dUQEuFcnTZT+Kir8t3w/jDTDTIgGIb8Ezpe53RVIiK1l6cYfv62pAPvx+DeVXYtKAzaXmXOEWnXt9Y3vlP4qIty9sM7Q0yvg5D6cPM75s4WERGxh8cDu1fD+rlmeebIjrJrgSFmSSYlDdr3g/BGjpVZXRQ+6prD282ppYe2mk1Qwz80Z3mIiIgzLAv2rjUhJH0eHNhUds0VaBrfpZQ2votxrk4fUvioS/b9BG8Phpy9EJ1oTi3VMcEiIv4lc4PZI5I+D/b977gLLnPbbnKauY03+hzHSjxbCh91xY5v4L2bID/LHAc8fDZExTldlYiInMrBLWUdeHevLn+tedeyY94btnSkvDOl8FEXbFwIH9wGRfmQcCncMhPCGjpdlYiIVMWRn81G1fWlje+O+0iO7VzSgXcQNG3nWImVpfBR2615Fz66F6xiaNsXbngTQsKdrkpERM5G9t6yDrzbl5dvfNc0uSSIpEGzjn55bpPCR2321V9g8RPm912GQtrfdLKeiEhtk3sANiwwQWTrMtObq1SjVmVLM/EX+E0QUfiojSwLFj8OX//NPO5+H1z1tJociYjUdkePwKZFZmlm82flG99FJ5qNqilp0PxiRz8TFD5qm+IimHcf/PiueXz109DjfmdrEhER+xVkQ8anJohkLIbC3LJr9WMheUBJ47seEBhka2kKH7XJsTz4cJRJva5ASPsrnD/c6apERMRphUdh8xKzNLNxERRklV0Lb2wa3yUPMmeKBIVUezkKH7XF0cPw3lD4+RsIqgfXvwEd+jldlYiI+JuiY7BtmTlddcN/4Oihsmv1oqFdqlmaaf0bCA6rlhIUPmoD9x6YMQQyf4LQaHMrbYvuTlclIiL+rrgIdiw3SzMb5kPOvrJrIfWhbR8TRNql+rQDr8JHTXdgM8y4ztz/Xb+ZOTws9lynqxIRkZrGUww7V5ScrvoxuH8xzwcEwUObfXo+VFU+v+3djSKnt/sHmHE95B0wt1ONmFPjTrkTERE/ERAILbqZcc0k2LUa0j8yd9A4eDClwoc/2boMZt4Cx3IgrgsMmwX1mzpdlYiI1AYuFzS/0AyHKXz4i5/mwuw7oPgYtLwMbn4X6tXRZScREanVdEKVP1j5uunTUnzM3J897EMFDxERqbU08+Eky4Iv/gSfP2seXzgK+r9o1uhERERqKYUPp3g8sPBhWPlP8/jyh6HXBL85o19ERKS6KHw4oegYzLkTfpoNuCB1Mlxyp9NViYiI2ELhw24FOfD+cNj6OQQEw3WvQafrna5KRETENgofdso9CO9cD7tXQ3AE3PQ2tOntdFUiIiK2Uviwy5Gd8PZ1cDADwhrBsA+g+UVOVyUiImI7hQ87ZG4wwSN7N0Q1hxGzoWl7p6sSERFxhMJHddu5At65AfKPQJP2JnhEN3e6KhEREccofFSnjMXw/ggoOgrnXGSWWsIbOV2ViIiIoxQ+qsuP78NH94CnCNpcBTe+BSERTlclIiLiOB2vXh2+eRXm/M4Ej043wtCZCh4iIiIlNPPhS5YFS56G5S+Zx5fcDX2fgwBlPBERkVIKH75SXATzH4Af3jaPez8BPcfpuHQREZFfqfI/yb/44gsGDhxIfHw8LpeLuXPneq8VFhbyyCOP0KlTJyIiIoiPj+fWW29l9+7dvqzZ/xTmwwcjTfBwBcDAv8Jl/6fgISIiUoEqh4/c3Fy6dOnCK6+8csK1vLw8Vq9ezeOPP87q1auZPXs2mzZtIi0tzSfF+qX8LJgxBDbMh8BQs7H0wpFOVyUiIuK3XJZlWWf8xS4Xc+bM4dprrz3pa1auXMnFF1/Mjh07SExMPO33dLvdREdHk5WVRVRU1JmWZo/sfSZ47FsHoVFw87uQdJnTVYmIiNiuKp/f1b7nIysrC5fLRYMGDSq8XlBQQEFBgfex2+2u7pJ849BWc2rp4e0QEQPDZ0FcZ6erEhER8XvVehtGfn4+jz76KLfccstJU9CkSZOIjo72joSEhOosyTf2rIXX+5rg0bAl3P6JgoeIiEglVVv4KCws5Oabb8bj8fDqq6+e9HXjx48nKyvLO3bu3FldJfnG9uXwZn/IzYRmnWD0J9ColdNViYiI1BjVsuxSWFjIjTfeyLZt2/jvf/97yrWf0NBQQkNDq6MM30ufDx+OhuICaNHD7PEIa+B0VSIiIjWKz8NHafDIyMjg888/p3Hjxr7+Ec74fro5x8PyQPv+cP3rEBzmdFUiIiI1TpXDR05ODps3b/Y+3rZtG2vWrKFRo0bEx8dz/fXXs3r1aubPn09xcTF79+4FoFGjRoSEhPiucrtYljmxdMnT5vH5w2HAXyBQ57OJiIiciSrfart06VJ69ep1wvMjR47kySefJCkpqcKv+/zzz7nyyitP+/396lZbjwc+nQjfluxZ6TnOnFyqw8NERETKqdZbba+88kpOlVfO4tgQ/1JcCHPvgXX/No/7Pgfdxjhbk4iISC2gtYOKHMuFf4+EzYshIAgGvQpdbnK6KhERkVpB4ePX8g7BuzfCLyshKMwcl96uj9NViYiI1BoKH8fL2gUzBsP+DVCvAQz7ABIudroqERGRWkXho9T+Tea4dPcvEBkPI2ZDTLLTVYmIiNQ6Ch8Av3wP71wPRw9B47YmeDQ4fRM8ERERqTqFj81L4P0RUJgL8RfAsA8hopYcjCYiIuKH6nb4WPchzLkLPIXQqhfcNANC6ztdlYiISK1WrV1t/dp302DWb03w6DgYbnlfwUNERMQGdW/mw7Jg6SRYNtk87noHpE6GgEBn6xIREakj6lb48BTDgv+D798wj6+cAFc8rOPSRUREbFR3wkdRgVlmSZ8HuKD/i9D1dqerEhERqXPqTvg4sAk2fwaBITD4n9DxWqcrEhERqZPqTviI7QQ3vg2BQdDqSqerERERqbPqTvgAaHuV0xWIiIjUeXX3VlsRERFxhMKHiIiI2ErhQ0RERGyl8CEiIiK2UvgQERERWyl8iIiIiK0UPkRERMRWCh8iIiJiK4UPERERsZXCh4iIiNhK4UNERERspfAhIiIitlL4EBEREVspfIiIiIitFD5ERETEVgofIiIiYiuFDxEREbGVwoeIiIjYSuFDREREbKXwISIiIrZS+BARERFbKXyIiIiIrRQ+RERExFYKHyIiImIrhQ8RERGxlcKHiIiI2ErhQ0RERGyl8CEiIiK2UvgQERERWyl8iIiIiK0UPkRERMRWCh8iIiJiK4UPERERsZXCh4iIiNhK4UNERERsVeXw8cUXXzBw4EDi4+NxuVzMnTu33HXLsnjyySeJj48nLCyMK6+8kp9++slX9YqIiEgNV+XwkZubS5cuXXjllVcqvP7CCy/w0ksv8corr7By5UpiY2O5+uqryc7OPutiRUREpOYLquoXpKamkpqaWuE1y7KYMmUKEydOZPDgwQBMnz6dZs2a8e6773LnnXeeXbUiIiJS4/l0z8e2bdvYu3cvffr08T4XGhrKFVdcwddff13h1xQUFOB2u8sNERERqb18Gj727t0LQLNmzco936xZM++1X5s0aRLR0dHekZCQ4MuSRERExM9Uy90uLper3GPLsk54rtT48ePJysryjp07d1ZHSSIiIuInqrzn41RiY2MBMwMSFxfnfT4zM/OE2ZBSoaGhhIaG+rIMERER8WM+nflISkoiNjaWxYsXe587duwYy5Yto3v37r78USIiIlJDVXnmIycnh82bN3sfb9u2jTVr1tCoUSMSExN54IEHeO6552jbti1t27blueeeIzw8nFtuucWnhYuIiEjNVOXwsWrVKnr16uV9PG7cOABGjhzJm2++ycMPP8zRo0e55557OHz4MJdccgmffvopkZGRvqtaREREaiyXZVmW00Ucz+12Ex0dTVZWFlFRUU6XIyIiIpVQlc9v9XYRERERWyl8iIiIiK0UPkRERMRWCh8iIiJiK4UPERERsZXCh4iIiNhK4UNERERspfAhIiIitlL4EBEREVspfIiIiIitFD5ERETEVgofIiIiYiuFDxEREbGVwoeIiIjYSuFDREREbKXwISIiIrZS+BARERFbKXyIiIiIrRQ+RERExFYKHyIiImIrhQ8RERGxlcKHiIiI2ErhQ0RERGyl8CEiIiK2UvgQERERWyl8iIiIiK0UPkRERMRWCh8iIiJiK4UPERERsZXCh4iIiNhK4UNERERspfAhIiIitlL4EBEREVspfIiIiIitFD5ERETEVgofIiIiYiuFDxEREbGVwoeIiIjYSuFDREREbKXwISIiIrZS+BARERFbKXyIiIiIrRQ+RERExFYKHyIiImIrhQ8RERGxlcKHiIiI2ErhQ0RERGyl8CEiIiK2UvgQERERWyl8iIiIiK18Hj6Kiop47LHHSEpKIiwsjFatWvH000/j8Xh8/aNERESkBgry9TecPHkyr732GtOnT6djx46sWrWKUaNGER0dzf333+/rHyciIiI1jM/DxzfffMOgQYPo378/AC1btuS9995j1apVFb6+oKCAgoIC72O32+3rkkRERMSP+HzZpWfPnixZsoRNmzYB8OOPP7J8+XL69etX4esnTZpEdHS0dyQkJPi6JBEREfEjLsuyLF9+Q8uymDBhApMnTyYwMJDi4mKeffZZxo8fX+HrK5r5SEhIICsri6ioKF+WJiIiItXE7XYTHR1dqc9vny+7vP/++8yYMYN3332Xjh07smbNGh544AHi4+MZOXLkCa8PDQ0lNDTU12WIiIiIn/J5+HjooYd49NFHufnmmwHo1KkTO3bsYNKkSRWGDxEREalbfL7nIy8vj4CA8t82MDBQt9qKiIgIUA0zHwMHDuTZZ58lMTGRjh078sMPP/DSSy8xevRoX/8oERERqYF8vuE0Ozubxx9/nDlz5pCZmUl8fDxDhw7liSeeICQk5LRfX5UNKyIiIuIfqvL57fPwcbYUPkRERGqeqnx+q7eLiIiI2ErhQ0RERGyl8CEiIiK2UvgQERERWyl8iIiIiK0UPkRERMRWCh8iIiJ1hDu/kO+2HuQ/6/Y4WofPTzgVERERZ1mWxS+Hj7J+j5v1u92k73Gzfo+bXw4fBSCyXhCp58bicrkcqU/hQ0REpAbLLywmY1+ON2Cs32PCRnZ+UYWvj4+uR0p8FDkFRUTWC7a5WkPhQ0REpIY4kFNgQsZxsxlb9udS7DnxsPLgQBdtYyJJjosiJT6K5LhIUuKiaBB++lYn1U3hQ0RExM8Ueyy2Hcj1BozSwJGZXVDh6xuEB5MSF2WCRsmvbWLqExLkn1s7FT5EREQclFNQxMa9Jlys35PN+j1uNu51k1/oqfD1SU0ivLMYpbMasVH1HNu/cSYUPkRERGxgWRZ7svLLlk1KAsf2g3kVvr5ecAAdYssCRkpcFB1iI4kIrfkf3TX/TyAiIuJnjhV52JyZU27JJH2vmyN5hRW+vllUaLklk5T4KFo2jiAwoObMZlSFwoeIiMhZOJJ37LhbWs2yyebMbAqLT9wEGhjgok3T+sdtAI0mOS6SxvVDHajcOQofIiIileDxWPx8KK/8bMYeN7uz8it8fWS9IO9sRkrJbEabmPrUCw60uXL/o/AhIiLyK0ePFbNxX3a5W1o37HGTe6y4wtcnNAojObZsb0ZyXBTNG4bVqE2gdlL4EBGROsuyLPZnF/DTr2Yzth3IpYKjMwgJCqB9s9I7TSJJiY+mQ1wkUQ4d1lVTKXyIiEidUFTsYeuB3HKzGel73BzIOVbh6xtHhHhnMswejShaNYkgKNA/z86oSRQ+RESk1nHnF5JeLmRks3FfNseKTjw7I8Blzs5IiY/2np+REhdF08hQLZtUE4UPERGpsY5voFa6bHJ8A7VfiwgJJPm421mT46Jo3yySsBBtArWTwoeIiNQIZ9pA7fjzMxIbhRNQS8/OqEkUPkRExO+UNlBLP+78jM37c2pcAzWpmMKHiIg4prY3UJOKKXyIiIgtcguK2LC3pHlayWbQDbW8gZpUTOFDRER86mQN1HYcysOq4OyM2txATSqm/2VFROSMlTZQK7dsskcN1OTUFD5ERKRSzqSBmjkFNKrONlCTiil8iIhIOaUN1Ly3tKqBmviYwoeISB2mBmriBIUPEZE6oLSB2vrjjhtfvztLDdTEEQofIiK1zNk0UCvdBKoGalKdFD5ERGowd34hG0pmMUo3gaqBmvg7hQ8RkRqgogZq6Xvd7Dx08gZqHeLKt4NXAzXxFwofIiJ+Jr+wmM2ZOd4OrWqgJrWNwoeIiIMO5hSUn81QAzWpAxQ+RERsUOyx2H7wxE2g+9xqoCZ1j8KHiIiPVdRAbePebI4WVnx2RsvG4SfcbaIGalKbKXyIiJwhy7LY687/1WxGNtsP5laygVok7WOjqK8GalLH6L94EZFKqGoDtZjI0BNmM9RATcRQ+BAR+ZXSBmrpxy2bZFSygVpySdhoogZqIiel8CEiddavG6iV3nGiBmoi1UvhQ0TqhNIGaqUBoyoN1EoDhxqoifiGwoeI1DqZ2fnegKEGaiL+R+FDRGqs0gZqx89mqIGaiP9T+BCRGkEN1ERqD4UPEfErpQ3Ufn1La2UaqJXOZqiBmoh/U/gQEceogZpI3aTwISK2OJhTULJckuU9P+NUDdTaxEQe1w5eDdREapNqCR+7du3ikUceYeHChRw9epR27drx+uuvc+GFF1bHjxMRP6IGaiJyOj4PH4cPH6ZHjx706tWLhQsXEhMTw5YtW2jQoIGvf5SIOMw0UMsud0CXGqiJyOn4PHxMnjyZhIQE3njjDe9zLVu29PWPEREbqYGaiPiSz/8mmDdvHn379uWGG25g2bJlnHPOOdxzzz3ccccdFb6+oKCAgoKy6Vi32+3rkkSkCo4VediyP+eEZZPDaqAmIj7i8/CxdetWpk6dyrhx45gwYQIrVqxg7NixhIaGcuutt57w+kmTJvHUU0/5ugwRqQQ1UBMRJ7gsq6JJ0zMXEhLCRRddxNdff+19buzYsaxcuZJvvvnmhNdXNPORkJBAVlYWUVFRvixNpM7yeCx2Hs4rN5txygZqoUEkx6uBmohUntvtJjo6ulKf3z6f+YiLiyMlJaXcc8nJycyaNavC14eGhhIaqn85ifjKrxuopZcsm6iBmoj4C5+Hjx49erBx48Zyz23atIkWLVr4+keJ1HmlDdRKjxtXAzURqQl8Hj4efPBBunfvznPPPceNN97IihUrmDZtGtOmTfP1jxKpM9RATURqE5/v+QCYP38+48ePJyMjg6SkJMaNG3fSu11+rSprRiK1UWkDNe+yyV5zdkaBGqiJiB+ryud3tYSPs6HwIXWFGqiJSG3i6IZTETlRQVExGftyvHeZlG4CdauBmojUQQofIj5WUQO1LftzKDpNA7XS8zPUQE1EajuFD5EzVFBUzNb9uWzal83GvdneZRM1UBMROTWFD5HTOFbkYftBEzI27cth095sNmVms+NgXoXt4KGsgdrx52fERauBmogIKHyIeBUVe9h+MI+M0pCxL5tN+7LZdiC3wiUTgKh6QbRrFknbZpFqoCYiUkn6G1LqnGKPxc+H8ti0L5uMfdls3JdDxr5stu7P5VjxibezAtQPDaJts/q0i4k0vzaLpF2zSJpF6ZZWEZGqUviQWsvjMbeybtpnlkky9uWwcW82W/bnVHhmBkB4SCBtY+rTtlkk7ZqV/hpJvJZMRER8RuFDajzLsth15CgZ3qUS8+vmzByOFlbcz6RecABtYkpnMkzQaNcsknMahOl2VhGRaqbwITWGZVnsdeezqWSZZFPJksnmfdknbZoWEhhA65j63nDRNsb8mtAonECFDBERRyh8iN+xLIv92QXeGYyMTHMra0ZmDtknOZQrONBFqyb1j9uPYZZMWjQKVz8TERE/o/AhjjqQU1Cy8bPs7pJN+3LIOlpY4esDA1wkNYkw4SIm0hs0WjaJIFghQ0SkRlD4EFsczj1WsvGzbMlk074cDuVW3JU1wAUtG0d4ZzJK92UkNYkgNEi9TEREajKFD/GprKOF5c7JMEsmORzIqfjUT5cLEhuFl8xilAaN+rRuWp96wQoZIiK1kcKHnJHs/EIyvLMYZUsmJztaHOCcBmG0j430npfRrlkkbWLqqyuriEgdo/Ahp5R3rMi7HyMj05yTkbEvm91Z+Sf9mrjoeuU2fZbeZRKhUz9FRASFDymRX1jM5szy52Rs2pfNL4ePnvRrYiJDzUxGTFnQaNusPlH1gm2sXEREahqFjzomv9B0Ys3IzC4XNH4+lIdVcfsSmtQPoW1MZNmSSbNI2sVEEh2ukCEiIlWn8FFLHSvysO1Arrd/SWnI2H4wl5P0SKNheLD3rpL23jtMImkUEWJv8SIiUqspfNRwhcUedhzMLbu7ZF8OG/dls72SnVjbH3cra5P6IepfIiIi1U7ho4Yo9ljekJFRcl7Gpr3ZbD2QQ2FxxSHj+E6s7WLLbmWNiVQnVhERcY7Ch5/xeCx2Hs47bibD9C/Zsj+HY5XoxNq+Wdm+jDh1YhURET+k8OEQj6ekE2tmdrklk4zMbPILKw4Zx3diLZ3JaBujTqwiIlKzKHxUM8uy2JOVX75/ScnhXHkn68QaFEDrpmWdWEvPzGjeUJ1YRUSk5lP48BHLssjMLvDevlravyRjXw7ZBZXtxGpCRqI6sYqISC2m8FFFlmVxIOdYWXO0444Yr2wn1vYlSyYtGqsTq4iI1D0KH6dwqKQTa/lGaZXvxFo6kppEEBKkkCEiIgIKHwBk5RWyKTO7/L6MfZXvxFp6xHirphHqxCoiInIadSp8ZOcXHrcfI8d7xPipOrE2bxjmbfPermTJpHVTdWIVERE5U3UmfOxz53PJc0tOej0+up73aPHS8zLaqBOriIiIz9WZT9aYyFAiQ4MIDw0safFecuJnrGn3HqlOrCIiIraoM+HD5XLx7YTemskQERFxWJ26BUPBQ0RExHl1KnyIiIiI8xQ+RERExFYKHyIiImIrhQ8RERGxlcKHiIiI2ErhQ0RERGyl8CEiIiK2UvgQERERWyl8iIiIiK0UPkRERMRWCh8iIiJiK4UPERERsZXCh4iIiNjK79q8WpYFgNvtdrgSERERqazSz+3Sz/FT8bvwkZ2dDUBCQoLDlYiIiEhVZWdnEx0dfcrXuKzKRBQbeTwedu/eTWRkJC6Xy6ff2+12k5CQwM6dO4mKivLp965t9F5Vnt6rytN7VTV6vypP71XlVdd7ZVkW2dnZxMfHExBw6l0dfjfzERAQQPPmzav1Z0RFRek/zkrSe1V5eq8qT+9V1ej9qjy9V5VXHe/V6WY8SmnDqYiIiNhK4UNERERsVafCR2hoKH/4wx8IDQ11uhS/p/eq8vReVZ7eq6rR+1V5eq8qzx/eK7/bcCoiIiK1W52a+RARERHnKXyIiIiIrRQ+RERExFYKHyIiImKrOhE+Jk2aRNeuXYmMjCQmJoZrr72WjRs3Ol2WX5o6dSqdO3f2Hj7TrVs3Fi5c6HRZNcKkSZNwuVw88MADTpfid5588klcLle5ERsb63RZfmvXrl0MHz6cxo0bEx4eznnnncf333/vdFl+p2XLlif8d+VyuRgzZozTpfmdoqIiHnvsMZKSkggLC6NVq1Y8/fTTeDweR+rxuxNOq8OyZcsYM2YMXbt2paioiIkTJ9KnTx/Wr19PRESE0+X5lebNm/P888/Tpk0bAKZPn86gQYP44Ycf6Nixo8PV+a+VK1cybdo0Onfu7HQpfqtjx4589tln3seBgYEOVuO/Dh8+TI8ePejVqxcLFy4kJiaGLVu20KBBA6dL8zsrV66kuLjY+/h///sfV199NTfccIODVfmnyZMn89prrzF9+nQ6duzIqlWrGDVqFNHR0dx///2211Mnb7Xdv38/MTExLFu2jMsvv9zpcvxeo0aN+NOf/sTtt9/udCl+KScnhwsuuIBXX32VZ555hvPOO48pU6Y4XZZfefLJJ5k7dy5r1qxxuhS/9+ijj/LVV1/x5ZdfOl1KjfPAAw8wf/58MjIyfN4brKYbMGAAzZo14/XXX/c+N2TIEMLDw3n77bdtr6dOLLv8WlZWFmA+VOXkiouLmTlzJrm5uXTr1s3pcvzWmDFj6N+/P1dddZXTpfi1jIwM4uPjSUpK4uabb2br1q1Ol+SX5s2bx0UXXcQNN9xATEwM559/Pv/85z+dLsvvHTt2jBkzZjB69GgFjwr07NmTJUuWsGnTJgB+/PFHli9fTr9+/Rypp04suxzPsizGjRtHz549Offcc50uxy+tW7eObt26kZ+fT/369ZkzZw4pKSlOl+WXZs6cyerVq1m5cqXTpfi1Sy65hLfeeot27dqxb98+nnnmGbp3785PP/1E48aNnS7Pr2zdupWpU6cybtw4JkyYwIoVKxg7diyhoaHceuutTpfnt+bOncuRI0e47bbbnC7FLz3yyCNkZWXRoUMHAgMDKS4u5tlnn2Xo0KHOFGTVMffcc4/VokULa+fOnU6X4rcKCgqsjIwMa+XKldajjz5qNWnSxPrpp5+cLsvv/Pzzz1ZMTIy1Zs0a73NXXHGFdf/99ztXVA2Rk5NjNWvWzHrxxRedLsXvBAcHW926dSv33H333WddeumlDlVUM/Tp08caMGCA02X4rffee89q3ry59d5771lr16613nrrLatRo0bWm2++6Ug9dSp83HvvvVbz5s2trVu3Ol1KjdK7d2/rd7/7ndNl+J05c+ZYgBUYGOgdgOVyuazAwECrqKjI6RL92lVXXWXdddddTpfhdxITE63bb7+93HOvvvqqFR8f71BF/m/79u1WQECANXfuXKdL8VvNmze3XnnllXLP/fGPf7Tat2/vSD11YtnFsizuu+8+5syZw9KlS0lKSnK6pBrFsiwKCgqcLsPv9O7dm3Xr1pV7btSoUXTo0IFHHnlEd3OcQkFBAenp6Vx22WVOl+J3evToccJRAJs2baJFixYOVeT/3njjDWJiYujfv7/TpfitvLw8AgLKb/MMDAzUrbbVacyYMbz77rt89NFHREZGsnfvXgCio6MJCwtzuDr/MmHCBFJTU0lISCA7O5uZM2eydOlSFi1a5HRpficyMvKEfUMRERE0btxY+4l+5fe//z0DBw4kMTGRzMxMnnnmGdxuNyNHjnS6NL/z4IMP0r17d5577jluvPFGVqxYwbRp05g2bZrTpfklj8fDG2+8wciRIwkKqhMfaWdk4MCBPPvssyQmJtKxY0d++OEHXnrpJUaPHu1MQY7Mt9gMqHC88cYbTpfmd0aPHm21aNHCCgkJsZo2bWr17t3b+vTTT50uq8bQno+K3XTTTVZcXJwVHBxsxcfHW4MHD9Y+olP4+OOPrXPPPdcKDQ21OnToYE2bNs3pkvzWJ598YgHWxo0bnS7Fr7ndbuv++++3EhMTrXr16lmtWrWyJk6caBUUFDhST50850NEREScUyfP+RARERHnKHyIiIiIrRQ+RERExFYKHyIiImIrhQ8RERGxlcKHiIiI2ErhQ0RERGyl8CEiIiK2UvgQEb/kcrmYO3eu02WISDVQ+BCRE9x22224XK4TxjXXXON0aSJSC6gLj4hU6JprruGNN94o91xoaKhD1YhIbaKZDxGpUGhoKLGxseVGw4YNAbMkMnXqVFJTUwkLCyMpKYkPPvig3NevW7eO3/zmN4SFhdG4cWN+97vfkZOTU+41//rXv+jYsSOhoaHExcVx7733lrt+4MABrrvuOsLDw2nbti3z5s3zXjt8+DDDhg2jadOmhIWF0bZt2xPCkoj4J4UPETkjjz/+OEOGDOHHH39k+PDhDB06lPT0dADy8vK45ppraNiwIStXruSDDz7gs88+Kxcupk6dypgxY/jd737HunXrmDdvHm3atCn3M5566iluvPFG1q5dS79+/Rg2bBiHDh3y/vz169ezcOFC0tPTmTp1Kk2aNLHvDRCRM+dIL10R8WsjR460AgMDrYiIiHLj6aeftizLsgDrrrvuKvc1l1xyiXX33XdblmVZ06ZNsxo2bGjl5OR4ry9YsMAKCAiw9u7da1mWZcXHx1sTJ048aQ2A9dhjj3kf5+TkWC6Xy1q4cKFlWZY1cOBAa9SoUb75A4uIrbTnQ0Qq1KtXL6ZOnVruuUaNGnl/361bt3LXunXrxpo1awBIT0+nS5cuREREeK/36NEDj8fDxo0bcblc7N69m969e5+yhs6dO3t/HxERQWRkJJmZmQDcfffdDBkyhNWrV9OnTx+uvfZaunfvfkZ/VhGxl8KHiFQoIiLihGWQ03G5XABYluX9fUWvCQsLq9T3Cw4OPuFrPR4PAKmpqezYsYMFCxbw2Wef0bt3b8aMGcOf//znKtUsIvbTng8ROSPffvvtCY87dOgAQEpKCmvWrCE3N9d7/auvviIgIIB27doRGRlJy5YtWbJkyVnV0LRpU2677TZmzJjBlClTmDZt2ll9PxGxh2Y+RKRCBQUF7N27t9xzQUFB3k2dH3zwARdddBE9e/bknXfeYcWKFbz++usADBs2jD/84Q+MHDmSJ598kv3793PfffcxYsQImjVrBsCTTz7JXXfdRUxMDKmpqWRnZ/PVV19x3333Vaq+J554ggsvvJCOHTtSUFDA/PnzSU5O9uE7ICLVReFDRCq0aNEi4uLiyj3Xvn17NmzYAJg7UWbOnMk999xDbGws77zzDikpKQCEh4fzySefcP/999O1a1fCw8MZMmQIL730kvd7jRw5kvz8fF5++WV+//vf06RJE66//vpK1xcSEsL48ePZvn07YWFhXHbZZcycOdMHf3IRqW4uy7Isp4sQkZrF5XIxZ84crr32WqdLEZEaSHs+RERExFYKHyIiImIr7fkQkSrTaq2InA3NfIiIiIitFD5ERETEVgofIiIiYiuFDxEREbGVwoeIiIjYSuFDREREbKXwISIiIrZS+BARERFb/X+5qvKZo11m2QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_p.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec0513cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model  Lr  \n",
       "3h     0.01    Axes(0.125,0.11;0.775x0.77)\n",
       "       0.04    Axes(0.125,0.11;0.775x0.77)\n",
       "       0.16    Axes(0.125,0.11;0.775x0.77)\n",
       "       0.64    Axes(0.125,0.11;0.775x0.77)\n",
       "sl     0.01    Axes(0.125,0.11;0.775x0.77)\n",
       "       0.04    Axes(0.125,0.11;0.775x0.77)\n",
       "       0.16    Axes(0.125,0.11;0.775x0.77)\n",
       "       0.64    Axes(0.125,0.11;0.775x0.77)\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1)\n",
    "\n",
    "results.groupby(by=[\"Model\",\"Lr\"]).plot(x=\"Epochs\", y=\"Te_l\", legend =\"Model\",subplots=False,ax=axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ccddff1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1 loss: 5.014025497436523\n",
      "  batch 11 loss: 29.254683828353883\n",
      "  batch 21 loss: 9.781697273254395\n",
      "  batch 31 loss: 5.710300117731094\n",
      "  batch 41 loss: 2.2088923335075377\n",
      "  batch 51 loss: 1.2521924138069154\n",
      "  batch 61 loss: 0.8476809918880462\n",
      "  batch 71 loss: 0.7145717918872834\n",
      "  batch 81 loss: 1.0648151367902756\n",
      "  batch 91 loss: 1.1764125168323516\n",
      "  batch 101 loss: 1.3930197179317474\n",
      "  batch 111 loss: 1.0598139673471452\n",
      "  batch 121 loss: 0.7119953095912933\n",
      "  batch 131 loss: 0.3969255819916725\n",
      "  batch 141 loss: 0.15161588788032532\n",
      "  batch 151 loss: 0.05081282779574394\n",
      "  batch 161 loss: 0.057492995355278256\n",
      "  batch 171 loss: 0.03174470094963908\n",
      "  batch 181 loss: 0.17944115824066104\n",
      "  batch 191 loss: 0.3891167588531971\n",
      "  batch 201 loss: 0.3343778468668461\n",
      "  batch 211 loss: 0.07881808113306761\n",
      "  batch 221 loss: 0.07209362019784749\n",
      "  batch 231 loss: 0.02389383951667696\n",
      "  batch 241 loss: 0.00927038157824427\n",
      "  batch 251 loss: 0.019217728823423385\n",
      "  batch 261 loss: 0.005656250065658242\n",
      "  batch 271 loss: 0.027645727875642477\n",
      "  batch 281 loss: 0.055533090978860854\n",
      "  batch 291 loss: 0.048867400735616684\n",
      "  batch 301 loss: 0.032335142605006695\n",
      "  batch 311 loss: 0.10181412845849991\n",
      "  batch 321 loss: 0.05553252878598869\n",
      "  batch 331 loss: 0.06449013645760715\n",
      "  batch 341 loss: 0.08347483306424693\n",
      "  batch 351 loss: 0.06886577063705772\n",
      "  batch 361 loss: 0.3492445409297943\n",
      "  batch 371 loss: 0.32409417890012265\n",
      "  batch 381 loss: 0.43145625069737437\n",
      "  batch 391 loss: 0.27255123360082506\n",
      "  batch 401 loss: 0.1408680548891425\n",
      "  batch 411 loss: 0.07662014621309936\n",
      "  batch 421 loss: 0.06996560916304588\n",
      "  batch 431 loss: 0.012659353576600552\n",
      "  batch 441 loss: 0.03603442036546767\n",
      "  batch 451 loss: 0.05096065020188689\n",
      "  batch 461 loss: 0.05717828227207065\n",
      "  batch 471 loss: 0.04234333680942655\n",
      "  batch 481 loss: 0.03525760229676962\n",
      "  batch 491 loss: 0.02319082021713257\n",
      "  batch 501 loss: 0.006748130687628873\n",
      "  batch 511 loss: 0.0821329606231302\n",
      "  batch 521 loss: 0.03921913206577301\n",
      "  batch 531 loss: 0.1016169881913811\n",
      "  batch 541 loss: 0.04777913596481085\n",
      "  batch 551 loss: 0.0561755483970046\n",
      "  batch 561 loss: 0.019330148119479418\n",
      "  batch 571 loss: 0.010126232437323779\n",
      "  batch 581 loss: 0.005121741077164188\n",
      "  batch 591 loss: 0.009273339109495283\n",
      "  batch 601 loss: 0.0033499096796731466\n",
      "  batch 611 loss: 0.0024609179177787154\n",
      "  batch 621 loss: 0.028215074536274188\n",
      "  batch 631 loss: 0.15093845836818218\n",
      "  batch 641 loss: 0.1334834708366543\n",
      "  batch 651 loss: 0.1232506399974227\n",
      "  batch 661 loss: 0.15017857970669865\n",
      "  batch 671 loss: 0.029275576281361283\n",
      "  batch 681 loss: 0.021762445871718227\n",
      "  batch 691 loss: 0.025458759721368553\n",
      "  batch 701 loss: 0.14663281738758088\n",
      "  batch 711 loss: 0.5459677234292031\n",
      "  batch 721 loss: 0.8272186160087586\n",
      "  batch 731 loss: 2.1122767239809037\n",
      "  batch 741 loss: 1.5274374968372286\n",
      "  batch 751 loss: 0.6914779272861779\n",
      "  batch 761 loss: 0.5023526236414909\n",
      "  batch 771 loss: 0.1517713526263833\n",
      "  batch 781 loss: 0.08165764920413494\n",
      "  batch 791 loss: 0.017193373781628905\n",
      "  batch 801 loss: 0.05300073474645615\n",
      "  batch 811 loss: 0.04478607140481472\n",
      "  batch 821 loss: 0.04256503712385893\n",
      "  batch 831 loss: 0.05662568137049675\n",
      "  batch 841 loss: 0.100787509419024\n",
      "  batch 851 loss: 0.05975536247715354\n",
      "  batch 861 loss: 0.15805283770896494\n",
      "  batch 871 loss: 0.09974857554771006\n",
      "  batch 881 loss: 0.306473795324564\n",
      "  batch 891 loss: 0.42952128238976\n",
      "  batch 901 loss: 0.6884322047233582\n",
      "  batch 911 loss: 0.3688009441830218\n",
      "  batch 921 loss: 0.2756534477695823\n",
      "  batch 931 loss: 0.2315810491796583\n",
      "  batch 941 loss: 0.1640509232878685\n",
      "  batch 951 loss: 0.039248089957982304\n",
      "  batch 961 loss: 0.03930866667069495\n",
      "  batch 971 loss: 0.020517614390701055\n",
      "  batch 981 loss: 0.07403590362519026\n",
      "  batch 991 loss: 0.04635147638618946\n",
      "  batch 1001 loss: 0.02688807900995016\n",
      "  batch 1011 loss: 0.04117324640974403\n",
      "  batch 1021 loss: 0.031188667519018054\n",
      "  batch 1031 loss: 0.06063990343827754\n",
      "  batch 1041 loss: 0.08661296275677159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.08661296275677159 valid 3.904047966003418\n",
      "EPOCH 2:\n",
      "  batch 1 loss: 0.02090938538312912\n",
      "  batch 11 loss: 0.09438872532919049\n",
      "  batch 21 loss: 0.07301831487566232\n",
      "  batch 31 loss: 0.0687874548137188\n",
      "  batch 41 loss: 0.04335537906736135\n",
      "  batch 51 loss: 0.01343401710037142\n",
      "  batch 61 loss: 0.012673099082894624\n",
      "  batch 71 loss: 0.0033747910347301513\n",
      "  batch 81 loss: 0.0032376127783209085\n",
      "  batch 91 loss: 0.0050210075220093135\n",
      "  batch 101 loss: 0.04086588271893561\n",
      "  batch 111 loss: 0.10871437033638358\n",
      "  batch 121 loss: 0.05554338982328773\n",
      "  batch 131 loss: 0.018714431207627058\n",
      "  batch 141 loss: 0.014958285726606846\n",
      "  batch 151 loss: 0.009049979958217592\n",
      "  batch 161 loss: 0.09049982214346527\n",
      "  batch 171 loss: 0.05634141012560576\n",
      "  batch 181 loss: 0.05383996358141303\n",
      "  batch 191 loss: 0.15448499694466591\n",
      "  batch 201 loss: 0.07344593983143569\n",
      "  batch 211 loss: 0.07399076828733087\n",
      "  batch 221 loss: 0.04730522809550166\n",
      "  batch 231 loss: 0.029957952070981266\n",
      "  batch 241 loss: 0.010596320335753261\n",
      "  batch 251 loss: 0.0058343114680610595\n",
      "  batch 261 loss: 0.003570551288430579\n",
      "  batch 271 loss: 0.025823189492803066\n",
      "  batch 281 loss: 0.09808701733127237\n",
      "  batch 291 loss: 0.058836061879992484\n",
      "  batch 301 loss: 0.02562751229852438\n",
      "  batch 311 loss: 0.016274018120020627\n",
      "  batch 321 loss: 0.013721380545757712\n",
      "  batch 331 loss: 0.09080871012993157\n",
      "  batch 341 loss: 0.1885477046482265\n",
      "  batch 351 loss: 0.0731916121323593\n",
      "  batch 361 loss: 0.32959048482589426\n",
      "  batch 371 loss: 0.5612702272832394\n",
      "  batch 381 loss: 0.46981954062357545\n",
      "  batch 391 loss: 0.1424390389584005\n",
      "  batch 401 loss: 0.12345585729926825\n",
      "  batch 411 loss: 0.046364872623234986\n",
      "  batch 421 loss: 0.03803887865506113\n",
      "  batch 431 loss: 0.009315922390669584\n",
      "  batch 441 loss: 0.01758218847680837\n",
      "  batch 451 loss: 0.06193007852416486\n",
      "  batch 461 loss: 0.08646036116406322\n",
      "  batch 471 loss: 0.03443220406770706\n",
      "  batch 481 loss: 0.08508301544934511\n",
      "  batch 491 loss: 0.05204596370458603\n",
      "  batch 501 loss: 0.01093321448424831\n",
      "  batch 511 loss: 0.04430036405101419\n",
      "  batch 521 loss: 0.027187689975835382\n",
      "  batch 531 loss: 0.2229345218744129\n",
      "  batch 541 loss: 0.06254002284258604\n",
      "  batch 551 loss: 0.0789134968072176\n",
      "  batch 561 loss: 0.016779900155961515\n",
      "  batch 571 loss: 0.008072053990326821\n",
      "  batch 581 loss: 0.0056813836330547925\n",
      "  batch 591 loss: 0.0013838128274073825\n",
      "  batch 601 loss: 0.0013321831676876173\n",
      "  batch 611 loss: 0.0024043790006544443\n",
      "  batch 621 loss: 0.019536860991502182\n",
      "  batch 631 loss: 0.13548161489889027\n",
      "  batch 641 loss: 0.08669444341212511\n",
      "  batch 651 loss: 0.02606688616797328\n",
      "  batch 661 loss: 0.04151380201801658\n",
      "  batch 671 loss: 0.007442409568466246\n",
      "  batch 681 loss: 0.041113505203975366\n",
      "  batch 691 loss: 0.05636916435323656\n",
      "  batch 701 loss: 0.05536407551844604\n",
      "  batch 711 loss: 0.7249754764139652\n",
      "  batch 721 loss: 1.1490103377960623\n",
      "  batch 731 loss: 1.5129323959350587\n",
      "  batch 741 loss: 0.8960556676611304\n",
      "  batch 751 loss: 0.9104519613087177\n",
      "  batch 761 loss: 0.4780047118663788\n",
      "  batch 771 loss: 0.22260651364922523\n",
      "  batch 781 loss: 0.2033675378188491\n",
      "  batch 791 loss: 0.04850405100733042\n",
      "  batch 801 loss: 0.08356870170682669\n",
      "  batch 811 loss: 0.08368598334491253\n",
      "  batch 821 loss: 0.09556306079030037\n",
      "  batch 831 loss: 0.12647643620148302\n",
      "  batch 841 loss: 0.19857341423630714\n",
      "  batch 851 loss: 0.11709788609296083\n",
      "  batch 861 loss: 0.2504751946777105\n",
      "  batch 871 loss: 0.13599587576463817\n",
      "  batch 881 loss: 0.12388312593102455\n",
      "  batch 891 loss: 0.2648409436456859\n",
      "  batch 901 loss: 0.1377824072726071\n",
      "  batch 911 loss: 0.12240502745844424\n",
      "  batch 921 loss: 0.05770151866599917\n",
      "  batch 931 loss: 0.03847510484047234\n",
      "  batch 941 loss: 0.005615107831545174\n",
      "  batch 951 loss: 0.0037089900812134146\n",
      "  batch 961 loss: 0.002321924013085663\n",
      "  batch 971 loss: 0.024651157908374445\n",
      "  batch 981 loss: 0.07026527673006058\n",
      "  batch 991 loss: 0.057002369314432144\n",
      "  batch 1001 loss: 0.028587526688352228\n",
      "  batch 1011 loss: 0.07172878962010146\n",
      "  batch 1021 loss: 0.0396287681767717\n",
      "  batch 1031 loss: 0.0456041032448411\n",
      "  batch 1041 loss: 0.06320269641000778\n",
      "LOSS train 0.06320269641000778 valid 3.846433162689209\n",
      "EPOCH 3:\n",
      "  batch 1 loss: 0.021434128284454346\n",
      "  batch 11 loss: 0.05276574743911624\n",
      "  batch 21 loss: 0.06327738463878632\n",
      "  batch 31 loss: 0.026077858917415143\n",
      "  batch 41 loss: 0.014204119192436337\n",
      "  batch 51 loss: 0.005912562250159681\n",
      "  batch 61 loss: 0.006017147179227323\n",
      "  batch 71 loss: 0.0018893940199632198\n",
      "  batch 81 loss: 0.0015300357335945591\n",
      "  batch 91 loss: 0.0034822917397832496\n",
      "  batch 101 loss: 0.02669448866508901\n",
      "  batch 111 loss: 0.06343821212649345\n",
      "  batch 121 loss: 0.028096250863745807\n",
      "  batch 131 loss: 0.011693520518019796\n",
      "  batch 141 loss: 0.016868560423608868\n",
      "  batch 151 loss: 0.008410633335006423\n",
      "  batch 161 loss: 0.058572854427620766\n",
      "  batch 171 loss: 0.04163968563079834\n",
      "  batch 181 loss: 0.033486451813951136\n",
      "  batch 191 loss: 0.08114591301418841\n",
      "  batch 201 loss: 0.03319248408079147\n",
      "  batch 211 loss: 0.017919063987210392\n",
      "  batch 221 loss: 0.006756538536865264\n",
      "  batch 231 loss: 0.003758174169342965\n",
      "  batch 241 loss: 0.0008328067080583424\n",
      "  batch 251 loss: 0.0009596341085853055\n",
      "  batch 261 loss: 0.0010586184311250691\n",
      "  batch 271 loss: 0.016129160509444775\n",
      "  batch 281 loss: 0.034882455691695215\n",
      "  batch 291 loss: 0.020034139044582844\n",
      "  batch 301 loss: 0.022361876326613128\n",
      "  batch 311 loss: 0.10577227822504938\n",
      "  batch 321 loss: 0.04841558001935482\n",
      "  batch 331 loss: 0.05563643572386354\n",
      "  batch 341 loss: 0.10090167759917676\n",
      "  batch 351 loss: 0.05080132586881518\n",
      "  batch 361 loss: 0.482184390258044\n",
      "  batch 371 loss: 0.5841804758645595\n",
      "  batch 381 loss: 0.2286409421823919\n",
      "  batch 391 loss: 0.2648524668067694\n",
      "  batch 401 loss: 0.12136187843279914\n",
      "  batch 411 loss: 0.06034286790527403\n",
      "  batch 421 loss: 0.014248784957453608\n",
      "  batch 431 loss: 0.00487175949383527\n",
      "  batch 441 loss: 0.009257020207587629\n",
      "  batch 451 loss: 0.05478182293009013\n",
      "  batch 461 loss: 0.07014528391882777\n",
      "  batch 471 loss: 0.057712750509381294\n",
      "  batch 481 loss: 0.03155744876712561\n",
      "  batch 491 loss: 0.03038433874025941\n",
      "  batch 501 loss: 0.012103038537316025\n",
      "  batch 511 loss: 0.09601093837991356\n",
      "  batch 521 loss: 0.05299052312038839\n",
      "  batch 531 loss: 0.13057048700284213\n",
      "  batch 541 loss: 0.05705419853329659\n",
      "  batch 551 loss: 0.03476081728003919\n",
      "  batch 561 loss: 0.021947988867759706\n",
      "  batch 571 loss: 0.01268495962722227\n",
      "  batch 581 loss: 0.0077923779492266474\n",
      "  batch 591 loss: 0.0018698041705647484\n",
      "  batch 601 loss: 0.00222461893572472\n",
      "  batch 611 loss: 0.002505319580086507\n",
      "  batch 621 loss: 0.01718749474384822\n",
      "  batch 631 loss: 0.0731818275526166\n",
      "  batch 641 loss: 0.046833605784922835\n",
      "  batch 651 loss: 0.014860864519141615\n",
      "  batch 661 loss: 0.029069044889183715\n",
      "  batch 671 loss: 0.012165487394668162\n",
      "  batch 681 loss: 0.03990593566850294\n",
      "  batch 691 loss: 0.060848761419765654\n",
      "  batch 701 loss: 0.06385334108490497\n",
      "  batch 711 loss: 0.984696039184928\n",
      "  batch 721 loss: 0.49260970843024554\n",
      "  batch 731 loss: 0.15318682752549648\n",
      "  batch 741 loss: 0.1118127878755331\n",
      "  batch 751 loss: 0.045741716271732\n",
      "  batch 761 loss: 0.02917200142983347\n",
      "  batch 771 loss: 0.006386649771593511\n",
      "  batch 781 loss: 0.008973757165949791\n",
      "  batch 791 loss: 0.010260914464015513\n",
      "  batch 801 loss: 0.056588978692889216\n",
      "  batch 811 loss: 0.03535958472639322\n",
      "  batch 821 loss: 0.03423090274445713\n",
      "  batch 831 loss: 0.0670096518471837\n",
      "  batch 841 loss: 0.10943296421319246\n",
      "  batch 851 loss: 0.056344253150746225\n",
      "  batch 861 loss: 0.08150867340154946\n",
      "  batch 871 loss: 0.05585418019909412\n",
      "  batch 881 loss: 0.02739614681340754\n",
      "  batch 891 loss: 0.019898655265569686\n",
      "  batch 901 loss: 0.009849232132546603\n",
      "  batch 911 loss: 0.005685910582542419\n",
      "  batch 921 loss: 0.002313879079883918\n",
      "  batch 931 loss: 0.0028236315003596245\n",
      "  batch 941 loss: 0.001359710536780767\n",
      "  batch 951 loss: 0.0008390902410610579\n",
      "  batch 961 loss: 0.0008501806660206057\n",
      "  batch 971 loss: 0.014040352819574765\n",
      "  batch 981 loss: 0.03936568687204271\n",
      "  batch 991 loss: 0.018726021319162102\n",
      "  batch 1001 loss: 0.04536925386637449\n",
      "  batch 1011 loss: 0.04635528004728258\n",
      "  batch 1021 loss: 0.021626697498140855\n",
      "  batch 1031 loss: 0.008704361703712494\n",
      "  batch 1041 loss: 0.012181615037843586\n",
      "LOSS train 0.012181615037843586 valid 3.7563045024871826\n",
      "EPOCH 4:\n",
      "  batch 1 loss: 0.013533103466033935\n",
      "  batch 11 loss: 0.032656860165297986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 21 loss: 0.022157061472535135\n",
      "  batch 31 loss: 0.013926070462912322\n",
      "  batch 41 loss: 0.005900491602369584\n",
      "  batch 51 loss: 0.001963285333476961\n",
      "  batch 61 loss: 0.0028009775327518583\n",
      "  batch 71 loss: 0.0011555030068848282\n",
      "  batch 81 loss: 0.0011010069923941047\n",
      "  batch 91 loss: 0.002496063862054143\n",
      "  batch 101 loss: 0.02865811815718189\n",
      "  batch 111 loss: 0.06418613004498183\n",
      "  batch 121 loss: 0.030088707990944385\n",
      "  batch 131 loss: 0.029109309846535324\n",
      "  batch 141 loss: 0.015604101470671594\n",
      "  batch 151 loss: 0.0036773117855773306\n",
      "  batch 161 loss: 0.02082880727830343\n",
      "  batch 171 loss: 0.01753796208940912\n",
      "  batch 181 loss: 0.03250947707565501\n",
      "  batch 191 loss: 0.018273625546135007\n",
      "  batch 201 loss: 0.012113772204611451\n",
      "  batch 211 loss: 0.019446222530677914\n",
      "  batch 221 loss: 0.00906983760651201\n",
      "  batch 231 loss: 0.004608506805379875\n",
      "  batch 241 loss: 0.0028406723809894173\n",
      "  batch 251 loss: 0.0006927587557584048\n",
      "  batch 261 loss: 0.0010074058183818125\n",
      "  batch 271 loss: 0.012067234006826766\n",
      "  batch 281 loss: 0.032325856504030526\n",
      "  batch 291 loss: 0.014211427513509988\n",
      "  batch 301 loss: 0.031176650291308762\n",
      "  batch 311 loss: 0.05404859313275665\n",
      "  batch 321 loss: 0.024955419381149112\n",
      "  batch 331 loss: 0.015711646946147084\n",
      "  batch 341 loss: 0.025808676658198238\n",
      "  batch 351 loss: 0.03541978282155469\n",
      "  batch 361 loss: 0.25574087966233494\n",
      "  batch 371 loss: 0.3690913422033191\n",
      "  batch 381 loss: 0.37557478905655445\n",
      "  batch 391 loss: 0.141758787445724\n",
      "  batch 401 loss: 0.05430537075735629\n",
      "  batch 411 loss: 0.021968154166825116\n",
      "  batch 421 loss: 0.016888079000636935\n",
      "  batch 431 loss: 0.0064842695253901185\n",
      "  batch 441 loss: 0.008542009326629341\n",
      "  batch 451 loss: 0.019882208411581816\n",
      "  batch 461 loss: 0.024252634856384247\n",
      "  batch 471 loss: 0.028644504334079102\n",
      "  batch 481 loss: 0.0702973437961191\n",
      "  batch 491 loss: 0.04731035782024264\n",
      "  batch 501 loss: 0.015647000772878526\n",
      "  batch 511 loss: 0.008557405590545386\n",
      "  batch 521 loss: 0.010766837140545249\n",
      "  batch 531 loss: 0.07303199865855277\n",
      "  batch 541 loss: 0.012269435822963715\n",
      "  batch 551 loss: 0.012889619125053287\n",
      "  batch 561 loss: 0.016226147790439426\n",
      "  batch 571 loss: 0.008358020789455623\n",
      "  batch 581 loss: 0.0043018236639909445\n",
      "  batch 591 loss: 0.002546972472919151\n",
      "  batch 601 loss: 0.0005503501481143758\n",
      "  batch 611 loss: 0.001204268471337855\n",
      "  batch 621 loss: 0.01453460251505021\n",
      "  batch 631 loss: 0.07897567064501346\n",
      "  batch 641 loss: 0.036121506709605455\n",
      "  batch 651 loss: 0.007317325181793422\n",
      "  batch 661 loss: 0.010363578796386719\n",
      "  batch 671 loss: 0.002983458832022734\n",
      "  batch 681 loss: 0.01860528846445959\n",
      "  batch 691 loss: 0.02581176091916859\n",
      "  batch 701 loss: 0.047022719687083735\n",
      "  batch 711 loss: 0.610342625528574\n",
      "  batch 721 loss: 0.7806032359600067\n",
      "  batch 731 loss: 0.9259720042347908\n",
      "  batch 741 loss: 0.43124859109520913\n",
      "  batch 751 loss: 0.31561668645590546\n",
      "  batch 761 loss: 0.2581433614715934\n",
      "  batch 771 loss: 0.07611102201044559\n",
      "  batch 781 loss: 0.0675746461842209\n",
      "  batch 791 loss: 0.021888134302571416\n",
      "  batch 801 loss: 0.04178437795490027\n",
      "  batch 811 loss: 0.027841760544106364\n",
      "  batch 821 loss: 0.06438473688904196\n",
      "  batch 831 loss: 0.19329094630666077\n",
      "  batch 841 loss: 0.19786860924214125\n",
      "  batch 851 loss: 0.09252389972098171\n",
      "  batch 861 loss: 0.29936228413134813\n",
      "  batch 871 loss: 0.1646509362384677\n",
      "  batch 881 loss: 0.05280990045284852\n",
      "  batch 891 loss: 0.06334984265267848\n",
      "  batch 901 loss: 0.029610279481858015\n",
      "  batch 911 loss: 0.007242085493635387\n",
      "  batch 921 loss: 0.01301088014151901\n",
      "  batch 931 loss: 0.0035430914955213665\n",
      "  batch 941 loss: 0.005364861679845489\n",
      "  batch 951 loss: 0.004651299130637198\n",
      "  batch 961 loss: 0.003342223126674071\n",
      "  batch 971 loss: 0.02305613493663259\n",
      "  batch 981 loss: 0.032872857293114066\n",
      "  batch 991 loss: 0.02182639972306788\n",
      "  batch 1001 loss: 0.042178867507027464\n",
      "  batch 1011 loss: 0.0440900647547096\n",
      "  batch 1021 loss: 0.017667727591469885\n",
      "  batch 1031 loss: 0.04675904207397252\n",
      "  batch 1041 loss: 0.059516599494963886\n",
      "LOSS train 0.059516599494963886 valid 3.709750175476074\n",
      "EPOCH 5:\n",
      "  batch 1 loss: 0.0036588162183761597\n",
      "  batch 11 loss: 0.017580635286867617\n",
      "  batch 21 loss: 0.022691048495471478\n",
      "  batch 31 loss: 0.004022281602374278\n",
      "  batch 41 loss: 0.0026946172933094204\n",
      "  batch 51 loss: 0.0017632094502914696\n",
      "  batch 61 loss: 0.0029463460203260185\n",
      "  batch 71 loss: 0.002562652510823682\n",
      "  batch 81 loss: 0.002114824022282846\n",
      "  batch 91 loss: 0.004033524065744132\n",
      "  batch 101 loss: 0.02584701939485967\n",
      "  batch 111 loss: 0.02829622817225754\n",
      "  batch 121 loss: 0.010555475554428994\n",
      "  batch 131 loss: 0.02891988371848129\n",
      "  batch 141 loss: 0.02580243374686688\n",
      "  batch 151 loss: 0.022289301082491875\n",
      "  batch 161 loss: 0.06567507642321288\n",
      "  batch 171 loss: 0.029914244054816665\n",
      "  batch 181 loss: 0.021061336051207035\n",
      "  batch 191 loss: 0.0322281954344362\n",
      "  batch 201 loss: 0.011522813374176622\n",
      "  batch 211 loss: 0.0038857048028148712\n",
      "  batch 221 loss: 0.0033026831690222023\n",
      "  batch 231 loss: 0.0020613801607396454\n",
      "  batch 241 loss: 0.0010339671309338883\n",
      "  batch 251 loss: 0.0010690232913475484\n",
      "  batch 261 loss: 0.0012467961612856015\n",
      "  batch 271 loss: 0.012588359581422992\n",
      "  batch 281 loss: 0.014301416138187051\n",
      "  batch 291 loss: 0.018456612061709166\n",
      "  batch 301 loss: 0.05637954140547663\n",
      "  batch 311 loss: 0.09302514186128974\n",
      "  batch 321 loss: 0.026565720234066247\n",
      "  batch 331 loss: 0.06773909330368041\n",
      "  batch 341 loss: 0.10878118129912764\n",
      "  batch 351 loss: 0.08135678854305298\n",
      "  batch 361 loss: 0.41155460979789493\n",
      "  batch 371 loss: 0.33169592544436455\n",
      "  batch 381 loss: 0.18300711158663036\n",
      "  batch 391 loss: 0.08252422250807286\n",
      "  batch 401 loss: 0.04612386333756149\n",
      "  batch 411 loss: 0.010222455358598382\n",
      "  batch 421 loss: 0.006664007634390146\n",
      "  batch 431 loss: 0.0027361433720216157\n",
      "  batch 441 loss: 0.007580461900215596\n",
      "  batch 451 loss: 0.06639722817344591\n",
      "  batch 461 loss: 0.06763332355767489\n",
      "  batch 471 loss: 0.06705661322921515\n",
      "  batch 481 loss: 0.11749591082334518\n",
      "  batch 491 loss: 0.06616921648383141\n",
      "  batch 501 loss: 0.0463163124397397\n",
      "  batch 511 loss: 0.1619550885632634\n",
      "  batch 521 loss: 0.07564515597186983\n",
      "  batch 531 loss: 0.051232424844056365\n",
      "  batch 541 loss: 0.03259827769361436\n",
      "  batch 551 loss: 0.03091715006157756\n",
      "  batch 561 loss: 0.02986915500368923\n",
      "  batch 571 loss: 0.010846090235281736\n",
      "  batch 581 loss: 0.008432225207798183\n",
      "  batch 591 loss: 0.0051174787455238405\n",
      "  batch 601 loss: 0.004819764138665051\n",
      "  batch 611 loss: 0.0015407216502353548\n",
      "  batch 621 loss: 0.00805356178607326\n",
      "  batch 631 loss: 0.01582104850676842\n",
      "  batch 641 loss: 0.009416207228787244\n",
      "  batch 651 loss: 0.04603378539904952\n",
      "  batch 661 loss: 0.04706917223520577\n",
      "  batch 671 loss: 0.03234225243795663\n",
      "  batch 681 loss: 0.04868937148712575\n",
      "  batch 691 loss: 0.05217654863372445\n",
      "  batch 701 loss: 0.14533152689691634\n",
      "  batch 711 loss: 0.9522883661091328\n",
      "  batch 721 loss: 0.647725211083889\n",
      "  batch 731 loss: 0.23590436168015003\n",
      "  batch 741 loss: 0.2612674545496702\n",
      "  batch 751 loss: 0.07700728722847998\n",
      "  batch 761 loss: 0.029645261773839592\n",
      "  batch 771 loss: 0.016322661889716983\n",
      "  batch 781 loss: 0.003444855159614235\n",
      "  batch 791 loss: 0.004033379850443453\n",
      "  batch 801 loss: 0.012190706515684723\n",
      "  batch 811 loss: 0.006558445212431252\n",
      "  batch 821 loss: 0.03387861019000411\n",
      "  batch 831 loss: 0.03661403802689165\n",
      "  batch 841 loss: 0.02268039220944047\n",
      "  batch 851 loss: 0.012900784169323743\n",
      "  batch 861 loss: 0.04315456254407764\n",
      "  batch 871 loss: 0.040003817179240286\n",
      "  batch 881 loss: 0.10904217376373708\n",
      "  batch 891 loss: 0.029834889294579624\n",
      "  batch 901 loss: 0.030167615273967385\n",
      "  batch 911 loss: 0.018281508609652518\n",
      "  batch 921 loss: 0.015325889829546213\n",
      "  batch 931 loss: 0.012225049990229308\n",
      "  batch 941 loss: 0.005011662736069411\n",
      "  batch 951 loss: 0.004008930805139243\n",
      "  batch 961 loss: 0.002489853257429786\n",
      "  batch 971 loss: 0.011617174604907632\n",
      "  batch 981 loss: 0.021097208722494543\n",
      "  batch 991 loss: 0.0280719303060323\n",
      "  batch 1001 loss: 0.061234147785580714\n",
      "  batch 1011 loss: 0.03182576037943363\n",
      "  batch 1021 loss: 0.03460525944828987\n",
      "  batch 1031 loss: 0.09496474070474506\n",
      "  batch 1041 loss: 0.08142050132155418\n",
      "LOSS train 0.08142050132155418 valid 3.576242208480835\n",
      "EPOCH 6:\n",
      "  batch 1 loss: 0.005167391896247864\n",
      "  batch 11 loss: 0.08198221323546022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 21 loss: 0.0526805798523128\n",
      "  batch 31 loss: 0.031799664907157424\n",
      "  batch 41 loss: 0.044718948751688005\n",
      "  batch 51 loss: 0.01078072835225612\n",
      "  batch 61 loss: 0.004209500132128596\n",
      "  batch 71 loss: 0.004889599315356463\n",
      "  batch 81 loss: 0.0024053539149463178\n",
      "  batch 91 loss: 0.004378106415970251\n",
      "  batch 101 loss: 0.00997951765311882\n",
      "  batch 111 loss: 0.00569124601315707\n",
      "  batch 121 loss: 0.015465011401101948\n",
      "  batch 131 loss: 0.06566890473477542\n",
      "  batch 141 loss: 0.03685456831008196\n",
      "  batch 151 loss: 0.014562756568193436\n",
      "  batch 161 loss: 0.05754876341670752\n",
      "  batch 171 loss: 0.04630758473649621\n",
      "  batch 181 loss: 0.04087518014712259\n",
      "  batch 191 loss: 0.05683742193505168\n",
      "  batch 201 loss: 0.05437297970056534\n",
      "  batch 211 loss: 0.038644682709127666\n",
      "  batch 221 loss: 0.023133251094259323\n",
      "  batch 231 loss: 0.007381812972016633\n",
      "  batch 241 loss: 0.00578883730340749\n",
      "  batch 251 loss: 0.004177649243501946\n",
      "  batch 261 loss: 0.0016481579921673983\n",
      "  batch 271 loss: 0.006202278361888603\n",
      "  batch 281 loss: 0.005560542282182723\n",
      "  batch 291 loss: 0.009200953808613122\n",
      "  batch 301 loss: 0.03565246313810348\n",
      "  batch 311 loss: 0.021375560015439988\n",
      "  batch 321 loss: 0.021420205564936623\n",
      "  batch 331 loss: 0.009272268658969551\n",
      "  batch 341 loss: 0.008985232544364407\n",
      "  batch 351 loss: 0.027330096976947972\n",
      "  batch 361 loss: 0.13156347055919468\n",
      "  batch 371 loss: 0.04943222403526306\n",
      "  batch 381 loss: 0.015629929571878164\n",
      "  batch 391 loss: 0.016883572237566112\n",
      "  batch 401 loss: 0.005495965341106057\n",
      "  batch 411 loss: 0.0031604176154360177\n",
      "  batch 421 loss: 0.002103985007852316\n",
      "  batch 431 loss: 0.0015118006325792522\n",
      "  batch 441 loss: 0.003958667500410229\n",
      "  batch 451 loss: 0.009769479418173433\n",
      "  batch 461 loss: 0.005169720656704157\n",
      "  batch 471 loss: 0.02483042985550128\n",
      "  batch 481 loss: 0.03506584500428289\n",
      "  batch 491 loss: 0.029159770923433824\n",
      "  batch 501 loss: 0.018266968859825282\n",
      "  batch 511 loss: 0.021838011359795927\n",
      "  batch 521 loss: 0.03268537721596658\n",
      "  batch 531 loss: 0.025142685312312098\n",
      "  batch 541 loss: 0.01723274525720626\n",
      "  batch 551 loss: 0.013688440888654441\n",
      "  batch 561 loss: 0.012628815416246653\n",
      "  batch 571 loss: 0.011813626356888563\n",
      "  batch 581 loss: 0.005369816123857163\n",
      "  batch 591 loss: 0.0027779766387538984\n",
      "  batch 601 loss: 0.0032407889899332075\n",
      "  batch 611 loss: 0.0024451367266010494\n",
      "  batch 621 loss: 0.007967958351946436\n",
      "  batch 631 loss: 0.01584157090401277\n",
      "  batch 641 loss: 0.011749617615714669\n",
      "  batch 651 loss: 0.04219112943392247\n",
      "  batch 661 loss: 0.03865426681004465\n",
      "  batch 671 loss: 0.020563586964271963\n",
      "  batch 681 loss: 0.03305533756501973\n",
      "  batch 691 loss: 0.039585847733542325\n",
      "  batch 701 loss: 0.11259062553872354\n",
      "  batch 711 loss: 0.8586217341944575\n",
      "  batch 721 loss: 0.21524778716266155\n",
      "  batch 731 loss: 0.22296194015070797\n",
      "  batch 741 loss: 0.11336287665180862\n",
      "  batch 751 loss: 0.056708638556301594\n",
      "  batch 761 loss: 0.017482022743206472\n",
      "  batch 771 loss: 0.012231706106103957\n",
      "  batch 781 loss: 0.00419975402764976\n",
      "  batch 791 loss: 0.006166498965467326\n",
      "  batch 801 loss: 0.012284830631688236\n",
      "  batch 811 loss: 0.007150278287008404\n",
      "  batch 821 loss: 0.018980398355051876\n",
      "  batch 831 loss: 0.017009137687273322\n",
      "  batch 841 loss: 0.018063965160399674\n",
      "  batch 851 loss: 0.00331890054512769\n",
      "  batch 861 loss: 0.03136519973631948\n",
      "  batch 871 loss: 0.035921171843074265\n",
      "  batch 881 loss: 0.1664070982427802\n",
      "  batch 891 loss: 0.0403789984062314\n",
      "  batch 901 loss: 0.026699869893491268\n",
      "  batch 911 loss: 0.01433778622886166\n",
      "  batch 921 loss: 0.010626653244253248\n",
      "  batch 931 loss: 0.004172516288235784\n",
      "  batch 941 loss: 0.002174082168494351\n",
      "  batch 951 loss: 0.002154903145856224\n",
      "  batch 961 loss: 0.0024073311797110364\n",
      "  batch 971 loss: 0.014300457283388824\n",
      "  batch 981 loss: 0.0399697529617697\n",
      "  batch 991 loss: 0.044115090183913706\n",
      "  batch 1001 loss: 0.0611343122087419\n",
      "  batch 1011 loss: 0.04505140036344528\n",
      "  batch 1021 loss: 0.027715741749852897\n",
      "  batch 1031 loss: 0.09847794529050588\n",
      "  batch 1041 loss: 0.09091396676376462\n",
      "LOSS train 0.09091396676376462 valid 3.6231439113616943\n",
      "EPOCH 7:\n",
      "  batch 1 loss: 0.02160649746656418\n",
      "  batch 11 loss: 0.15425475030206143\n",
      "  batch 21 loss: 0.08526378518436104\n",
      "  batch 31 loss: 0.052063626749441025\n",
      "  batch 41 loss: 0.05953251360915601\n",
      "  batch 51 loss: 0.01614001392154023\n",
      "  batch 61 loss: 0.007861759699881076\n",
      "  batch 71 loss: 0.005987826082855463\n",
      "  batch 81 loss: 0.0022180395637406035\n",
      "  batch 91 loss: 0.0024142077134456487\n",
      "  batch 101 loss: 0.00930676432326436\n",
      "  batch 111 loss: 0.008416901214513928\n",
      "  batch 121 loss: 0.015397208323702217\n",
      "  batch 131 loss: 0.05979638928547502\n",
      "  batch 141 loss: 0.033323035854846236\n",
      "  batch 151 loss: 0.005999814730603248\n",
      "  batch 161 loss: 0.03428506643977016\n",
      "  batch 171 loss: 0.020961996429832652\n",
      "  batch 181 loss: 0.020693181175738574\n",
      "  batch 191 loss: 0.012432766915298998\n",
      "  batch 201 loss: 0.010335633245995268\n",
      "  batch 211 loss: 0.013141864212229848\n",
      "  batch 221 loss: 0.012584359187167138\n",
      "  batch 231 loss: 0.003933155519189313\n",
      "  batch 241 loss: 0.00312168572563678\n",
      "  batch 251 loss: 0.0015787433687364683\n",
      "  batch 261 loss: 0.0011509461066452787\n",
      "  batch 271 loss: 0.009835583268431947\n",
      "  batch 281 loss: 0.011668731016106904\n",
      "  batch 291 loss: 0.021545708086341618\n",
      "  batch 301 loss: 0.05115597937256098\n",
      "  batch 311 loss: 0.02977911224588752\n",
      "  batch 321 loss: 0.028389232832705603\n",
      "  batch 331 loss: 0.009860669309273363\n",
      "  batch 341 loss: 0.005397427047137171\n",
      "  batch 351 loss: 0.013719831447815523\n",
      "  batch 361 loss: 0.085656583821401\n",
      "  batch 371 loss: 0.03087861427338794\n",
      "  batch 381 loss: 0.007360602065455168\n",
      "  batch 391 loss: 0.0045181916910223665\n",
      "  batch 401 loss: 0.0016571016167290509\n",
      "  batch 411 loss: 0.0016645088748191484\n",
      "  batch 421 loss: 0.0009279860649257898\n",
      "  batch 431 loss: 0.0007711354730417952\n",
      "  batch 441 loss: 0.003167185683560092\n",
      "  batch 451 loss: 0.01397715883795172\n",
      "  batch 461 loss: 0.011323762196116149\n",
      "  batch 471 loss: 0.022995662596076726\n",
      "  batch 481 loss: 0.046690551040228456\n",
      "  batch 491 loss: 0.013501384691335262\n",
      "  batch 501 loss: 0.0077665680786594745\n",
      "  batch 511 loss: 0.04137806473299861\n",
      "  batch 521 loss: 0.030513883754611015\n",
      "  batch 531 loss: 0.020857624092604964\n",
      "  batch 541 loss: 0.016487931925803424\n",
      "  batch 551 loss: 0.008882495120633393\n",
      "  batch 561 loss: 0.005998159031150863\n",
      "  batch 571 loss: 0.0070540515036555005\n",
      "  batch 581 loss: 0.003645939117996022\n",
      "  batch 591 loss: 0.0017383411119226365\n",
      "  batch 601 loss: 0.001963476803211961\n",
      "  batch 611 loss: 0.0017430716950912028\n",
      "  batch 621 loss: 0.009848731732927263\n",
      "  batch 631 loss: 0.017200913606211544\n",
      "  batch 641 loss: 0.013668668130412698\n",
      "  batch 651 loss: 0.05130422660149634\n",
      "  batch 661 loss: 0.04526269594207406\n",
      "  batch 671 loss: 0.024985910393297672\n",
      "  batch 681 loss: 0.03741695585194975\n",
      "  batch 691 loss: 0.04647022141143679\n",
      "  batch 701 loss: 0.11911105560138821\n",
      "  batch 711 loss: 0.7742268210276961\n",
      "  batch 721 loss: 0.3981474686414003\n",
      "  batch 731 loss: 0.4765389247331768\n",
      "  batch 741 loss: 0.29566261544823647\n",
      "  batch 751 loss: 0.1672603465616703\n",
      "  batch 761 loss: 0.03348752148449421\n",
      "  batch 771 loss: 0.01739297593012452\n",
      "  batch 781 loss: 0.011218635458499193\n",
      "  batch 791 loss: 0.007764923141803592\n",
      "  batch 801 loss: 0.029804795049130917\n",
      "  batch 811 loss: 0.02473005522042513\n",
      "  batch 821 loss: 0.058404180919751525\n",
      "  batch 831 loss: 0.1396550181787461\n",
      "  batch 841 loss: 0.08631953690201044\n",
      "  batch 851 loss: 0.028998222015798093\n",
      "  batch 861 loss: 0.030443480378016828\n",
      "  batch 871 loss: 0.017964103585109116\n",
      "  batch 881 loss: 0.341589561640285\n",
      "  batch 891 loss: 0.24296322800219058\n",
      "  batch 901 loss: 0.12615015087649226\n",
      "  batch 911 loss: 0.0522415864514187\n",
      "  batch 921 loss: 0.01760803076904267\n",
      "  batch 931 loss: 0.007488550757989288\n",
      "  batch 941 loss: 0.005622427223715931\n",
      "  batch 951 loss: 0.0014876059372909366\n",
      "  batch 961 loss: 0.0013421407027635723\n",
      "  batch 971 loss: 0.009481895872158929\n",
      "  batch 981 loss: 0.008724916749633849\n",
      "  batch 991 loss: 0.013382372399792074\n",
      "  batch 1001 loss: 0.038228326337412\n",
      "  batch 1011 loss: 0.020837584557011724\n",
      "  batch 1021 loss: 0.007741359010105952\n",
      "  batch 1031 loss: 0.025156447070185096\n",
      "  batch 1041 loss: 0.024976303963921965\n",
      "LOSS train 0.024976303963921965 valid 3.8679122924804688\n",
      "EPOCH 8:\n",
      "  batch 1 loss: 0.08975131511688232\n",
      "  batch 11 loss: 0.28916360456496476\n",
      "  batch 21 loss: 0.21545961312949657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 31 loss: 0.1964397018775344\n",
      "  batch 41 loss: 0.0625870150513947\n",
      "  batch 51 loss: 0.012990357202943415\n",
      "  batch 61 loss: 0.008232004067394882\n",
      "  batch 71 loss: 0.003607075777836144\n",
      "  batch 81 loss: 0.0035183037281967698\n",
      "  batch 91 loss: 0.005286720732692629\n",
      "  batch 101 loss: 0.005367406597360969\n",
      "  batch 111 loss: 0.0064805703004822135\n",
      "  batch 121 loss: 0.01918066293001175\n",
      "  batch 131 loss: 0.01801814353093505\n",
      "  batch 141 loss: 0.009294932227930985\n",
      "  batch 151 loss: 0.0023148211010266097\n",
      "  batch 161 loss: 0.018619660404510796\n",
      "  batch 171 loss: 0.014190488355234265\n",
      "  batch 181 loss: 0.016008278424851596\n",
      "  batch 191 loss: 0.009568007849156856\n",
      "  batch 201 loss: 0.017743047000840305\n",
      "  batch 211 loss: 0.014749151933938266\n",
      "  batch 221 loss: 0.00657103902194649\n",
      "  batch 231 loss: 0.002120138320606202\n",
      "  batch 241 loss: 0.0016377845022361726\n",
      "  batch 251 loss: 0.0008826199220493436\n",
      "  batch 261 loss: 0.0010320662637241184\n",
      "  batch 271 loss: 0.010373137606075033\n",
      "  batch 281 loss: 0.0086392862489447\n",
      "  batch 291 loss: 0.010362393967807294\n",
      "  batch 301 loss: 0.021310953819192947\n",
      "  batch 311 loss: 0.013852437725290656\n",
      "  batch 321 loss: 0.006286727776750922\n",
      "  batch 331 loss: 0.020344674692023546\n",
      "  batch 341 loss: 0.03724052667384967\n",
      "  batch 351 loss: 0.02803390733897686\n",
      "  batch 361 loss: 0.03425150224938989\n",
      "  batch 371 loss: 0.022671782039105894\n",
      "  batch 381 loss: 0.0468168655410409\n",
      "  batch 391 loss: 0.027409235620871185\n",
      "  batch 401 loss: 0.017113531450740994\n",
      "  batch 411 loss: 0.006525873555801809\n",
      "  batch 421 loss: 0.003275489460793324\n",
      "  batch 431 loss: 0.0016116518061608076\n",
      "  batch 441 loss: 0.0038868317351443693\n",
      "  batch 451 loss: 0.023469084058888257\n",
      "  batch 461 loss: 0.026101687084883453\n",
      "  batch 471 loss: 0.04888613196089864\n",
      "  batch 481 loss: 0.07970332112163306\n",
      "  batch 491 loss: 0.08522318485192955\n",
      "  batch 501 loss: 0.05333923334255815\n",
      "  batch 511 loss: 0.027503367577446626\n",
      "  batch 521 loss: 0.023932820837944745\n",
      "  batch 531 loss: 0.08278010245412588\n",
      "  batch 541 loss: 0.09454084197059273\n",
      "  batch 551 loss: 0.08809089835267514\n",
      "  batch 561 loss: 0.05659163924865425\n",
      "  batch 571 loss: 0.01911603300832212\n",
      "  batch 581 loss: 0.004787978762760758\n",
      "  batch 591 loss: 0.0029776658862829208\n",
      "  batch 601 loss: 0.0025762678356841206\n",
      "  batch 611 loss: 0.0019488468067720532\n",
      "  batch 621 loss: 0.012449896725593134\n",
      "  batch 631 loss: 0.009384461597073823\n",
      "  batch 641 loss: 0.01824536072090268\n",
      "  batch 651 loss: 0.029089673794806002\n",
      "  batch 661 loss: 0.017242430965416132\n",
      "  batch 671 loss: 0.009578438312746584\n",
      "  batch 681 loss: 0.015998435314395466\n",
      "  batch 691 loss: 0.015920154057675974\n",
      "  batch 701 loss: 0.14432325433008372\n",
      "  batch 711 loss: 0.46506029441952706\n",
      "  batch 721 loss: 0.5689393635839224\n",
      "  batch 731 loss: 0.21278487388044595\n",
      "  batch 741 loss: 0.15794412940740585\n",
      "  batch 751 loss: 0.04647438987158239\n",
      "  batch 761 loss: 0.024931191094219686\n",
      "  batch 771 loss: 0.008160549262538553\n",
      "  batch 781 loss: 0.003106043103616685\n",
      "  batch 791 loss: 0.004647966456832364\n",
      "  batch 801 loss: 0.008470775955356658\n",
      "  batch 811 loss: 0.0053154629888013\n",
      "  batch 821 loss: 0.023452796787023545\n",
      "  batch 831 loss: 0.01376744779990986\n",
      "  batch 841 loss: 0.006888511590659618\n",
      "  batch 851 loss: 0.004048459505429492\n",
      "  batch 861 loss: 0.03261651108041406\n",
      "  batch 871 loss: 0.021738377783913167\n",
      "  batch 881 loss: 0.1898431264795363\n",
      "  batch 891 loss: 0.13729156758636235\n",
      "  batch 901 loss: 0.05950819323770702\n",
      "  batch 911 loss: 0.023608642152976245\n",
      "  batch 921 loss: 0.01355744181200862\n",
      "  batch 931 loss: 0.005006389354821295\n",
      "  batch 941 loss: 0.0015818983316421508\n",
      "  batch 951 loss: 0.0020049088052473962\n",
      "  batch 961 loss: 0.0014499704935587942\n",
      "  batch 971 loss: 0.008625581813976168\n",
      "  batch 981 loss: 0.006682114745490253\n",
      "  batch 991 loss: 0.01124880351126194\n",
      "  batch 1001 loss: 0.030925987800583244\n",
      "  batch 1011 loss: 0.013158163847401738\n",
      "  batch 1021 loss: 0.0031217666110023856\n",
      "  batch 1031 loss: 0.027264714741613717\n",
      "  batch 1041 loss: 0.02340685933595523\n",
      "LOSS train 0.02340685933595523 valid 3.7628676891326904\n",
      "EPOCH 9:\n",
      "  batch 1 loss: 0.057114052772521975\n",
      "  batch 11 loss: 0.19937697146087885\n",
      "  batch 21 loss: 0.12961115876678378\n",
      "  batch 31 loss: 0.10000854283571244\n",
      "  batch 41 loss: 0.027818341739475727\n",
      "  batch 51 loss: 0.006345352379139513\n",
      "  batch 61 loss: 0.005597688572015614\n",
      "  batch 71 loss: 0.002358876174548641\n",
      "  batch 81 loss: 0.0015439856273587794\n",
      "  batch 91 loss: 0.00406092320336029\n",
      "  batch 101 loss: 0.0052200992126017805\n",
      "  batch 111 loss: 0.008340603299438953\n",
      "  batch 121 loss: 0.018508541537448762\n",
      "  batch 131 loss: 0.013959382055327296\n",
      "  batch 141 loss: 0.007424076696042903\n",
      "  batch 151 loss: 0.0018544682883657516\n",
      "  batch 161 loss: 0.017262546182610094\n",
      "  batch 171 loss: 0.012340803793631495\n",
      "  batch 181 loss: 0.011832555197179318\n",
      "  batch 191 loss: 0.009154510009102524\n",
      "  batch 201 loss: 0.01740955524146557\n",
      "  batch 211 loss: 0.012388957710936666\n",
      "  batch 221 loss: 0.00450227249530144\n",
      "  batch 231 loss: 0.0011040365236112848\n",
      "  batch 241 loss: 0.0009995657281251624\n",
      "  batch 251 loss: 0.0008243754287832417\n",
      "  batch 261 loss: 0.0007921239535789937\n",
      "  batch 271 loss: 0.008374182376428507\n",
      "  batch 281 loss: 0.007235296885482967\n",
      "  batch 291 loss: 0.008110715763177723\n",
      "  batch 301 loss: 0.015744248940609395\n",
      "  batch 311 loss: 0.007687021838501095\n",
      "  batch 321 loss: 0.0032838318511494435\n",
      "  batch 331 loss: 0.0159144611141528\n",
      "  batch 341 loss: 0.028948064404539765\n",
      "  batch 351 loss: 0.017422694779816082\n",
      "  batch 361 loss: 0.0337779114022851\n",
      "  batch 371 loss: 0.020795316249132157\n",
      "  batch 381 loss: 0.03210491335485131\n",
      "  batch 391 loss: 0.01765292843338102\n",
      "  batch 401 loss: 0.01172317871823907\n",
      "  batch 411 loss: 0.004089566314360127\n",
      "  batch 421 loss: 0.002062859716534149\n",
      "  batch 431 loss: 0.0009671690786490217\n",
      "  batch 441 loss: 0.003865898941876367\n",
      "  batch 451 loss: 0.020606840134132654\n",
      "  batch 461 loss: 0.024177835043519735\n",
      "  batch 471 loss: 0.050007892912253736\n",
      "  batch 481 loss: 0.07116625545313582\n",
      "  batch 491 loss: 0.08293640119954944\n",
      "  batch 501 loss: 0.054065274470485744\n",
      "  batch 511 loss: 0.027301004802575336\n",
      "  batch 521 loss: 0.02526250509545207\n",
      "  batch 531 loss: 0.0625738313421607\n",
      "  batch 541 loss: 0.07607352584600449\n",
      "  batch 551 loss: 0.06607334790751337\n",
      "  batch 561 loss: 0.0359000576660037\n",
      "  batch 571 loss: 0.012467497726902366\n",
      "  batch 581 loss: 0.003385460842400789\n",
      "  batch 591 loss: 0.0019627159461379053\n",
      "  batch 601 loss: 0.0012731756723951548\n",
      "  batch 611 loss: 0.0010962418920826167\n",
      "  batch 621 loss: 0.00871370899840258\n",
      "  batch 631 loss: 0.005603144958149642\n",
      "  batch 641 loss: 0.01416936689056456\n",
      "  batch 651 loss: 0.025305090309120714\n",
      "  batch 661 loss: 0.012385159567929804\n",
      "  batch 671 loss: 0.005859501441591419\n",
      "  batch 681 loss: 0.017106939511722884\n",
      "  batch 691 loss: 0.018274929327890276\n",
      "  batch 701 loss: 0.1585526040289551\n",
      "  batch 711 loss: 0.5164808068424463\n",
      "  batch 721 loss: 0.621959961950779\n",
      "  batch 731 loss: 0.3824788141064346\n",
      "  batch 741 loss: 0.26926610209047797\n",
      "  batch 751 loss: 0.07016802851576358\n",
      "  batch 761 loss: 0.019572440232150257\n",
      "  batch 771 loss: 0.005987326009199023\n",
      "  batch 781 loss: 0.0051187048200517895\n",
      "  batch 791 loss: 0.006160771637223661\n",
      "  batch 801 loss: 0.017180968960747122\n",
      "  batch 811 loss: 0.007047835947014391\n",
      "  batch 821 loss: 0.023289434611797333\n",
      "  batch 831 loss: 0.013989443355239928\n",
      "  batch 841 loss: 0.006596524990163744\n",
      "  batch 851 loss: 0.0034944979241117837\n",
      "  batch 861 loss: 0.03657259633764624\n",
      "  batch 871 loss: 0.017489602393470704\n",
      "  batch 881 loss: 0.16942087835632264\n",
      "  batch 891 loss: 0.13829795017372817\n",
      "  batch 901 loss: 0.05664263376966119\n",
      "  batch 911 loss: 0.027138651022687553\n",
      "  batch 921 loss: 0.007879862771369517\n",
      "  batch 931 loss: 0.003285311034414917\n",
      "  batch 941 loss: 0.0014847183309029787\n",
      "  batch 951 loss: 0.0023021888453513386\n",
      "  batch 961 loss: 0.0013450839149300009\n",
      "  batch 971 loss: 0.006984105857554823\n",
      "  batch 981 loss: 0.004932208219543099\n",
      "  batch 991 loss: 0.00835288017988205\n",
      "  batch 1001 loss: 0.014371860632672906\n",
      "  batch 1011 loss: 0.004694670799653977\n",
      "  batch 1021 loss: 0.0014110089949099347\n",
      "  batch 1031 loss: 0.015544454503105954\n",
      "  batch 1041 loss: 0.014060329867061228\n",
      "LOSS train 0.014060329867061228 valid 3.6858818531036377\n",
      "EPOCH 10:\n",
      "  batch 1 loss: 0.020416146516799925\n",
      "  batch 11 loss: 0.08512822035700082\n",
      "  batch 21 loss: 0.04709902983158827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 31 loss: 0.03181058862246573\n",
      "  batch 41 loss: 0.009023668570443987\n",
      "  batch 51 loss: 0.002065034699626267\n",
      "  batch 61 loss: 0.0026263585314154625\n",
      "  batch 71 loss: 0.001180204446427524\n",
      "  batch 81 loss: 0.0007569867302663624\n",
      "  batch 91 loss: 0.002306951061473228\n",
      "  batch 101 loss: 0.006031109357718378\n",
      "  batch 111 loss: 0.0062348788196686655\n",
      "  batch 121 loss: 0.011645292327739299\n",
      "  batch 131 loss: 0.007041696831583977\n",
      "  batch 141 loss: 0.003149422415299341\n",
      "  batch 151 loss: 0.0016072271406301296\n",
      "  batch 161 loss: 0.013002473872620612\n",
      "  batch 171 loss: 0.010959920147433877\n",
      "  batch 181 loss: 0.007939372188411653\n",
      "  batch 191 loss: 0.007221403019502759\n",
      "  batch 201 loss: 0.015252494299784303\n",
      "  batch 211 loss: 0.010592903289943934\n",
      "  batch 221 loss: 0.00485858540632762\n",
      "  batch 231 loss: 0.0015657728014048188\n",
      "  batch 241 loss: 0.0014883278927300125\n",
      "  batch 251 loss: 0.0010600625944789499\n",
      "  batch 261 loss: 0.0010846409888472408\n",
      "  batch 271 loss: 0.006435127853183076\n",
      "  batch 281 loss: 0.004827773803845048\n",
      "  batch 291 loss: 0.005399784911423922\n",
      "  batch 301 loss: 0.011038295214530081\n",
      "  batch 311 loss: 0.006005688838195055\n",
      "  batch 321 loss: 0.0030531612399499865\n",
      "  batch 331 loss: 0.012253398177563213\n",
      "  batch 341 loss: 0.02344544562511146\n",
      "  batch 351 loss: 0.0163433494977653\n",
      "  batch 361 loss: 0.028328128205612303\n",
      "  batch 371 loss: 0.02604930899105966\n",
      "  batch 381 loss: 0.051743220537900925\n",
      "  batch 391 loss: 0.02172504891641438\n",
      "  batch 401 loss: 0.008087423373945057\n",
      "  batch 411 loss: 0.002496380271622911\n",
      "  batch 421 loss: 0.0006883748312247917\n",
      "  batch 431 loss: 0.001158449100330472\n",
      "  batch 441 loss: 0.003865898681397084\n",
      "  batch 451 loss: 0.02309926520101726\n",
      "  batch 461 loss: 0.026017788983881473\n",
      "  batch 471 loss: 0.04773998432792723\n",
      "  batch 481 loss: 0.06132278311997652\n",
      "  batch 491 loss: 0.04833695790730417\n",
      "  batch 501 loss: 0.02401791946031153\n",
      "  batch 511 loss: 0.04697107784450054\n",
      "  batch 521 loss: 0.03698901609750464\n",
      "  batch 531 loss: 0.06107988511794247\n",
      "  batch 541 loss: 0.04964341018348932\n",
      "  batch 551 loss: 0.03685356035130098\n",
      "  batch 561 loss: 0.017828682821709664\n",
      "  batch 571 loss: 0.006940284627489746\n",
      "  batch 581 loss: 0.002223512809723616\n",
      "  batch 591 loss: 0.0018302145297639072\n",
      "  batch 601 loss: 0.001316505839349702\n",
      "  batch 611 loss: 0.0015775108942762018\n",
      "  batch 621 loss: 0.006344912553322502\n",
      "  batch 631 loss: 0.00491617617662996\n",
      "  batch 641 loss: 0.010841944068670274\n",
      "  batch 651 loss: 0.016274295607581736\n",
      "  batch 661 loss: 0.006892548652831465\n",
      "  batch 671 loss: 0.004231691907625646\n",
      "  batch 681 loss: 0.013007117898087017\n",
      "  batch 691 loss: 0.014845384005457162\n",
      "  batch 701 loss: 0.16378135685808956\n",
      "  batch 711 loss: 0.5241483241319657\n",
      "  batch 721 loss: 0.41533041941002014\n",
      "  batch 731 loss: 0.06898239925503731\n",
      "  batch 741 loss: 0.06980217206291854\n",
      "  batch 751 loss: 0.015562498243525624\n",
      "  batch 761 loss: 0.008095342898741364\n",
      "  batch 771 loss: 0.0027015594183467328\n",
      "  batch 781 loss: 0.001692378963343799\n",
      "  batch 791 loss: 0.0027589475736021995\n",
      "  batch 801 loss: 0.007168761151842773\n",
      "  batch 811 loss: 0.0060487776063382626\n",
      "  batch 821 loss: 0.022108642710372807\n",
      "  batch 831 loss: 0.009463043394498527\n",
      "  batch 841 loss: 0.006652617338113486\n",
      "  batch 851 loss: 0.002531400916632265\n",
      "  batch 861 loss: 0.03525351812131703\n",
      "  batch 871 loss: 0.015623660641722381\n",
      "  batch 881 loss: 0.09018997102975845\n",
      "  batch 891 loss: 0.0762410624884069\n",
      "  batch 901 loss: 0.036249067960307\n",
      "  batch 911 loss: 0.016401880769990385\n",
      "  batch 921 loss: 0.008490925852674991\n",
      "  batch 931 loss: 0.0034154531895183027\n",
      "  batch 941 loss: 0.0014741376973688603\n",
      "  batch 951 loss: 0.0021497692563571037\n",
      "  batch 961 loss: 0.0013884483312722295\n",
      "  batch 971 loss: 0.0069843963487073776\n",
      "  batch 981 loss: 0.0043985501397401094\n",
      "  batch 991 loss: 0.008034858386963606\n",
      "  batch 1001 loss: 0.020866869110614063\n",
      "  batch 1011 loss: 0.008698025194462389\n",
      "  batch 1021 loss: 0.0026595412229653446\n",
      "  batch 1031 loss: 0.019698973713093437\n",
      "  batch 1041 loss: 0.01890832442441024\n",
      "LOSS train 0.01890832442441024 valid 3.6211631298065186\n",
      "EPOCH 11:\n",
      "  batch 1 loss: 0.009159481525421143\n",
      "  batch 11 loss: 0.0543394879437983\n",
      "  batch 21 loss: 0.044098596274852755\n",
      "  batch 31 loss: 0.049940514378249645\n",
      "  batch 41 loss: 0.02227381004486233\n",
      "  batch 51 loss: 0.0035321479314006864\n",
      "  batch 61 loss: 0.0024725863942876456\n",
      "  batch 71 loss: 0.0015557780337985606\n",
      "  batch 81 loss: 0.0008924049208872021\n",
      "  batch 91 loss: 0.0027222459553740918\n",
      "  batch 101 loss: 0.006502711586654187\n",
      "  batch 111 loss: 0.007883927633520216\n",
      "  batch 121 loss: 0.0180026070214808\n",
      "  batch 131 loss: 0.014835123665397987\n",
      "  batch 141 loss: 0.00916448510979535\n",
      "  batch 151 loss: 0.0037822683676495216\n",
      "  batch 161 loss: 0.014332279800146352\n",
      "  batch 171 loss: 0.013572481460869312\n",
      "  batch 181 loss: 0.015806179167702793\n",
      "  batch 191 loss: 0.012006372539326548\n",
      "  batch 201 loss: 0.02418657038360834\n",
      "  batch 211 loss: 0.01629963853629306\n",
      "  batch 221 loss: 0.005750642652856186\n",
      "  batch 231 loss: 0.0010916089406237007\n",
      "  batch 241 loss: 0.0010983225103700534\n",
      "  batch 251 loss: 0.0008622371344245039\n",
      "  batch 261 loss: 0.0008713307077414356\n",
      "  batch 271 loss: 0.007506593220750801\n",
      "  batch 281 loss: 0.006409498141147196\n",
      "  batch 291 loss: 0.006335355961346068\n",
      "  batch 301 loss: 0.016579377301968633\n",
      "  batch 311 loss: 0.0097248918376863\n",
      "  batch 321 loss: 0.004604875658696983\n",
      "  batch 331 loss: 0.018120257183909416\n",
      "  batch 341 loss: 0.03285023234784603\n",
      "  batch 351 loss: 0.036813547182828185\n",
      "  batch 361 loss: 0.05642700563184917\n",
      "  batch 371 loss: 0.0393170353025198\n",
      "  batch 381 loss: 0.07002349579706788\n",
      "  batch 391 loss: 0.0307285527465865\n",
      "  batch 401 loss: 0.01068114226218313\n",
      "  batch 411 loss: 0.0037938992609269917\n",
      "  batch 421 loss: 0.0008379400533158332\n",
      "  batch 431 loss: 0.001463946637522895\n",
      "  batch 441 loss: 0.004249618542962708\n",
      "  batch 451 loss: 0.029828054341487588\n",
      "  batch 461 loss: 0.03330319714732468\n",
      "  batch 471 loss: 0.05013689436018467\n",
      "  batch 481 loss: 0.06522535365074873\n",
      "  batch 491 loss: 0.0506218237336725\n",
      "  batch 501 loss: 0.02093681558035314\n",
      "  batch 511 loss: 0.046981332916766406\n",
      "  batch 521 loss: 0.03164302416844293\n",
      "  batch 531 loss: 0.04383468172454741\n",
      "  batch 541 loss: 0.034038664493709805\n",
      "  batch 551 loss: 0.0316204534843564\n",
      "  batch 561 loss: 0.019791280385106802\n",
      "  batch 571 loss: 0.007528017146978527\n",
      "  batch 581 loss: 0.0022894187830388548\n",
      "  batch 591 loss: 0.0018946903408505022\n",
      "  batch 601 loss: 0.0010812559252372012\n",
      "  batch 611 loss: 0.0010177559306612238\n",
      "  batch 621 loss: 0.008526900183642282\n",
      "  batch 631 loss: 0.006380098516819999\n",
      "  batch 641 loss: 0.015537525882245972\n",
      "  batch 651 loss: 0.02372968140989542\n",
      "  batch 661 loss: 0.011267150088679045\n",
      "  batch 671 loss: 0.006356486841104925\n",
      "  batch 681 loss: 0.01670477375155315\n",
      "  batch 691 loss: 0.018078307854011655\n",
      "  batch 701 loss: 0.1845547162927687\n",
      "  batch 711 loss: 0.5596291996538639\n",
      "  batch 721 loss: 0.7376050233840943\n",
      "  batch 731 loss: 0.21387012917548417\n",
      "  batch 741 loss: 0.20903246980160475\n",
      "  batch 751 loss: 0.029960612393915655\n",
      "  batch 761 loss: 0.023279520124197005\n",
      "  batch 771 loss: 0.013601452857255936\n",
      "  batch 781 loss: 0.006547648226842284\n",
      "  batch 791 loss: 0.005024062911979854\n",
      "  batch 801 loss: 0.008338319230824709\n",
      "  batch 811 loss: 0.005587987042963505\n",
      "  batch 821 loss: 0.023322816006839275\n",
      "  batch 831 loss: 0.009540464403107763\n",
      "  batch 841 loss: 0.0038158656941959636\n",
      "  batch 851 loss: 0.0026151762082008644\n",
      "  batch 861 loss: 0.030417320760898293\n",
      "  batch 871 loss: 0.010394259687745943\n",
      "  batch 881 loss: 0.061080757452873516\n",
      "  batch 891 loss: 0.05965347926830873\n",
      "  batch 901 loss: 0.03550315760076046\n",
      "  batch 911 loss: 0.01720406913664192\n",
      "  batch 921 loss: 0.005646275461185723\n",
      "  batch 931 loss: 0.0027935599093325434\n",
      "  batch 941 loss: 0.0018730984826106577\n",
      "  batch 951 loss: 0.0018756595090962946\n",
      "  batch 961 loss: 0.001432046527042985\n",
      "  batch 971 loss: 0.006635260337498039\n",
      "  batch 981 loss: 0.0040570825804024935\n",
      "  batch 991 loss: 0.0080488940468058\n",
      "  batch 1001 loss: 0.0212472902610898\n",
      "  batch 1011 loss: 0.008708546491106972\n",
      "  batch 1021 loss: 0.0031924116192385554\n",
      "  batch 1031 loss: 0.02433611013984773\n",
      "  batch 1041 loss: 0.021342442976310848\n",
      "LOSS train 0.021342442976310848 valid 3.6143805980682373\n",
      "EPOCH 12:\n",
      "  batch 1 loss: 0.003882637247443199\n",
      "  batch 11 loss: 0.03959192093461752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 21 loss: 0.025606606365181507\n",
      "  batch 31 loss: 0.028871831856667994\n",
      "  batch 41 loss: 0.007897123135626316\n",
      "  batch 51 loss: 0.0023233047570101915\n",
      "  batch 61 loss: 0.002321641438174993\n",
      "  batch 71 loss: 0.0009836506855208428\n",
      "  batch 81 loss: 0.0007028279767837375\n",
      "  batch 91 loss: 0.0025602836831239983\n",
      "  batch 101 loss: 0.007254553999518976\n",
      "  batch 111 loss: 0.008672437793575228\n",
      "  batch 121 loss: 0.020321443281136452\n",
      "  batch 131 loss: 0.015856040338985623\n",
      "  batch 141 loss: 0.006640060036443174\n",
      "  batch 151 loss: 0.004545637283445103\n",
      "  batch 161 loss: 0.024995424889493734\n",
      "  batch 171 loss: 0.018209320935420693\n",
      "  batch 181 loss: 0.013427434861660004\n",
      "  batch 191 loss: 0.014726458839140833\n",
      "  batch 201 loss: 0.02719929567538202\n",
      "  batch 211 loss: 0.015059817815199494\n",
      "  batch 221 loss: 0.007309973007068038\n",
      "  batch 231 loss: 0.002713561407290399\n",
      "  batch 241 loss: 0.0021193387219682336\n",
      "  batch 251 loss: 0.0009737199463415891\n",
      "  batch 261 loss: 0.0012048274977132678\n",
      "  batch 271 loss: 0.009026048082159833\n",
      "  batch 281 loss: 0.007526141428388655\n",
      "  batch 291 loss: 0.007114557834574953\n",
      "  batch 301 loss: 0.018859616946429014\n",
      "  batch 311 loss: 0.010086522001074627\n",
      "  batch 321 loss: 0.004014424374327063\n",
      "  batch 331 loss: 0.02055074512027204\n",
      "  batch 341 loss: 0.03584503550082445\n",
      "  batch 351 loss: 0.028962251218035816\n",
      "  batch 361 loss: 0.054481192119419576\n",
      "  batch 371 loss: 0.02868756917305291\n",
      "  batch 381 loss: 0.05021718624047935\n",
      "  batch 391 loss: 0.02624079119414091\n",
      "  batch 401 loss: 0.004122462274972349\n",
      "  batch 411 loss: 0.003258743177866563\n",
      "  batch 421 loss: 0.0012371502962196246\n",
      "  batch 431 loss: 0.001591972421738319\n",
      "  batch 441 loss: 0.005453065258916467\n",
      "  batch 451 loss: 0.03314312300644815\n",
      "  batch 461 loss: 0.032322244718670845\n",
      "  batch 471 loss: 0.036825679172761736\n",
      "  batch 481 loss: 0.036066817864775655\n",
      "  batch 491 loss: 0.01085565957473591\n",
      "  batch 501 loss: 0.004910293994180392\n",
      "  batch 511 loss: 0.03891998333856463\n",
      "  batch 521 loss: 0.026512429118156433\n",
      "  batch 531 loss: 0.024373266939073802\n",
      "  batch 541 loss: 0.010735636623576284\n",
      "  batch 551 loss: 0.01612482303753495\n",
      "  batch 561 loss: 0.013601153437048197\n",
      "  batch 571 loss: 0.005410795728676021\n",
      "  batch 581 loss: 0.0016303769341902807\n",
      "  batch 591 loss: 0.001478812628192827\n",
      "  batch 601 loss: 0.0009384961158502847\n",
      "  batch 611 loss: 0.0011293085612123833\n",
      "  batch 621 loss: 0.010209114835015498\n",
      "  batch 631 loss: 0.007890929782297463\n",
      "  batch 641 loss: 0.018062091449974105\n",
      "  batch 651 loss: 0.025082517880946398\n",
      "  batch 661 loss: 0.012469075375702233\n",
      "  batch 671 loss: 0.007515190989943221\n",
      "  batch 681 loss: 0.027023181854747235\n",
      "  batch 691 loss: 0.026416608784347772\n",
      "  batch 701 loss: 0.17758608935400844\n",
      "  batch 711 loss: 0.5084504511207342\n",
      "  batch 721 loss: 0.5145827077329159\n",
      "  batch 731 loss: 0.20651644393801688\n",
      "  batch 741 loss: 0.08291439362801611\n",
      "  batch 751 loss: 0.04703247044235468\n",
      "  batch 761 loss: 0.04066977552138269\n",
      "  batch 771 loss: 0.03951336741447449\n",
      "  batch 781 loss: 0.042262165271677074\n",
      "  batch 791 loss: 0.028612996137235315\n",
      "  batch 801 loss: 0.02835235947277397\n",
      "  batch 811 loss: 0.015489272121340037\n",
      "  batch 821 loss: 0.03252503406256437\n",
      "  batch 831 loss: 0.018799779703840613\n",
      "  batch 841 loss: 0.0145040447358042\n",
      "  batch 851 loss: 0.0036515994695946576\n",
      "  batch 861 loss: 0.05327734556049109\n",
      "  batch 871 loss: 0.01669508977793157\n",
      "  batch 881 loss: 0.03440830039326102\n",
      "  batch 891 loss: 0.044767906330525874\n",
      "  batch 901 loss: 0.02423821035772562\n",
      "  batch 911 loss: 0.013393457210622729\n",
      "  batch 921 loss: 0.006466452300082892\n",
      "  batch 931 loss: 0.0038463964592665434\n",
      "  batch 941 loss: 0.0012257847236469388\n",
      "  batch 951 loss: 0.0018483608146198094\n",
      "  batch 961 loss: 0.0013568638416472823\n",
      "  batch 971 loss: 0.006542197894304991\n",
      "  batch 981 loss: 0.005282959411852061\n",
      "  batch 991 loss: 0.009572567057330162\n",
      "  batch 1001 loss: 0.015127897483762354\n",
      "  batch 1011 loss: 0.006104974914342165\n",
      "  batch 1021 loss: 0.001351393734512385\n",
      "  batch 1031 loss: 0.01745247850631131\n",
      "  batch 1041 loss: 0.016287922265473754\n",
      "LOSS train 0.016287922265473754 valid 3.7702372074127197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.5762)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = NN_classes.ObjectiveEstimator_ANN_Single_layer(input_size=tr_in.shape[1],output_size=1)\n",
    "model_2 = NN_classes.ObjectiveEstimator_ANN_3hidden_layer(input_size=tr_in.shape[1],hidden_size1=int(tr_in.shape[1]/4),hidden_size2=int(tr_in.shape[1]/16),hidden_size3=int(tr_in.shape[1]/64),output_size=1)\n",
    "#NN_classes.train_and_get_loss(model_1,tr_in,tr_out,300,0.1,True)\n",
    "#NN_classes.train_and_get_loss(model_2,tr_in,tr_out,1000,0.002,True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.01)\n",
    "\n",
    "training_methods.train_multiple_epochs(3,model_2,training_loader,validation_loader,loss_fn,optimizer_2,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c28e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m e\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[1;32m----> 3\u001b[0m train_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_2\u001b[49m(tr_in\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_predictions\u001b[38;5;241m.\u001b[39mdetach()[s:e],label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(tr_out[s:e],label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "e=200\n",
    "train_predictions = model_2(tr_in.float())\n",
    "plt.plot(train_predictions.detach()[s:e],label = \"Predictions_2\")\n",
    "plt.plot(tr_out[s:e],label = \"Actual\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a35823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c3696e9e40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=24*(200-10)\n",
    "e=24*200\n",
    "test_predictions_1 = model_1(te_in.float())\n",
    "test_predictions_2 = model_2(te_in.float())\n",
    "#plt.plot(test_predictions_1.detach()[s:e],label = \"Predictions_1\")\n",
    "plt.plot(test_predictions_2.detach()[s:e],label = \"Predictions_2\")\n",
    "plt.plot(te_out[s:e],label = \"Actual\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
