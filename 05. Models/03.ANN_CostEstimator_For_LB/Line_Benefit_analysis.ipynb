{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc25a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import DataLoading\n",
    "import NN_classes\n",
    "import NN_evaluation\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b3b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "folder = \"../Data/3-bus_DC_fy/\"\n",
    "\n",
    "all_executions = DataLoading.list_executions(folder=folder,per = period,sc=sc)\n",
    "te_s = 0.3\n",
    "val_s = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865568f9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_f_sc01_Network_Existing_Generation_Full_2030.csv\n",
      "14\n",
      "input_f_sc01_Network_Full_Generation_Full_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_1_Node_2_cac1_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_1_Node_2_cac2_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_1_Node_2_cac3_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_1_Node_3_cac1_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_1_Node_3_cac2_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_1_Node_3_cac3_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_2_Node_3_cac1_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_2_Node_3_cac2_2030.csv\n",
      "14\n",
      "input_f_sc01_PINT_Network_Line_In_Node_2_Node_3_cac3_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_1_Node_2_cac1_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_1_Node_2_cac2_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_1_Node_2_cac3_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_1_Node_3_cac1_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_1_Node_3_cac2_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_1_Node_3_cac3_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_2_Node_3_cac1_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_2_Node_3_cac2_2030.csv\n",
      "14\n",
      "input_f_sc01_TOOT_Network_Line_In_Node_2_Node_3_cac3_2030.csv\n",
      "14\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "join_frames_inter_layer() missing 1 required positional argument: 'executions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dfs_in, dfs_out, dfs_inter \u001b[38;5;241m=\u001b[39m DataLoading\u001b[38;5;241m.\u001b[39mload_data_ext_out(folder, all_executions, period, sc, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPowerFlow\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m dfs_inter_j \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin_frames_inter_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs_inter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dfs_inter_j \u001b[38;5;241m=\u001b[39m DataLoading\u001b[38;5;241m.\u001b[39mtrim_columns_to_common(dfs_inter_j)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert to pytorch tensors\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: join_frames_inter_layer() missing 1 required positional argument: 'executions'"
     ]
    }
   ],
   "source": [
    "dfs_in, dfs_out, dfs_inter = DataLoading.load_data_ext_out(folder, all_executions, period, sc, [\"PowerFlow\"])\n",
    "dfs_inter_j = DataLoading.join_frames_inter_layer(dfs_inter)\n",
    "dfs_inter_j = DataLoading.trim_columns_to_common(dfs_inter_j)\n",
    "# Convert to pytorch tensors\n",
    "ts_in, ts_out, ts_inter = DataLoading.split_tr_val_te_ext_out(dfs_in, dfs_out, dfs_inter_j, all_executions, te_s, val_s)\n",
    "d_ft_in, d_ft_out, d_ft_inter,maxs = DataLoading.concat_and_normalize_ext_out(ts_in, ts_out, ts_inter, all_executions)\n",
    "\n",
    "input_size = dfs_in[\"Network_Existing_Generation_Full\"].shape[1]\n",
    "inter_size = dfs_inter_j[\"Network_Existing_Generation_Full\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9191452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lb_from_dfs_out(dfs_out,execution): \n",
    "    return (dfs_out[\"Network_Existing_Generation_Full\"].sum(axis=1) - dfs_out[execution].sum(axis=1))\n",
    "\n",
    "def calculate_lb_from_ts_out(ts_out,ex):\n",
    "    b= \"Network_Existing_Generation_Full\"\n",
    "    all_ts_out_ex = torch.concat((ts_out[\"train\"][ex],ts_out[\"test\"][ex],ts_out[\"val\"][ex]))\n",
    "    all_ts_out_benchmark = torch.concat((ts_out[\"train\"][b],ts_out[\"test\"][b],ts_out[\"val\"][b]))\n",
    "    return all_ts_out_benchmark-all_ts_out_ex\n",
    "    \n",
    "\n",
    "def find_xthbest_model_params_from_df(df_losses,loss_to_sort,xth_best=1):\n",
    "    return df_losses.sort_values(by =loss_to_sort)[xth_best-1:xth_best]\n",
    "\n",
    "def extract_model_params_from_row(row):\n",
    "    model_type = row.Model_type.item()\n",
    "    model_type = tuple(map(int, model_type.replace(\"(\",\"\").replace(\")\",\"\").split(', ')))\n",
    "    dor = row.Dor.item()\n",
    "    lr = row.Lr.item()\n",
    "    nb_e = row.Epochs.item()\n",
    "\n",
    "    relu_out = row.Relu_out.item()\n",
    "    np =row.Np.item()\n",
    "    bs = row.Batch_size.item()\n",
    "    alpha = row.alpha.item()\n",
    "    MAE = row.MAE.item()\n",
    "    \n",
    "    return {\"Model_type\": model_type,\"nb_e\":nb_e,\"lr\":lr,\"dor\":dor,\"np\":np,\"ro\":relu_out,\"bs\":bs,\"alpha\":alpha,\"MAE\":MAE}\n",
    "    \n",
    "\n",
    "def create_model_and_load_state_from_row(row,input_size,inter_size,hyperloop_name,cluster_run = True):\n",
    "    #First, extract params from row\n",
    "    \n",
    "    model_type = row.Model_type.item()\n",
    "    model_type = tuple(map(int, model_type.replace(\"(\",\"\").replace(\")\",\"\").split(', ')))\n",
    "    dor = row.Dor.item()\n",
    "    lr = row.Lr.item()\n",
    "    nb_e = row.Epochs.item()\n",
    "\n",
    "    relu_out = row.Relu_out.item()\n",
    "    np =row.Np.item()\n",
    "    bs = row.Batch_size.item()\n",
    "    alpha = row.alpha.item()\n",
    "    MAE = row.MAE.item()\n",
    "    \n",
    "    if str(alpha) == \"0.0\": \n",
    "        alpha = \"0\"\n",
    "\n",
    "    if row.Min_val.item(): \n",
    "        mt = \"min_val\"\n",
    "    else: \n",
    "        mt = \"all_epochs\"\n",
    "    \n",
    "    #Then create model of given type\n",
    "    m = NN_classes.create_model(model_type,input_size, dropout_ratio= dor,relu_out =relu_out,inter=True,inter_size=inter_size)\n",
    "    \n",
    "    #Finally, extract model state from dict\n",
    "    \n",
    "    #m_name = f\"OE_{model_type}h_{nb_e}e_{lr}lr_{dor}dor_{np}np_{relu_out}_ro_{bs}bs\"\n",
    "    m_name = f\"OE_{model_type}h_{nb_e}e_{lr}lr_{dor}dor_{np}np_{relu_out}ro_{bs}bs_{alpha}ill_{MAE}MAE\"\n",
    "\n",
    "    if cluster_run:\n",
    "        #m_name = f\"OE_{model_type}h_{nb_e}e_{lr}lr_{dor}dor_{np}np_{relu_out}_ro_{bs}bs\"\n",
    "        path = f\"ResultsClusterRuns/trained_models/{hyperloop_name}/{mt}/model_{m_name}.pth\"\n",
    "    else:\n",
    "        path = f\"trained_models/{hyperloop_name}/{mt}/model_{m_name}.pth\"\n",
    "\n",
    "    m.load_state_dict(torch.load(path))\n",
    "    m.eval()\n",
    "    \n",
    "    return m\n",
    "def get_lb_est_and_actual(m,ex,dfs_in,dfs_out): \n",
    "    negf = all_executions[0]\n",
    "    ex_in_e = torch.nan_to_num(dfs_in[ex].to_numpy()/maxs[\"in\"])\n",
    "    ex_in_negf = torch.nan_to_num(dfs_in[negf].to_numpy()/maxs[\"in\"])\n",
    "\n",
    "    prediction_e = m(ex_in_e.float())[0].detach().numpy()\n",
    "    prediction_negf = m(ex_in_negf.float())[0].detach().numpy()\n",
    "\n",
    "    lb_est = prediction_negf- prediction_e\n",
    "    lb_actual = calculate_lb_from_dfs_out(dfs_out,ex).to_numpy()\n",
    "    return lb_est.flatten(),lb_actual.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95264dac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ResultsClusterRuns/Loss_results_csv/9n_AC_12w_dummy_0.3_v0.4_PF_LCOE_0_13.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m hyperloop_name \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-bus_AC_12w_dummy_0.3_v0.4_PF_LCOE_0_10\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m hyperloop_name \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9n_AC_12w_dummy_0.3_v0.4_PF_LCOE_0_13\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m df_losses \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResultsClusterRuns/Loss_results_csv/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhyperloop_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#df_losses = pd.read_csv(f\"Loss_results_csv/{hyperloop_name}.csv\",index_col=0)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m f \u001b[38;5;241m=\u001b[39m df_losses\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ResultsClusterRuns/Loss_results_csv/9n_AC_12w_dummy_0.3_v0.4_PF_LCOE_0_13.csv'"
     ]
    }
   ],
   "source": [
    "#Counting ocurences of negative and positive values for all execs: \n",
    "#hyperloop_name = \"RTS24_AC_12w_dummy_0.3_v0.4_PF_sa_rand_0_40\"\n",
    "hyperloop_name =\"3-bus_AC_12w_dummy_0.3_v0.4_PF_LCOE_0_10\"\n",
    "hyperloop_name =\"9n_AC_12w_dummy_0.3_v0.4_PF_LCOE_0_13\"\n",
    "df_losses = pd.read_csv(f\"ResultsClusterRuns/Loss_results_csv/{hyperloop_name}.csv\",index_col=0)\n",
    "#df_losses = pd.read_csv(f\"Loss_results_csv/{hyperloop_name}.csv\",index_col=0)\n",
    "\n",
    "f = df_losses.alpha ==0.0\n",
    "\n",
    "loss_to_sort = \"Te_l_t_mse\"\n",
    "\n",
    "xth_best = 1\n",
    "row = NN_evaluation.find_xthbest_model_params_from_df(df_losses[f],loss_to_sort,xth_best)\n",
    "m = NN_evaluation.create_model_and_load_state_from_row(row,input_size,inter_size,hyperloop_name,cluster_run=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f09846a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m all_counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m all_executions:\n\u001b[1;32m----> 6\u001b[0m     lb_est,lb_actual \u001b[38;5;241m=\u001b[39m NN_evaluation\u001b[38;5;241m.\u001b[39mget_lb_est_and_actual(\u001b[43mm\u001b[49m,ex,dfs_in,dfs_out,all_executions,maxs)\n\u001b[0;32m      8\u001b[0m     both_positive_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((lb_est \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (lb_actual \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      9\u001b[0m     both_negative_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((lb_est \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (lb_actual \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "ex = all_executions[0]\n",
    "\n",
    "all_counts = pd.DataFrame()\n",
    "for ex in all_executions:\n",
    "    lb_est,lb_actual = NN_evaluation.get_lb_est_and_actual(m,ex,dfs_in,dfs_out,all_executions,maxs)\n",
    "\n",
    "    both_positive_count = np.sum((lb_est > 0) & (lb_actual > 0))\n",
    "    both_negative_count = np.sum((lb_est < 0) & (lb_actual < 0))\n",
    "    opposite_sign_count = np.sum((lb_est * lb_actual) < 0)\n",
    "    BZ = np.sum((lb_est==0) & (lb_actual == 0))\n",
    "    OZ = np.sum((lb_est * lb_actual) == 0)\n",
    "\n",
    "\n",
    "    row_lb = pd.DataFrame({\"exec\":ex,\"BP\":both_positive_count, \"BN\":both_negative_count,\"OS\":opposite_sign_count,\"OZ\":OZ,\"BZ\":BZ,}, index = [i])\n",
    "    all_counts = pd.concat([all_counts,row_lb],axis=0)\n",
    "    i+=1\n",
    "plt.bar(height = [both_positive_count,both_negative_count,opposite_sign_count],x=[0,1,2],xlabels =[\"both_positive\",\"both_negative\",\"Opposite sign\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db83eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd = model_params_dict = extract_model_params_from_row(row)\n",
    "keys = [\"Model_type\",\"nb_e\",\"lr\",\"dor\",\"np\",\"ro\",\"bs\",\"alpha\",\"MAE\"]\n",
    "name = f\"sign_counts_{mpd[keys[0]]}h_{mpd[keys[1]]}e_{mpd[keys[2]]}lr_{mpd[keys[3]]}dor_{mpd[keys[4]]}np_{mpd[keys[5]]}ro_{mpd[keys[6]]}bs_{mpd[keys[7]]}ill_{mpd[keys[8]]}MAE\"\n",
    "#all_counts.to_csv(f\"LB_sign_counts/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d7284c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exec    Network_Existing_Generation_FullNetwork_Line_I...\n",
       "BP                                                   8944\n",
       "BN                                                   3232\n",
       "OS                                                  11132\n",
       "OZ                                                   5084\n",
       "BZ                                                   2184\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f0063f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((lb_est > 0) & (lb_actual > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da47c4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((lb_est > 0) & (lb_actual > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d9ba14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.67787075e-05, 1.67414546e-05, 1.56611204e-05, ...,\n",
       "       1.58406794e-04, 1.11535192e-05, 1.40964985e-05], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lb_est > 0) & (lb_actual > 0)\n",
    "lb_est.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
