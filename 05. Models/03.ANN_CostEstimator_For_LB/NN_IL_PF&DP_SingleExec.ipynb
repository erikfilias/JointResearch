{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c381f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import DataLoading\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef99acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ext_out(folder,executions,period,sc,il_os = None):\n",
    "    dfs_in = dict()\n",
    "    dfs_out = dict()\n",
    "    dfs_inter = dict()\n",
    "    for execution in executions:\n",
    "        # Read the data from desired execution\n",
    "        df_in_e = pd.read_csv(f\"{folder}/input_f_{sc}_{execution}_{period}.csv\", header=[0],index_col=0)\n",
    "        df_out_e = pd.read_csv(f\"{folder}/output_f_{sc}_{execution}_{period}_SystemCosts.csv\", header=[0],index_col=0)\n",
    "        \n",
    "        print(f\"input_f_{sc}_{execution}_{period}.csv\")\n",
    "\n",
    "        # And order the variables:\n",
    "\n",
    "        print(len(df_in_e.columns))\n",
    "        for col in df_out_e.columns:\n",
    "            df_out_e[col] = df_out_e[col].astype(float)\n",
    "        for col in df_in_e.columns:\n",
    "            df_in_e[col] = df_in_e[col].astype(float)\n",
    "\n",
    "        \n",
    "        if il_os != None:\n",
    "            dfs_ilo = dict()\n",
    "            for il_o in il_os:\n",
    "                df_inter = pd.read_csv(f\"{folder}/output_f_{sc}_{execution}_{period}_{il_o}.csv\", header=[0],index_col=0)\n",
    "                for col in df_inter.columns:\n",
    "                    df_inter[col] = df_inter[col].astype(float)\n",
    "                dfs_ilo[il_o]=df_inter\n",
    "            dfs_inter[execution] = dfs_ilo\n",
    "        \n",
    "        dfs_in[execution] = df_in_e\n",
    "        dfs_out[execution] = df_out_e\n",
    "        \n",
    "    return dfs_in,dfs_out,dfs_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fef97f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tr_val_te_ext_out(dfs_in,dfs_out,dfs_inter_j,executions,te_s,val_s):\n",
    "    ts_in = dict()\n",
    "    ts_out = dict()\n",
    "    ts_inter = dict()\n",
    "\n",
    "    ts_in[\"train\"] = dict()\n",
    "    ts_in[\"test\"] = dict()\n",
    "    ts_in[\"val\"] = dict()\n",
    "\n",
    "    ts_out[\"train\"] = dict()\n",
    "    ts_out[\"test\"] = dict()\n",
    "    ts_out[\"val\"] = dict()\n",
    "    \n",
    "    ts_inter[\"train\"] = dict()\n",
    "    ts_inter[\"test\"] = dict()\n",
    "    ts_inter[\"val\"] = dict()\n",
    "\n",
    "    # Test size as fraction of full dataset, validation size as fraction of training data set\n",
    "    test_size, validation_size = te_s, val_s\n",
    "    \n",
    "    for execution in executions:\n",
    "        \n",
    "        # Convert input dataframes numpy arrays sum the columns of the output:\n",
    "        np_in = dfs_in[execution].to_numpy()\n",
    "        np_out = dfs_out[execution].to_numpy().sum(axis=1)\n",
    "        np_inter = dfs_inter_j[execution].to_numpy()        \n",
    "                                  \n",
    "        # We don't normalize the separate runs, but will do it afterward, all together\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        t_in = torch.from_numpy(np_in)\n",
    "        t_out = torch.from_numpy(np_out)\n",
    "        t_inter = torch.from_numpy(np_inter)\n",
    "\n",
    "        # And split into train, validation, and test set:\n",
    "        train_in, ts_in[\"test\"][execution], train_out, ts_out[\"test\"][execution],train_inter,ts_inter[\"test\"][execution] = train_test_split(t_in, t_out,t_inter,\n",
    "                                                                                                    test_size=test_size,\n",
    "                                                                                                    shuffle=False)\n",
    "        ts_in[\"train\"][execution], ts_in[\"val\"][execution], ts_out[\"train\"][execution], ts_out[\"val\"][\n",
    "            execution],ts_inter[\"train\"][execution], ts_inter[\"val\"][\n",
    "            execution] = train_test_split(train_in, train_out,train_inter, test_size=validation_size, shuffle=False)\n",
    "    return ts_in,ts_out,ts_inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b567749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_and_normalize_ext_out(ts_in,ts_out,ts_inter,executions):\n",
    "    # concatenate all the training and testing sets to a single tensor, and normalize:\n",
    "    first = True\n",
    "    for execution in executions:\n",
    "        if first:\n",
    "            tr_in = ts_in[\"train\"][execution]\n",
    "            tr_out = ts_out[\"train\"][execution]\n",
    "            tr_inter = ts_inter[\"train\"][execution]\n",
    "            \n",
    "            te_in = ts_in[\"test\"][execution]\n",
    "            te_out = ts_out[\"test\"][execution]\n",
    "            te_inter = ts_inter[\"test\"][execution]\n",
    "            \n",
    "            val_in = ts_in[\"val\"][execution]\n",
    "            val_out = ts_out[\"val\"][execution]\n",
    "            val_inter = ts_inter[\"val\"][execution]\n",
    "            first = False\n",
    "        else:\n",
    "            tr_in = torch.cat((tr_in, ts_in[\"train\"][execution]))\n",
    "            tr_out = torch.cat((tr_out, ts_out[\"train\"][execution]))\n",
    "            tr_inter = torch.cat((tr_inter, ts_inter[\"train\"][execution]))\n",
    "\n",
    "            \n",
    "            te_in = torch.cat((te_in, ts_in[\"test\"][execution]))\n",
    "            te_out = torch.cat((te_out, ts_out[\"test\"][execution]))\n",
    "            te_inter = torch.cat((te_inter, ts_inter[\"test\"][execution]))\n",
    "            \n",
    "            val_in = torch.cat((val_in, ts_in[\"val\"][execution]))\n",
    "            val_out = torch.cat((val_out, ts_out[\"val\"][execution]))\n",
    "            val_inter = torch.cat((val_inter, ts_inter[\"val\"][execution]))\n",
    "            \n",
    "    maxs=dict()\n",
    "    maxs[\"in\"] = torch.cat((tr_in, te_in, val_in)).abs().max(dim=0).values\n",
    "    maxs[\"inter\"] = torch.cat((tr_inter, te_inter, val_inter)).abs().max(dim=0).values\n",
    "    # maxs_te = te_in.abs().max(dim = 0).values\n",
    "    \n",
    "    tr_in = torch.nan_to_num(tr_in / maxs[\"in\"])\n",
    "    te_in = torch.nan_to_num(te_in / maxs[\"in\"])\n",
    "    val_in = torch.nan_to_num(val_in / maxs[\"in\"])\n",
    "    \n",
    "    tr_inter = torch.nan_to_num(tr_inter / maxs[\"inter\"])\n",
    "    te_inter = torch.nan_to_num(te_inter / maxs[\"inter\"])\n",
    "    val_inter = torch.nan_to_num(val_inter / maxs[\"inter\"])\n",
    "\n",
    "    d_ft_in = {\"train\": tr_in,\"val\": val_in,\"test\": te_in}\n",
    "    d_ft_out = {\"train\": tr_out,\"val\": val_out,\"test\": te_out}\n",
    "    d_ft_inter = {\"train\": tr_inter,\"val\": val_inter,\"test\": te_inter}\n",
    "\n",
    "\n",
    "    return d_ft_in,d_ft_out,d_ft_inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a999d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_frames_inter_layer(dfs_inter):\n",
    "    dfs_inter_j = dict()\n",
    "    for execution in dfs_inter.keys(): \n",
    "        dfs_inter_j[execution] = pd.concat([dfs_inter[execution][t] for t in dfs_inter[execution].keys()],axis=1)\n",
    "    return dfs_inter_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f175619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectiveEstimator_ANN_1hidden_layer_inter(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_ratio=0.0,relu_out = False ):\n",
    "        super().__init__()\n",
    "        hidden_size1 = hidden_sizes[0]\n",
    "        print(hidden_size1)\n",
    "        print(output_size)\n",
    "        self.hidden_layer1 = torch.nn.Linear(input_size, hidden_size1)\n",
    "        self.dropout = torch.nn.Dropout(dropout_ratio)\n",
    "        self.output_layer = torch.nn.Linear(hidden_size1, output_size)\n",
    "        self.relu_out = relu_out\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden1 = torch.relu(self.hidden_layer1(input))\n",
    "        hidden1_dropout = self.dropout(hidden1)\n",
    "        if (self.relu_out):\n",
    "            output = torch.relu(self.output_layer(hidden1_dropout))\n",
    "        else:\n",
    "            output = self.output_layer(hidden1_dropout)\n",
    "        return output,hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d42da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_loss(output, target_output, hidden_layer_representation, target_hidden, alpha=1.0):\n",
    "    # Compute the standard loss (e.g., mean squared error) for the output layer\n",
    "    standard_loss = F.mse_loss(output, target_output)\n",
    "\n",
    "    # Compute a loss term based on the hidden layer representation and its target\n",
    "    hidden_loss = F.mse_loss(hidden_layer_representation, target_hidden)\n",
    "\n",
    "    # Combine the two loss terms with a weighting factor alpha\n",
    "    total_loss = standard_loss + alpha * hidden_loss\n",
    "\n",
    "    return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee4a9f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_f_sc01_Network_Existing_Generation_Full_2030.csv\n",
      "1203\n"
     ]
    }
   ],
   "source": [
    "executions = [\"Network_Existing_Generation_Full\"]\n",
    "\n",
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "folder = \"../Data/RTS24_AC_12w_ext_o\"\n",
    "te_s = 0.1\n",
    "val_s = 0.2\n",
    "\n",
    "dfs_in,dfs_out,dfs_inter = load_data_ext_out(folder,executions,period,sc,[\"PowerOutput\",\"PowerFlow\"])\n",
    "dfs_inter_j = join_frames_inter_layer(dfs_inter)\n",
    "ts_in,ts_out,ts_inter = split_tr_val_te_ext_out(dfs_in,dfs_out,dfs_inter_j,executions,te_s,val_s)\n",
    "d_ft_in, d_ft_out,d_ft_inter = concat_and_normalize_ext_out(ts_in,ts_out,ts_inter,executions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3bac4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(d_ft_in['train'].float(), d_ft_out['train'].float(),d_ft_inter['train'])\n",
    "validation = TensorDataset(d_ft_in['val'].float(), d_ft_out['val'].float(),d_ft_inter['val'].float())\n",
    "\n",
    "training_loader = DataLoader(train,batch_size=32)\n",
    "validation_loader = DataLoader(validation,batch_size=32)\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001\n",
    "inp_size = train.tensors[0].shape[1]\n",
    "inter_size = train.tensors[2].shape[1]\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cadba332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2399abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "1\n",
      "tensor([[-0.0169],\n",
      "        [-0.0169],\n",
      "        [-0.0166],\n",
      "        [-0.0159],\n",
      "        [-0.0137],\n",
      "        [-0.0106],\n",
      "        [-0.0093],\n",
      "        [-0.0073],\n",
      "        [-0.0094],\n",
      "        [-0.0104],\n",
      "        [-0.0099],\n",
      "        [-0.0096],\n",
      "        [-0.0104],\n",
      "        [-0.0117],\n",
      "        [-0.0115],\n",
      "        [-0.0121],\n",
      "        [-0.0130],\n",
      "        [-0.0104],\n",
      "        [-0.0107],\n",
      "        [-0.0112],\n",
      "        [-0.0121],\n",
      "        [-0.0141],\n",
      "        [-0.0159],\n",
      "        [-0.0168],\n",
      "        [-0.0172],\n",
      "        [-0.0173],\n",
      "        [-0.0171],\n",
      "        [-0.0164],\n",
      "        [-0.0145],\n",
      "        [-0.0120],\n",
      "        [-0.0109],\n",
      "        [-0.0097]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0000, 0.5571, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5571, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5569, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.5539, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5530, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5125, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor(145.9290, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0138303\\AppData\\Local\\Temp\\ipykernel_12432\\2393041748.py:5: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  standard_loss = F.mse_loss(output, target_output)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets, hidden_representation, target_hidden)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Workdir\\Programs\\Miniconda\\envs\\jr23\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "criterion = custom_loss  # Use your custom loss function\n",
    "\n",
    "model = ObjectiveEstimator_ANN_1hidden_layer_inter(inp_size,[inter_size],output_size)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets, target_hidden in training_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, hidden_representation = model(inputs)\n",
    "        print(outputs)\n",
    "        print(hidden_representation)\n",
    "        loss = criterion(outputs, targets, hidden_representation, target_hidden)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef658478",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in,ts_out =  DataLoading.split_tr_val_te(dfs_in,dfs_out,executions,te_s,val_s)\n",
    "ts_in_2,ts_out_2,ts_inter = split_tr_val_te_ext_out(dfs_in,dfs_out,dfs_inter_j,executions,te_s,val_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00cbdc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train in True\n",
      "train out True\n",
      "test in True\n",
      "test out True\n",
      "val in True\n",
      "val out True\n"
     ]
    }
   ],
   "source": [
    "key = \"val\"\n",
    "key2 = \"Network_Existing_Generation_Full\"\n",
    "for key in [\"train\", \"test\",\"val\"]:\n",
    "    print(key,\"in\", torch.equal(ts_in[key][key2],ts_in_2[key][key2]))\n",
    "    print(key,\"out\", torch.equal(ts_out[key][key2],ts_out_2[key][key2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb894896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1572, 89]), torch.Size([1572]), torch.Size([1572, 1203]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_inter[\"train\"][\"Network_Existing_Generation_Full\"].shape,ts_out[\"train\"][\"Network_Existing_Generation_Full\"].shape,ts_in[\"train\"][\"Network_Existing_Generation_Full\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7610bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Network_Existing_Generation_Full'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_in[\"train\"].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
