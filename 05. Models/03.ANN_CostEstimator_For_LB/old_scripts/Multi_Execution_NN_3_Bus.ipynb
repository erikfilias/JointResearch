{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110ea70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import torch\n",
    "#from torchviz import make_dot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import NN_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737f0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "executions = [\"Network_Full_Generation_Full\",\"Network_Line_Out_Node_1_Node_2_cac1\"]\n",
    "sc = \"sc01\"\n",
    "period = \"2030\"\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/input_f_sc01_Network_Full_Generation_Full_2030.csv\n",
      "23\n",
      "Data/input_f_sc01_Network_Line_Out_Node_1_Node_2_cac1_2030.csv\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "dfs_in = dict()\n",
    "dfs_out = dict()\n",
    "for execution in executions:\n",
    "    #Read the data from desired execution\n",
    "    df_in_e = pd.read_csv(f\"Data/input_f_{sc}_{execution}_{period}.csv\",header=[0,1])\n",
    "    df_out_e = pd.read_csv(f\"Data/output_f_{sc}_{execution}_{period}.csv\",header=[0,1])\n",
    "\n",
    "    #Drop the first row because its useless \n",
    "    df_in_e = df_in_e.drop([0])\n",
    "    df_out_e = df_out_e.drop([0])\n",
    "    print(f\"Data/input_f_{sc}_{execution}_{period}.csv\")\n",
    "    \n",
    "\n",
    "    #Focus for now only on the real part of the input data: \n",
    "    df_in_e_r = df_in_e[\"Value_R\"]\n",
    "    #df_in_e_i = df_in_e[\"Value_I\"].loc[:, (df_in_e[\"Value_I\"] != 0).any(axis=0)]\n",
    "    df_in_e_i = df_in_e[\"Value_I\"].drop([\"Node_1\", \"Node_2\",\"Node_3\",\"SolarPV_1\",\"WindFarm_1\"],axis=1)\n",
    "    \n",
    "    print(len(df_in_e_r.columns)+ len(df_in_e_i.columns))\n",
    "    \n",
    "    df_in_e_c = pd.concat([df_in_e_r,df_in_e_i],axis=1)\n",
    "    df_out_e = df_out_e[\"Value\"]\n",
    "    dfs_in[execution] = df_in_e_c\n",
    "    dfs_out[execution] = df_out_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d42180ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in  = dict()\n",
    "ts_out = dict()\n",
    "\n",
    "ts_in[\"train\"] = dict()\n",
    "ts_in[\"test\"]  = dict()\n",
    "ts_out[\"train\"]= dict()\n",
    "ts_out[\"test\"] = dict()\n",
    "\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "for execution in executions: \n",
    "    #Convert input dataframes numpy arrays sum the columns of the output: \n",
    "    np_in = dfs_in[execution].to_numpy()\n",
    "    #We don't normalize the separate runs, but will do it afterward, all together\n",
    "    #np_in = np_in/np.abs(np_in.max(axis=0))\n",
    "    #np_in = np.nan_to_num(np_in,nan = 0)\n",
    "    np_out = dfs_out[execution].to_numpy().sum(axis=1)\n",
    "\n",
    "    #Convert to torch tensors\n",
    "    t_in = torch.from_numpy(np_in)\n",
    "    t_out = torch.from_numpy(np_out)\n",
    "\n",
    "    #And split into train and test set:\n",
    "    ts_in[\"train\"][execution],ts_in[\"test\"][execution],ts_out[\"train\"][execution],ts_out[\"test\"][execution]= train_test_split(t_in,t_out,test_size=test_size,shuffle=False)\n",
    "#     train_size = 0.8\n",
    "#     nb_train = int(train_size*len(t_out))\n",
    "#     tr_in,te_in = t_in[:nb_train],t_in[nb_train:]\n",
    "#     tr_out,te_out = t_out[:nb_train],t_out[nb_train:]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f3ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all the training and testing sets to a single tensor, and normalize: \n",
    "first = True\n",
    "for execution in executions:\n",
    "    if first: \n",
    "        tr_in = ts_in[\"train\"][execution]\n",
    "        tr_out = ts_out[\"train\"][execution]\n",
    "        te_in = ts_in[\"test\"][execution]\n",
    "        te_out = ts_out[\"test\"][execution]\n",
    "    else: \n",
    "        torch.cat(tr_in,ts_in[\"train\"][execution])\n",
    "        torch.cat(tr_out,ts_out[\"train\"][execution])\n",
    "        torch.cat(te_in,ts_in[\"test\"][execution])\n",
    "        torch.cat(te_out,ts_out[\"test\"][execution])\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ff2e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0335, 0.9794, 0.0000, 0.9794, 0.0606, 0.0000, 0.0000, 0.0000, 0.1842,\n",
       "        0.9794, 0.0000, 0.9794, 0.0468, 0.1000, 0.1420, 0.0000, 0.1420, 0.0000,\n",
       "        0.0000, 0.0000, 0.1420, 0.0000, 0.1420], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_in.abs().max(dim = 0).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
